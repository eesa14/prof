[
    {
        "pregunta": "1.-Una empresa necesita diseñar una solución de DNS híbrida. Esta solución utilizará una zona alojada privada de Amazon Route 53 para el dominio cloud.example.com para los recursos almacenados dentro de las VPC. La empresa tiene los siguientes requisitos de resolución de DNS: Los sistemas on-premises deben poder resolver y conectarse a cloud.example.com. Todas las VPCs deben poder resolver cloud.example.com. Ya existe una conexión AWS Direct Connect entre la red corporativa on-premises y AWS Transit Gateway. ¿Qué arquitectura debe utilizar la empresa para cumplir con estos requisitos con el MEJOR rendimiento?",
        "opciones": [
            "A. Asociar la zona alojada privada a todas las VPCs. Crear un resolver de entrada (inbound resolver) de Route 53 en la VPC de servicios compartidos. Adjuntar todas las VPCs al transit gateway y crear reglas de reenvío en el servidor DNS on-premises para cloud.example.com que apunten al inbound resolver.",
            "B. Asociar la zona alojada privada a todas las VPCs. Implementar un reenviador condicional (conditional forwarder) en Amazon EC2 en la VPC de servicios compartidos. Adjuntar todas las VPCs al transit gateway y crear reglas de reenvío en el servidor DNS on-premises para cloud.example.com que apunten al reenviador condicional.",
            "C. Asociar la zona alojada privada a la VPC de servicios compartidos. Crear un resolver de salida (outbound resolver) de Route 53 en la VPC de servicios compartidos. Adjuntar todas las VPCs al transit gateway y crear reglas de reenvío en el servidor DNS on-premises para cloud.example.com que apunten al outbound resolver.",
            "D. Asociar la zona alojada privada a la VPC de servicios compartidos. Crear un resolver de entrada (inbound resolver) de Route 53 en la VPC de servicios compartidos. Adjuntar la VPC de servicios compartidos al transit gateway y crear reglas de reenvío en el servidor DNS on-premises para cloud.example.com que apunten al inbound resolver."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "2.- Una empresa proporciona datos meteorológicos a través de una API basada en REST a varios clientes. La API está alojada en Amazon API Gateway e integrada con diferentes funciones de AWS Lambda para cada operación de la API. La empresa usa Amazon Route 53 para DNS y ha creado un registro de recursos para weather.example.com. Los datos de la API se almacenan en tablas de Amazon DynamoDB. La empresa necesita una solución de conmutación por error para que la API pueda operar en otra región de AWS en caso de falla. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Implementar un nuevo conjunto de funciones Lambda en una nueva Región. Actualizar la API en API Gateway para utilizar un endpoint optimizado para el borde con funciones Lambda de ambas regiones como objetivos. Convertir las tablas de DynamoDB en tablas globales.",
            "B. Implementar una nueva API Gateway API y funciones Lambda en otra Región. Cambiar el registro DNS de Route 53 a un registro de respuesta multivalor. Agregar ambas API Gateway al registro de respuesta. Habilitar monitoreo de salud del destino. Convertir las tablas de DynamoDB en tablas globales.",
            "C. Implementar una nueva API Gateway API y funciones Lambda en otra Región. Cambiar el registro DNS de Route 53 a un registro de conmutación por error. Habilitar monitoreo de salud del destino. Convertir las tablas de DynamoDB en tablas globales.",
            "D. Implementar una nueva API Gateway API en una nueva Región. Cambiar las funciones Lambda a funciones globales. Cambiar el registro DNS de Route 53 a un registro de respuesta multivalor. Agregar ambas API Gateway al registro de respuesta. Habilitar monitoreo de salud del destino. Convertir las tablas de DynamoDB en tablas globales."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "3.- Una empresa utiliza AWS Organizations con una única Unidad Organizativa (OU) llamada Producción para administrar varias cuentas. Todas las cuentas son miembros de la OU de Producción. Los administradores utilizan SCPs de lista de denegación en la raíz de la organización para gestionar el acceso a servicios restringidos. Recientemente, la empresa adquirió una nueva unidad de negocio e invitó a la cuenta existente de la nueva unidad a unirse a la organización. Una vez integrada, los administradores de la nueva unidad de negocio descubrieron que no pueden actualizar las reglas existentes de AWS Config para cumplir con las políticas de la empresa. ¿Qué opción permitirá a los administradores realizar cambios y continuar aplicando las políticas actuales sin introducir un mantenimiento adicional a largo plazo?",
        "opciones": [
            "A. Eliminar las SCPs en la raíz de la organización que limitan el acceso a AWS Config. Crear productos en AWS Service Catalog para las reglas estándar de AWS Config de la empresa y desplegarlas en toda la organización, incluida la nueva cuenta.",
            "B. Crear una OU temporal llamada Onboarding para la nueva cuenta. Aplicar una SCP a la OU de Onboarding para permitir acciones de AWS Config. Mover la nueva cuenta a la OU de Producción cuando los ajustes en AWS Config estén completos.",
            "C. Convertir las SCPs de lista de denegación en la raíz de la organización en SCPs de lista de permitidos, de modo que solo se permitan los servicios requeridos. Aplicar temporalmente una SCP en la raíz de la organización que permita acciones de AWS Config solo para los principales en la nueva cuenta.",
            "D. Crear una OU temporal llamada Onboarding para la nueva cuenta. Aplicar una SCP a la OU de Onboarding para permitir acciones de AWS Config. Mover la SCP raíz de la organización a la OU de Producción. Mover la nueva cuenta a la OU de Producción cuando los ajustes en AWS Config estén completos."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "4.- Una empresa ejecuta una aplicación web de dos niveles en un centro de datos on-premises. La capa de aplicación consiste en un único servidor que ejecuta una aplicación stateful. La aplicación se conecta a una base de datos PostgreSQL que se ejecuta en un servidor separado. Se espera que la base de usuarios de la aplicación crezca significativamente, por lo que la empresa está migrando la aplicación y la base de datos a AWS. La solución utilizará Amazon Aurora PostgreSQL, Amazon EC2 Auto Scaling y Elastic Load Balancing. ¿Qué solución proporcionará una experiencia de usuario consistente y permitirá que las capas de aplicación y base de datos escalen?",
        "opciones": [
            "A. Habilitar Aurora Auto Scaling para réplicas de Aurora. Usar un Network Load Balancer (NLB) con el algoritmo de enrutamiento least outstanding requests y sesiones persistentes (sticky sessions) habilitadas.",
            "B. Habilitar Aurora Auto Scaling para escritores de Aurora. Usar un Application Load Balancer (ALB) con el algoritmo de enrutamiento round robin y sesiones persistentes (sticky sessions) habilitadas.",
            "C. Habilitar Aurora Auto Scaling para réplicas de Aurora. Usar un Application Load Balancer (ALB) con el algoritmo de enrutamiento round robin y sesiones persistentes (sticky sessions) habilitadas.",
            "D. Habilitar Aurora Auto Scaling para escritores de Aurora. Usar un Network Load Balancer (NLB) con el algoritmo de enrutamiento least outstanding requests y sesiones persistentes (sticky sessions) habilitadas."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "5.- Una empresa utiliza un servicio para recopilar metadatos de aplicaciones que aloja on-premises. Dispositivos de consumo como TVs y radios por internet acceden a las aplicaciones. Muchos dispositivos antiguos no son compatibles con ciertos encabezados HTTP y muestran errores cuando estos encabezados están presentes en las respuestas. La empresa ha configurado un balanceador de carga on-premises para eliminar los encabezados no compatibles de las respuestas enviadas a los dispositivos más antiguos, identificándolos mediante el encabezado User-Agent. La empresa quiere migrar el servicio a AWS, adoptar tecnologías serverless y mantener la capacidad de admitir los dispositivos antiguos.\nYa ha migrado las aplicaciones a un conjunto de funciones AWS Lambda. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Crear una distribución de Amazon CloudFront para el servicio de metadatos. Crear un Application Load Balancer (ALB). Configurar CloudFront para reenviar solicitudes al ALB. Configurar el ALB para invocar la función Lambda correcta según el tipo de solicitud. Crear una CloudFront function para eliminar los encabezados problemáticos basándose en el valor del encabezado User-Agent.",
            "B. Crear una API REST de Amazon API Gateway para el servicio de metadatos. Configurar API Gateway para invocar la función Lambda correcta según el tipo de solicitud. Modificar las respuestas predeterminadas de API Gateway para eliminar los encabezados problemáticos según el valor del encabezado User-Agent.",
            "C. Crear una API HTTP de Amazon API Gateway para el servicio de metadatos. Configurar API Gateway para invocar la función Lambda correcta según el tipo de solicitud. Crear una plantilla de mapeo de respuesta para eliminar los encabezados problemáticos según el valor del User-Agent. Asociar la plantilla de mapeo de respuesta con la API HTTP.",
            "D. Crear una distribución de Amazon CloudFront para el servicio de metadatos. Crear un Application Load Balancer (ALB). Configurar CloudFront para reenviar solicitudes al ALB. Configurar el ALB para invocar la función Lambda correcta según el tipo de solicitud. Crear una función Lambda@Edge que elimine los encabezados problemáticos en respuesta a las solicitudes de los usuarios, basándose en el valor del User-Agent."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "6.- Una empresa minorista necesita proporcionar una serie de archivos de datos a otra empresa, que es su socio comercial. Estos archivos están guardados en un bucket de Amazon S3 bajo la Cuenta A, que pertenece a la empresa minorista. La empresa socio comercial quiere que uno de sus usuarios IAM, User_DataProcessor, acceda a los archivos desde su propia cuenta de AWS (Cuenta B). ¿Qué combinación de pasos deben seguir las empresas para que User_DataProcessor pueda acceder al bucket S3 con éxito? (Elige dos.)",
        "opciones": [
            "A. Activar la función de intercambio de recursos de origen cruzado (CORS) para el bucket S3 en la Cuenta A.",
            "B. En la Cuenta A, configurar la política del bucket S3 de la siguiente manera:",
            "C. En la Cuenta A, configurar la política del bucket S3 de la siguiente manera:",
            "D. En la Cuenta B, configurar los permisos de User_DataProcessor de la siguiente manera:",
            "E. En la Cuenta B, configurar los permisos de User_DataProcessor de la siguiente manera:"
        ],
        "respuestas_correctas": [
            "D",
            "C"
        ],
        "imagenes": [ {
            "respuesta": "B",
            "url": "images/image6-1.png"
        },
        {
            "respuesta": "C",
            "url": "images/image6-2.png"
        },
        {
            "respuesta": "D",
            "url": "images/image6-3.png"
        },
        {
            "respuesta": "E",
            "url": "images/image6-4.png"
        }]
    },
    {
        "pregunta": "7.- Una empresa está ejecutando una aplicación web tradicional en instancias de Amazon EC2. La empresa necesita refactorizar la aplicación como microservicios que se ejecuten en contenedores. Existen versiones separadas de la aplicación en dos entornos distintos: producción y pruebas. La carga de la aplicación es variable, pero se conocen la carga mínima y la carga máxima. Un arquitecto de soluciones necesita diseñar la aplicación actualizada con una arquitectura sin servidores que minimice la complejidad operativa. ¿Qué solución cumplirá estos requisitos de manera MÁS rentable?",
        "opciones": [
            "A. Subir las imágenes de los contenedores a AWS Lambda como funciones. Configurar un límite de concurrencia para las funciones Lambda asociadas para manejar la carga máxima esperada. Configurar dos integraciones Lambda separadas dentro de Amazon API Gateway: una para producción y otra para pruebas.",
            "B. Subir las imágenes de los contenedores a Amazon Elastic Container Registry (Amazon ECR). Configurar dos clústeres de Amazon Elastic Container Service (Amazon ECS) con el tipo de lanzamiento Fargate para manejar la carga esperada. Desplegar tareas desde las imágenes de ECR. Configurar dos Application Load Balancers separados para dirigir el tráfico a los clústeres ECS.",
            "C. Subir las imágenes de los contenedores a Amazon Elastic Container Registry (Amazon ECR). Configurar dos clústeres autoescalados de Amazon Elastic Kubernetes Service (Amazon EKS) con el tipo de lanzamiento Fargate para manejar la carga esperada. Desplegar tareas desde las imágenes de ECR. Configurar dos Application Load Balancers separados para dirigir el tráfico a los clústeres EKS.",
            "D. Subir las imágenes de los contenedores a AWS Elastic Beanstalk. En Elastic Beanstalk, crear entornos y despliegues separados para producción y pruebas. Configurar dos Application Load Balancers separados para dirigir el tráfico a los despliegues de Elastic Beanstalk."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "8.- Una empresa tiene una aplicación web de múltiples capas que se ejecuta en una flota de instancias de Amazon EC2 detrás de un Application Load Balancer (ALB). Las instancias están en un grupo de Auto Scaling. El ALB y el grupo de Auto Scaling están replicados en una región de respaldo de AWS. El valor mínimo y el valor máximo para el grupo de Auto Scaling están establecidos en cero. Una instancia de base de datos Amazon RDS Multi-AZ almacena los datos de la aplicación. La instancia de la base de datos tiene una réplica de lectura en la región de respaldo. La aplicación presenta un punto de enlace a los usuarios finales mediante un registro de Amazon Route 53. La empresa necesita reducir su RTO a menos de 15 minutos dándole a la aplicación la capacidad de fallar automáticamente hacia la región de respaldo. La empresa no tiene un presupuesto lo suficientemente grande para una estrategia activa-activa. ¿Qué debería recomendar un arquitecto de soluciones para cumplir con estos requisitos?",
        "opciones": [
            "A. Reconfigurar el registro de Route 53 de la aplicación con una política de enrutamiento basada en latencia que balancee la carga entre los dos ALBs. Crear una función de AWS Lambda en la región de respaldo para promover la réplica de lectura y modificar los valores del grupo de Auto Scaling. Crear una alarma de Amazon CloudWatch basada en la métrica HTTPCode_Target_5XX_Count para el ALB en la región primaria. Configurar la alarma de CloudWatch para invocar la función Lambda.",
            "B. Crear una función de AWS Lambda en la región de respaldo para promover la réplica de lectura y modificar los valores del grupo de Auto Scaling. Configurar Route 53 con una verificación de estado que supervise la aplicación web y envíe una notificación de Amazon Simple Notification Service (Amazon SNS) a la función Lambda cuando el estado de la verificación de estado sea no saludable. Actualizar el registro de Route 53 de la aplicación con una política de failover que enrute el tráfico al ALB en la región de respaldo cuando ocurra una falla de la verificación de estado.",
            "C. Configurar el grupo de Auto Scaling en la región de respaldo para que tenga los mismos valores que el grupo de Auto Scaling en la región primaria. Reconfigurar el registro de Route 53 de la aplicación con una política de enrutamiento basada en latencia que balancee la carga entre los dos ALBs. Eliminar la réplica de lectura. Reemplazar la réplica de lectura con una instancia de base de datos RDS independiente. Configurar la replicación entre regiones entre las instancias de base de datos RDS mediante instantáneas y Amazon S3.",
            "D. Configurar un punto de enlace en AWS Global Accelerator con los dos ALBs como objetivos de peso igual. Crear una función de AWS Lambda en la región de respaldo para promover la réplica de lectura y modificar los valores del grupo de Auto Scaling. Crear una alarma de Amazon CloudWatch basada en la métrica HTTPCode_Target_5XX_Count para el ALB en la región primaria. Configurar la alarma de CloudWatch para invocar la función Lambda."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "9.- Una empresa está alojando una aplicación crítica en una única instancia de Amazon EC2. La aplicación utiliza un clúster de un solo nodo de Amazon ElastiCache para Redis como almacenamiento de datos en memoria. La aplicación utiliza una instancia de base de datos Amazon RDS para MariaDB como base de datos relacional. Para que la aplicación funcione, cada parte de la infraestructura debe estar saludable y debe estar en un estado activo. Un arquitecto de soluciones necesita mejorar la arquitectura de la aplicación para que la infraestructura pueda recuperarse automáticamente de fallos con el menor tiempo de inactividad posible. ¿Qué combinación de pasos cumplirá estos requisitos? (Elige tres.)",
        "opciones": [
            "A. Utilizar un Elastic Load Balancer para distribuir el tráfico entre varias instancias EC2. Asegurar que las instancias EC2 sean parte de un grupo de Auto Scaling que tenga una capacidad mínima de dos instancias.",
            "B. Utilizar un Elastic Load Balancer para distribuir el tráfico entre varias instancias EC2. Asegurar que las instancias EC2 estén configuradas en modo ilimitado.",
            "C. Modificar la instancia de base de datos para crear una réplica de lectura en la misma zona de disponibilidad. Promover la réplica de lectura a la instancia principal en escenarios de fallo.",
            "D. Modificar la instancia de base de datos para crear una implementación Multi-AZ que se extienda a través de dos zonas de disponibilidad.",
            "E. Crear un grupo de replicación para el clúster de ElastiCache para Redis. Configurar el clúster para usar un grupo de Auto Scaling que tenga una capacidad mínima de dos instancias.",
            "F. Crear un grupo de replicación para el clúster de ElastiCache para Redis. Habilitar Multi-AZ en el clúster."
        ],
        "respuestas_correctas": [
            "F",
            "D",
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "10.- Una empresa minorista está operando su aplicación de comercio electrónico en AWS. La aplicación se ejecuta en instancias de Amazon EC2 detrás de un Application Load Balancer (ALB). La empresa utiliza una instancia de base de datos Amazon RDS como la base de datos principal. Amazon CloudFront está configurado con un origen que apunta al ALB. El contenido estático se almacena en caché. Amazon Route 53 se utiliza para alojar todas las zonas públicas. Después de una actualización de la aplicación, el ALB ocasionalmente devuelve un código de estado 502 (Bad Gateway). La causa raíz es que los encabezados HTTP están mal formateados y se devuelven al ALB. La página web se carga correctamente cuando un arquitecto de soluciones recarga la página web inmediatamente después de que ocurre el error. Mientras la empresa trabaja en el problema, el arquitecto de soluciones necesita proporcionar una página de error personalizada en lugar de la página de error estándar de ALB a los visitantes. ¿Qué combinación de pasos cumplirá este requisito con la MENOR cantidad de sobrecarga operativa? (Elige dos.)",
        "opciones": [
            "A. Crear un bucket de Amazon S3. Configurar el bucket S3 para alojar una página web estática. Subir las páginas de error personalizadas a Amazon S3.",
            "B. Crear una alarma de Amazon CloudWatch para invocar una función de AWS Lambda si la respuesta de la verificación de estado del ALB Target.FailedHealthChecks es mayor que 0. Configurar la función Lambda para modificar la regla de reenvío en el ALB para que apunte a un servidor web accesible públicamente.",
            "C. Modificar los registros existentes de Amazon Route 53 agregando verificaciones de estado. Configurar un objetivo de respaldo si la verificación de estado falla. Modificar los registros DNS para que apunten a una página web accesible públicamente.",
            "D. Crear una alarma de Amazon CloudWatch para invocar una función de AWS Lambda si la respuesta de la verificación de estado del ALB Elb.InternalError es mayor que 0. Configurar la función Lambda para modificar la regla de reenvío en el ALB para que apunte a un servidor web accesible públicamente.",
            "E. Agregar una respuesta de error personalizada configurando una página de error personalizada en CloudFront. Modificar los registros DNS para que apunten a una página web accesible públicamente."
        ],
        "respuestas_correctas": [
            "E",
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "11.-Una empresa tiene muchas cuentas de AWS y utiliza AWS Organizations para administrar todas ellas. Un arquitecto de soluciones debe implementar una solución que la empresa pueda usar para compartir una red común entre varias cuentas. El equipo de infraestructura de la empresa tiene una cuenta dedicada de infraestructura que tiene un VPC. El equipo de infraestructura debe usar esta cuenta para administrar la red. Las cuentas individuales no pueden tener la capacidad de administrar sus propias redes. Sin embargo, las cuentas individuales deben poder crear recursos de AWS dentro de subredes. ¿Qué combinación de acciones debe realizar el arquitecto de soluciones para cumplir con estos requisitos? (Elige dos.)",
        "opciones": [
            "A. Crear un transit gateway en la cuenta de infraestructura.",
            "B. Habilitar el uso compartido de recursos desde la cuenta de administración de AWS Organizations.",
            "C. Crear VPCs en cada cuenta de AWS dentro de la organización en AWS Organizations. Configurar las VPCs para que compartan el mismo rango CIDR y las subredes que la VPC en la cuenta de infraestructura. Emparejar las VPCs de cada cuenta individual con la VPC en la cuenta de infraestructura.",
            "D. Crear un recurso compartido en AWS Resource Access Manager en la cuenta de infraestructura. Seleccionar la unidad organizacional específica de AWS Organizations que usará la red compartida. Seleccionar cada subred para asociarla con el recurso compartido.",
            "E. Crear un recurso compartido en AWS Resource Access Manager en la cuenta de infraestructura. Seleccionar la unidad organizacional específica de AWS Organizations que usará la red compartida. Seleccionar cada lista de prefijos para asociarla con el recurso compartido."
        ],
        "respuestas_correctas": [
            "D",
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "12.- Una empresa quiere usar una aplicación de software como servicio (SaaS) de un tercero. La aplicación SaaS de terceros se consume a través de varias llamadas API. La aplicación SaaS de terceros también se ejecuta en AWS dentro de un VPC. La empresa consumirá la aplicación SaaS de terceros desde dentro de un VPC. La empresa tiene políticas internas de seguridad que exigen el uso de conectividad privada que no atraviese Internet. No se permite que los recursos que se ejecutan en el VPC de la empresa sean accesibles desde fuera del VPC de la empresa. Todos los permisos deben cumplir con los principios de privilegio mínimo. ¿Qué solución cumple con estos requisitos?",
        "opciones": [
            "A. Crear un punto de enlace de interfaz AWS PrivateLink. Conectar este punto de enlace al servicio de punto de enlace que proporciona la aplicación SaaS de terceros. Crear un grupo de seguridad para limitar el acceso al punto de enlace. Asociar el grupo de seguridad con el punto de enlace.",
            "B. Crear una conexión VPN Site-to-Site entre la aplicación SaaS de terceros y el VPC de la empresa. Configurar ACLs de red para limitar el acceso a través de los túneles VPN.",
            "C. Crear una conexión de emparejamiento de VPC entre la aplicación SaaS de terceros y el VPC de la empresa. Actualizar las tablas de rutas agregando las rutas necesarias para la conexión de emparejamiento.",
            "D. Crear un servicio de punto de enlace AWS PrivateLink. Pedir al proveedor de la aplicación SaaS de terceros que cree un punto de enlace de interfaz VPC para este servicio de punto de enlace. Otorgar permisos para el servicio de punto de enlace a la cuenta específica del proveedor de la aplicación SaaS."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "13.- Una empresa necesita implementar un proceso de parcheo para sus servidores. Los servidores locales y las instancias de Amazon EC2 utilizan una variedad de herramientas para realizar el parcheo. La gerencia requiere un informe único que muestre el estado de los parches de todos los servidores e instancias. ¿Qué conjunto de acciones debe tomar un arquitecto de soluciones para cumplir con estos requisitos?",
        "opciones": [
            "A. Usar AWS Systems Manager para administrar los parches en los servidores locales e instancias EC2. Usar Systems Manager para generar informes de cumplimiento de parches.",
            "B. Usar AWS OpsWorks para administrar los parches en los servidores locales e instancias EC2. Usar la integración de Amazon QuickSight con OpsWorks para generar informes de cumplimiento de parches.",
            "C. Usar una regla de Amazon EventBridge para aplicar parches programando un trabajo de remediación de parches de AWS Systems Manager. Usar Amazon Inspector para generar informes de cumplimiento de parches.",
            "D. Usar AWS OpsWorks para administrar los parches en los servidores locales e instancias EC2. Usar AWS X-Ray para publicar el estado de los parches en AWS Systems Manager OpsCenter para generar informes de cumplimiento de parches."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "14.- Una empresa está ejecutando una aplicación en varias instancias de Amazon EC2 en un grupo de Auto Scaling detrás de un Application Load Balancer. La carga de la aplicación varía a lo largo del día, y las instancias EC2 se escalan hacia adentro y hacia afuera de manera regular. Los archivos de registro de las instancias EC2 se copian a un bucket central de Amazon S3 cada 15 minutos. El equipo de seguridad descubre que algunos archivos de registro están desaparecidos de algunas de las instancias EC2 terminadas. ¿Qué conjunto de acciones garantizará que los archivos de registro se copien al bucket S3 central desde las instancias EC2 terminadas?",
        "opciones": [
            "A. Crear un script para copiar los archivos de registro a Amazon S3 y almacenar el script en un archivo en la instancia EC2. Crear un gancho de ciclo de vida de Auto Scaling y una regla de Amazon EventBridge para detectar eventos de ciclo de vida del grupo de Auto Scaling. Invocar una función de AWS Lambda en la transición autoscaling:EC2_INSTANCE_TERMINATING para enviar ABANDON al grupo de Auto Scaling para evitar la terminación, ejecutar el script para copiar los archivos de registro y terminar la instancia usando el AWS SDK.",
            "B. Crear un documento de AWS Systems Manager con un script para copiar los archivos de registro a Amazon S3. Crear un gancho de ciclo de vida de Auto Scaling y una regla de Amazon EventBridge para detectar eventos de ciclo de vida del grupo de Auto Scaling. Invocar una función de AWS Lambda en la transición autoscaling:EC2_INSTANCE_TERMINATING para llamar a la operación API SendCommand de AWS Systems Manager para ejecutar el documento para copiar los archivos de registro y enviar CONTINUE al grupo de Auto Scaling para terminar la instancia.",
            "C. Cambiar la tasa de entrega de registros a cada 5 minutos. Crear un script para copiar los archivos de registro a Amazon S3 y agregar el script a los datos de usuario de la instancia EC2. Crear una regla de Amazon EventBridge para detectar la terminación de la instancia EC2. Invocar una función de AWS Lambda desde la regla de EventBridge que use el AWS CLI para ejecutar el script de datos de usuario para copiar los archivos de registro y terminar la instancia.",
            "D. Crear un documento de AWS Systems Manager con un script para copiar los archivos de registro a Amazon S3. Crear un gancho de ciclo de vida de Auto Scaling que publique un mensaje en un tema de Amazon Simple Notification Service (Amazon SNS). Desde la notificación SNS, llamar a la operación API SendCommand de AWS Systems Manager para ejecutar el documento para copiar los archivos de registro y enviar ABANDON al grupo de Auto Scaling para terminar la instancia."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "15.-Una empresa está utilizando varias cuentas de AWS. Los registros DNS se almacenan en una zona alojada privada para Amazon Route 53 en la Cuenta A. Las aplicaciones y bases de datos de la empresa se están ejecutando en la Cuenta B. Un arquitecto de soluciones implementará una aplicación de dos niveles en una nueva VPC. Para simplificar la configuración, se creó el conjunto de registros CNAME para db.example.com con el punto de enlace de Amazon RDS en una zona alojada privada para Amazon Route 53. Durante la implementación, la aplicación no pudo iniciarse. La solución de problemas reveló que db.example.com no es resolvible en la instancia de Amazon EC2. El arquitecto de soluciones confirmó que el conjunto de registros se creó correctamente en Route 53. ¿Qué combinación de pasos debe seguir el arquitecto de soluciones para resolver este problema? (Elija dos.)",
        "opciones": [
            "A. Implementar la base de datos en una instancia EC2 separada en la nueva VPC. Crear un conjunto de registros para la IP privada de la instancia en la zona alojada privada.",
            "B. Usar SSH para conectarse a la instancia EC2 de la capa de la aplicación. Agregar una dirección IP del punto de enlace de RDS al archivo /etc/resolv.conf.",
            "C. Crear una autorización para asociar la zona alojada privada en la Cuenta A con la nueva VPC en la Cuenta B.",
            "D. Crear una zona alojada privada para el dominio example.com en la Cuenta B. Configurar la replicación de Route 53 entre cuentas de AWS.",
            "E. Asociar una nueva VPC en la Cuenta B con una zona alojada en la Cuenta A. Eliminar la autorización de asociación en la Cuenta A."
        ],
        "respuestas_correctas": [
            "E",
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "16.- Una empresa usó instancias de Amazon EC2 para implementar una flota web para alojar un sitio de blog. Las instancias de EC2 están detrás de un Application Load Balancer (ALB) y están configuradas en un grupo de Auto Scaling. La aplicación web almacena todo el contenido del blog en un volumen de Amazon EFS. La empresa recientemente agregó una característica para que los blogueros puedan agregar videos a sus publicaciones, lo que atrajo 10 veces más tráfico de usuarios que antes. En los horarios de mayor tráfico, los usuarios informan problemas de buffering y tiempos de espera al intentar acceder al sitio o ver los videos. ¿Cuál es la implementación MÁS rentable y escalable que resolverá los problemas de los usuarios?",
        "opciones": [
            "A. Reconfigurar Amazon EFS para habilitar el máximo I/O.",
            "B. Actualizar el sitio de blog para usar volúmenes de almacenamiento en instancias. Copiar los contenidos del sitio a los volúmenes al iniciarse y a Amazon S3 al apagarse.",
            "C. Configurar una distribución de Amazon CloudFront. Apuntar la distribución a un bucket de S3 y migrar los videos desde EFS a Amazon S3.",
            "D. Configurar una distribución de Amazon CloudFront para todo el contenido del sitio y apuntar la distribución al ALB."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "17.- Una empresa con oficinas globales tiene una única conexión de AWS Direct Connect de 1 Gbps a una sola región de AWS. La red local de la empresa utiliza la conexión para comunicarse con los recursos de la empresa en la nube de AWS. La conexión tiene una única interfaz virtual privada que se conecta a una sola VPC. Un arquitecto de soluciones debe implementar una solución que agregue una conexión redundante de Direct Connect en la misma región. La solución también debe proporcionar conectividad a otras regiones a través del mismo par de conexiones de Direct Connect a medida que la empresa se expande a otras regiones. ¿Qué solución cumple con estos requisitos?",
        "opciones": [
            "A. Provisionar una puerta de enlace de Direct Connect. Eliminar la interfaz virtual privada existente de la conexión actual. Crear la segunda conexión de Direct Connect. Crear una nueva interfaz virtual privada en cada conexión y conectar ambas interfaces virtuales privadas a la puerta de enlace de Direct Connect. Conectar la puerta de enlace de Direct Connect a la única VPC.",
            "B. Mantener la interfaz virtual privada existente. Crear la segunda conexión de Direct Connect. Crear una nueva interfaz virtual privada en la nueva conexión y conectar la nueva interfaz virtual privada a la única VPC.",
            "C. Mantener la interfaz virtual privada existente. Crear la segunda conexión de Direct Connect. Crear una nueva interfaz virtual pública en la nueva conexión y conectar la nueva interfaz virtual pública a la única VPC.",
            "D. Provisionar una puerta de enlace de tránsito. Eliminar la interfaz virtual privada existente de la conexión actual. Crear la segunda conexión de Direct Connect. Crear una nueva interfaz virtual privada en cada conexión y conectar ambas interfaces virtuales privadas a la puerta de enlace de tránsito. Asociar la puerta de enlace de tránsito con la única VPC."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "18.- Una empresa tiene una aplicación web que permite a los usuarios cargar videos cortos. Los videos se almacenan en volúmenes de Amazon EBS y se analizan mediante software personalizado de reconocimiento para su categorización. El sitio web contiene contenido estático que tiene tráfico variable con picos en ciertos meses. La arquitectura consiste en instancias de Amazon EC2 ejecutándose en un grupo de Auto Scaling para la aplicación web e instancias de EC2 ejecutándose en un grupo de Auto Scaling para procesar una cola de Amazon SQS. La empresa desea reestructurar la aplicación para reducir la sobrecarga operativa utilizando servicios gestionados de AWS cuando sea posible y eliminar las dependencias de software de terceros. ¿Qué solución cumple con estos requisitos?",
        "opciones": [
            "A. Utilizar contenedores de Amazon ECS para la aplicación web y usar instancias Spot para el grupo de Auto Scaling que procesa la cola de SQS. Reemplazar el software personalizado con Amazon Rekognition para categorizar los videos.",
            "B. Almacenar los videos cargados en Amazon EFS y montar el sistema de archivos en las instancias de EC2 para la aplicación web. Procesar la cola de SQS con una función de AWS Lambda que llama a la API de Amazon Rekognition para categorizar los videos.",
            "C. Alojar la aplicación web en Amazon S3. Almacenar los videos cargados en Amazon S3. Usar notificaciones de eventos de S3 para publicar eventos en la cola de SQS. Procesar la cola de SQS con una función de AWS Lambda que llama a la API de Amazon Rekognition para categorizar los videos.",
            "D. Usar AWS Elastic Beanstalk para lanzar instancias de EC2 en un grupo de Auto Scaling para la aplicación web y lanzar un entorno de trabajo para procesar la cola de SQS. Reemplazar el software personalizado con Amazon Rekognition para categorizar los videos."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "19.- Una empresa tiene una aplicación sin servidor compuesta por Amazon CloudFront, Amazon API Gateway y funciones de AWS Lambda. El proceso actual de implementación del código de la aplicación consiste en crear un nuevo número de versión de la función Lambda y ejecutar un script de AWS CLI para actualizarla. Si la nueva versión de la función tiene errores, otro script de CLI revierte al implementar la versión anterior que funcionaba correctamente. La empresa quisiera reducir el tiempo de implementación de nuevas versiones de la lógica de la aplicación proporcionada por las funciones Lambda, y también reducir el tiempo para detectar y revertir cuando se identifiquen errores. ¿Cómo se puede lograr esto?",
        "opciones": [
            "A. Crear e implementar pilas anidadas de AWS CloudFormation, siendo la pila principal la distribución de AWS CloudFront y API Gateway, y la pila secundaria que contiene la función Lambda. Para los cambios en Lambda, crear un conjunto de cambios de AWS CloudFormation e implementarlo; si se activan errores, revertir el conjunto de cambios de AWS CloudFormation a la versión anterior.",
            "B. Usar AWS SAM y AWS CodeDeploy integrado para implementar la nueva versión de Lambda, cambiar gradualmente el tráfico a la nueva versión, y usar funciones de prueba antes y después del tráfico para verificar el código. Realizar un rollback si se activan alarmas de Amazon CloudWatch.",
            "C. Refactorizar los scripts de AWS CLI en un solo script que implemente la nueva versión de Lambda. Cuando se complete la implementación, el script ejecuta pruebas. Si se detectan errores, revertir a la versión anterior de Lambda.",
            "D. Crear e implementar una pila de AWS CloudFormation que consista en un nuevo punto de enlace de API Gateway que haga referencia a la nueva versión de Lambda. Cambiar el origen de CloudFront al nuevo punto de enlace de API Gateway, monitorear los errores y, si se detectan, cambiar el origen de AWS CloudFront al punto de enlace anterior de API Gateway."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "20.- Una empresa está planeando almacenar una gran cantidad de documentos archivados y hacer que los documentos estén disponibles para los empleados a través de la intranet corporativa. Los empleados accederán al sistema conectándose a través de un servicio VPN cliente que está adjunto a una VPC. Los datos no deben ser accesibles al público. Los documentos que la empresa está almacenando son copias de datos que se encuentran en medios físicos en otro lugar. El número de solicitudes será bajo. La disponibilidad y la velocidad de recuperación no son preocupaciones para la empresa. ¿Qué solución cumplirá con estos requisitos al costo MÁS BAJO?",
        "opciones": [
            "A. Crear un bucket de Amazon S3. Configurar el bucket de S3 para usar la clase de almacenamiento S3 One Zone-Infrequent Access (S3 One Zone-IA) como predeterminada. Configurar el bucket de S3 para hospedaje de sitios web. Crear un endpoint de interfaz S3. Configurar el bucket de S3 para permitir el acceso solo a través de ese endpoint.",
            "B. Lanzar una instancia de Amazon EC2 que ejecute un servidor web. Adjuntar un sistema de archivos Amazon Elastic File System (Amazon EFS) para almacenar los datos archivados en la clase de almacenamiento EFS One Zone-Infrequent Access (EFS One Zone-IA). Configurar los grupos de seguridad de la instancia para permitir el acceso solo desde redes privadas.",
            "C. Lanzar una instancia de Amazon EC2 que ejecute un servidor web. Adjuntar un volumen de Amazon Elastic Block Store (Amazon EBS) para almacenar los datos archivados. Usar el tipo de volumen Cold HDD (sc1). Configurar los grupos de seguridad de la instancia para permitir el acceso solo desde redes privadas.",
            "D. Crear un bucket de Amazon S3. Configurar el bucket de S3 para usar la clase de almacenamiento S3 Glacier Deep Archive como predeterminada. Configurar el bucket de S3 para hospedaje de sitios web. Crear un endpoint de interfaz S3. Configurar el bucket de S3 para permitir el acceso solo a través de ese endpoint."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "21.- Una empresa está utilizando un servicio de Active Directory en las instalaciones para la autenticación de usuarios. La empresa quiere usar el mismo servicio de autenticación para iniciar sesión en las cuentas de AWS de la empresa, que están organizadas mediante AWS Organizations. Ya existe conectividad AWS Site-to-Site VPN entre el entorno local y todas las cuentas de AWS de la empresa. La política de seguridad de la empresa requiere acceso condicional a las cuentas en función de grupos de usuarios y roles. Las identidades de los usuarios deben administrarse en un solo lugar. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Configurar AWS IAM Identity Center (AWS Single Sign-On) para conectarse a Active Directory mediante SAML 2.0. Habilitar el aprovisionamiento automático utilizando el protocolo System for Cross-domain Identity Management (SCIM) v2.0. Conceder acceso a las cuentas de AWS utilizando controles de acceso basados en atributos (ABAC).",
            "B. Configurar AWS IAM Identity Center (AWS Single Sign-On) utilizando IAM Identity Center como fuente de identidad. Habilitar el aprovisionamiento automático mediante el protocolo SCIM v2.0. Conceder acceso a las cuentas de AWS utilizando conjuntos de permisos de IAM Identity Center.",
            "C. En una de las cuentas de AWS de la empresa, configurar AWS Identity and Access Management (IAM) para usar un proveedor de identidad SAML 2.0. Aprovisionar usuarios de IAM que estén mapeados a los usuarios federados. Conceder acceso de acuerdo con los grupos apropiados en Active Directory. Conceder acceso a las cuentas de AWS necesarias utilizando usuarios de IAM con acceso entre cuentas.",
            "D. En una de las cuentas de AWS de la empresa, configurar AWS Identity and Access Management (IAM) para usar un proveedor de identidad OpenID Connect (OIDC). Aprovisionar roles de IAM que concedan acceso a la cuenta de AWS para los usuarios federados que correspondan a los grupos apropiados en Active Directory. Conceder acceso a las cuentas de AWS necesarias utilizando roles de IAM con acceso entre cuentas."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "22.- Una empresa de software ha implementado una aplicación que consume una API REST utilizando Amazon API Gateway, funciones AWS Lambda y una tabla de Amazon DynamoDB. La aplicación está mostrando un aumento en el número de errores durante las solicitudes PUT. La mayoría de las llamadas PUT provienen de un pequeño número de clientes autenticados con claves API específicas. Un arquitecto de soluciones ha identificado que una gran cantidad de solicitudes PUT provienen de un solo cliente. La API no es crítica, y los clientes pueden tolerar reintentos de llamadas no exitosas. Sin embargo, los errores se muestran a los clientes y están dañando la reputación de la API. ¿Qué debería recomendar el arquitecto de soluciones para mejorar la experiencia del cliente?",
        "opciones": [
            "A. Implementar lógica de reintento con backoff exponencial y variación irregular en la aplicación cliente. Asegurar que los errores sean capturados y manejados con mensajes descriptivos.",
            "B. Implementar limitación de API (throttling) a través de un plan de uso en API Gateway. Asegurar que la aplicación cliente maneje correctamente las respuestas con el código 429 sin generar errores.",
            "C. Activar la caché de API para mejorar la capacidad de respuesta en el entorno de producción. Realizar pruebas de carga de 10 minutos y verificar que la capacidad de la caché sea adecuada para la carga de trabajo.",
            "D. Implementar concurrencia reservada a nivel de función Lambda para proporcionar los recursos necesarios durante aumentos repentinos en el tráfico"
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "23.- Una empresa está ejecutando una aplicación intensiva en datos en AWS. La aplicación se ejecuta en un clúster de cientos de instancias Amazon EC2. También hay un sistema de archivos compartido que se ejecuta en varias instancias EC2 y almacena 200 TB de datos. La aplicación lee y modifica los datos en el sistema de archivos compartido y genera un informe. El trabajo se ejecuta una vez al mes, lee un subconjunto de archivos del sistema de archivos compartido y tarda aproximadamente 72 horas en completarse. Las instancias de cómputo escalan automáticamente mediante un grupo de Auto Scaling, pero las instancias que alojan el sistema de archivos compartido se ejecutan continuamente. Tanto las instancias de cómputo como las de almacenamiento están en la misma región de AWS. Un arquitecto de soluciones debe reducir costos reemplazando las instancias que ejecutan el sistema de archivos compartido. El nuevo sistema de archivos debe proporcionar alto rendimiento para acceder a los datos durante las 72 horas que dura la ejecución del trabajo. ¿Qué solución proporcionará la MAYOR reducción de costos mientras cumple con estos requisitos?",
        "opciones": [
            "A. Migrar los datos del sistema de archivos compartido a un bucket de Amazon S3 que use la clase de almacenamiento S3 Intelligent-Tiering. Antes de ejecutar el trabajo cada mes, usar Amazon FSx for Lustre para crear un nuevo sistema de archivos con los datos desde S3 mediante carga diferida (lazy loading). Usar este sistema de archivos como almacenamiento compartido durante el trabajo y eliminarlo al finalizar.",
            "B. Migrar los datos del sistema de archivos compartido a un volumen de Amazon EBS grande con la opción Multi-Attach habilitada. Adjuntar el volumen de EBS a cada instancia mediante un script en user data dentro de la plantilla de lanzamiento del Auto Scaling group. Usar el volumen EBS como almacenamiento compartido durante el trabajo y desvincularlo al finalizar.",
            "C. Migrar los datos del sistema de archivos compartido a un bucket de Amazon S3 que use la clase de almacenamiento S3 Standard. Antes de ejecutar el trabajo cada mes, usar Amazon FSx for Lustre para crear un nuevo sistema de archivos con los datos desde S3 mediante carga por lotes (batch loading). Usar este sistema de archivos como almacenamiento compartido durante el trabajo y eliminarlo al finalizar.",
            "D. Migrar los datos del sistema de archivos compartido a un bucket de Amazon S3. Antes de ejecutar el trabajo cada mes, usar AWS Storage Gateway para crear un file gateway con los datos desde S3. Usar el file gateway como almacenamiento compartido durante el trabajo y eliminarlo al finalizar."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "24-Una empresa está desarrollando un nuevo servicio que será accesible mediante TCP en un puerto estático. Un arquitecto de soluciones debe garantizar que el servicio sea: Altamente disponible Tenga redundancia entre Zonas de Disponibilidad (AZs) Sea accesible mediante DNS con el nombre my.service.com (públicamente accesible) Utilice direcciones IP fijas para que otras empresas puedan agregarlas a sus listas de permitidos (allow lists) Suponiendo que los recursos están implementados en múltiples Zonas de Disponibilidad dentro de una sola Región ¿qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Crear instancias Amazon EC2 con una Elastic IP para cada instancia. Crear un Network Load Balancer (NLB) y exponer el puerto TCP estático. Registrar las instancias EC2 en el NLB. Crear un nuevo registro de servidor de nombres llamado my.service.com y asignar las Elastic IP de las instancias EC2 al registro. Proporcionar las Elastic IP de las instancias EC2 a otras empresas para que las agreguen a sus listas de permitidos.",
            "B. Crear un clúster de Amazon ECS y una definición de servicio para la aplicación. Asignar direcciones IP públicas al clúster de ECS. Crear un Network Load Balancer (NLB) y exponer el puerto TCP. Crear un grupo de destino y asignar el nombre del clúster ECS al NLB. Crear un nuevo registro A llamado my.service.com y asignar las direcciones IP públicas del clúster ECS al registro. Proporcionar las direcciones IP públicas del clúster ECS a otras empresas para que las agreguen a sus listas de permitidos.",
            "C. Crear instancias Amazon EC2 para el servicio. Crear una Elastic IP para cada Zona de Disponibilidad. Crear un Network Load Balancer (NLB) y exponer el puerto TCP asignado. Asignar las Elastic IP al NLB en cada Zona de Disponibilidad. Crear un grupo de destino y registrar las instancias EC2 en el NLB. Crear un nuevo registro A (alias) llamado my.service.com y asignar el nombre DNS del NLB al registro.",
            "D. Crear un clúster de Amazon ECS y una definición de servicio para la aplicación. Asignar una dirección IP pública para cada host en el clúster. Crear un Application Load Balancer (ALB) y exponer el puerto TCP estático. Crear un grupo de destino y asignar el nombre del servicio ECS al ALB. Crear un nuevo registro CNAME y asociar las direcciones IP públicas al registro. Proporcionar las Elastic IP de las instancias EC2 a otras empresas para que las agreguen a sus listas de permitidos."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "25.- Una empresa utiliza una plataforma de análisis de datos on-premises. El sistema es altamente disponible en una configuración totalmente redundante con 12 servidores en el centro de datos de la empresa. El sistema ejecuta trabajos programados, tanto cada hora como diariamente, además de solicitudes puntuales de los usuarios. Los trabajos programados tardan entre 20 minutos y 2 horas en ejecutarse y tienen estrictos SLA. Representan el 65% del uso del sistema. Los trabajos de los usuarios tardan menos de 5 minutos en ejecutarse y no tienen SLA. Representan el 35% del uso del sistema. En caso de fallos del sistema, los trabajos programados deben cumplir los SLA, pero los trabajos de los usuarios pueden retrasarse. Un arquitecto de soluciones debe migrar el sistema a instancias Amazon EC2 y adoptar un modelo basado en consumo para reducir costos sin compromisos a largo plazo. La solución debe mantener alta disponibilidad y no afectar los SLA. ¿Qué solución cumplirá estos requisitos de manera MÁS rentable?",
        "opciones": [
            "A. Dividir las 12 instancias en dos Zonas de Disponibilidad en la Región de AWS seleccionada. Ejecutar dos instancias en cada Zona de Disponibilidad como On-Demand Instances con Capacity Reservations. Ejecutar cuatro instancias en cada Zona de Disponibilidad como Spot Instances.",
            "B. Dividir las 12 instancias en tres Zonas de Disponibilidad en la Región de AWS seleccionada. En una de las Zonas de Disponibilidad, ejecutar las cuatro instancias como On-Demand Instances con Capacity Reservations. Ejecutar las instancias restantes como Spot Instances.",
            "C. Dividir las 12 instancias en tres Zonas de Disponibilidad en la Región de AWS seleccionada. Ejecutar dos instancias en cada Zona de Disponibilidad como On-Demand Instances con un Savings Plan. Ejecutar dos instancias en cada Zona de Disponibilidad como Spot Instances.",
            "D. Dividir las 12 instancias en tres Zonas de Disponibilidad en la Región de AWS seleccionada. Ejecutar tres instancias en cada Zona de Disponibilidad como On-Demand Instances con Capacity Reservations. Ejecutar una instancia en cada Zona de Disponibilidad como Spot Instance."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "26.- Un ingeniero de seguridad determinó que una aplicación existente recupera credenciales para una base de datos Amazon RDS para MySQL desde un archivo cifrado en Amazon S3. Para la próxima versión de la aplicación, el ingeniero de seguridad quiere implementar los siguientes cambios en el diseño para mejorar la seguridad: La base de datos debe usar contraseñas fuertes y generadas aleatoriamente, almacenadas en un servicio administrado de AWS. Los recursos de la aplicación deben desplegarse a través de AWS CloudFormation. Las credenciales de la base de datos deben rotarse cada 90 días. Un arquitecto de soluciones generará una plantilla de CloudFormation para implementar la aplicación. ¿Qué recursos especificados en la plantilla de CloudFormation cumplirán con los requisitos del ingeniero de seguridad con el MENOR esfuerzo operativo?",
        "opciones": [
            "A. Generar la contraseña de la base de datos como un recurso secreto en AWS Secrets Manager. Crear un recurso de función AWS Lambda para rotar la contraseña de la base de datos. Especificar un recurso Secrets Manager RotationSchedule para rotar la contraseña cada 90 días.",
            "B. Generar la contraseña de la base de datos como un parámetro de tipo SecureString en AWS Systems Manager Parameter Store. Crear un recurso de función AWS Lambda para rotar la contraseña de la base de datos. Especificar un recurso Parameter Store RotationSchedule para rotar la contraseña cada 90 días.",
            "C. Generar la contraseña de la base de datos como un recurso secreto en AWS Secrets Manager. Crear un recurso de función AWS Lambda para rotar la contraseña de la base de datos. Crear un recurso de regla programada en Amazon EventBridge para activar la rotación de la contraseña mediante la función Lambda cada 90 días.",
            "D. Generar la contraseña de la base de datos como un parámetro de tipo SecureString en AWS Systems Manager Parameter Store. Especificar un recurso AWS AppSync DataSource para rotar automáticamente la contraseña de la base de datos cada 90 días."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "27.- Una empresa está almacenando datos en varias tablas de Amazon DynamoDB. Un arquitecto de soluciones debe utilizar una arquitectura sin servidor (serverless) para hacer que los datos sean accesibles públicamente a través de una API simple sobre HTTPS. La solución debe escalar automáticamente en respuesta a la demanda. ¿Qué soluciones cumplen con estos requisitos? (Selecciona dos opciones)",
        "opciones": [
            "A. Crear una API REST en Amazon API Gateway. Configurar esta API con integraciones directas a DynamoDB utilizando el tipo de integración AWS de API Gateway.",
            "B. Crear una API HTTP en Amazon API Gateway. Configurar esta API con integraciones directas a DynamoDB utilizando el tipo de integración AWS de API Gateway.",
            "C. Crear una API HTTP en Amazon API Gateway. Configurar esta API con integraciones a funciones AWS Lambda, que devolverán datos desde las tablas de DynamoDB.",
            "D. Crear un acelerador en AWS Global Accelerator. Configurar este acelerador con integraciones de funciones AWS Lambda@Edge, que devolverán datos desde las tablas de DynamoDB.",
            "E. Crear un Network Load Balancer (NLB). Configurar reglas de escucha (listener rules) para reenviar las solicitudes a las funciones AWS Lambda correspondientes."
        ],
        "respuestas_correctas": [
            "C",
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "28.- Una empresa ha registrado 10 nuevos nombres de dominio. La empresa utiliza estos dominios para marketing en línea y necesita una solución que redirija a los visitantes a una URL específica para cada dominio. Todos los dominios y URLs de destino están definidos en un documento JSON. Todos los registros DNS son administrados por Amazon Route 53. Un arquitecto de soluciones debe implementar un servicio de redirección que acepte solicitudes HTTP y HTTPS. ¿Qué combinación de pasos debe seguir el arquitecto de soluciones para cumplir con estos requisitos con el MENOR esfuerzo operativo? (Elige tres opciones)",
        "opciones": [
            "A. Crear una página web dinámica en una instancia de Amazon EC2. Configurar la página para usar el documento JSON junto con el mensaje del evento para buscar y responder con una URL de redirección.",
            "B. Crear un Application Load Balancer (ALB) que incluya listeners HTTP y HTTPS.",
            "C. Crear una función AWS Lambda que use el documento JSON junto con el mensaje del evento para buscar y responder con una URL de redirección.",
            "D. Usar una API de Amazon API Gateway con un dominio personalizado para publicar una función AWS Lambda.",
            "E. Crear una distribución de Amazon CloudFront. Implementar una función Lambda@Edge.",
            "F. Crear un certificado SSL con AWS Certificate Manager (ACM). Incluir los dominios como Subject Alternative Names (SANs)."
        ],
        "respuestas_correctas": [
            "F",
            "D",
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "29.- Una empresa con múltiples cuentas de AWS está utilizando AWS Organizations. Las cuentas de AWS de la empresa alojan VPCs, instancias de Amazon EC2 y contenedores. El equipo de cumplimiento de la empresa ha implementado una herramienta de seguridad en cada VPC donde hay despliegues. Estas herramientas de seguridad se ejecutan en instancias EC2 y envían información a una cuenta de AWS dedicada al equipo de cumplimiento. La empresa ha etiquetado todos los recursos relacionados con el cumplimiento con la clave costCenter y el valor compliance. La empresa quiere identificar el costo de las herramientas de seguridad que se ejecutan en las instancias EC2 para poder asignar estos costos a la cuenta de AWS del equipo de cumplimiento. El cálculo del costo debe ser lo más preciso posible. ¿Qué debe hacer un arquitecto de soluciones para cumplir con estos requisitos?",
        "opciones": [
            "A. En la cuenta de administración de la organización, activar la etiqueta definida por el usuario costCenter. Configurar Informes de Costos y Uso de AWS (AWS Cost and Usage Reports) mensuales para guardarlos en un bucket de Amazon S3 en la cuenta de administración. Usar el desglose por etiquetas en el informe para obtener el costo total de los recursos etiquetados con costCenter.",
            "B. En las cuentas miembro de la organización, activar la etiqueta definida por el usuario costCenter. Configurar Informes de Costos y Uso de AWS mensuales para guardarlos en un bucket de Amazon S3 en la cuenta de administración. Programar una función AWS Lambda mensual para recuperar los informes y calcular el costo total de los recursos etiquetados con costCenter.",
            "C. En las cuentas miembro de la organización, activar la etiqueta definida por el usuario costCenter. Desde la cuenta de administración, programar un Informe de Costos y Uso de AWS mensual. Usar el desglose por etiquetas en el informe para calcular el costo total de los recursos etiquetados con costCenter.",
            "D. Crear un informe personalizado en la vista de organización de AWS Trusted Advisor. Configurar el informe para generar un resumen de facturación mensual para los recursos etiquetados con costCenter en la cuenta de AWS del equipo de cumplimiento."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "30.- Una empresa tiene 50 cuentas de AWS que son miembros de una organización en AWS Organizations. Cada cuenta contiene varias VPCs. La empresa quiere usar AWS Transit Gateway para establecer conectividad entre las VPCs de cada cuenta miembro. Cada vez que se crea una nueva cuenta miembro, la empresa quiere automatizar el proceso de crear una nueva VPC y una vinculación de Transit Gateway. ¿Qué combinación de pasos cumplirá con estos requisitos? (Elige dos opciones)",
        "opciones": [
            "A. Desde la cuenta de administración, compartir el Transit Gateway con las cuentas miembro mediante AWS Resource Access Manager.",
            "B. Desde la cuenta de administración, compartir el Transit Gateway con las cuentas miembro mediante una Política de Control de Servicio (SCP) de AWS Organizations.",
            "C. Lanzar un stack set de AWS CloudFormation desde la cuenta de administración que cree automáticamente una nueva VPC y una vinculación de Transit Gateway VPC en una cuenta miembro. Asociar la vinculación con el Transit Gateway en la cuenta de administración utilizando el ID del Transit Gateway.",
            "D. Lanzar un stack set de AWS CloudFormation desde la cuenta de administración que cree automáticamente una nueva VPC y una vinculación de Transit Gateway por emparejamiento en una cuenta miembro. Compartir la vinculación con el Transit Gateway en la cuenta de administración mediante un rol vinculado al servicio Transit Gateway.",
            "E. Desde la cuenta de administración, compartir el Transit Gateway con las cuentas miembro mediante AWS Service Catalog."
        ],
        "respuestas_correctas": [
            "C",
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "31.- Una empresa quiere permitir que sus desarrolladores compren software de terceros a través de AWS Marketplace. La empresa usa una estructura de cuentas AWS Organizations con características completas habilitadas y tiene una cuenta de servicios compartidos en cada unidad organizacional (OU) que será utilizada por los gerentes de compras. La política del equipo de compras indica que los desarrolladores deben poder obtener software de terceros solo de una lista aprobada y usar Private Marketplace en AWS Marketplace para lograr este requisito. El equipo de compras quiere que la administración de Private Marketplace esté restringida a un rol denominado procurement-manager-role, el cual podría ser asumido por los gerentes de compras. A otros usuarios, grupos, roles de IAM y administradores de cuentas en la empresa se les debe negar el acceso administrativo a Private Marketplace. ¿Cuál es la forma más eficiente de diseñar una arquitectura para cumplir con estos requisitos?",
        "opciones": [
            "A. Crear un rol de IAM denominado procurement-manager-role en todas las cuentas de AWS en la organización. Añadir la política administrada PowerUserAccess al rol. Aplicar una política en línea a todos los usuarios y roles de IAM en cada cuenta de AWS para negar permisos sobre la política administrada AWSPrivateMarketplaceAdminFullAccess.",
            "B. Crear un rol de IAM denominado procurement-manager-role en todas las cuentas de AWS en la organización. Añadir la política administrada AdministratorAccess al rol. Definir un límite de permisos con la política administrada AWSPrivateMarketplaceAdminFullAccess y adjuntarlo a todos los roles de desarrollador.",
            "C. Crear un rol de IAM denominado procurement-manager-role en todas las cuentas de servicios compartidos en la organización. Añadir la política administrada AWSPrivateMarketplaceAdminFullAccess al rol. Crear una SCP de nivel raíz de la organización para negar permisos para administrar Private Marketplace a todos, excepto al rol denominado procurement-manager-role. Crear otra SCP de nivel raíz de la organización para negar permisos para crear un rol de IAM denominado procurement-manager-role a todos en la organización.",
            "D. Crear un rol de IAM denominado procurement-manager-role en todas las cuentas de AWS que serán usadas por los desarrolladores. Añadir la política administrada AWSPrivateMarketplaceAdminFullAccess al rol. Crear una SCP en Organizations para negar permisos para administrar Private Marketplace a todos, excepto al rol denominado procurement-manager-role. Aplicar la SCP a todas las cuentas de servicios compartidos en la organización."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "32.- Una empresa está en el proceso de implementar AWS Organizations para restringir a sus desarrolladores a usar solo Amazon EC2, Amazon S3 y Amazon DynamoDB. La cuenta de los desarrolladores reside en una unidad organizacional (OU) dedicada. El arquitecto de soluciones ha implementado la siguiente política de control de acceso (SCP) en la cuenta de los desarrolladores: Cuando se implementa esta política, los usuarios IAM en la cuenta de los desarrolladores aún pueden usar servicios de AWS que no están listados en la política. ¿Qué debe hacer el arquitecto de soluciones para eliminar la capacidad de los desarrolladores de usar servicios fuera del alcance de esta política?",
        "opciones": [
            "A. Crear una declaración de denegación explícita para cada servicio de AWS que deba ser restringido.",
            "B. Eliminar el SCP FullAWSAccess de la OU de la cuenta de los desarrolladores.",
            "C. Modificar el SCP FullAWSAccess para denegar explícitamente todos los servicios.",
            "D. Agregar una declaración de denegación explícita usando un comodín al final del SCP."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": [{
            "respuesta": "B",
            "url": "images/image32.png"
        }]
    },
    {
        "pregunta": "33.- Una empresa está alojando una API monolítica basada en REST para una aplicación móvil en cinco instancias de Amazon EC2 en subredes públicas de una VPC. Los clientes móviles se conectan a la API mediante un nombre de dominio alojado en Amazon Route 53. La empresa ha creado una política de enrutamiento de respuesta múltiple de Route 53 con las direcciones IP de todas las instancias de EC2. Recientemente, la aplicación se ha visto abrumada por grandes y repentinas aumentos en el tráfico. La aplicación no ha podido mantener el ritmo con el tráfico. Un arquitecto de soluciones debe implementar una solución para que la aplicación pueda manejar la nueva y variable carga. ¿Qué solución cumplirá con estos requisitos con la MENOR sobrecarga operativa?",
        "opciones": [
            "A. Separar la API en funciones individuales de AWS Lambda. Configurar una API REST de Amazon API Gateway con integración Lambda para el backend. Actualizar el registro de Route 53 para que apunte a la API de API Gateway.",
            "B. Contenerizar la lógica de la API. Crear un clúster de Amazon Elastic Kubernetes Service (Amazon EKS). Ejecutar los contenedores en el clúster utilizando Amazon EC2. Crear un ingreso de Kubernetes. Actualizar el registro de Route 53 para que apunte al ingreso de Kubernetes.",
            "C. Crear un grupo de Auto Scaling. Colocar todas las instancias de EC2 en el grupo de Auto Scaling. Configurar el grupo de Auto Scaling para realizar acciones de escalado basadas en la utilización de CPU. Crear una función de AWS Lambda que reaccione a los cambios del grupo de Auto Scaling y actualice el registro de Route 53.",
            "D. Crear un balanceador de carga de aplicación (ALB) frente a la API. Mover las instancias de EC2 a subredes privadas en la VPC. Agregar las instancias de EC2 como destinos del ALB. Actualizar el registro de Route 53 para que apunte al ALB."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "34.- Una empresa ha creado una Unidad Organizativa (OU) en AWS Organizations para cada uno de sus equipos de ingeniería. Cada OU posee múltiples cuentas de AWS. La organización tiene cientos de cuentas de AWS. Un arquitecto de soluciones debe diseñar una solución para que cada OU pueda ver un desglose de los costos de uso a través de sus cuentas de AWS. ¿Qué solución cumple con estos requisitos?",
        "opciones": [
            "A. Crear un informe de costos y uso de AWS (CUR) para cada OU utilizando AWS Resource Access Manager. Permitir que cada equipo visualice el CUR a través de un panel de Amazon QuickSight.",
            "B. Crear un informe de costos y uso de AWS (CUR) desde la cuenta de administración de AWS Organizations. Permitir que cada equipo visualice el CUR a través de un panel de Amazon QuickSight.",
            "C. Crear un informe de costos y uso de AWS (CUR) en cada cuenta miembro de AWS Organizations. Permitir que cada equipo visualice el CUR a través de un panel de Amazon QuickSight.",
            "D. Crear un informe de costos y uso de AWS (CUR) mediante AWS Systems Manager. Permitir que cada equipo visualice el CUR a través de los paneles de Systems Manager OpsCenter."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "35.- Una empresa está almacenando datos en sus instalaciones en un servidor de archivos de Windows. La empresa produce 5 GB de nuevos datos diariamente. La empresa ha migrado parte de su carga de trabajo basada en Windows a AWS y necesita que los datos estén disponibles en un sistema de archivos en la nube. La empresa ya ha establecido una conexión AWS Direct Connect entre la red local y AWS. ¿Qué estrategia de migración de datos debe usar la empresa?",
        "opciones": [
            "A. Utilizar la opción de puerta de enlace de archivos en AWS Storage Gateway para reemplazar el servidor de archivos de Windows existente y apuntar el recurso compartido de archivos existente a la nueva puerta de enlace de archivos.",
            "B. Utilizar AWS DataSync para programar una tarea diaria para replicar los datos entre el servidor de archivos de Windows en las instalaciones y Amazon FSx.",
            "C. Utilizar AWS Data Pipeline para programar una tarea diaria para replicar los datos entre el servidor de archivos de Windows en las instalaciones y Amazon Elastic File System (Amazon EFS).",
            "D. Utilizar AWS DataSync para programar una tarea diaria para replicar los datos entre el servidor de archivos de Windows en las instalaciones y Amazon Elastic File System (Amazon EFS)."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "36.- Un arquitecto de soluciones de una empresa está revisando una aplicación web que se ejecuta en AWS. La aplicación hace referencia a activos estáticos en un bucket de Amazon S3 en la Región us-east-1. La empresa necesita resiliencia a través de múltiples Regiones de AWS. La empresa ya ha creado un bucket de S3 en una segunda región. ¿Cuál solución cumplirá con estos requisitos con el MENOR esfuerzo operativo?",
        "opciones": [
            "A. Configurar la aplicación para escribir cada objeto en ambos buckets de S3. Configurar una zona alojada pública de Amazon Route 53 con un conjunto de registros utilizando una política de enrutamiento ponderado para cada bucket de S3. Configurar la aplicación para hacer referencia a los objetos utilizando el nombre DNS de Route 53.",
            "B. Crear una función de AWS Lambda para copiar los objetos del bucket de S3 en us-east-1 al bucket de S3 en la segunda Región. Invocar la función Lambda cada vez que se escriba un objeto en el bucket de S3 en us-east-1. Configurar una distribución de Amazon CloudFront con un grupo de orígenes que contenga ambos buckets de S3 como orígenes.",
            "C. Configurar la replicación en el bucket de S3 en us-east-1 para replicar los objetos al bucket de S3 en la segunda Región. Configurar una distribución de Amazon CloudFront con un grupo de orígenes que contenga ambos buckets de S3 como orígenes.",
            "D. Configurar la replicación en el bucket de S3 en us-east-1 para replicar los objetos al bucket de S3 en la segunda Región. Si se requiere failover, actualizar el código de la aplicación para cargar los objetos de S3 desde el bucket de S3 en la segunda Región."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "37.- Una empresa está alojando una aplicación web de tres niveles en un entorno local. Debido a un reciente aumento en el tráfico que resultó en tiempo de inactividad y un impacto financiero significativo, la dirección de la empresa ha ordenado que la aplicación se mueva a AWS. La aplicación está escrita en .NET y tiene una dependencia de una base de datos MySQL. Un arquitecto de soluciones debe diseñar una solución escalable y altamente disponible para satisfacer la demanda de 200,000 usuarios diarios. ¿Qué pasos debe seguir el arquitecto de soluciones para diseñar una solución adecuada?",
        "opciones": [
            "A. Usar AWS Elastic Beanstalk para crear una nueva aplicación con un entorno de servidor web y una instancia DB de MySQL Multi-AZ de Amazon RDS. El entorno debe lanzar un Network Load Balancer (NLB) frente a un grupo de Auto Scaling de Amazon EC2 en múltiples Zonas de Disponibilidad. Usar un registro alias de Amazon Route 53 para enrutar el tráfico desde el dominio de la empresa hacia el NLB.",
            "B. Usar AWS CloudFormation para lanzar un stack que contenga un Application Load Balancer (ALB) frente a un grupo de Auto Scaling de Amazon EC2 que abarque tres Zonas de Disponibilidad. El stack debe lanzar un despliegue Multi-AZ de un clúster Amazon Aurora MySQL DB con una política de eliminación Retain. Usar un registro alias de Amazon Route 53 para enrutar el tráfico desde el dominio de la empresa hacia el ALB.",
            "C. Usar AWS Elastic Beanstalk para crear un entorno de servidor web que se escale automáticamente y abarque dos Regiones separadas con un Application Load Balancer (ALB) en cada Región. Crear un despliegue Multi-AZ de un clúster Amazon Aurora MySQL DB con una réplica de lectura entre Regiones. Usar Amazon Route 53 con una política de enrutamiento por proximidad geográfica para enrutar el tráfico entre las dos Regiones.",
            "D. Usar AWS CloudFormation para lanzar un stack que contenga un Application Load Balancer (ALB) frente a un clúster de Amazon ECS de instancias Spot que abarque tres Zonas de Disponibilidad. El stack debe lanzar una instancia DB de MySQL de Amazon RDS con una política de eliminación de Snapshot. Usar un registro alias de Amazon Route 53 para enrutar el tráfico desde el dominio de la empresa hacia el ALB."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "38.- Una empresa está utilizando AWS Organizations para gestionar múltiples cuentas de AWS. Por motivos de seguridad, la empresa requiere la creación de un tema de Amazon Simple Notification Service (Amazon SNS) que habilite la integración con un sistema de alertas de terceros en todas las cuentas miembros de Organizations. Un arquitecto de soluciones utilizó una plantilla de AWS CloudFormation para crear el tema SNS y conjuntos de pilas (stack sets) para automatizar el despliegue de pilas de CloudFormation. Se ha habilitado el acceso de confianza en Organizations. ¿Qué debe hacer el arquitecto de soluciones para desplegar los CloudFormation StackSets en todas las cuentas de AWS?",
        "opciones": [
            "A. Crear un conjunto de pilas en las cuentas miembros de Organizations. Usar permisos gestionados por el servicio. Configurar las opciones de despliegue para desplegar a una organización. Usar la detección de desviaciones de CloudFormation StackSets.",
            "B. Crear pilas en las cuentas miembros de Organizations. Usar permisos de autoservicio. Configurar las opciones de despliegue para desplegar a una organización. Habilitar el despliegue automático de CloudFormation StackSets.",
            "C. Crear un conjunto de pilas en la cuenta de administración de Organizations. Usar permisos gestionados por el servicio. Configurar las opciones de despliegue para desplegar a la organización. Habilitar el despliegue automático de CloudFormation StackSets.",
            "D. Crear pilas en la cuenta de administración de Organizations. Usar permisos gestionados por el servicio. Configurar las opciones de despliegue para desplegar a la organización. Habilitar la detección de desviaciones de CloudFormation StackSets."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "39.- Una empresa desea migrar sus cargas de trabajo desde sus instalaciones locales a AWS. Las cargas de trabajo se ejecutan en Linux y Windows. La empresa tiene una gran infraestructura en las instalaciones que consta de máquinas físicas y máquinas virtuales (VM) que alojan numerosas aplicaciones. La empresa debe capturar detalles sobre la configuración del sistema, el rendimiento del sistema, los procesos en ejecución y las conexiones de red de sus cargas de trabajo locales. Además, la empresa debe dividir las aplicaciones locales en grupos para migrarlas a AWS. La empresa también necesita recomendaciones sobre los tipos de instancias de Amazon EC2 para que pueda ejecutar sus cargas de trabajo en AWS de manera más rentable. ¿Qué combinación de pasos debe seguir un arquitecto de soluciones para cumplir con estos requisitos? (Elija tres.)",
        "opciones": [
            "A. Evaluar las aplicaciones existentes instalando AWS Application Discovery Agent en las máquinas físicas y VMs.",
            "B. Evaluar las aplicaciones existentes instalando AWS Systems Manager Agent en las máquinas físicas y VMs.",
            "C. Agrupar servidores en aplicaciones para la migración utilizando AWS Systems Manager Application Manager.",
            "D. Agrupar servidores en aplicaciones para la migración utilizando AWS Migration Hub.",
            "E. Generar tipos de instancias recomendados y costos asociados utilizando AWS Migration Hub.",
            "F. Importar datos sobre los tamaños de los servidores a AWS Trusted Advisor. Seguir las recomendaciones para la optimización de costos."
        ],
        "respuestas_correctas": [
            "E",
            "D",
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "40.- Una empresa está alojando un servicio de procesamiento de imágenes en AWS dentro de una VPC. La VPC se extiende a través de dos zonas de disponibilidad. Cada zona de disponibilidad contiene una subred pública y una subred privada. El servicio se ejecuta en instancias de Amazon EC2 en las subredes privadas. Un Application Load Balancer en las subredes públicas se encuentra delante del servicio. El servicio necesita comunicarse con Internet y lo hace a través de dos NAT gateways. El servicio utiliza Amazon S3 para almacenar imágenes. Las instancias EC2 recuperan aproximadamente 1 TB de datos de un bucket de S3 cada día. La empresa ha promovido el servicio como altamente seguro. Un arquitecto de soluciones debe reducir los gastos de la nube tanto como sea posible sin comprometer la postura de seguridad del servicio ni aumentar el tiempo dedicado a las operaciones continuas. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Reemplazar los NAT gateways por instancias NAT. En la tabla de enrutamiento de la VPC, crear una ruta desde las subredes privadas hacia las instancias NAT.",
            "B. Mover las instancias EC2 a las subredes públicas. Eliminar los NAT gateways.",
            "C. Configurar un endpoint de S3 gateway en la VPC. Adjuntar una política de endpoint para permitir las acciones requeridas en el bucket de S3.",
            "D. Adjuntar un volumen de Amazon Elastic File System (Amazon EFS) a las instancias EC2. Alojar las imágenes en el volumen de EFS."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "41.- Una empresa implementó recientemente una aplicación en AWS. La aplicación utiliza Amazon DynamoDB. La empresa midió la carga de la aplicación y configuró las unidades de capacidad de lectura (RCUs) y escritura (WCUs) de la tabla de DynamoDB para que coincidieran con la carga máxima esperada. La carga máxima ocurre una vez a la semana durante un período de 4 horas y es el doble de la carga promedio. La carga de la aplicación está cerca de la carga promedio durante el resto de la semana. El patrón de acceso incluye muchas más escrituras en la tabla que lecturas. Un arquitecto de soluciones necesita implementar una solución para minimizar el costo de la tabla. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Usar AWS Application Auto Scaling para aumentar la capacidad durante el período de carga máxima. Comprar unidades de capacidad reservada de RCUs y WCUs para que coincidan con la carga promedio.",
            "B. Configurar el modo de capacidad bajo demanda para la tabla.",
            "C. Configurar DynamoDB Accelerator (DAX) frente a la tabla. Reducir la capacidad de lectura aprovisionada para que coincida con la nueva carga máxima en la tabla.",
            "D. Configurar DynamoDB Accelerator (DAX) frente a la tabla. Configurar el modo de capacidad bajo demanda para la tabla."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "42.- Un arquitecto de soluciones necesita asesorar a una empresa sobre cómo migrar su aplicación de procesamiento de datos en las instalaciones a la nube de AWS. Actualmente, los usuarios cargan archivos de entrada a través de un portal web. El servidor web luego almacena los archivos cargados en un NAS y envía mensajes al servidor de procesamiento a través de una cola de mensajes. Cada archivo multimedia puede tardar hasta 1 hora en procesarse. La empresa ha determinado que el número de archivos multimedia esperando procesamiento es significativamente más alto durante las horas laborales, y el número de archivos disminuye rápidamente después del horario laboral. ¿Cuál es la recomendación de migración MÁS rentable?",
        "opciones": [
            "A. Crear una cola usando Amazon SQS. Configurar el servidor web existente para publicar en la nueva cola. Cuando haya mensajes en la cola, invocar una función de AWS Lambda para extraer solicitudes de la cola y procesar los archivos. Almacenar los archivos procesados en un bucket de Amazon S3.",
            "B. Crear una cola usando Amazon MQ. Configurar el servidor web existente para publicar en la nueva cola. Cuando haya mensajes en la cola, crear una nueva instancia de Amazon EC2 para extraer solicitudes de la cola y procesar los archivos. Almacenar los archivos procesados en Amazon EFS. Apagar la instancia de EC2 después de que se complete la tarea.",
            "C. Crear una cola usando Amazon MQ. Configurar el servidor web existente para publicar en la nueva cola. Cuando haya mensajes en la cola, invocar una función de AWS Lambda para extraer solicitudes de la cola y procesar los archivos. Almacenar los archivos procesados en Amazon EFS.",
            "D. Crear una cola usando Amazon SQS. Configurar el servidor web existente para publicar en la nueva cola. Usar instancias de Amazon EC2 en un grupo de Auto Scaling de EC2 para extraer solicitudes de la cola y procesar los archivos. Escalar las instancias de EC2 en función de la longitud de la cola SQS. Almacenar los archivos procesados en un bucket de Amazon S3."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "43.- Una empresa está utilizando Amazon OpenSearch Service para analizar datos. La empresa carga datos en un clúster de OpenSearch Service con 10 nodos de datos desde un bucket de Amazon S3 que usa almacenamiento S3 Standard. Los datos residen en el clúster durante 1 mes para análisis solo de lectura. Después de 1 mes, la empresa elimina el índice que contiene los datos del clúster. Por razones de cumplimiento, la empresa debe retener una copia de todos los datos de entrada. La empresa está preocupada por los costos continuos y pide a un arquitecto de soluciones que recomiende una nueva solución. ¿Qué solución cumplirá con estos requisitos de manera MÁS rentable?",
        "opciones": [
            "A. Reemplazar todos los nodos de datos con nodos UltraWarm para manejar la capacidad esperada. Transicionar los datos de entrada desde S3 Standard a S3 Glacier Deep Archive cuando la empresa cargue los datos en el clúster.",
            "B. Reducir el número de nodos de datos en el clúster a 2. Agregar nodos UltraWarm para manejar la capacidad esperada. Configurar los índices para que se transicionen a UltraWarm cuando OpenSearch Service ingiera los datos. Transicionar los datos de entrada a S3 Glacier Deep Archive después de 1 mes utilizando una política de ciclo de vida de S3.",
            "C. Reducir el número de nodos de datos en el clúster a 2. Agregar nodos UltraWarm para manejar la capacidad esperada. Configurar los índices para que se transicionen a UltraWarm cuando OpenSearch Service ingiera los datos. Agregar nodos de almacenamiento en frío al clúster. Transicionar los índices de UltraWarm a almacenamiento en frío. Eliminar los datos de entrada del bucket de S3 después de 1 mes mediante una política de ciclo de vida de S3.",
            "D. Reducir el número de nodos de datos en el clúster a 2. Agregar nodos de datos respaldados por instancias para manejar la capacidad esperada. Transicionar los datos de entrada desde S3 Standard a S3 Glacier Deep Archive cuando la empresa cargue los datos en el clúster."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "44.- Una empresa tiene 10 cuentas que forman parte de una organización en AWS Organizations. AWS Config está configurado en cada cuenta. Todas las cuentas pertenecen a la OU Prod o a la OU NonProd. La empresa ha configurado una regla de Amazon EventBridge en cada cuenta de AWS para notificar a un tema de Amazon Simple Notification Service (Amazon SNS) cuando se crea una regla de entrada de grupo de seguridad de Amazon EC2 con 0.0.0.0/0 como origen. El equipo de seguridad de la empresa está suscrito al tema SNS. Para todas las cuentas en la OU NonProd, el equipo de seguridad necesita eliminar la capacidad de crear una regla de entrada de grupo de seguridad que incluya 0.0.0.0/0 como origen. ¿Qué solución cumplirá con este requisito con el MENOR esfuerzo operativo?",
        "opciones": [
            "A. Modificar la regla de EventBridge para invocar una función de AWS Lambda que elimine la regla de entrada del grupo de seguridad y publique en el tema SNS. Desplegar la regla actualizada en la OU NonProd.",
            "B. Agregar la regla gestionada por AWS vpc-sg-open-only-to-authorized-ports a la OU NonProd.",
            "C. Configurar una SCP para permitir la acción ec2:AuthorizeSecurityGroupIngress cuando el valor de la clave de condición aws:SourceIp no sea 0.0.0.0/0. Aplicar la SCP a la OU NonProd.",
            "D. Configurar una SCP para denegar la acción ec2:AuthorizeSecurityGroupIngress cuando el valor de la clave de condición aws:SourceIp sea 0.0.0.0/0. Aplicar la SCP a la OU NonProd."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "45.- Una empresa aloja un repositorio de Git en un centro de datos local. La empresa utiliza webhooks para invocar funcionalidades que se ejecutan en la nube de AWS. La empresa aloja la lógica de los webhooks en un conjunto de instancias de Amazon EC2 en un grupo de Auto Scaling, que se establece como objetivo de un Application Load Balancer (ALB). El servidor Git llama al ALB para los webhooks configurados. La empresa quiere mover la solución a una arquitectura sin servidores. ¿Qué solución cumplirá estos requisitos con el MENOR esfuerzo operativo?",
        "opciones": [
            "A. Para cada webhook, crear y configurar una URL de función AWS Lambda. Actualizar los servidores Git para llamar a las URLs individuales de las funciones Lambda.",
            "B. Crear una API HTTP de Amazon API Gateway. Implementar cada lógica de webhook en una función Lambda separada. Actualizar los servidores Git para llamar al endpoint de API Gateway.",
            "C. Desplegar la lógica de los webhooks en AWS App Runner. Crear un ALB, y configurar App Runner como el objetivo. Actualizar los servidores Git para llamar al endpoint del ALB.",
            "D. Contenerizar la lógica de los webhooks. Crear un clúster de Amazon Elastic Container Service (Amazon ECS), y ejecutar la lógica de los webhooks en AWS Fargate. Crear una API REST de Amazon API Gateway, y configurar Fargate como el objetivo. Actualizar los servidores Git para llamar al endpoint de API Gateway."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "46.- Una empresa está planeando migrar 1,000 servidores locales a AWS. Los servidores se ejecutan en varios clústeres de VMware en el centro de datos de la empresa. Como parte del plan de migración, la empresa quiere recopilar métricas de los servidores, como detalles de CPU, uso de RAM, información del sistema operativo y procesos en ejecución. Luego, la empresa desea consultar y analizar los datos. ¿Qué solución cumplirá estos requisitos?",
        "opciones": [
            "A. Desplegar y configurar el conector de descubrimiento sin agente de AWS en las máquinas virtuales locales. Configurar la exploración de datos en AWS Migration Hub. Utilizar AWS Glue para realizar un trabajo ETL sobre los datos. Consultar los datos utilizando Amazon S3 Select.",
            "B. Exportar solo la información de rendimiento de la máquina virtual de los hosts locales. Importar directamente los datos requeridos en AWS Migration Hub. Actualizar cualquier información faltante en Migration Hub. Consultar los datos usando Amazon QuickSight.",
            "C. Crear un script para recopilar automáticamente la información del servidor de los hosts locales. Usar la AWS CLI para ejecutar el comando put-resource-attributes y almacenar los datos detallados del servidor en AWS Migration Hub. Consultar los datos directamente en la consola de Migration Hub.",
            "D. Desplegar el AWS Application Discovery Agent en cada servidor local. Configurar la exploración de datos en AWS Migration Hub. Utilizar Amazon Athena para ejecutar consultas predefinidas sobre los datos en Amazon S3."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "47.- Una empresa está construyendo una aplicación sin servidor que se ejecuta en una función de AWS Lambda que está vinculada a una VPC. La empresa necesita integrar la aplicación con un nuevo servicio de un proveedor externo. El proveedor externo solo admite solicitudes que provengan de direcciones IPv4 públicas que estén en una lista blanca. La empresa debe proporcionar una única dirección IP pública al proveedor externo antes de que la aplicación pueda comenzar a usar el nuevo servicio. ¿Qué solución permitirá que la aplicación acceda al nuevo servicio?",
        "opciones": [
            "A. Desplegar una puerta de enlace NAT. Asociar una dirección IP elástica con la puerta de enlace NAT. Configurar la VPC para utilizar la puerta de enlace NAT.",
            "B. Desplegar una puerta de enlace de solo salida a internet. Asociar una dirección IP elástica con la puerta de enlace de solo salida a internet. Configurar la interfaz de red elástica en la función Lambda para utilizar la puerta de enlace de solo salida a internet.",
            "C. Desplegar una puerta de enlace a internet. Asociar una dirección IP elástica con la puerta de enlace a internet. Configurar la función Lambda para utilizar la puerta de enlace a internet.",
            "D. Desplegar una puerta de enlace a internet. Asociar una dirección IP elástica con la puerta de enlace a internet. Configurar la ruta predeterminada en la tabla de rutas de la VPC pública para utilizar la puerta de enlace a internet."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "48.- Un arquitecto de soluciones ha desarrollado una aplicación web que utiliza un endpoint regional de Amazon API Gateway y una función AWS Lambda. Los consumidores de la aplicación web están todos cerca de la región de AWS donde se desplegará la aplicación. La función Lambda solo realiza consultas a una base de datos Amazon Aurora MySQL. El arquitecto de soluciones ha configurado la base de datos para tener tres réplicas de lectura. Durante las pruebas, la aplicación no cumple con los requisitos de rendimiento. Bajo una alta carga, la aplicación abre un gran número de conexiones a la base de datos. El arquitecto de soluciones debe mejorar el rendimiento de la aplicación. ¿Qué acciones debe tomar el arquitecto de soluciones para cumplir con estos requisitos? (Elija dos.)",
        "opciones": [
            "A. Usar el endpoint del clúster de la base de datos Aurora.",
            "B. Usar RDS Proxy para configurar un pool de conexiones al endpoint de lectura de la base de datos Aurora.",
            "C. Usar la característica de Concurrencia Provisionada de Lambda.",
            "D. Mover el código para abrir la conexión a la base de datos en la función Lambda fuera del controlador de eventos.",
            "E. Cambiar el endpoint de API Gateway a un endpoint optimizado para el borde."
        ],
        "respuestas_correctas": [
            "D",
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "49.- Una empresa está planeando alojar una aplicación web en AWS y desea equilibrar la carga del tráfico a través de un grupo de instancias Amazon EC2. Uno de los requisitos de seguridad es habilitar la encriptación de extremo a extremo en tránsito entre el cliente y el servidor web. ¿Qué solución cumplirá con este requisito?",
        "opciones": [
            "A. Colocar las instancias EC2 detrás de un Application Load Balancer (ALB). Proporcionar un certificado SSL usando AWS Certificate Manager (ACM) y asociar el certificado SSL con el ALB. Exportar el certificado SSL e instalarlo en cada instancia EC2. Configurar el ALB para escuchar en el puerto 443 y redirigir el tráfico al puerto 443 en las instancias.",
            "B. Asociar las instancias EC2 con un grupo de destino. Proporcionar un certificado SSL usando AWS Certificate Manager (ACM). Crear una distribución de Amazon CloudFront y configurarla para usar el certificado SSL. Configurar CloudFront para usar el grupo de destino como servidor de origen.",
            "C. Colocar las instancias EC2 detrás de un Application Load Balancer (ALB). Proporcionar un certificado SSL usando AWS Certificate Manager (ACM) y asociar el certificado SSL con el ALB. Proporcionar un certificado SSL de un tercero e instalarlo en cada instancia EC2. Configurar el ALB para escuchar en el puerto 443 y redirigir el tráfico al puerto 443 en las instancias.",
            "D. Colocar las instancias EC2 detrás de un Network Load Balancer (NLB). Proporcionar un certificado SSL de un tercero e instalarlo en el NLB y en cada instancia EC2. Configurar el NLB para escuchar en el puerto 443 y redirigir el tráfico al puerto 443 en las instancias."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "50.- Una empresa quiere migrar su entorno de análisis de datos desde las instalaciones locales a AWS. El entorno consta de dos aplicaciones simples de Node.js. Una de las aplicaciones recopila datos de sensores y los carga en una base de datos MySQL. La otra aplicación agrega los datos en informes. Cuando se ejecutan los trabajos de agregación, algunos de los trabajos de carga fallan. La empresa debe resolver el problema de carga de datos. Además, la migración debe realizarse sin interrupciones ni cambios para los clientes de la empresa. ¿Qué debe hacer un arquitecto de soluciones para cumplir con estos requisitos?",
        "opciones": [
            "A. Configurar una base de datos Amazon Aurora MySQL como destino de replicación de la base de datos local. Crear un Aurora Replica para la base de datos Aurora MySQL y mover los trabajos de agregación para que se ejecuten en la Aurora Replica. Configurar puntos de recopilación como funciones AWS Lambda detrás de un Network Load Balancer (NLB) y utilizar Amazon RDS Proxy para escribir en la base de datos Aurora MySQL. Cuando las bases de datos estén sincronizadas, deshabilitar el trabajo de replicación y reiniciar la Aurora Replica como la instancia principal. Apuntar el registro DNS del colector al NLB.",
            "B. Configurar una base de datos Amazon Aurora MySQL. Usar AWS Database Migration Service (AWS DMS) para realizar la replicación de datos continua desde la base de datos local a Aurora. Mover los trabajos de agregación para que se ejecuten en la base de datos Aurora MySQL. Configurar puntos de recopilación detrás de un Application Load Balancer (ALB) como instancias Amazon EC2 en un grupo de Auto Scaling. Cuando las bases de datos estén sincronizadas, apuntar el registro DNS del colector al ALB. Deshabilitar la tarea de sincronización de AWS DMS después de la migración completa de las instalaciones locales a AWS.",
            "C. Configurar una base de datos Amazon Aurora MySQL. Usar AWS Database Migration Service (AWS DMS) para realizar la replicación de datos continua desde la base de datos local a Aurora. Crear un Aurora Replica para la base de datos Aurora MySQL y mover los trabajos de agregación para que se ejecuten en la Aurora Replica. Configurar puntos de recopilación como funciones AWS Lambda detrás de un Application Load Balancer (ALB) y utilizar Amazon RDS Proxy para escribir en la base de datos Aurora MySQL. Cuando las bases de datos estén sincronizadas, apuntar el registro DNS del colector al ALB. Deshabilitar la tarea de sincronización de AWS DMS después de la migración completa de las instalaciones locales a AWS.",
            "D. Configurar una base de datos Amazon Aurora MySQL. Crear un Aurora Replica para la base de datos Aurora MySQL y mover los trabajos de agregación para que se ejecuten en la Aurora Replica. Configurar puntos de recopilación como un flujo de datos de Amazon Kinesis. Usar Amazon Kinesis Data Firehose para replicar los datos en la base de datos Aurora MySQL. Cuando las bases de datos estén sincronizadas, deshabilitar el trabajo de replicación y reiniciar la Aurora Replica como la instancia principal. Apuntar el registro DNS del colector al flujo de datos de Kinesis."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "51.- Una compañía de seguros de salud almacena información de identificación personal (PII) en un bucket de Amazon S3. La compañía usa cifrado del lado del servidor con claves de cifrado administradas por S3 (SSE-S3) para cifrar los objetos. Según un nuevo requisito, todos los objetos actuales y futuros en el bucket de S3 deben estar cifrados con claves administradas por el equipo de seguridad de la compañía. El bucket de S3 no tiene habilitada la versión de objetos. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. En las propiedades del bucket de S3, cambiar el cifrado predeterminado a SSE-S3 con una clave administrada por el cliente. Usar la AWS CLI para volver a cargar todos los objetos en el bucket de S3. Establecer una política de bucket de S3 para denegar solicitudes PutObject no cifradas.",
            "B. En las propiedades del bucket de S3, cambiar el cifrado predeterminado a cifrado del lado del servidor con claves de cifrado administradas por AWS KMS (SSE-KMS). Establecer una política de bucket de S3 para denegar solicitudes PutObject no cifradas. Usar la AWS CLI para volver a cargar todos los objetos en el bucket de S3.",
            "C. En las propiedades del bucket de S3, cambiar el cifrado predeterminado a cifrado del lado del servidor con claves de cifrado administradas por AWS KMS (SSE-KMS). Establecer una política de bucket de S3 para cifrar automáticamente los objetos en las solicitudes GetObject y PutObject.",
            "D. En las propiedades del bucket de S3, cambiar el cifrado predeterminado a AES-256 con una clave administrada por el cliente. Adjuntar una política para denegar solicitudes PutObject no cifradas a cualquier entidad que acceda al bucket de S3. Usar la AWS CLI para volver a cargar todos los objetos en el bucket de S3."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "52.- Una empresa ejecuta una aplicación web en la nube de AWS. La aplicación consiste en contenido dinámico que se genera en un conjunto de instancias de Amazon EC2. Las instancias de EC2 se ejecutan en un grupo de Auto Scaling que está configurado como un grupo de destino para un Application Load Balancer (ALB). La empresa usa una distribución de Amazon CloudFront para distribuir la aplicación a nivel global. La distribución de CloudFront usa el ALB como origen. La empresa utiliza Amazon Route 53 para DNS y ha creado un registro A de www.example.com para la distribución de CloudFront. Un arquitecto de soluciones debe configurar la aplicación para que sea altamente disponible y tolerante a fallos. ¿Qué solución cumple con estos requisitos?",
        "opciones": [
            "A. Aprovisionar una implementación secundaria completa de la aplicación en una región de AWS diferente. Actualizar el registro A de Route 53 para que sea un registro de conmutación por error (failover). Agregar ambas distribuciones de CloudFront como valores. Crear verificaciones de estado en Route 53.",
            "B. Aprovisionar un ALB, un grupo de Auto Scaling y un conjunto de instancias de EC2 en una región de AWS diferente. Actualizar la distribución de CloudFront y crear un segundo origen para el nuevo ALB. Crear un grupo de orígenes en CloudFront para los dos orígenes. Configurar un origen como primario y otro como secundario.",
            "C. Aprovisionar un grupo de Auto Scaling y un conjunto de instancias de EC2 en una región de AWS diferente. Crear un segundo grupo de destino para el nuevo grupo de Auto Scaling en el ALB. Configurar el algoritmo de enrutamiento de conmutación por error en el ALB.",
            "D. Aprovisionar una implementación secundaria completa de la aplicación en una región de AWS diferente. Crear una segunda distribución de CloudFront y agregar la nueva configuración de la aplicación como origen. Crear un acelerador en AWS Global Accelerator. Agregar ambas distribuciones de CloudFront como extremos (endpoints)."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "53.- Una empresa tiene una organización en AWS Organizations que cuenta con un gran número de cuentas de AWS. Una de las cuentas de AWS está designada como cuenta de tránsito y tiene un transit gateway que se comparte con todas las demás cuentas de AWS. Se han configurado conexiones de AWS Site-to-Site VPN entre todas las oficinas globales de la empresa y la cuenta de tránsito. La empresa tiene AWS Config habilitado en todas sus cuentas. El equipo de redes de la empresa necesita administrar de manera centralizada una lista de rangos de direcciones IP internas que pertenecen a las oficinas globales. Los desarrolladores harán referencia a esta lista para acceder de manera segura a sus aplicaciones. ¿Qué solución cumple con estos requisitos con la menor cantidad de sobrecarga operativa?",
        "opciones": [
            "A. Crear un archivo JSON alojado en Amazon S3 que contenga todos los rangos de direcciones IP internas. Configurar un tema de Amazon Simple Notification Service (Amazon SNS) en cada una de las cuentas, que pueda ser invocado cuando se actualice el archivo JSON. Suscribir una función de AWS Lambda al tema de SNS para actualizar todas las reglas de los grupos de seguridad relevantes con los rangos de direcciones IP actualizados.",
            "B. Crear una nueva regla administrada de AWS Config que contenga todos los rangos de direcciones IP internas. Usar la regla para verificar los grupos de seguridad en cada cuenta y garantizar el cumplimiento de la lista de direcciones IP. Configurar la regla para remediar automáticamente cualquier grupo de seguridad que no cumpla con la lista de direcciones IP permitidas.",
            "C. En la cuenta de tránsito, crear una VPC prefix list con todos los rangos de direcciones IP internas. Usar AWS Resource Access Manager para compartir la lista de prefijos con todas las demás cuentas. Utilizar la lista de prefijos compartida para configurar las reglas de los grupos de seguridad en las demás cuentas.",
            "D. En la cuenta de tránsito, crear un grupo de seguridad con todos los rangos de direcciones IP internas. Configurar los grupos de seguridad en las otras cuentas para hacer referencia al grupo de seguridad de la cuenta de tránsito utilizando una referencia anidada de grupo de seguridad con el formato sg-1a2b3c4d."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "54.- Una empresa ejecuta una nueva aplicación como un sitio web estático en Amazon S3. La empresa ha implementado la aplicación en una cuenta de producción de AWS y usa Amazon CloudFront para entregar el sitio web. El sitio web llama a una API REST de Amazon API Gateway. Cada método de la API está respaldado por una función de AWS Lambda. La empresa quiere crear un informe en formato CSV cada 2 semanas para mostrar la memoria recomendada configurada para cada función Lambda de la API, el costo recomendado y la diferencia de precio entre la configuración actual y las recomendaciones. La empresa almacenará los informes en un bucket de S3. ¿Qué solución cumplirá con estos requisitos con el menor tiempo de desarrollo?",
        "opciones": [
            "A. Crear una función Lambda que extraiga los datos de métricas de cada función Lambda de la API desde Amazon CloudWatch Logs para el período de 2 semanas. Organizar los datos en formato tabular. Almacenar los datos en un archivo .csv en un bucket de S3. Crear una regla de Amazon EventBridge para programar la ejecución de la función Lambda cada 2 semanas.",
            "B. Optar por AWS Compute Optimizer. Crear una función Lambda que llame a la operación ExportLambdaFunctionRecommendations. Exportar el archivo .csv a un bucket de S3. Crear una regla de Amazon EventBridge para programar la ejecución de la función Lambda cada 2 semanas.",
            "C. Optar por AWS Compute Optimizer. Configurar métricas de infraestructura mejoradas. Dentro de la consola de Compute Optimizer, programar un trabajo para exportar las recomendaciones de Lambda a un archivo .csv. Almacenar el archivo en un bucket de S3 cada 2 semanas.",
            "D. Comprar el plan de soporte AWS Business para la cuenta de producción. Optar por AWS Compute Optimizer para los chequeos de AWS Trusted Advisor. En la consola de Trusted Advisor, programar un trabajo para exportar los chequeos de optimización de costos a un archivo .csv y almacenarlo en un bucket de S3 cada 2 semanas."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "55.- Una empresa tiene aplicaciones de fábrica y automatización ejecutándose en una sola VPC. Más de 20 aplicaciones operan en una combinación de Amazon EC2, Amazon ECS y Amazon RDS. La empresa tiene ingenieros de software distribuidos en tres equipos. Cada equipo es responsable de los costos y el rendimiento de sus aplicaciones. Los recursos de cada equipo tienen etiquetas (tags) que representan su aplicación y equipo. Los equipos usan IAM para sus actividades diarias. La empresa necesita determinar qué costos de la factura mensual de AWS corresponden a cada aplicación o equipo. También debe generar informes para comparar costos de los últimos 12 meses y prever costos para los próximos 12 meses. Un arquitecto de soluciones debe recomendar una solución de Billing and Cost Management de AWS que proporcione estos informes de costos. ¿Qué combinación de acciones cumplirá con estos requisitos? (Elige tres.)",
        "opciones": [
            "A. Activar las etiquetas de asignación de costos definidas por el usuario que representan la aplicación y el equipo.",
            "B. Activar las etiquetas de asignación de costos generadas por AWS que representan la aplicación y el equipo.",
            "C. Crear una categoría de costos para cada aplicación en Billing and Cost Management.",
            "D. Activar el acceso de IAM a Billing and Cost Management.",
            "E. Crear un presupuesto de costos.",
            "F. Habilitar Cost Explorer."
        ],
        "respuestas_correctas": [
            "C",
            "F",
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "56.- Un cliente de AWS tiene una aplicación web que se ejecuta on-premises. La aplicación web obtiene datos de una API de terceros que está detrás de un firewall. El tercero solo acepta un único bloque CIDR público en la lista de permitidos de cada cliente. El cliente quiere migrar su aplicación web a la nube de AWS. La aplicación se alojará en un conjunto de instancias de Amazon EC2 detrás de un Application Load Balancer (ALB) en una VPC. El ALB se encuentra en subredes públicas. Las instancias EC2 están en subredes privadas. Los NAT Gateways proporcionan acceso a internet a las subredes privadas. ¿Cómo debe un arquitecto de soluciones asegurarse de que la aplicación web pueda seguir llamando a la API de terceros después de la migración?",
        "opciones": [
            "A. Asociar un bloque de direcciones IP públicas propiedad del cliente a la VPC. Habilitar el direccionamiento IP público para las subredes públicas en la VPC.",
            "B. Registrar un bloque de direcciones IP públicas propiedad del cliente en la cuenta de AWS. Crear direcciones IP elásticas (Elastic IPs) a partir del bloque de direcciones y asignarlas a los NAT Gateways en la VPC.",
            "C. Crear direcciones IP elásticas (Elastic IPs) a partir del bloque de direcciones IP propiedad del cliente. Asignar las direcciones IP elásticas estáticas al ALB.",
            "D. Registrar un bloque de direcciones IP públicas propiedad del cliente en la cuenta de AWS. Configurar AWS Global Accelerator para usar direcciones IP elásticas del bloque de direcciones. Configurar el ALB como el endpoint del acelerador."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "57.- Una empresa con varias cuentas de AWS está utilizando AWS Organizations y políticas de control de servicio (SCPs). Un administrador creó la siguiente SCP y la ha adjuntado a una unidad organizativa (OU) que contiene la cuenta de AWS 1111-1111-1111: Los desarrolladores que trabajan en la cuenta 1111-1111-1111 se quejan de que no pueden crear buckets de Amazon S3. ¿Cómo debería el administrador solucionar este problema?",
        "opciones": [
            "A. Agregar s3:CreateBucket con el efecto Allow a la SCP.",
            "B. Eliminar la cuenta de la OU y adjuntar la SCP directamente a la cuenta 1111-1111-1111.",
            "C. Indicar a los desarrolladores que agreguen permisos de Amazon S3 a sus entidades de IAM.",
            "D. Eliminar la SCP de la cuenta 1111-1111-1111."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": [{
            "respuesta": "",
            "url": "images/image57.png"
        }]
    },
    {
        "pregunta": "58.- La empresa tiene una aplicación monolítica que es crítica para el negocio. La empresa aloja la aplicación en una instancia de Amazon EC2 que ejecuta Amazon Linux 2. El equipo de aplicaciones de la empresa recibe una directiva del departamento legal para realizar una copia de seguridad de los datos del volumen cifrado de Amazon Elastic Block Store (Amazon EBS) de la instancia en un bucket de Amazon S3. El equipo de aplicaciones no tiene la clave SSH administrativa para la instancia. La aplicación debe seguir sirviendo a los usuarios. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Adjuntar un rol a la instancia con permisos para escribir en Amazon S3. Usar la opción de AWS Systems Manager Session Manager para obtener acceso a la instancia y ejecutar comandos para copiar los datos en Amazon S3.",
            "B. Crear una imagen de la instancia con la opción de reinicio activada. Lanzar una nueva instancia EC2 desde la imagen. Adjuntar un rol a la nueva instancia con permisos para escribir en Amazon S3. Ejecutar un comando para copiar los datos en Amazon S3.",
            "C. Tomar una instantánea del volumen EBS usando Amazon Data Lifecycle Manager (Amazon DLM). Copiar los datos en Amazon S3.",
            "D. Crear una imagen de la instancia. Lanzar una nueva instancia EC2 desde la imagen. Adjuntar un rol a la nueva instancia con permisos para escribir en Amazon S3. Ejecutar un comando para copiar los datos en Amazon S3."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "59.- Un arquitecto de soluciones necesita copiar datos de un bucket de Amazon S3 en una cuenta de AWS a un nuevo bucket S3 en una nueva cuenta de AWS. El arquitecto de soluciones debe implementar una solución que utilice la AWS CLI. ¿Qué combinación de pasos copiará correctamente los datos? (Elija tres.)",
        "opciones": [
            "A. Crear una política de bucket para permitir que el bucket de origen liste su contenido y ponga objetos y configure ACL de objetos en el bucket de destino. Adjuntar la política del bucket al bucket de destino.",
            "B. Crear una política de bucket para permitir que un usuario en la cuenta de destino liste el contenido del bucket de origen y lea los objetos del bucket de origen. Adjuntar la política del bucket al bucket de origen.",
            "C. Crear una política IAM en la cuenta de origen. Configurar la política para permitir que un usuario en la cuenta de origen liste el contenido y obtenga objetos en el bucket de origen, y para listar el contenido, poner objetos y establecer ACL de objetos en el bucket de destino. Adjuntar la política al usuario.",
            "D. Crear una política IAM en la cuenta de destino. Configurar la política para permitir que un usuario en la cuenta de destino liste el contenido y obtenga objetos en el bucket de origen, y para listar el contenido, poner objetos y establecer ACL de objetos en el bucket de destino. Adjuntar la política al usuario.",
            "E. Ejecutar el comando aws s3 sync como un usuario en la cuenta de origen. Especificar los buckets de origen y destino para copiar los datos.",
            "F. Ejecutar el comando aws s3 sync como un usuario en la cuenta de destino. Especificar los buckets de origen y destino para copiar los datos."
        ],
        "respuestas_correctas": [
            "F",
            "D",
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "60.- Una empresa construyó una aplicación basada en AWS Lambda desplegada en una pila de AWS CloudFormation. La última versión de producción de la aplicación web introdujo un problema que resultó en una interrupción de varios minutos. Un arquitecto de soluciones debe ajustar el proceso de despliegue para admitir un lanzamiento canario. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Crear un alias para cada nueva versión desplegada de la función Lambda. Usar el comando AWS CLI update-alias con el parámetro routing-config para distribuir la carga.",
            "B. Desplegar la aplicación en una nueva pila de CloudFormation. Usar una política de enrutamiento ponderado de Amazon Route 53 para distribuir la carga.",
            "C. Crear una versión para cada nueva función Lambda desplegada. Usar el comando AWS CLI update-function-configuration con el parámetro routing-config para distribuir la carga.",
            "D. Configurar AWS CodeDeploy y usar CodeDeployDefault.OneAtATime en la configuración de despliegue para distribuir la carga."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "61.- Una empresa financiera aloja un lago de datos en Amazon S3. La empresa recibe registros de datos financieros a través de SFTP cada noche de varios terceros. La empresa ejecuta su propio servidor SFTP en una instancia de Amazon EC2 en una subred pública de una VPC. Después de que los archivos se cargan, se mueven al Data lake mediante un trabajo cron que se ejecuta en la misma instancia. El servidor SFTP es accesible a través de DNS sftp.example.com mediante el uso de Amazon Route 53. ¿Qué debe hacer un arquitecto de soluciones para mejorar la fiabilidad y escalabilidad de la solución SFTP?.",
        "opciones": [
            "A. Mover la instancia EC2 a un grupo de Auto Scaling. Colocar la instancia EC2 detrás de un Application Load Balancer (ALB). Actualizar el registro DNS sftp.example.com en Route 53 para que apunte al ALB.",
            "B. Migrar el servidor SFTP a AWS Transfer for SFTP. Actualizar el registro DNS sftp.example.com en Route 53 para que apunte al nombre de host del endpoint del servidor.",
            "C. Migrar el servidor SFTP a un gateway de archivos en AWS Storage Gateway. Actualizar el registro DNS sftp.example.com en Route 53 para que apunte al endpoint del gateway de archivos.",
            "D. Colocar la instancia EC2 detrás de un Network Load Balancer (NLB). Actualizar el registro DNS sftp.example.com en Route 53 para que apunte al NLB."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "62.- Una empresa quiere migrar una aplicación a Amazon EC2 desde VMware Infrastructure que se ejecuta en un centro de datos local. Un arquitecto de soluciones debe preservar el software y la configuración durante la migración. ¿Qué debe hacer el arquitecto de soluciones para cumplir con estos requisitos?",
        "opciones": [
            "A. Configurar el agente de AWS DataSync para comenzar a replicar el almacenamiento de datos a Amazon FSx para Windows File Server. Usar el recurso compartido SMB para alojar el almacenamiento de datos de VMware. Usar VM Import/Export para mover las máquinas virtuales a Amazon EC2.",
            "B. Usar el cliente VMware vSphere para exportar la aplicación como una imagen en formato Open Virtualization Format (OVF). Crear un bucket de Amazon S3 para almacenar la imagen en la región de AWS de destino. Crear y aplicar un rol IAM para VM Import. Usar la CLI de AWS para ejecutar el comando de importación de EC2.",
            "C. Configurar el servicio de archivos de AWS Storage Gateway para exportar un recurso compartido CIFS (Common Internet File System). Crear una copia de seguridad en la carpeta compartida. Iniciar sesión en la consola de administración de AWS y crear una AMI a partir de la copia de seguridad. Lanzar una instancia EC2 basada en la AMI.",
            "D. Crear una activación de instancia administrada para un entorno híbrido en AWS Systems Manager. Descargar e instalar el agente de Systems Manager en la máquina virtual local. Registrar la máquina virtual con Systems Manager para que sea una instancia administrada. Usar AWS Backup para crear una instantánea de la máquina virtual y crear una AMI. Lanzar una instancia EC2 basada en la AMI."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "63.- Una empresa de procesamiento de videos tiene una aplicación que descarga imágenes de un bucket de Amazon S3, procesa las imágenes, almacena una imagen transformada en un segundo bucket de S3 y actualiza los metadatos sobre la imagen en una tabla de Amazon DynamoDB. La aplicación está escrita en Node.js y se ejecuta mediante una función de AWS Lambda. La función Lambda se invoca cuando se carga una nueva imagen en Amazon S3. La aplicación funcionó sin problemas durante un tiempo. Sin embargo, el tamaño de las imágenes ha aumentado significativamente. Ahora la función Lambda falla con frecuencia debido a errores de tiempo de espera. El tiempo de espera de la función está configurado en su valor máximo. Un arquitecto de soluciones necesita refactorizar la arquitectura de la aplicación para evitar fallas en las invocaciones. La empresa no quiere administrar la infraestructura subyacente. ¿Qué combinación de pasos debe tomar el arquitecto de soluciones para cumplir con estos requisitos? (Elija dos.)",
        "opciones": [
            "A. Modificar la implementación de la aplicación creando una imagen de Docker que contenga el código de la aplicación. Publicar la imagen en Amazon Elastic Container Registry (Amazon ECR).",
            "B. Crear una nueva definición de tarea de Amazon Elastic Container Service (Amazon ECS) con un tipo de compatibilidad de AWS Fargate. Configurar la definición de tarea para usar la nueva imagen en Amazon Elastic Container Registry (Amazon ECR). Ajustar la función Lambda para invocar una tarea de ECS mediante la definición de tarea de ECS cuando llegue un nuevo archivo a Amazon S3.",
            "C. Crear una máquina de estados de AWS Step Functions con un estado paralelo para invocar la función Lambda. Aumentar la concurrencia aprovisionada de la función Lambda.",
            "D. Crear una nueva definición de tarea de Amazon Elastic Container Service (Amazon ECS) con un tipo de compatibilidad de Amazon EC2. Configurar la definición de tarea para usar la nueva imagen en Amazon Elastic Container Registry (Amazon ECR). Ajustar la función Lambda para invocar una tarea de ECS mediante la definición de tarea de ECS cuando llegue un nuevo archivo a Amazon S3.",
            "E. Modificar la aplicación para almacenar imágenes en Amazon Elastic File System (Amazon EFS) y almacenar metadatos en una instancia de base de datos Amazon RDS. Ajustar la función Lambda para montar el recurso compartido de EFS."
        ],
        "respuestas_correctas": [
            "B",
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "64.- Una empresa tiene una organización en AWS Organizations. La empresa está utilizando AWS Control Tower para desplegar una zona de aterrizaje para la organización. La empresa desea implementar gobernanza y cumplimiento de políticas. La empresa debe implementar una política que detecte las instancias de Amazon RDS DB que no están cifradas en reposo en la unidad organizativa (OU) de producción de la empresa. ¿Qué solución cumplirá con este requisito?",
        "opciones": [
            "A. Activar las guardrails obligatorias en AWS Control Tower. Aplicar las guardrails obligatorias a la OU de producción.",
            "B. Habilitar la guardrail apropiada de la lista de guardrails fuertemente recomendadas en AWS Control Tower. Aplicar la guardrail a la OU de producción.",
            "C. Usar AWS Config para crear una nueva guardrail obligatoria. Aplicar la regla a todas las cuentas en la OU de producción.",
            "D. Crear una SCP personalizada en AWS Control Tower. Aplicar la SCP a la OU de producción."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "65.- Una empresa emergente aloja una flota de instancias de Amazon EC2 en subredes privadas utilizando la última AMI de Amazon Linux 2. Los ingenieros de la empresa dependen en gran medida del acceso SSH a las instancias para la solución de problemas. La arquitectura existente de la empresa incluye lo siguiente: Una VPC con subredes privadas y públicas, y una puerta de enlace NAT. VPN Site-to-Site para la conectividad con el entorno local. Grupos de seguridad de EC2 con acceso SSH directo desde el entorno local. La empresa necesita aumentar los controles de seguridad alrededor del acceso SSH y proporcionar auditoría de los comandos ejecutados por los ingenieros. ¿Qué estrategia debe usar un arquitecto de soluciones?",
        "opciones": [
            "A. Instalar y configurar EC2 Instance Connect en la flota de instancias EC2. Eliminar todas las reglas del grupo de seguridad adjuntas a las instancias EC2 que permitan TCP entrante en el puerto 22. Aconsejar a los ingenieros que accedan remotamente a las instancias utilizando el CLI de EC2 Instance Connect.",
            "B. Actualizar los grupos de seguridad de EC2 para permitir solo TCP entrante en el puerto 22 a las direcciones IP de los dispositivos de los ingenieros. Instalar el agente de Amazon CloudWatch en todas las instancias EC2 y enviar los registros de auditoría del sistema operativo a CloudWatch Logs.",
            "C. Actualizar los grupos de seguridad de EC2 para permitir solo TCP entrante en el puerto 22 a las direcciones IP de los dispositivos de los ingenieros. Habilitar AWS Config para los cambios de recursos de grupos de seguridad de EC2. Habilitar AWS Firewall Manager y aplicar una política de grupos de seguridad que remedie automáticamente los cambios en las reglas.",
            "D. Crear un rol IAM con la política administrada AmazonSSMManagedInstanceCore adjunta. Adjuntar el rol IAM a todas las instancias EC2. Eliminar todas las reglas del grupo de seguridad adjuntas a las instancias EC2 que permitan TCP entrante en el puerto 22. Hacer que los ingenieros instalen el complemento de AWS Systems Manager Session Manager en sus dispositivos y accedan remotamente a las instancias utilizando la llamada API start-session de Systems Manager."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "66.- Una empresa que usa AWS Organizations permite que los desarrolladores experimenten en AWS. Como parte de la zona de aterrizaje que la empresa ha desplegado, los desarrolladores usan su dirección de correo electrónico corporativa para solicitar una cuenta. La empresa desea asegurarse de que los desarrolladores no lancen servicios costosos ni ejecuten servicios innecesarios. La empresa debe darle a los desarrolladores un presupuesto mensual fijo para limitar sus costos de AWS. ¿Qué combinación de pasos satisfará estos requisitos? (Elija tres.)",
        "opciones": [
            "A. Crear un SCP para establecer un límite de uso mensual fijo para la cuenta. Aplicar el SCP a las cuentas de los desarrolladores.",
            "B. Usar AWS Budgets para crear un presupuesto mensual fijo para la cuenta de cada desarrollador como parte del proceso de creación de la cuenta.",
            "C. Crear un SCP para denegar el acceso a servicios y componentes costosos. Aplicar el SCP a las cuentas de los desarrolladores.",
            "D. Crear una política de IAM para denegar el acceso a servicios y componentes costosos. Aplicar la política de IAM a las cuentas de los desarrolladores.",
            "E. Crear una acción de alerta de AWS Budgets para finalizar los servicios cuando se alcance la cantidad presupuestada. Configurar la acción para finalizar todos los servicios.",
            "F. Crear una acción de alerta de AWS Budgets para enviar una notificación de Amazon Simple Notification Service (Amazon SNS) cuando se alcance la cantidad presupuestada. Invocar una función de AWS Lambda para finalizar todos los servicios."
        ],
        "respuestas_correctas": [
            "C",
            "F",
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "67.- Una empresa tiene aplicaciones en una cuenta de AWS llamada Source. La cuenta está en una organización de AWS Organizations. Una de las aplicaciones usa funciones de AWS Lambda y almacena datos de inventario en una base de datos Amazon Aurora. La aplicación despliega las funciones de Lambda mediante un paquete de despliegue. La empresa ha configurado copias de seguridad automatizadas para Aurora. La empresa desea migrar las funciones de Lambda y la base de datos Aurora a una nueva cuenta de AWS llamada Target. La aplicación procesa datos críticos, por lo que la empresa debe minimizar el tiempo de inactividad. ¿Qué solución satisfará estos requisitos?",
        "opciones": [
            "A. Descargar el paquete de despliegue de la función Lambda desde la cuenta Source. Usar el paquete de despliegue y crear nuevas funciones Lambda en la cuenta Target. Compartir la instantánea automática del clúster de Aurora con la cuenta Target.",
            "B. Descargar el paquete de despliegue de la función Lambda desde la cuenta Source. Usar el paquete de despliegue y crear nuevas funciones Lambda en la cuenta Target. Compartir el clúster de Aurora con la cuenta Target utilizando AWS Resource Access Manager (AWS RAM). Otorgar permiso a la cuenta Target para clonar el clúster de Aurora.",
            "C. Usar AWS Resource Access Manager (AWS RAM) para compartir las funciones Lambda y el clúster de Aurora con la cuenta Target. Otorgar permiso a la cuenta Target para clonar el clúster de Aurora.",
            "D. Usar AWS Resource Access Manager (AWS RAM) para compartir las funciones Lambda con la cuenta Target. Compartir la instantánea automática del clúster de Aurora con la cuenta Target."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "68.- Una empresa ejecuta un script en Python en una instancia de Amazon EC2 para procesar datos. El script se ejecuta cada 10 minutos. El script ingiere archivos de un bucket de Amazon S3 y procesa los archivos. En promedio, el script tarda aproximadamente 5 minutos en procesar cada archivo. El script no volverá a procesar un archivo que ya haya procesado. La empresa revisó las métricas de Amazon CloudWatch y notó que la instancia de EC2 está inactiva aproximadamente el 40% del tiempo debido a la velocidad de procesamiento de los archivos. La empresa desea hacer que la carga de trabajo sea altamente disponible y escalable. La empresa también quiere reducir la sobrecarga de administración a largo plazo. ¿Cuál de las siguientes soluciones cumplirá estos requisitos de manera MÁS rentable?",
        "opciones": [
            "A. Migrar el script de procesamiento de datos a una función de AWS Lambda. Usar una notificación de evento de S3 para invocar la función Lambda y procesar los objetos cuando la empresa cargue los objetos.",
            "B. Crear una cola de Amazon Simple Queue Service (Amazon SQS). Configurar Amazon S3 para enviar notificaciones de eventos a la cola SQS. Crear un grupo de Auto Scaling de EC2 con un tamaño mínimo de una instancia. Actualizar el script de procesamiento de datos para sondear la cola SQS. Procesar los objetos S3 que el mensaje de SQS identifique.",
            "C. Migrar el script de procesamiento de datos a una imagen de contenedor. Ejecutar el contenedor de procesamiento de datos en una instancia de EC2. Configurar el contenedor para sondear el bucket de S3 en busca de nuevos objetos y procesar los objetos resultantes.",
            "D. Migrar el script de procesamiento de datos a una imagen de contenedor que se ejecute en Amazon Elastic Container Service (Amazon ECS) en AWS Fargate. Crear una función de AWS Lambda que llame a la operación RunTaskAPI de Fargate cuando el contenedor procese el archivo. Usar una notificación de evento de S3 para invocar la función Lambda."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "69.- Una empresa de servicios financieros en América del Norte planea lanzar una nueva aplicación web en línea para sus clientes en AWS. La empresa lanzará la aplicación en la región us-east-1 en instancias de Amazon EC2. La aplicación debe ser altamente disponible y debe escalar dinámicamente para satisfacer el tráfico de usuarios. La empresa también quiere implementar un entorno de recuperación ante desastres para la aplicación en la región us-west-1 utilizando un conmutador por error activo-pasivo. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Crear una VPC en us-east-1 y una VPC en us-west-1. Configurar peering entre VPCs. En la VPC de us-east-1, crear un Application Load Balancer (ALB) que se extienda a través de múltiples zonas de disponibilidad en ambas VPCs. Crear un grupo de Auto Scaling que despliegue las instancias EC2 a través de las múltiples zonas de disponibilidad en ambas VPCs. Colocar el grupo de Auto Scaling detrás del ALB.",
            "B. Crear una VPC en us-east-1 y una VPC en us-west-1. En la VPC de us-east-1, crear un Application Load Balancer (ALB) que se extienda a través de múltiples zonas de disponibilidad en esa VPC. Crear un grupo de Auto Scaling que despliegue las instancias EC2 a través de las múltiples zonas de disponibilidad en la VPC de us-east-1. Colocar el grupo de Auto Scaling detrás del ALB. Configurar la misma configuración en la VPC de us-west-1. Crear una zona alojada de Amazon Route 53. Crear registros separados para cada ALB. Habilitar las comprobaciones de salud para asegurar alta disponibilidad entre las regiones.",
            "C. Crear una VPC en us-east-1 y una VPC en us-west-1. En la VPC de us-east-1, crear un Application Load Balancer (ALB) que se extienda a través de múltiples zonas de disponibilidad en esa VPC. Crear un grupo de Auto Scaling que despliegue las instancias EC2 a través de las múltiples zonas de disponibilidad en la VPC de us-east-1. Colocar el grupo de Auto Scaling detrás del ALB. Configurar la misma configuración en la VPC de us-west-1. Crear una zona alojada de Amazon Route 53. Crear registros separados para cada ALB. Habilitar las comprobaciones de salud y configurar una política de enrutamiento por conmutación por error para cada registro.",
            "D. Crear una VPC en us-east-1 y una VPC en us-west-1. Configurar peering entre VPCs. En la VPC de us-east-1, crear un Application Load Balancer (ALB) que se extienda a través de múltiples zonas de disponibilidad en ambas VPCs. Crear un grupo de Auto Scaling que despliegue las instancias EC2 a través de las múltiples zonas de disponibilidad en ambas VPCs. Colocar el grupo de Auto Scaling detrás del ALB. Crear una zona alojada de Amazon Route 53. Crear un registro para el ALB."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "70.- Una empresa tiene un entorno con una única cuenta de AWS. Un arquitecto de soluciones está revisando el entorno para recomendar qué podría mejorar específicamente en términos de acceso a la Consola de Administración de AWS. Los trabajadores de soporte de TI de la empresa actualmente acceden a la consola para tareas administrativas, autenticándose con usuarios IAM con nombre que han sido asignados a su rol laboral. Los trabajadores de soporte de TI ya no quieren mantener tanto sus cuentas de Active Directory como las de usuario IAM. Quieren poder acceder a la consola utilizando sus credenciales existentes de Active Directory. El arquitecto de soluciones está utilizando AWS IAM Identity Center (AWS Single Sign-On) para implementar esta funcionalidad. ¿Cuál solución cumplirá con estos requisitos de la manera más rentable?",
        "opciones": [
            "A. Crear una organización en AWS Organizations. Activar la función IAM Identity Center en Organizations. Crear y configurar un directorio en AWS Directory Service para Microsoft Active Directory (AWS Managed Microsoft AD) con una relación de confianza bidireccional con el Active Directory local de la empresa. Configurar IAM Identity Center y establecer el directorio AWS Managed Microsoft AD como la fuente de identidad. Crear conjuntos de permisos y asignarlos a los grupos existentes dentro del directorio AWS Managed Microsoft AD.",
            "B. Crear una organización en AWS Organizations. Activar la función IAM Identity Center en Organizations. Crear y configurar un AD Connector para conectarse al Active Directory local de la empresa. Configurar IAM Identity Center y seleccionar el AD Connector como la fuente de identidad. Crear conjuntos de permisos y asignarlos a los grupos existentes dentro del Active Directory de la empresa.",
            "C. Crear una organización en AWS Organizations. Activar todas las características para la organización. Crear y configurar un directorio en AWS Directory Service para Microsoft Active Directory (AWS Managed Microsoft AD) con una relación de confianza bidireccional con el Active Directory local de la empresa. Configurar IAM Identity Center y seleccionar el directorio AWS Managed Microsoft AD como la fuente de identidad. Crear conjuntos de permisos y asignarlos a los grupos existentes dentro del directorio AWS Managed Microsoft AD.",
            "D. Crear una organización en AWS Organizations. Activar todas las características para la organización. Crear y configurar un AD Connector para conectarse al Active Directory local de la empresa. Configurar IAM Identity Center y establecer el AD Connector como la fuente de identidad. Crear conjuntos de permisos y asignarlos a los grupos existentes dentro del Active Directory de la empresa."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "71.- Una empresa de transmisión de videos lanzó recientemente una aplicación móvil para compartir videos. La aplicación carga varios archivos a un bucket de Amazon S3 en la región us-east-1. Los archivos tienen tamaños que van desde 1 GB hasta 10 GB. Los usuarios que acceden a la aplicación desde Australia han experimentado cargas que toman mucho tiempo. A veces, los archivos no se cargan completamente para estos usuarios. Un arquitecto de soluciones debe mejorar el rendimiento de la aplicación para estas cargas. ¿Qué soluciones cumplirán con estos requisitos? (Elija dos.)",
        "opciones": [
            "A. Habilitar S3 Transfer Acceleration en el bucket de S3. Configurar la aplicación para usar el endpoint de Transfer Acceleration para las cargas.",
            "B. Configurar un bucket de S3 en cada región para recibir las cargas. Usar S3 Cross-Region Replication para copiar los archivos al bucket de S3 de distribución.",
            "C. Configurar Amazon Route 53 con enrutamiento basado en latencia para dirigir las cargas a la región del bucket de S3 más cercana.",
            "D. Configurar la aplicación para dividir los archivos de video en partes. Usar una carga multipart para transferir los archivos a Amazon S3.",
            "E. Modificar la aplicación para agregar prefijos aleatorios a los archivos antes de cargarlos."
        ],
        "respuestas_correctas": [
            "D",
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "72.- Una aplicación está utilizando una instancia de base de datos Amazon RDS para MySQL en Multi-AZ en la región us-east-1. Después de una prueba de failover, la aplicación perdió las conexiones con la base de datos y no pudo restablecer las conexiones. Después de reiniciar la aplicación, la aplicación restableció las conexiones. Un arquitecto de soluciones debe implementar una solución para que la aplicación pueda restablecer las conexiones con la base de datos sin requerir un reinicio. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Crear una instancia de base de datos Amazon Aurora MySQL Serverless v1. Migrar la instancia de base de datos RDS a la instancia de base de datos Aurora Serverless v1. Actualizar la configuración de conexión en la aplicación para que apunte al endpoint de lectura de Aurora.",
            "B. Crear un proxy RDS. Configurar el endpoint de RDS existente como un objetivo. Actualizar la configuración de conexión en la aplicación para que apunte al endpoint del proxy RDS.",
            "C. Crear un clúster de base de datos Amazon Aurora MySQL de dos nodos. Migrar la instancia de base de datos RDS al clúster de Aurora. Crear un proxy RDS. Configurar el endpoint de RDS existente como un objetivo. Actualizar la configuración de conexión en la aplicación para que apunte al endpoint del proxy RDS.",
            "D. Crear un bucket de Amazon S3. Exportar la base de datos a Amazon S3 utilizando el Servicio de Migración de Bases de Datos de AWS (AWS DMS). Configurar Amazon Athena para usar el bucket de S3 como almacén de datos. Instalar el controlador de conectividad de base de datos (ODBC) más reciente para la aplicación. Actualizar la configuración de conexión en la aplicación para que apunte al endpoint de Athena."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "73.- Una empresa está construyendo una solución en la nube de AWS. Miles de dispositivos se conectarán a la solución y enviarán datos. Cada dispositivo debe ser capaz de enviar y recibir datos en tiempo real a través del protocolo MQTT. Cada dispositivo debe autenticarse utilizando un certificado X.509 único. ¿Qué solución cumplirá con estos requisitos con el MENOR esfuerzo operativo?",
        "opciones": [
            "A. Configurar AWS IoT Core. Para cada dispositivo, crear una cola correspondiente en Amazon MQ y aprovisionar un certificado. Conectar cada dispositivo a Amazon MQ.",
            "B. Crear un Network Load Balancer (NLB) y configurarlo con un autorizador de AWS Lambda. Ejecutar un broker MQTT en instancias de Amazon EC2 en un grupo de Auto Scaling. Configurar el grupo de Auto Scaling como el objetivo del NLB. Conectar cada dispositivo al NLB.",
            "C. Configurar AWS IoT Core. Para cada dispositivo, crear un thing correspondiente de AWS IoT y aprovisionar un certificado. Conectar cada dispositivo a AWS IoT Core.",
            "D. Configurar una API HTTP de Amazon API Gateway y un Network Load Balancer (NLB). Crear integración entre API Gateway y el NLB. Configurar un autorizador de certificados TLS mutuos en la API HTTP. Ejecutar un broker MQTT en una instancia de Amazon EC2 que sea el objetivo del NLB. Conectar cada dispositivo al NLB."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "74.- Una empresa está ejecutando varias cargas de trabajo en una única cuenta de AWS. Una nueva política de la empresa establece que los ingenieros solo pueden aprovisionar recursos aprobados y que deben usar AWS CloudFormation para aprovisionar estos recursos. Un arquitecto de soluciones necesita crear una solución para hacer cumplir esta nueva restricción en el rol IAM que los ingenieros usan para acceder. ¿Qué debe hacer el arquitecto de soluciones para crear la solución?",
        "opciones": [
            "A. Subir plantillas de AWS CloudFormation que contengan los recursos aprobados a un bucket de Amazon S3. Actualizar la política IAM para el rol IAM de los ingenieros para permitir solo el acceso a Amazon S3 y AWS CloudFormation. Usar plantillas de AWS CloudFormation para aprovisionar recursos.",
            "B. Actualizar la política IAM para el rol IAM de los ingenieros con permisos que solo permitan el aprovisionamiento de recursos aprobados y AWS CloudFormation. Usar plantillas de AWS CloudFormation para crear pilas con recursos aprobados.",
            "C. Actualizar la política IAM para el rol IAM de los ingenieros con permisos que solo permitan acciones de AWS CloudFormation. Crear una nueva política IAM con permisos para aprovisionar recursos aprobados y asignar la política a un nuevo rol de servicio IAM. Asignar el rol de servicio IAM a AWS CloudFormation durante la creación de la pila.",
            "D. Aprovisionar recursos en pilas de AWS CloudFormation. Actualizar la política IAM para el rol IAM de los ingenieros para permitir solo el acceso a su propia pila de AWS CloudFormation."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "75.- Un arquitecto de soluciones está diseñando la arquitectura de almacenamiento y recuperación de datos para una nueva aplicación que una empresa lanzará próximamente. La aplicación está diseñada para ingerir millones de pequeños registros por minuto desde dispositivos de todo el mundo. Cada registro tiene un tamaño inferior a 4 KB y necesita ser almacenado en un lugar duradero donde se pueda recuperar con baja latencia. Los datos son efímeros y se requiere que la empresa los almacene solo durante 120 días, después de lo cual se pueden eliminar. El arquitecto de soluciones calcula que, durante el transcurso de un año, los requisitos de almacenamiento serían de aproximadamente 10-15 TB. ¿Cuál estrategia de almacenamiento es la MÁS rentable y cumple con los requisitos de diseño?",
        "opciones": [
            "A. Diseñar la aplicación para almacenar cada registro entrante como un único archivo .csv en un bucket de Amazon S3 para permitir una recuperación indexada. Configurar una política de ciclo de vida para eliminar los datos que tengan más de 120 días.",
            "B. Diseñar la aplicación para almacenar cada registro entrante en una tabla de Amazon DynamoDB correctamente configurada para la escala. Configurar la función Time to Live (TTL) de DynamoDB para eliminar los registros que tengan más de 120 días.",
            "C. Diseñar la aplicación para almacenar cada registro entrante en una única tabla en una base de datos Amazon RDS MySQL. Ejecutar un trabajo cron nocturno que ejecute una consulta para eliminar cualquier registro que tenga más de 120 días.",
            "D. Diseñar la aplicación para agrupar los registros entrantes antes de escribirlos en un bucket de Amazon S3. Actualizar los metadatos del objeto para que contenga la lista de registros del lote y utilizar la función de búsqueda de metadatos de Amazon S3 para recuperar los datos. Configurar una política de ciclo de vida para eliminar los datos después de 120 días."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "76.- Una empresa de comercio minorista está alojando un sitio web de comercio electrónico en AWS a través de múltiples regiones de AWS. La empresa desea que el sitio web esté operativo en todo momento para las compras en línea. El sitio web almacena datos en una instancia de base de datos Amazon RDS para MySQL. ¿Qué solución proporcionará la mayor disponibilidad para la base de datos?",
        "opciones": [
            "A. Configurar copias de seguridad automatizadas en Amazon RDS. En caso de interrupción, promover una copia de seguridad automatizada para que sea una instancia de base de datos independiente. Dirigir el tráfico de base de datos hacia la instancia de base de datos promovida. Crear una réplica de lectura de reemplazo que tenga la instancia de base de datos promovida como su fuente.",
            "B. Configurar tablas globales y réplicas de lectura en Amazon RDS. Activar el alcance entre regiones. En caso de interrupción, usar AWS Lambda para copiar las réplicas de lectura de una región a otra.",
            "C. Configurar tablas globales y copias de seguridad automatizadas en Amazon RDS. En caso de interrupción, usar AWS Lambda para copiar las réplicas de lectura de una región a otra.",
            "D. Configurar réplicas de lectura en Amazon RDS. En caso de interrupción, promover una réplica de lectura entre regiones para que sea una instancia de base de datos independiente. Dirigir el tráfico de base de datos hacia la instancia de base de datos promovida. Crear una réplica de lectura de reemplazo que tenga la instancia de base de datos promovida como su fuente."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "77.- Example Corp. tiene un centro de datos on-premises y una VPC llamada VPC A en la cuenta de AWS de Example Corp. La red on-premises se conecta a VPC A a través de una VPN Site-to-Site de AWS. Los servidores on-premises pueden acceder correctamente a VPC A. Example Corp. acaba de adquirir AnyCompany, que tiene una VPC llamada VPC B. No existe superposición de direcciones IP entre estas redes. Example Corp. ha establecido un peering entre VPC A y VPC B. Example Corp. quiere conectarse desde sus servidores on-premises a VPC B. Example Corp. ya ha configurado correctamente las ACL de red y los grupos de seguridad. ¿Qué solución cumplirá con este requisito con el MENOR esfuerzo operativo?",
        "opciones": [
            "A. Crear un transit gateway. Conectar la VPN Site-to-Site, VPC A y VPC B al transit gateway. Actualizar las tablas de rutas del transit gateway para todas las redes, agregando rutas de rango IP para todas las demás redes.",
            "B. Crear un transit gateway. Establecer una conexión VPN Site-to-Site entre la red on-premises y VPC B, y conectar la conexión VPN al transit gateway. Agregar una ruta para dirigir el tráfico hacia las VPC emparejadas, y agregar una regla de autorización para dar acceso a los clientes a las VPC A y B.",
            "C. Actualizar las tablas de rutas para la VPN Site-to-Site y ambas VPC para las tres redes. Configurar la propagación de BGP para las tres redes. Esperar hasta 5 minutos a que finalice la propagación de BGP.",
            "D. Modificar la definición del virtual private gateway de la VPN Site-to-Site para incluir VPC A y VPC B. Dividir los dos routers del virtual private gateway entre las dos VPC."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "78.- Una empresa completó recientemente la migración de un centro de datos local a la nube de AWS utilizando una estrategia de replatforming. Uno de los servidores migrados está ejecutando un servicio legado de Simple Mail Transfer Protocol (SMTP) del cual depende una aplicación crítica. La aplicación envía mensajes de correo electrónico salientes a los clientes de la empresa. El servidor SMTP heredado no admite cifrado TLS y usa el puerto TCP 25. La aplicación solo puede usar SMTP. La empresa decide usar Amazon Simple Email Service (Amazon SES) y descontinuar el servidor SMTP heredado. La empresa ha creado y validado el dominio de SES. La empresa ha levantado los límites de SES. ¿Qué debe hacer la empresa para modificar la aplicación y enviar mensajes de correo electrónico desde Amazon SES?",
        "opciones": [
            "A. Configurar la aplicación para conectarse a Amazon SES usando TLS Wrapper. Crear un rol de IAM que tenga permisos ses:SendEmail y ses:SendRawEmail. Adjuntar el rol de IAM a una instancia de Amazon EC2.",
            "B. Configurar la aplicación para conectarse a Amazon SES usando STARTTLS. Obtener las credenciales SMTP de Amazon SES. Usar las credenciales para autenticarse con Amazon SES.",
            "C. Configurar la aplicación para usar la API de SES para enviar mensajes de correo electrónico. Crear un rol de IAM que tenga permisos ses:SendEmail y ses:SendRawEmail. Usar el rol de IAM como un rol de servicio para Amazon SES.",
            "D. Configurar la aplicación para usar los SDK de AWS para enviar mensajes de correo electrónico. Crear un usuario de IAM para Amazon SES. Generar claves de acceso a la API. Usar las claves de acceso para autenticarse con Amazon SES."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "79.- Una empresa adquirió recientemente varias otras compañías. Cada compañía tenía una cuenta de AWS separada con un método diferente de facturación e informes. La empresa adquiriente ha consolidado todas las cuentas en una sola organización en AWS Organizations. Sin embargo, a la empresa adquiriente le ha resultado difícil generar un informe de costos que contenga grupos significativos para todos los equipos. El equipo financiero de la empresa adquiriente necesita una solución para reportar los costos de todas las compañías a través de una aplicación autoadministrada. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Crear un informe de Costos y Uso de AWS para la organización. Definir etiquetas y categorías de costos en el informe. Crear una tabla en Amazon Athena. Crear un conjunto de datos en Amazon QuickSight basado en la tabla de Athena. Compartir el conjunto de datos con el equipo financiero.",
            "B. Crear un informe de Costos y Uso de AWS para la organización. Definir etiquetas y categorías de costos en el informe. Crear una plantilla especializada en AWS Cost Explorer que el departamento financiero utilizará para generar informes.",
            "C. Crear un conjunto de datos en Amazon QuickSight que reciba información de gasto del AWS Price List Query API. Compartir el conjunto de datos con el equipo financiero.",
            "D. Utilizar el AWS Price List Query API para recopilar información sobre el gasto de las cuentas. Crear una plantilla especializada en AWS Cost Explorer que el departamento financiero utilizará para generar informes."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "80.- Una empresa ejecuta una plataforma IoT en AWS. Los sensores IoT en varias ubicaciones envían datos a los servidores API de Node.js de la empresa en instancias de Amazon EC2 que están detrás de un Application Load Balancer. Los datos se almacenan en una instancia de Amazon RDS MySQL DB que usa un volumen SSD de propósito general de 4 TB. El número de sensores que la empresa ha desplegado en el campo ha aumentado con el tiempo y se espera que crezca significativamente. Los servidores API están constantemente sobrecargados y las métricas de RDS muestran alta latencia en las escrituras. ¿Cuáles de los siguientes pasos juntos resolverán los problemas de manera permanente y permitirán el crecimiento a medida que se aprovisionen nuevos sensores, mientras mantienen la plataforma rentable? (Elija dos.)",
        "opciones": [
            "A. Redimensionar el almacenamiento SSD de propósito general de MySQL a 6 TB para mejorar los IOPS del volumen.",
            "B. Reestructurar la capa de base de datos para usar Amazon Aurora en lugar de una instancia RDS MySQL DB e incluir réplicas de lectura.",
            "C. Aprovechar Amazon Kinesis Data Streams y AWS Lambda para ingerir y procesar los datos en crudo.",
            "D. Usar AWS X-Ray para analizar y depurar problemas de la aplicación y agregar más servidores API para ajustar la carga.",
            "E. Reestructurar la capa de base de datos para usar Amazon DynamoDB en lugar de una instancia RDS MySQL DB."
        ],
        "respuestas_correctas": [
            "C",
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "81.- Una empresa de streaming de videos está construyendo un sistema de gestión electrónica de documentos en el que los usuarios cargan sus documentos. La pila de la aplicación es completamente sin servidor y se ejecuta en AWS en la región eu-central-1. El sistema incluye una aplicación web que utiliza una distribución de Amazon CloudFront para la entrega, teniendo a Amazon S3 como origen. La aplicación web se comunica con endpoints regionales de Amazon API Gateway. Las API de API Gateway invocan funciones de AWS Lambda que almacenan metadatos en una base de datos Aurora Serverless y depositan los documentos en un bucket de S3. La empresa está creciendo de forma constante y ha completado una prueba de concepto con su mayor cliente. Ahora, la empresa debe mejorar la latencia fuera de Europa. ¿Qué combinación de acciones cumplirá estos requisitos? (Elija dos.)",
        "opciones": [
            "A. Habilitar S3 Transfer Acceleration en el bucket de S3. Asegurarse de que la aplicación web utilice las URL firmadas de Transfer Acceleration para las cargas.",
            "B. Crear un acelerador en AWS Global Accelerator y asociarlo a la distribución de CloudFront.",
            "C. Cambiar los endpoints regionales de API Gateway a endpoints optimizados para el borde.",
            "D. Aprovisionar toda la pila en dos ubicaciones adicionales distribuidas globalmente y utilizar bases de datos globales en el clúster Aurora Serverless.",
            "E. Agregar un proxy de Amazon RDS entre las funciones Lambda y la base de datos Aurora Serverless."
        ],
        "respuestas_correctas": [
            "C",
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "82.- Una compañía de aventuras ha lanzado una nueva función en su aplicación móvil. Los usuarios pueden utilizar la función para subir en cualquier momento sus fotos y videos de senderismo y rafting. Las fotos y los videos se almacenan en almacenamiento Amazon S3 Standard en un bucket de S3 y se sirven a través de Amazon CloudFront. La compañía necesita optimizar el costo del almacenamiento. Un arquitecto de soluciones descubre que la mayoría de las fotos y videos subidos se acceden de forma poco frecuente después de 30 días. Sin embargo, algunas de las fotos y videos subidos se acceden de forma frecuente después de 30 días. El arquitecto de soluciones debe implementar una solución que mantenga una disponibilidad de recuperación en milisegundos de las fotos y videos al costo más bajo posible. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Configurar S3 Intelligent-Tiering en el bucket de S3.",
            "B. Configurar una política de ciclo de vida en S3 para trasladar los objetos de imagen y video de S3 Standard a S3 Glacier Deep Archive después de 30 días.",
            "C. Reemplazar Amazon S3 con un sistema de archivos Amazon Elastic File System (Amazon EFS) que se monte en instancias de Amazon EC2.",
            "D. Añadir una cabecera Cache-Control: max-age a los objetos de imagen y video en S3. Establecer la cabecera en 30 días."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "83.- Una empresa utiliza Amazon S3 para almacenar archivos e imágenes en una variedad de clases de almacenamiento. Los costos de S3 de la empresa han aumentado sustancialmente durante el último año. Un arquitecto de soluciones necesita revisar las tendencias de datos de los últimos 12 meses e identificar la clase de almacenamiento apropiada para los objetos. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Descargar los informes de costos y uso de AWS para los últimos 12 meses de uso de S3. Revisar las recomendaciones de AWS Trusted Advisor para el ahorro de costos.",
            "B. Usar el análisis de clases de almacenamiento de S3. Importar las tendencias de datos en un panel de Amazon QuickSight para analizar las tendencias de almacenamiento.",
            "C. Usar Amazon S3 Storage Lens. Actualizar el panel de control predeterminado para incluir métricas avanzadas sobre las tendencias de almacenamiento.",
            "D. Usar Access Analyzer para S3. Descargar el informe de Access Analyzer para S3 de los últimos 12 meses. Importar el archivo .csv a un panel de Amazon QuickSight."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "84.- Una empresa tiene su infraestructura en la nube en AWS. Un arquitecto de soluciones necesita definir la infraestructura como código. Actualmente, la infraestructura está desplegada en una única Región de AWS. El plan de expansión del negocio de la empresa incluye despliegues en múltiples Regiones a través de varias cuentas de AWS. ¿Qué debe hacer el arquitecto de soluciones para cumplir con estos requisitos?",
        "opciones": [
            "A. Usar plantillas de AWS CloudFormation. Agregar políticas IAM para controlar las distintas cuentas y desplegar las plantillas en las múltiples Regiones.",
            "B. Usar AWS Organizations. Desplegar plantillas de AWS CloudFormation desde la cuenta de administración. Usar AWS Control Tower para gestionar los despliegues a través de las cuentas.",
            "C. Usar AWS Organizations y AWS CloudFormation StackSets. Desplegar una plantilla de CloudFormation desde una cuenta que tenga los permisos IAM necesarios.",
            "D. Usar pilas anidadas con plantillas de AWS CloudFormation. Cambiar la Región utilizando pilas anidadas."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "85.- Una empresa tiene su infraestructura en la nube en AWS. Un arquitecto de soluciones necesita definir la infraestructura como código. Actualmente, la infraestructura está desplegada en una única Región de AWS. El plan de expansión del negocio de la empresa incluye despliegues en múltiples Regiones a través de varias cuentas de AWS. ¿Qué debe hacer el arquitecto de soluciones para cumplir con estos requisitos?",
        "opciones": [
            "A. Usar plantillas de AWS CloudFormation. Agregar políticas IAM para controlar las distintas cuentas y desplegar las plantillas en las múltiples Regiones.",
            "B. Usar AWS Organizations. Desplegar plantillas de AWS CloudFormation desde la cuenta de administración. Usar AWS Control Tower para gestionar los despliegues a través de las cuentas.",
            "C. Usar AWS Organizations y AWS CloudFormation StackSets. Desplegar una plantilla de CloudFormation desde una cuenta que tenga los permisos IAM necesarios.",
            "D. Usar pilas anidadas con plantillas de AWS CloudFormation. Cambiar la Región utilizando pilas anidadas."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "86.- Una empresa planea refactorizar una aplicación monolítica en un diseño de aplicación moderno desplegado en AWS. La canalización de CI/CD debe actualizarse para admitir el diseño moderno de la aplicación con los siguientes requisitos: • Debe permitir que se publiquen cambios varias veces cada hora.\n• Debe ser capaz de revertir los cambios lo más rápidamente posible. ¿Qué diseño cumplirá con estos requisitos?",
        "opciones": [
            "A. Desplegar una canalización de CI/CD que incorpore AMIs para contener la aplicación y sus configuraciones. Desplegar la aplicación reemplazando las instancias de Amazon EC2.",
            "B. Especificar AWS Elastic Beanstalk para preparar (staging) un entorno secundario como destino de despliegue para la canalización de CI/CD de la aplicación. Para desplegar, intercambiar las URL del entorno de preparación y producción.",
            "C. Utilizar AWS Systems Manager para reprovisionar la infraestructura en cada despliegue. Actualizar los datos de usuario de Amazon EC2 para extraer el último artefacto de código desde Amazon S3 y usar el enrutamiento ponderado de Amazon Route 53 para apuntar al nuevo entorno.",
            "D. Desplegar las actualizaciones de la aplicación como parte de un evento de Auto Scaling utilizando AMIs preconstruidas. Utilizar nuevas versiones de las AMIs para agregar instancias y eliminar progresivamente todas las instancias que usan la versión anterior de la AMI, con la política de terminación configurada durante el evento de despliegue."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "87.- Una empresa tiene una aplicación que se ejecuta en instancias de Amazon EC2. Un arquitecto de soluciones está diseñando la infraestructura de VPC en una región de AWS donde la aplicación necesita acceder a un clúster de bases de datos Amazon Aurora. Todas las instancias EC2 están asociadas con el mismo grupo de seguridad, mientras que el clúster de Aurora tiene su propio grupo de seguridad. El arquitecto de soluciones debe agregar reglas a los grupos de seguridad para proporcionar a la aplicación un acceso de mínimo privilegio al clúster de Aurora. ¿Qué combinación de pasos cumplirá con estos requisitos? (Elija dos.)",
        "opciones": [
            "A. Agregar una regla de entrada al grupo de seguridad de las instancias EC2. Especificar el grupo de seguridad del clúster de Aurora como origen sobre el puerto predeterminado de Aurora.",
            "B. Agregar una regla de salida al grupo de seguridad de las instancias EC2. Especificar el grupo de seguridad del clúster de Aurora como destino sobre el puerto predeterminado de Aurora.",
            "C. Agregar una regla de entrada al grupo de seguridad del clúster de Aurora. Especificar el grupo de seguridad de las instancias EC2 como origen sobre el puerto predeterminado de Aurora.",
            "D. Agregar una regla de salida al grupo de seguridad del clúster de Aurora. Especificar el grupo de seguridad de las instancias EC2 como destino sobre el puerto predeterminado de Aurora.",
            "E. Agregar una regla de salida al grupo de seguridad del clúster de Aurora. Especificar el grupo de seguridad de las instancias EC2 como destino sobre los puertos efímeros."
        ],
        "respuestas_correctas": [
            "C",
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "88.- Una empresa desea cambiar su estrategia interna de facturación en la nube para cada una de sus unidades de negocio. Actualmente, el equipo de gobernanza en la nube comparte informes sobre el gasto global en la nube con el jefe de cada unidad de negocio. La empresa utiliza AWS Organizations para gestionar las cuentas de AWS separadas para cada unidad de negocio. El estándar de etiquetado existente en Organizations incluye la aplicación, el entorno y el propietario. El equipo de gobernanza en la nube quiere una solución centralizada para que cada unidad de negocio reciba informes mensuales sobre su gasto en la nube. La solución también debe enviar notificaciones para cualquier gasto en la nube que supere un umbral establecido. ¿Cuál solución es la forma MÁS rentable de cumplir con estos requisitos?",
        "opciones": [
            "A. Configurar AWS Budgets en cada cuenta y configurar alertas de presupuesto que se agrupen por aplicación, entorno y propietario. Agregar cada unidad de negocio a un tema de Amazon SNS para cada alerta. Usar Cost Explorer en cada cuenta para crear informes mensuales para cada unidad de negocio.",
            "B. Configurar AWS Budgets en la cuenta de administración de la organización y configurar alertas de presupuesto que se agrupen por aplicación, entorno y propietario. Agregar cada unidad de negocio a un tema de Amazon SNS para cada alerta. Usar Cost Explorer en la cuenta de administración de la organización para crear informes mensuales para cada unidad de negocio.",
            "C. Configurar AWS Budgets en cada cuenta y configurar alertas de presupuesto que se agrupen por aplicación, entorno y propietario. Agregar cada unidad de negocio a un tema de Amazon SNS para cada alerta. Usar el panel de AWS Billing and Cost Management en cada cuenta para crear informes mensuales para cada unidad de negocio.",
            "D. Habilitar los Informes de Costos y Uso de AWS en la cuenta de administración de la organización y configurar informes agrupados por aplicación, entorno y propietario. Crear una función AWS Lambda que procese los Informes de Costos y Uso de AWS, envíe alertas de presupuesto y envíe informes mensuales a la lista de correos electrónicos de cada unidad de negocio."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "89.- Una empresa está utilizando AWS CloudFormation para desplegar su infraestructura. La empresa está preocupada de que, si se elimina una pila de CloudFormation de producción, los datos importantes almacenados en las bases de datos de Amazon RDS o en los volúmenes de Amazon EBS también puedan eliminarse. ¿Cómo puede la empresa evitar que los usuarios eliminen datos de forma accidental de esta manera?",
        "opciones": [
            "A. Modificar las plantillas de CloudFormation para agregar un atributo **DeletionPolicy** a los recursos de RDS y EBS.",
            "B. Configurar una política de pila que deshabilite la eliminación de recursos de RDS y EBS.",
            "C. Modificar las políticas de IAM para denegar la eliminación de recursos de RDS y EBS que tengan una etiqueta aws:cloudformation:stack-name.",
            "D. Utilizar reglas de AWS Config para evitar la eliminación de recursos de RDS y EBS."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "90.- Una empresa tiene habilitados los registros de flujo de VPC para su gateway NAT. La empresa está viendo Action = ACCEPT para el tráfico entrante que proviene de la dirección IP pública 198.51.100.2, con destino a una instancia privada de Amazon EC2. Un arquitecto de soluciones debe determinar si el tráfico representa conexiones entrantes no solicitadas desde Internet. Los dos primeros octetos del bloque CIDR de la VPC son 203.0. ¿Qué conjunto de pasos debe seguir el arquitecto de soluciones para cumplir con estos requisitos?",
        "opciones": [
            "A. Abrir la consola de AWS CloudTrail. Seleccionar el grupo de registros que contiene la interfaz de red elástica del gateway NAT y la interfaz de red elástica de la instancia privada. Ejecutar una consulta filtrando con la dirección de destino como like 203.0 y la dirección de origen como like 198.51.100.2. Ejecutar el comando stats para filtrar la suma de bytes transferidos por la dirección de origen y destino.",
            "B. Abrir la consola de Amazon CloudWatch. Seleccionar el grupo de registros que contiene la interfaz de red elástica del gateway NAT y la interfaz de red elástica de la instancia privada. Ejecutar una consulta filtrando con la dirección de destino como like 203.0 y la dirección de origen como like 198.51.100.2. Ejecutar el comando stats para filtrar la suma de bytes transferidos por la dirección de origen y destino.",
            "C. Abrir la consola de AWS CloudTrail. Seleccionar el grupo de registros que contiene la interfaz de red elástica del gateway NAT y la interfaz de red elástica de la instancia privada. Ejecutar una consulta filtrando con la dirección de destino como like 198.51.100.2 y la dirección de origen como like 203.0. Ejecutar el comando stats para filtrar la suma de bytes transferidos por la dirección de origen y destino.",
            "D. Abrir la consola de Amazon CloudWatch. Seleccionar el grupo de registros que contiene la interfaz de red elástica del gateway NAT y la interfaz de red elástica de la instancia privada. Ejecutar una consulta filtrando con la dirección de destino como like 198.51.100.2 y la dirección de origen como like 203.0. Ejecutar el comando stats para filtrar la suma de bytes transferidos por la dirección de origen y destino."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "91.- Una empresa está compuesta por dos unidades de negocio separadas. Cada unidad de negocio tiene su propia cuenta de AWS dentro de una única organización en AWS Organizations. Las unidades de negocio comparten regularmente documentos confidenciales entre sí. Para facilitar el intercambio, la empresa creó un bucket de Amazon S3 en cada cuenta y configuró la replicación bidireccional entre los buckets de S3. Los buckets de S3 contienen millones de objetos. Recientemente, una auditoría de seguridad identificó que ninguno de los buckets de S3 tiene habilitado el cifrado en reposo. La política de la empresa requiere que todos los documentos se almacenen con cifrado en reposo. La empresa quiere implementar el cifrado del lado del servidor con claves administradas por Amazon S3 (SSE-S3). ¿Cuál es la solución MÁS eficiente operativamente que cumple con estos requisitos?",
        "opciones": [
            "A. Activar SSE-S3 en ambos buckets de S3. Usar S3 Batch Operations para copiar y cifrar los objetos en la misma ubicación.",
            "B. Crear una clave de AWS Key Management Service (AWS KMS) en cada cuenta. Activar el cifrado del lado del servidor con claves de AWS KMS (SSE-KMS) en cada bucket de S3 utilizando la clave KMS correspondiente en esa cuenta de AWS. Cifrar los objetos existentes utilizando un comando de copia de S3 en la AWS CLI.",
            "C. Activar SSE-S3 en ambos buckets de S3. Cifrar los objetos existentes utilizando un comando de copia de S3 en la AWS CLI.",
            "D. Crear una clave de AWS Key Management Service (AWS KMS) en cada cuenta. Activar el cifrado del lado del servidor con claves de AWS KMS (SSE-KMS) en cada bucket de S3 utilizando la clave KMS correspondiente en esa cuenta de AWS. Usar S3 Batch Operations para copiar los objetos en la misma ubicación."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "92.- Una empresa ejecuta una aplicación en la nube de AWS. La aplicación recopila y almacena una gran cantidad de datos no estructurados en un bucket de Amazon S3. El bucket de S3 contiene varios terabytes de datos y utiliza la clase de almacenamiento S3 Standard. Los datos aumentan en tamaño varios gigabytes cada día. La empresa necesita consultar y analizar los datos. No accede a datos de más de 1 año de antigüedad. Sin embargo, debe retener todos los datos indefinidamente por razones de cumplimiento. ¿Qué solución cumplirá con estos requisitos de la manera MÁS rentable?",
        "opciones": [
            "A. Usar S3 Select para consultar los datos. Crear una política de ciclo de vida de S3 para transferir los datos de más de 1 año de antigüedad a S3 Glacier Deep Archive.",
            "B. Usar Amazon Redshift Spectrum para consultar los datos. Crear una política de ciclo de vida de S3 para transferir los datos de más de 1 año de antigüedad a S3 Glacier Deep Archive.",
            "C. Usar un AWS Glue Data Catalog y Amazon Athena para consultar los datos. Crear una política de ciclo de vida de S3 para transferir los datos de más de 1 año de antigüedad a S3 Glacier Deep Archive.",
            "D. Usar Amazon Redshift Spectrum para consultar los datos. Crear una política de ciclo de vida de S3 para transferir los datos de más de 1 año de antigüedad a S3 Intelligent-Tiering."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "93.- Una empresa de procesamiento de video quiere construir un modelo de aprendizaje automático (ML) utilizando 600 TB de datos comprimidos almacenados como miles de archivos en el sistema de almacenamiento en red (NAS) local de la empresa. La empresa no tiene los recursos de cómputo necesarios en sus instalaciones para realizar experimentos de ML y desea usar AWS. La empresa necesita completar la transferencia de datos a AWS en un plazo de 3 semanas. La transferencia de datos será única y los datos deben estar cifrados en tránsito. La velocidad de carga medida de la conexión a internet de la empresa es de 100 Mbps, y múltiples departamentos comparten la conexión. ¿Cuál solución cumplirá con estos requisitos de la manera MÁS rentable?",
        "opciones": [
            "A. Pedir varios dispositivos AWS Snowball Edge Storage Optimized mediante la Consola de administración de AWS. Configurar los dispositivos con un bucket de destino en S3. Copiar los datos a los dispositivos. Enviar los dispositivos de vuelta a AWS.",
            "B. Configurar una conexión AWS Direct Connect de 10 Gbps entre la ubicación de la empresa y la región de AWS más cercana. Transferir los datos a través de una conexión VPN hacia la región para almacenarlos en Amazon S3.",
            "C. Crear una conexión VPN entre el sistema de almacenamiento en red local y la región de AWS más cercana. Transferir los datos a través de la conexión VPN.",
            "D. Implementar un AWS Storage Gateway en modo file gateway en las instalaciones. Configurar el file gateway con un bucket de destino en S3. Copiar los datos al file gateway."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "94.- Una empresa ha migrado su aplicación de procesamiento de formularios a AWS. Cuando los usuarios interactúan con la aplicación, suben formularios escaneados como archivos a través de una aplicación web. Una base de datos almacena metadatos de usuario y referencias a archivos que se almacenan en Amazon S3. La aplicación web se ejecuta en instancias de Amazon EC2 y en una base de datos Amazon RDS para PostgreSQL. Cuando se suben formularios, la aplicación envía notificaciones a un equipo a través de Amazon Simple Notification Service (Amazon SNS). Un miembro del equipo inicia sesión y procesa cada formulario. El miembro del equipo realiza la validación de datos en el formulario y extrae los datos relevantes antes de ingresar la información en otro sistema que utiliza una API. Un arquitecto de soluciones necesita automatizar el procesamiento manual de los formularios. La solución debe proporcionar extracción precisa de los formularios, minimizar el tiempo de comercialización y reducir la sobrecarga operativa a largo plazo. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Desarrollar bibliotecas personalizadas para realizar reconocimiento óptico de caracteres (OCR) en los formularios. Implementar las bibliotecas en un clúster de Amazon Elastic Kubernetes Service (Amazon EKS) como una capa de aplicación. Utilizar esta capa para procesar los formularios cuando se suban. Almacenar la salida en Amazon S3. Analizar esta salida extrayendo los datos en una tabla de Amazon DynamoDB. Enviar los datos a la API del sistema de destino. Alojar la nueva capa de aplicación en instancias EC2.",
            "B. Ampliar el sistema con una capa de aplicación que utilice AWS Step Functions y AWS Lambda. Configurar esta capa para utilizar modelos de inteligencia artificial y aprendizaje automático (AI/ML) que se entrenan y alojan en una instancia EC2 para realizar reconocimiento óptico de caracteres (OCR) en los formularios cuando se suben. Almacenar la salida en Amazon S3. Analizar esta salida extrayendo los datos requeridos dentro de la capa de aplicación. Enviar los datos a la API del sistema de destino.",
            "C. Alojar una nueva capa de aplicación en instancias EC2. Utilizar esta capa para llamar a puntos finales que alojan modelos de inteligencia artificial y aprendizaje automático (AI/ML) que se entrenan y alojan en Amazon SageMaker para realizar reconocimiento óptico de caracteres (OCR) en los formularios. Almacenar la salida en Amazon ElastiCache. Analizar esta salida extrayendo los datos requeridos dentro de la capa de aplicación. Enviar los datos a la API del sistema de destino.",
            "D. Ampliar el sistema con una capa de aplicación que utilice AWS Step Functions y AWS Lambda. Configurar esta capa para utilizar Amazon Textract y Amazon Comprehend para realizar reconocimiento óptico de caracteres (OCR) en los formularios cuando se suben. Almacenar la salida en Amazon S3. Analizar esta salida extrayendo los datos requeridos dentro de la capa de aplicación. Enviar los datos a la API del sistema de destino."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "95.- Una empresa está refactorizando su plataforma de procesamiento de pedidos on-premises en la nube de AWS. La plataforma incluye un frontend web alojado en una flota de máquinas virtuales, RabbitMQ para conectar el frontend con el backend y un clúster de Kubernetes que ejecuta un sistema backend en contenedores para procesar los pedidos. La empresa no quiere realizar cambios importantes en la aplicación. ¿Qué solución cumplirá con estos requisitos con el MENOR esfuerzo operativo?",
        "opciones": [
            "A. Crear una AMI del servidor web. Crear un grupo de Auto Scaling de Amazon EC2 que use la AMI y un Application Load Balancer. Configurar Amazon MQ para reemplazar la cola de mensajería on-premises. Configurar Amazon Elastic Kubernetes Service (Amazon EKS) para alojar el backend de procesamiento de pedidos.",
            "B. Crear un runtime personalizado de AWS Lambda para imitar el entorno del servidor web. Crear una API en Amazon API Gateway para reemplazar los servidores web frontend. Configurar Amazon MQ para reemplazar la cola de mensajería on-premises. Configurar Amazon Elastic Kubernetes Service (Amazon EKS) para alojar el backend de procesamiento de pedidos.",
            "C. Crear una AMI del servidor web. Crear un grupo de Auto Scaling de Amazon EC2 que use la AMI y un Application Load Balancer. Configurar Amazon MQ para reemplazar la cola de mensajería on-premises. Instalar Kubernetes en una flota de instancias EC2 para alojar el backend de procesamiento de pedidos.",
            "D. Crear una AMI del servidor web. Crear un grupo de Auto Scaling de Amazon EC2 que use la AMI y un Application Load Balancer. Configurar una cola de Amazon Simple Queue Service (Amazon SQS) para reemplazar la cola de mensajería on-premises. Configurar Amazon Elastic Kubernetes Service (Amazon EKS) para alojar el backend de procesamiento de pedidos."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "96.- Un arquitecto de soluciones necesita implementar un mecanismo de cifrado del lado del cliente para los objetos que se almacenarán en un nuevo bucket de Amazon S3. Para este propósito, el arquitecto de soluciones creó una clave maestra de cliente (CMK) que se almacena en AWS Key Management Service (AWS KMS). El arquitecto de soluciones creó la siguiente política de IAM y la adjuntó a un rol de IAM: Durante las pruebas, el arquitecto de soluciones pudo obtener exitosamente los objetos de prueba existentes en el bucket de S3. Sin embargo, los intentos de cargar un nuevo objeto resultaron en un mensaje de error que indicaba que la acción estaba prohibida. ¿Qué acción debe agregar el arquitecto de soluciones a la política de IAM para cumplir con todos los requisitos?",
        "opciones": [
            "A. kms:GenerateDataKey",
            "B. kms:GetKeyPolicy",
            "C. kms:GetPublicKey",
            "D. kms:Sign"
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": [{
            "respuesta": "A",
            "url": "images/image96.png"
        }]
    },
    {
        "pregunta": "97.- Una empresa ha desarrollado una aplicación web. La empresa está alojando la aplicación en un grupo de instancias de Amazon EC2 detrás de un balanceador de carga de aplicaciones. La empresa desea mejorar la postura de seguridad de la aplicación y planea utilizar ACL web de AWS WAF. La solución no debe afectar negativamente el tráfico legítimo a la aplicación. ¿Cómo debe un arquitecto de soluciones configurar las ACL web para cumplir con estos requisitos?",
        "opciones": [
            "A. Establecer la acción de las reglas de la ACL web en Contar. Habilitar el registro de AWS WAF. Analizar las solicitudes en busca de falsos positivos. Modificar las reglas para evitar cualquier falso positivo. Con el tiempo, cambiar la acción de las reglas de la ACL web de Contar a Bloquear.",
            "B. Usar solo reglas basadas en la tasa en las ACL web, y establecer el límite de aceleración lo más alto posible. Bloquear temporalmente todas las solicitudes que excedan el límite. Definir reglas anidadas para reducir el alcance del seguimiento de la tasa.",
            "C. Establecer la acción de las reglas de la ACL web en Bloquear. Usar solo grupos de reglas administradas por AWS en las ACL web. Evaluar los grupos de reglas mediante métricas de Amazon CloudWatch con solicitudes muestreadas de AWS WAF o registros de AWS WAF.",
            "D. Usar solo grupos de reglas personalizadas en las ACL web, y establecer la acción en Permitir. Habilitar el registro de AWS WAF. Analizar las solicitudes en busca de falsos positivos. Modificar las reglas para evitar cualquier falso positivo. Con el tiempo, cambiar la acción de las reglas de la ACL web de Permitir a Bloquear."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "98.- Una empresa tiene una organización con muchas cuentas de AWS dentro de AWS Organizations. Un arquitecto de soluciones debe mejorar la gestión de las reglas comunes de los grupos de seguridad en todas las cuentas de la organización. La empresa tiene un conjunto común de rangos CIDR en una lista de permitidos en cada cuenta de AWS para permitir el acceso hacia y desde la red on-premises de la empresa. Los desarrolladores de cada cuenta son responsables de agregar nuevos rangos CIDR a sus grupos de seguridad. El equipo de seguridad tiene su propia cuenta de AWS. Actualmente, el equipo de seguridad notifica a los propietarios de las otras cuentas de AWS cuando se realizan cambios en la lista de permitidos. El arquitecto de soluciones debe diseñar una solución que distribuya el conjunto común de rangos CIDR en todas las cuentas. ¿Qué solución cumple con estos requisitos con el menor esfuerzo operativo?",
        "opciones": [
            "A. Configurar un tema de Amazon SNS en la cuenta de AWS del equipo de seguridad. Implementar una función de AWS Lambda en cada cuenta de AWS. Configurar la función Lambda para que se ejecute cada vez que el tema SNS reciba un mensaje. Configurar la función Lambda para recibir una dirección IP como entrada y agregarla a una lista de grupos de seguridad en la cuenta. Instruir al equipo de seguridad para distribuir cambios publicando mensajes en el tema SNS.",
            "B. Crear nuevas listas de prefijos administradas por el cliente en cada cuenta de AWS dentro de la organización. Poblar las listas de prefijos en cada cuenta con todos los rangos CIDR internos. Notificar al propietario de cada cuenta de AWS para permitir los nuevos ID de listas de prefijos en sus grupos de seguridad. Instruir al equipo de seguridad para compartir actualizaciones con cada propietario de cuenta de AWS.",
            "C. Crear una lista de prefijos administrada por el cliente en la cuenta de AWS del equipo de seguridad. Poblar la lista con todos los rangos CIDR internos. Compartir la lista de prefijos con la organización mediante AWS Resource Access Manager. Notificar al propietario de cada cuenta de AWS para permitir el nuevo ID de la lista de prefijos administrada en sus grupos de seguridad.",
            "D. Crear un rol de IAM en cada cuenta de la organización. Otorgar permisos para actualizar los grupos de seguridad. Implementar una función de AWS Lambda en la cuenta de AWS del equipo de seguridad. Configurar la función Lambda para recibir una lista de direcciones IP internas como entrada, asumir un rol en cada cuenta de la organización y agregar la lista de direcciones IP a los grupos de seguridad en cada cuenta."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "99.- Una empresa ha introducido una nueva política que permite a los empleados trabajar de forma remota desde sus hogares si se conectan mediante una VPN. La empresa aloja aplicaciones internas en VPC dentro de múltiples cuentas de AWS. Actualmente, las aplicaciones son accesibles desde la red local de la empresa a través de una conexión AWS Site-to-Site VPN. La VPC en la cuenta principal de AWS de la empresa tiene conexiones de peering establecidas con las VPC en otras cuentas de AWS. Un arquitecto de soluciones debe diseñar una solución escalable de AWS Client VPN para que los empleados la usen mientras trabajan desde casa. ¿Cuál es la solución más rentable que cumple con estos requisitos?",
        "opciones": [
            "A. Crear un endpoint de Client VPN en cada cuenta de AWS. Configurar el enrutamiento necesario para permitir el acceso a las aplicaciones internas.",
            "B. Crear un endpoint de Client VPN en la cuenta principal de AWS. Configurar el enrutamiento necesario para permitir el acceso a las aplicaciones internas.",
            "C. Crear un endpoint de Client VPN en la cuenta principal de AWS. Provisionar un transit gateway conectado a cada cuenta de AWS. Configurar el enrutamiento necesario para permitir el acceso a las aplicaciones internas.",
            "D. Crear un endpoint de Client VPN en la cuenta principal de AWS. Establecer conectividad entre el endpoint de Client VPN y la AWS Site-to-Site VPN."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "100.- Una empresa está ejecutando una aplicación en la nube de AWS. Los métricas recientes de la aplicación muestran tiempos de respuesta inconsistentes y un aumento significativo en las tasas de errores. Las llamadas a servicios de terceros están causando las demoras. Actualmente, la aplicación realiza llamadas a servicios de terceros de manera sincrónica invocando directamente una función AWS Lambda. Un arquitecto de soluciones debe desacoplar las llamadas a los servicios de terceros y asegurarse de que todas las llamadas se completen eventualmente. ¿Qué solución cumple con estos requisitos?",
        "opciones": [
            "A. Usar una cola de Amazon Simple Queue Service (Amazon SQS) para almacenar eventos e invocar la función Lambda.",
            "B. Usar una máquina de estados de AWS Step Functions para pasar eventos a la función Lambda.",
            "C. Usar una regla de Amazon EventBridge para pasar eventos a la función Lambda.",
            "D. Usar un tema de Amazon Simple Notification Service (Amazon SNS) para almacenar eventos e invocar la función Lambda."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "101.- Una empresa está ejecutando aplicaciones en AWS en un entorno de múltiples cuentas. El equipo de ventas y el equipo de marketing utilizan cuentas separadas en AWS Organizations. El equipo de ventas almacena petabytes de datos en un bucket de Amazon S3. El equipo de marketing usa Amazon QuickSight para visualizaciones de datos. El equipo de marketing necesita acceder a los datos que el equipo de ventas almacena en el bucket de S3. La empresa ha encriptado el bucket de S3 con una clave de AWS Key Management Service (AWS KMS). El equipo de marketing ya ha creado el rol de servicio IAM para QuickSight en la cuenta de marketing para otorgar acceso a QuickSight. La empresa necesita una solución que proporcione acceso seguro a los datos en el bucket de S3 entre cuentas de AWS. ¿Qué solución cumplirá con estos requisitos con el menor esfuerzo operativo?",
        "opciones": [
            "A. Crear un nuevo bucket de S3 en la cuenta de marketing. Crear una regla de replicación de S3 en la cuenta de ventas para copiar los objetos al nuevo bucket en la cuenta de marketing. Actualizar los permisos de QuickSight en la cuenta de marketing para otorgar acceso al nuevo bucket de S3.",
            "B. Crear una política de control de servicio (SCP) para otorgar acceso al bucket de S3 a la cuenta de marketing. Usar AWS Resource Access Manager (AWS RAM) para compartir la clave de KMS de la cuenta de ventas con la cuenta de marketing. Actualizar los permisos de QuickSight en la cuenta de marketing para otorgar acceso al bucket de S3.",
            "C. Actualizar la política de bucket de S3 en la cuenta de marketing para otorgar acceso al rol de QuickSight. Crear una otorgación de KMS para la clave de cifrado que se usa en el bucket de S3. Conceder acceso de descifrado al rol de QuickSight. Actualizar los permisos de QuickSight en la cuenta de marketing para otorgar acceso al bucket de S3.",
            "D. Crear un rol IAM en la cuenta de ventas y otorgar acceso al bucket de S3. Desde la cuenta de marketing, asumir el rol IAM en la cuenta de ventas para acceder al bucket de S3. Actualizar el rol de QuickSight para crear una relación de confianza con el nuevo rol IAM en la cuenta de ventas."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "102.-Una empresa está planeando migrar sus aplicaciones críticas para el negocio desde un centro de datos local a AWS. La empresa tiene una instalación local de un clúster de Microsoft SQL Server Always On. La empresa desea migrar a un servicio de base de datos administrado de AWS. Un arquitecto de soluciones debe diseñar una migración de base de datos heterogénea en AWS. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Migrar las bases de datos de SQL Server a Amazon RDS para MySQL utilizando las utilidades de respaldo y restauración.",
            "B. Usar un dispositivo AWS Snowball Edge Storage Optimized para transferir datos a Amazon S3. Configurar Amazon RDS para MySQL. Usar la integración de S3 con características de SQL Server, como BULK INSERT.",
            "C. Usar la AWS Schema Conversion Tool para traducir el esquema de la base de datos a Amazon RDS para MySQL. Luego, usar AWS Database Migration Service (AWS DMS) para migrar los datos desde las bases de datos locales a Amazon RDS.",
            "D. Usar AWS DataSync para migrar datos a través de la red entre el almacenamiento local y Amazon S3. Configurar Amazon RDS para MySQL. Usar la integración de S3 con características de SQL Server, como BULK INSERT."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "103.- El equipo de diseño de una empresa editorial actualiza los iconos y otros activos estáticos que una aplicación web de comercio electrónico utiliza. La empresa sirve los iconos y activos desde un bucket de Amazon S3 alojado en la cuenta de producción de la empresa. La empresa también usa una cuenta de desarrollo a la que los miembros del equipo de diseño pueden acceder. Después de que el equipo de diseño prueba los activos estáticos en la cuenta de desarrollo, necesitan cargar los activos en el bucket de S3 de la cuenta de producción. Un arquitecto de soluciones debe proporcionar al equipo de diseño acceso a la cuenta de producción sin exponer otras partes de la aplicación web al riesgo de cambios no deseados. ¿Qué combinación de pasos cumplirá con estos requisitos? (Elija tres.)",
        "opciones": [
            "A. En la cuenta de producción, crear una nueva política de IAM que permita acceso de lectura y escritura al bucket de S3.",
            "B. En la cuenta de desarrollo, crear una nueva política de IAM que permita acceso de lectura y escritura al bucket de S3.",
            "C. En la cuenta de producción, crear un rol. Adjuntar la nueva política al rol. Definir la cuenta de desarrollo como una entidad de confianza.",
            "D. En la cuenta de desarrollo, crear un rol. Adjuntar la nueva política al rol. Definir la cuenta de producción como una entidad de confianza.",
            "E. En la cuenta de desarrollo, crear un grupo que contenga todos los usuarios IAM del equipo de diseño. Adjuntar una política IAM diferente al grupo para permitir la acción sts:AssumeRole sobre el rol en la cuenta de producción.",
            "F. En la cuenta de desarrollo, crear un grupo que contenga todos los usuarios IAM del equipo de diseño. Adjuntar una política IAM diferente al grupo para permitir la acción sts:AssumeRole sobre el rol en la cuenta de desarrollo."
        ],
        "respuestas_correctas": [
            "C",
            "E",
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "104.- Una empresa desarrolló una aplicación piloto utilizando AWS Elastic Beanstalk y Java. Para ahorrar costos durante el desarrollo, el equipo de desarrollo de la empresa desplegó la aplicación en un entorno de una sola instancia. Las pruebas recientes indican que la aplicación consume más CPU de lo esperado. La utilización de la CPU es regularmente mayor al 85%, lo que causa algunos cuellos de botella en el rendimiento. Un arquitecto de soluciones debe mitigar los problemas de rendimiento antes de que la empresa lance la aplicación a producción. ¿Qué solución cumplirá con estos requisitos con la menor sobrecarga operativa?",
        "opciones": [
            "A. Crear una nueva aplicación de Elastic Beanstalk. Seleccionar un tipo de entorno equilibrado por carga. Seleccionar todas las zonas de disponibilidad. Agregar una regla de escalado que se ejecute si la utilización máxima de la CPU es superior al 85% durante 5 minutos.",
            "B. Crear un segundo entorno de Elastic Beanstalk. Aplicar la política de despliegue de división de tráfico. Especificar un porcentaje del tráfico entrante para dirigirlo al nuevo entorno si la utilización promedio de la CPU es superior al 85% durante 5 minutos.",
            "C. Modificar la configuración de capacidad del entorno existente para usar un tipo de entorno equilibrado por carga. Seleccionar todas las zonas de disponibilidad. Agregar una regla de escalado que se ejecute si la utilización promedio de la CPU es superior al 85% durante 5 minutos.",
            "D. Seleccionar la acción de Reconstruir entorno con la opción de balanceo de carga. Seleccionar zonas de disponibilidad. Agregar una regla de escalado que se ejecute si la utilización total de la CPU es superior al 85% durante 5 minutos."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "105.- Una empresa financiera está ejecutando su aplicación crítica para el negocio en instancias EC2 de Linux de última generación. La aplicación incluye una base de datos MySQL autogestionada que realiza operaciones de I/O pesadas. La aplicación funciona correctamente para manejar una cantidad moderada de tráfico durante el mes. Sin embargo, se ralentiza durante los últimos tres días de cada mes debido a los informes de fin de mes, a pesar de que la empresa está utilizando Elastic Load Balancers y Auto Scaling dentro de su infraestructura para satisfacer la mayor demanda. ¿Cuál de las siguientes acciones permitiría que la base de datos maneje la carga de fin de mes con el MENOR impacto en el rendimiento?",
        "opciones": [
            "A. Pre-calentar los Elastic Load Balancers, usar un tipo de instancia más grande, cambiar todos los volúmenes de Amazon EBS a volúmenes GP2.",
            "B. Realizar una migración única del clúster de base de datos a Amazon RDS y crear varios réplicas de solo lectura para manejar la carga durante el fin de mes.",
            "C. Usar Amazon CloudWatch con AWS Lambda para cambiar el tipo, tamaño o IOPS de los volúmenes de Amazon EBS en el clúster según una métrica específica de CloudWatch.",
            "D. Reemplazar todos los volúmenes de Amazon EBS existentes con nuevos volúmenes PIOPS que tengan el tamaño de almacenamiento y I/O por segundo máximo disponible, tomando instantáneas antes del fin de mes y restaurándolas después."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "106.- Una empresa ejecuta una aplicación Java que tiene dependencias complejas en máquinas virtuales (VM) que están en el centro de datos de la empresa. La aplicación es estable, pero la empresa quiere modernizar la pila tecnológica. La empresa desea migrar la aplicación a AWS y minimizar la sobrecarga administrativa para mantener los servidores. ¿Qué solución cumplirá con estos requisitos con los menores cambios en el código?",
        "opciones": [
            "A. Migrar la aplicación a Amazon Elastic Container Service (Amazon ECS) en AWS Fargate utilizando AWS App2Container. Almacenar las imágenes de contenedor en Amazon Elastic Container Registry (Amazon ECR). Otorgar al rol de ejecución de tareas de ECS permisos para acceder al repositorio de imágenes ECR. Configurar Amazon ECS para usar un Application Load Balancer (ALB). Usar el ALB para interactuar con la aplicación.",
            "B. Migrar el código de la aplicación a un contenedor que se ejecute en AWS Lambda. Crear una API REST de Amazon API Gateway con integración de Lambda. Usar API Gateway para interactuar con la aplicación.",
            "C. Migrar la aplicación a Amazon Elastic Kubernetes Service (Amazon EKS) en grupos de nodos administrados de EKS utilizando AWS App2Container. Almacenar las imágenes de contenedor en Amazon Elastic Container Registry (Amazon ECR). Dar a los nodos de EKS permisos para acceder al repositorio de imágenes ECR. Usar Amazon API Gateway para interactuar con la aplicación.",
            "D. Migrar el código de la aplicación a un contenedor que se ejecute en AWS Lambda. Configurar Lambda para usar un Application Load Balancer (ALB). Usar el ALB para interactuar con la aplicación."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "107.- Una empresa tiene una aplicación HTTP asincrónica que está alojada como una función de AWS Lambda. Un punto de enlace público de Amazon API Gateway invoca la función Lambda. La función Lambda y el punto de enlace de API Gateway residen en la región us-east-1. Un arquitecto de soluciones necesita rediseñar la aplicación para admitir la conmutación por error a otra región de AWS. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Crear un punto de enlace de API Gateway en la región us-west-2 para dirigir el tráfico hacia la función Lambda en us-east-1. Configurar Amazon Route 53 para usar una política de enrutamiento de conmutación por error para dirigir el tráfico entre los dos puntos de enlace de API Gateway.",
            "B. Crear una cola de Amazon Simple Queue Service (Amazon SQS). Configurar API Gateway para dirigir el tráfico hacia la cola SQS en lugar de hacia la función Lambda. Configurar la función Lambda para extraer los mensajes de la cola para su procesamiento.",
            "C. Desplegar la función Lambda en la región us-west-2. Crear un punto de enlace de API Gateway en us-west-2 para dirigir el tráfico hacia la función Lambda en us-west-2. Configurar AWS Global Accelerator y un Application Load Balancer para gestionar el tráfico entre los dos puntos de enlace de API Gateway.",
            "D. Desplegar la función Lambda y un punto de enlace de API Gateway en la región us-west-2. Configurar Amazon Route 53 para usar una política de enrutamiento de conmutación por error para dirigir el tráfico entre los dos puntos de enlace de API Gateway."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "108.- Una empresa minorista ha estructurado sus cuentas de AWS para que sean parte de una organización en AWS Organizations. La empresa ha configurado la facturación consolidada y ha asignado sus departamentos a las siguientes OUs: Finanzas, Ventas, Recursos Humanos (HR), Marketing y Operaciones. Cada OU tiene múltiples cuentas de AWS, una para cada entorno dentro de un departamento. Estos entornos son desarrollo, prueba, preproducción y producción. El departamento de Recursos Humanos (HR) está lanzando un nuevo sistema que se pondrá en marcha en 3 meses. En preparación, el departamento de HR ha comprado varias Instancias Reservadas (RIs) en su cuenta de producción de AWS. El departamento de HR instalará la nueva aplicación en esta cuenta. El departamento de HR quiere asegurarse de que otros departamentos no puedan compartir los descuentos de las RI. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. En la consola de Facturación y Gestión de Costos de AWS para la cuenta de producción del departamento de HR, desactivar el uso compartido de RI.",
            "B. Eliminar la cuenta de producción del departamento de HR de la organización. Agregar la cuenta solo a la configuración de facturación consolidada.",
            "C. En la consola de Facturación y Gestión de Costos de AWS, usar la cuenta de administración de la organización para desactivar el uso compartido de RI para la cuenta de producción del departamento de HR.",
            "D. Crear un SCP en la organización para restringir el acceso a las RI. Aplicar el SCP a las OUs de los otros departamentos."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "109.- Una gran empresa está ejecutando una aplicación web popular. La aplicación se ejecuta en varias instancias Amazon EC2 Linux en un grupo de Auto Scaling en una subred privada. Un Application Load Balancer está dirigido a las instancias en el grupo de Auto Scaling en la subred privada. AWS Systems Manager Session Manager está configurado, y AWS Systems Manager Agent se está ejecutando en todas las instancias EC2. La empresa recientemente lanzó una nueva versión de la aplicación. Algunas instancias EC2 ahora están siendo marcadas como no saludables y están siendo terminadas. Como resultado, la aplicación está funcionando con capacidad reducida. Un arquitecto de soluciones intenta determinar la causa raíz analizando los registros de Amazon CloudWatch que se recopilan de la aplicación, pero los registros no son concluyentes. ¿Cómo debe el arquitecto de soluciones acceder a una instancia EC2 para solucionar el problema?",
        "opciones": [
            "A. Suspender el proceso de escalado de HealthCheck del grupo de Auto Scaling. Usar Session Manager para iniciar sesión en una instancia marcada como no saludable.",
            "B. Habilitar la protección contra terminación de la instancia EC2. Usar Session Manager para iniciar sesión en una instancia marcada como no saludable.",
            "C. Establecer la política de terminación en OldestInstance en el grupo de Auto Scaling. Usar Session Manager para iniciar sesión en una instancia marcada como no saludable.",
            "D. Suspender el proceso de Terminación del grupo de Auto Scaling. Usar Session Manager para iniciar sesión en una instancia marcada como no saludable."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "110.- Una empresa desea implementar una solución de AWS WAF para gestionar reglas de AWS WAF en varias cuentas de AWS. Las cuentas están gestionadas bajo diferentes OUs en AWS Organizations. Los administradores deben poder agregar o quitar cuentas o OUs de los conjuntos de reglas de AWS WAF gestionados según sea necesario. Los administradores también deben tener la capacidad de actualizar y remediar automáticamente las reglas de AWS WAF no conformes en todas las cuentas. ¿Qué solución cumple con estos requisitos con la menor cantidad de sobrecarga operativa?",
        "opciones": [
            "A. Usar AWS Firewall Manager para gestionar las reglas de AWS WAF en cuentas de la organización. Usar un parámetro de AWS Systems Manager Parameter Store para almacenar los números de cuenta y las OUs a gestionar. Actualizar el parámetro según sea necesario para agregar o quitar cuentas o OUs. Usar una regla de Amazon EventBridge para identificar cualquier cambio en el parámetro e invocar una función de AWS Lambda para actualizar la política de seguridad en la cuenta administrativa de Firewall Manager.",
            "B. Implementar una regla de AWS Config a nivel de la organización que requiera que todos los recursos en las OUs seleccionadas asocien las reglas de AWS WAF. Implementar acciones de remediación automática usando AWS Lambda para corregir los recursos no conformes. Implementar reglas de AWS WAF usando un conjunto de pilas de AWS CloudFormation dirigido a las mismas OUs donde se aplica la regla de AWS Config.",
            "C. Crear reglas de AWS WAF en la cuenta de gestión de la organización. Usar variables de entorno de AWS Lambda para almacenar los números de cuenta y las OUs a gestionar. Actualizar las variables de entorno según sea necesario para agregar o quitar cuentas o OUs. Crear roles de IAM de cuenta cruzada en las cuentas miembros. Asumir los roles usando AWS Security Token Service (AWS STS) en la función Lambda para crear y actualizar las reglas de AWS WAF en las cuentas miembros.",
            "D. Usar AWS Control Tower para gestionar las reglas de AWS WAF en las cuentas de la organización. Usar AWS Key Management Service (AWS KMS) para almacenar los números de cuenta y las OUs a gestionar. Actualizar AWS KMS según sea necesario para agregar o quitar cuentas o OUs. Crear usuarios de IAM en las cuentas miembros. Permitir que AWS Control Tower en la cuenta de gestión use la clave de acceso y la clave secreta para crear y actualizar las reglas de AWS WAF en las cuentas miembros."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "111.- Un arquitecto de soluciones está auditando la configuración de seguridad de una función AWS Lambda para una empresa. La función Lambda recupera los últimos cambios de una base de datos Amazon Aurora. La función Lambda y la base de datos se ejecutan en la misma VPC. Las variables de entorno de Lambda proporcionan las credenciales de la base de datos a la función Lambda. La función Lambda agrega datos y pone los datos disponibles en un bucket de Amazon S3 que está configurado para encriptación del lado del servidor con claves de encriptación gestionadas por AWS KMS (SSE-KMS). Los datos no deben viajar a través de Internet. Si alguna de las credenciales de la base de datos se ve comprometida, la empresa necesita una solución que minimice el impacto de la violación. ¿Qué debe recomendar el arquitecto de soluciones para cumplir con estos requisitos?",
        "opciones": [
            "A. Habilitar la autenticación de base de datos IAM en el clúster de Aurora. Cambiar el rol IAM de la función Lambda para permitir que la función acceda a la base de datos mediante la autenticación de base de datos IAM. Desplegar un endpoint de VPC para Amazon S3 en la VPC.",
            "B. Habilitar la autenticación de base de datos IAM en el clúster de Aurora. Cambiar el rol IAM de la función Lambda para permitir que la función acceda a la base de datos mediante la autenticación de base de datos IAM. Forzar HTTPS en la conexión a Amazon S3 durante las transferencias de datos.",
            "C. Guardar las credenciales de la base de datos en AWS Systems Manager Parameter Store. Configurar la rotación de contraseñas en las credenciales de Parameter Store. Cambiar el rol IAM de la función Lambda para permitir que la función acceda a Parameter Store. Modificar la función Lambda para recuperar las credenciales desde Parameter Store. Desplegar un endpoint de VPC para Amazon S3 en la VPC.",
            "D. Guardar las credenciales de la base de datos en AWS Secrets Manager. Configurar la rotación de contraseñas en las credenciales de Secrets Manager. Cambiar el rol IAM de la función Lambda para permitir que la función acceda a Secrets Manager. Modificar la función Lambda para recuperar las credenciales desde Secrets Manager. Forzar HTTPS en la conexión a Amazon S3 durante las transferencias de datos"
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "112.- Una gran empresa de juegos móviles ha migrado con éxito toda su infraestructura local a la nube de AWS. Un arquitecto de soluciones está revisando el entorno para asegurarse de que se haya construido de acuerdo con el diseño y que esté funcionando en alineación con el Marco Bien Arquitectado. Mientras revisaba los costos mensuales anteriores en Cost Explorer, el arquitecto de soluciones notó que la creación y posterior terminación de varios tipos de instancias grandes representaba una alta proporción de los costos. El arquitecto descubre que los desarrolladores de la empresa están lanzando nuevas instancias de Amazon EC2 como parte de sus pruebas y que los desarrolladores no están utilizando los tipos de instancias apropiados. El arquitecto de soluciones debe implementar un mecanismo de control para limitar los tipos de instancias que solo los desarrolladores pueden lanzar. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Crear una regla administrada de tipo de instancia deseado en AWS Config. Configurar la regla con los tipos de instancias que están permitidos. Adjuntar la regla a un evento para que se ejecute cada vez que se lance una nueva instancia de EC2.",
            "B. En la consola de EC2, crear una plantilla de lanzamiento que especifique los tipos de instancias que están permitidos. Asignar la plantilla de lanzamiento a las cuentas de IAM de los desarrolladores.",
            "C. Crear una nueva política de IAM. Especificar los tipos de instancias que están permitidos. Adjuntar la política a un grupo de IAM que contenga las cuentas de IAM de los desarrolladores.",
            "D. Usar EC2 Image Builder para crear una canalización de imágenes para los desarrolladores y ayudarles en la creación de una imagen dorada."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "113.- Una empresa está desarrollando y alojando varios proyectos en la nube de AWS. Los proyectos se desarrollan en múltiples cuentas de AWS bajo la misma organización en AWS Organizations. La empresa requiere que el costo de la infraestructura en la nube se asigne al proyecto propietario. El equipo responsable de todas las cuentas de AWS ha descubierto que varias instancias de Amazon EC2 carecen de la etiqueta de Proyecto utilizada para la asignación de costos. ¿Qué acciones debe tomar un arquitecto de soluciones para resolver el problema y evitar que vuelva a ocurrir en el futuro? (Elija tres.)",
        "opciones": [
            "A. Crear una regla de AWS Config en cada cuenta para encontrar recursos con etiquetas faltantes.",
            "B. Crear una SCP en la organización con una acción de denegación para ec2:RunInstances si falta la etiqueta de Proyecto.",
            "C. Usar Amazon Inspector en la organización para encontrar recursos con etiquetas faltantes.",
            "D. Crear una política de IAM en cada cuenta con una acción de denegación para ec2:RunInstances si falta la etiqueta de Proyecto.",
            "E. Crear un agregador de AWS Config para la organización para recopilar una lista de instancias EC2 con la etiqueta de Proyecto faltante.",
            "F. Usar AWS Security Hub para agregar una lista de instancias EC2 con la etiqueta de Proyecto faltante"
        ],
        "respuestas_correctas": [
            "E",
            "B",
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "114.- Una empresa tiene una solución de monitoreo local utilizando una base de datos PostgreSQL para la persistencia de eventos. La base de datos no puede escalar debido a una alta ingestión de datos y con frecuencia se queda sin almacenamiento. La empresa desea crear una solución híbrida y ya ha configurado una conexión VPN entre su red y AWS. La solución debe incluir los siguientes atributos: • Servicios gestionados de AWS para minimizar la complejidad operativa. • Un búfer que escale automáticamente para igualar el rendimiento de los datos y que no requiera administración continua. • Una herramienta de visualización para crear paneles de control para observar los eventos en tiempo casi real. • Soporte para datos semi-estructurados en formato JSON y esquemas dinámicos. ¿Qué combinación de componentes permitirá a la empresa crear una solución de monitoreo que satisfaga estos requisitos? (Elija dos.)",
        "opciones": [
            "A. Usar Amazon Kinesis Data Firehose para almacenar eventos en búfer. Crear una función de AWS Lambda para procesar y transformar los eventos.",
            "B. Crear un flujo de datos de Amazon Kinesis para almacenar eventos en búfer. Crear una función de AWS Lambda para procesar y transformar los eventos.",
            "C. Configurar un clúster de Amazon Aurora PostgreSQL para recibir eventos. Usar Amazon QuickSight para leer desde la base de datos y crear visualizaciones y paneles de control en tiempo casi real.",
            "D. Configurar Amazon Elasticsearch Service (Amazon ES) para recibir eventos. Usar el endpoint de Kibana implementado con Amazon ES para crear visualizaciones y paneles de control en tiempo casi real.",
            "E. Configurar una instancia de Amazon Neptune DB para recibir eventos. Usar Amazon QuickSight para leer desde la base de datos y crear visualizaciones y paneles de control en tiempo casi real."
        ],
        "respuestas_correctas": [
            "D",
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "115.- Un equipo recopila y dirige datos de comportamiento para toda la empresa. La empresa ejecuta un entorno VPC Multi-AZ con subredes públicas, subredes privadas y una puerta de enlace de internet. Cada subred pública también contiene una puerta de enlace NAT. La mayoría de las aplicaciones de la empresa leen y escriben en Amazon Kinesis Data Streams. La mayoría de las cargas de trabajo se ejecutan en subredes privadas. Un arquitecto de soluciones debe revisar la infraestructura. El arquitecto de soluciones necesita reducir costos y mantener el funcionamiento de las aplicaciones. El arquitecto de soluciones usa Cost Explorer y observa que el costo en la categoría EC2-Other es consistentemente alto. Una revisión adicional muestra que los cargos de NatGateway-Bytes están aumentando el costo en la categoría EC2-Other. ¿Qué debe hacer el arquitecto de soluciones para cumplir con estos requisitos?",
        "opciones": [
            "A. Habilitar los registros de flujo de VPC. Usar Amazon Athena para analizar los registros en busca de tráfico que se pueda eliminar. Asegurarse de que los grupos de seguridad estén bloqueando el tráfico que es responsable de los altos costos.",
            "B. Agregar un punto de enlace de VPC de interfaz para Kinesis Data Streams a la VPC. Asegurarse de que las aplicaciones tengan los permisos de IAM correctos para usar el punto de enlace de VPC.",
            "C. Habilitar los registros de flujo de VPC y Amazon Detective. Revisar los hallazgos de Detective para encontrar tráfico que no esté relacionado con Kinesis Data Streams. Configurar los grupos de seguridad para bloquear ese tráfico.",
            "D. Agregar un punto de enlace de VPC de interfaz para Kinesis Data Streams a la VPC. Asegurarse de que la política del punto de enlace de VPC permita el tráfico desde las aplicaciones."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "116.- Una empresa minorista tiene un centro de datos local en Europa. La empresa también tiene una presencia multi-Región en AWS que incluye las regiones eu-west-1 y us-east-1. La empresa quiere poder enrutar el tráfico de red desde su infraestructura local hacia VPCs en cualquiera de esas regiones. La empresa también necesita soportar el tráfico que se enruta directamente entre las VPCs en esas regiones. No puede haber puntos únicos de falla en la red. La empresa ya ha creado dos conexiones de AWS Direct Connect de 1 Gbps desde su centro de datos local. Cada conexión va a una ubicación separada de Direct Connect en Europa para alta disponibilidad. Estas dos ubicaciones se llaman DX-A y DX-B, respectivamente. Cada región tiene un único AWS Transit Gateway configurado para enrutar todo el tráfico inter-VPC dentro de esa región. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Crear un VIF privado desde la conexión DX-A hacia una puerta de enlace de Direct Connect. Crear un VIF privado desde la conexión DX-B hacia la misma puerta de enlace de Direct Connect para alta disponibilidad. Asociar tanto los gateways de tránsito de eu-west-1 como de us-east-1 con la puerta de enlace de Direct Connect. Hacer el emparejamiento de los gateways de tránsito entre sí para soportar el enrutamiento entre regiones.",
            "B. Crear un VIF de tránsito desde la conexión DX-A hacia una puerta de enlace de Direct Connect. Asociar el gateway de tránsito de eu-west-1 con esta puerta de enlace de Direct Connect. Crear un VIF de tránsito desde la conexión DX-B hacia una puerta de enlace de Direct Connect separada. Asociar el gateway de tránsito de us-east-1 con esta puerta de enlace separada. Emparejar las puertas de enlace de Direct Connect entre sí para soportar alta disponibilidad y enrutamiento entre regiones.",
            "C. Crear un VIF de tránsito desde la conexión DX-A hacia una puerta de enlace de Direct Connect. Crear un VIF de tránsito desde la conexión DX-B hacia la misma puerta de enlace de Direct Connect para alta disponibilidad. Asociar tanto los gateways de tránsito de eu-west-1 como de us-east-1 con esta puerta de enlace de Direct Connect. Configurar la puerta de enlace de Direct Connect para enrutar tráfico entre los gateways de tránsito.",
            "D. Crear un VIF de tránsito desde la conexión DX-A hacia una puerta de enlace de Direct Connect. Crear un VIF de tránsito desde la conexión DX-B hacia la misma puerta de enlace de Direct Connect para alta disponibilidad. Asociar tanto los gateways de tránsito de eu-west-1 como de us-east-1 con esta puerta de enlace de Direct Connect. Emparejar los gateways de tránsito entre sí para soportar el enrutamiento entre regiones."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "117.- Una empresa está ejecutando una aplicación en la nube de AWS. El equipo de seguridad de la empresa debe aprobar la creación de todos los nuevos usuarios de IAM. Cuando se crea un nuevo usuario de IAM, se debe eliminar automáticamente todo el acceso para el usuario. Luego, el equipo de seguridad debe recibir una notificación para aprobar al usuario. La empresa tiene un rastro de AWS CloudTrail multi-Región en la cuenta de AWS. ¿Qué combinación de pasos cumplirá con estos requisitos? (Elija tres.)",
        "opciones": [
            "A. Crear una regla de Amazon EventBridge (Amazon CloudWatch Events). Definir un patrón con el valor de detail-type establecido en AWS API Call via CloudTrail y un eventName de CreateUser.",
            "B. Configurar CloudTrail para enviar una notificación para el evento CreateUser a un tema de Amazon Simple Notification Service (Amazon SNS).",
            "C. Invocar un contenedor que se ejecute en Amazon Elastic Container Service (Amazon ECS) con tecnología AWS Fargate para eliminar el acceso.",
            "D. Invocar una máquina de estados de AWS Step Functions para eliminar el acceso.",
            "E. Usar Amazon Simple Notification Service (Amazon SNS) para notificar al equipo de seguridad.",
            "F. Usar Amazon Pinpoint para notificar al equipo de seguridad."
        ],
        "respuestas_correctas": [
            "E",
            "D",
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "118.- Una empresa desea migrar a AWS. La empresa quiere usar una estructura de múltiples cuentas con acceso gestionado de manera centralizada a todas las cuentas y aplicaciones. También quiere mantener el tráfico en una red privada. Se requiere autenticación multifactor (MFA) en el inicio de sesión y se asignan roles específicos a los grupos de usuarios. La empresa debe crear cuentas separadas para desarrollo, pruebas, producción y red compartida. La cuenta de producción y la cuenta de red compartida deben tener conectividad a todas las cuentas. Las cuentas de desarrollo y de pruebas solo deben tener acceso entre ellas. ¿Qué combinación de pasos debe seguir un arquitecto de soluciones para cumplir con estos requisitos? (Elija tres.)",
        "opciones": [
            "A. Desplegar un entorno de landing zone utilizando AWS Control Tower. Inscribir cuentas e invitar cuentas existentes a la organización resultante en AWS Organizations.",
            "B. Habilitar AWS Security Hub en todas las cuentas para gestionar el acceso entre cuentas. Recoger hallazgos a través de AWS CloudTrail para forzar el inicio de sesión con MFA.",
            "C. Crear gateways de tránsito y adjuntos de gateway de tránsito en cada cuenta. Configurar las tablas de rutas apropiadas.",
            "D. Configurar y habilitar AWS IAM Identity Center (AWS Single Sign-On). Crear conjuntos de permisos adecuados con MFA requerido para las cuentas existentes.",
            "E. Habilitar AWS Control Tower en todas las cuentas para gestionar el enrutamiento entre cuentas. Recoger hallazgos a través de AWS CloudTrail para forzar el inicio de sesión con MFA.",
            "F. Crear usuarios y grupos de IAM. Configurar MFA para todos los usuarios. Configurar los grupos de usuarios y los grupos de identidad de Amazon Cognito para gestionar el acceso entre cuentas y dentro de las cuentas."
        ],
        "respuestas_correctas": [
            "C",
            "D",
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "119.- Una empresa ejecuta su aplicación en la región eu-west-1 y tiene una cuenta para cada uno de sus entornos: desarrollo, pruebas y producción. Todos los entornos funcionan 24 horas al día, 7 días a la semana, utilizando instancias de Amazon EC2 con estado y bases de datos Amazon RDS para MySQL. Las bases de datos tienen un tamaño de entre 500 GB y 800 GB. El equipo de desarrollo y el equipo de pruebas trabajan en los días hábiles durante las horas laborales, pero el entorno de producción funciona las 24 horas al día, 7 días a la semana. La empresa quiere reducir costos. Todos los recursos están etiquetados con una etiqueta de entorno que tiene como clave desarrollo, pruebas o producción. ¿Qué debe hacer un arquitecto de soluciones para reducir los costos con el MENOR esfuerzo operativo?",
        "opciones": [
            "A. Crear una regla de Amazon EventBridge que se ejecute una vez al día. Configurar la regla para invocar una función de AWS Lambda que inicie o detenga las instancias según la etiqueta, el día y la hora.",
            "B. Crear una regla de Amazon EventBridge que se ejecute cada día hábil por la tarde. Configurar la regla para invocar una función de AWS Lambda que detenga las instancias según la etiqueta. Crear una segunda regla de EventBridge que se ejecute cada día hábil por la mañana. Configurar la segunda regla para invocar otra función Lambda que inicie las instancias según la etiqueta.",
            "C. Crear una regla de Amazon EventBridge que se ejecute cada día hábil por la tarde. Configurar la regla para invocar una función de AWS Lambda que termine las instancias según la etiqueta. Crear una segunda regla de EventBridge que se ejecute cada día hábil por la mañana. Configurar la segunda regla para invocar otra función Lambda que restaure las instancias desde su última copia de seguridad según la etiqueta.",
            "D. Crear una regla de Amazon EventBridge que se ejecute cada hora. Configurar la regla para invocar una función de AWS Lambda que termine o restaure las instancias desde su última copia de seguridad según la etiqueta, el día y la hora."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "120.- Una empresa está construyendo una solución de software como servicio (SaaS) en AWS. La empresa ha implementado una API REST de Amazon API Gateway con integración de AWS Lambda en múltiples Regiones de AWS y en la misma cuenta de producción. La empresa ofrece precios por niveles que brindan a los clientes la capacidad de pagar por la capacidad de hacer un número determinado de llamadas a la API por segundo. El nivel premium ofrece hasta 3,000 llamadas por segundo, y los clientes se identifican por una clave API única. Varios clientes del nivel premium en varias Regiones informan que reciben respuestas de error 429 Too Many Requests de múltiples métodos de la API durante las horas de mayor uso. Los registros indican que la función Lambda nunca se invoca. ¿Cuál podría ser la causa de los mensajes de error para estos clientes?",
        "opciones": [
            "A. La función Lambda alcanzó su límite de concurrencia.",
            "B. La función Lambda alcanzó su límite de concurrencia por Región.",
            "C. La empresa alcanzó su límite de llamadas por segundo de la cuenta de API Gateway.",
            "D. La empresa alcanzó su límite por defecto de llamadas por segundo por método de API Gateway."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "121.- Una empresa financiera está planeando migrar su aplicación web de sus instalaciones locales a AWS. la empresa usa una herramienta de seguridad de terceros para monitorear el tráfico entrante a la aplicación. La empresa ha utilizado esta herramienta de seguridad durante los últimos 15 años, y la herramienta no tiene soluciones en la nube disponibles por parte de su proveedor. El equipo de seguridad de la empresa está preocupado por cómo integrar la herramienta de seguridad con la tecnología de AWS. La empresa planea migrar la aplicación a AWS en instancias de Amazon EC2. Las instancias EC2 estarán en un grupo de Auto Scaling dentro de una VPC dedicada. La empresa necesita usar la herramienta de seguridad para inspeccionar todos los paquetes que entran y salen de la VPC. Esta inspección debe ocurrir en tiempo real y no debe afectar el rendimiento de la aplicación. Un arquitecto de soluciones debe diseñar una arquitectura de destino en AWS que sea altamente disponible dentro de una región de AWS. ¿Qué combinación de pasos debe seguir el arquitecto de soluciones para cumplir con estos requisitos? (Elija dos.)",
        "opciones": [
            "A. Desplegar la herramienta de seguridad en instancias EC2 en un nuevo grupo de Auto Scaling en la VPC existente.",
            "B. Desplegar la aplicación web detrás de un Network Load Balancer.",
            "C. Desplegar un Application Load Balancer frente a las instancias de la herramienta de seguridad.",
            "D. Proveer un Gateway Load Balancer para cada zona de disponibilidad para redirigir el tráfico a la herramienta de seguridad.",
            "E. Proveer un transit gateway para facilitar la comunicación entre las VPCs."
        ],
        "respuestas_correctas": [
            "D",
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "122.- Una empresa ha comprado electrodomésticos de diferentes proveedores. Los electrodomésticos tienen sensores IoT. Los sensores envían información de estado en los formatos propietarios de los proveedores a una aplicación heredada que analiza la información y la convierte en JSON. El análisis es sencillo, pero cada proveedor tiene un formato único. Una vez al día, la aplicación analiza todos los registros JSON y almacena los registros en una base de datos relacional para su análisis. La empresa necesita diseñar una nueva solución de análisis de datos que pueda entregar resultados más rápidos y optimizar los costos. ¿Qué solución satisfará estos requisitos?",
        "opciones": [
            "A. Conecte los sensores IoT a AWS IoT Core. Configure una regla para invocar una función de AWS Lambda para analizar la información y guardar un archivo .csv en Amazon S3. Use AWS Glue para catalogar los archivos. Use Amazon Athena y Amazon QuickSight para el análisis.",
            "B. Migre el servidor de la aplicación a AWS Fargate, que recibirá la información de los sensores IoT y analizará la información en un formato relacional. Guarde la información analizada en Amazon Redshift para su análisis.",
            "C. Cree un servidor AWS Transfer for SFTP. Actualice el código del sensor IoT para enviar la información como un archivo .csv a través de SFTP al servidor. Use AWS Glue para catalogar los archivos. Use Amazon Athena para el análisis.",
            "D. Use AWS Snowball Edge para recopilar datos de los sensores IoT directamente y realizar análisis locales. Periódicamente recopile los datos en Amazon Redshift para realizar análisis globales."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "123.- Una empresa está migrando algunas de sus aplicaciones a AWS. La empresa quiere migrar y modernizar las aplicaciones rápidamente después de finalizar las estrategias de red y seguridad. La empresa ha configurado una conexión de AWS Direct Connect en una cuenta central de red. Se espera que la empresa tenga cientos de cuentas de AWS y VPCs en el futuro cercano. La red corporativa debe poder acceder a los recursos de AWS de manera fluida y también debe poder comunicarse con todas las VPCs. La empresa también quiere enrutar sus recursos en la nube hacia Internet a través de su centro de datos local. ¿Qué combinación de pasos cumplirá con estos requisitos? (Elija tres.)",
        "opciones": [
            "A. Crear un Direct Connect gateway en la cuenta central. En cada una de las cuentas, crear una propuesta de asociación utilizando el Direct Connect gateway y el ID de cuenta para cada puerta de enlace privada virtual.",
            "B. Crear un Direct Connect gateway y un transit gateway en la cuenta central de red. Conectar el transit gateway al Direct Connect gateway mediante un VIF de tránsito.",
            "C. Provisionar un internet gateway. Adjuntar el internet gateway a las subredes. Permitir el tráfico de Internet a través del gateway.",
            "D. Compartir el transit gateway con otras cuentas. Adjuntar las VPCs al transit gateway.",
            "E. Provisionar peering de VPC según sea necesario.",
            "F. Provisionar solo subredes privadas. Abrir la ruta necesaria en el transit gateway y en el customer gateway para permitir el tráfico de salida a Internet desde AWS para que fluya a través de servicios NAT que se ejecutan en el centro de datos."
        ],
        "respuestas_correctas": [
            "F",
            "D",
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "124.- Una empresa tiene cientos de cuentas de AWS. Recientemente, la empresa implementó un proceso interno centralizado para la compra de nuevas Instancias Reservadas y la modificación de Instancias Reservadas existentes. Este proceso requiere que todas las unidades de negocio que deseen comprar o modificar Instancias Reservadas presenten solicitudes a un equipo dedicado para la adquisición. Anteriormente, las unidades de negocio compraban o modificaban Instancias Reservadas de manera autónoma en sus propias cuentas de AWS respectivas. Un arquitecto de soluciones necesita hacer cumplir este nuevo proceso de la manera más segura posible. ¿Qué combinación de pasos debe tomar el arquitecto de soluciones para cumplir con estos requisitos? (Elija dos.)",
        "opciones": [
            "A. Asegúrese de que todas las cuentas de AWS sean parte de una organización en AWS Organizations con todas las características habilitadas.",
            "B. Use AWS Config para informar sobre la asignación de una política IAM que niega el acceso a la acción ec2:PurchaseReservedInstancesOffering y la acción ec2:ModifyReservedInstances.",
            "C. En cada cuenta de AWS, cree una política IAM que niegue la acción ec2:PurchaseReservedInstancesOffering y la acción ec2:ModifyReservedInstances.",
            "D. Cree una política de control de servicio (SCP) que niegue la acción ec2:PurchaseReservedInstancesOffering y la acción ec2:ModifyReservedInstances. Aplique la SCP a cada OU de la organización.",
            "E. Asegúrese de que todas las cuentas de AWS sean parte de una organización en AWS Organizations que utilice la función de facturación consolidada."
        ],
        "respuestas_correctas": [
            "D",
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "125.- Una empresa está ejecutando una aplicación crítica que utiliza una base de datos Amazon RDS para MySQL para almacenar datos. La instancia de base de datos RDS está desplegada en modo Multi-AZ. Una reciente prueba de conmutación por error (failover) de la base de datos RDS causó una interrupción de 40 segundos en la aplicación. Un arquitecto de soluciones necesita diseñar una solución para reducir el tiempo de interrupción a menos de 20 segundos. ¿Qué combinación de pasos debe tomar el arquitecto de soluciones para cumplir con estos requisitos? (Elija tres.)",
        "opciones": [
            "A. Usar Amazon ElastiCache para Memcached frente a la base de datos.",
            "B. Usar Amazon ElastiCache para Redis frente a la base de datos.",
            "C. Usar RDS Proxy frente a la base de datos.",
            "D. Migrar la base de datos a Amazon Aurora MySQL.",
            "E. Crear una réplica de Amazon Aurora.",
            "F. Crear una réplica de lectura de RDS para MySQL."
        ],
        "respuestas_correctas": [
            "E",
            "D",
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "126.- Una empresa asociada de AWS está construyendo un servicio en AWS Organizations utilizando su organización llamada org1. Este servicio requiere que la empresa asociada tenga acceso a los recursos de AWS en una cuenta de cliente, que está en una organización separada llamada org2. La empresa debe establecer acceso de seguridad con el menor privilegio posible mediante una API o una herramienta de línea de comandos a la cuenta del cliente. ¿Cuál es la forma más segura de permitir que org1 acceda a los recursos en org2?",
        "opciones": [
            "A. El cliente debe proporcionar a la empresa asociada sus claves de acceso a la cuenta de AWS para iniciar sesión y realizar las tareas requeridas.",
            "B. El cliente debe crear un usuario de IAM y asignarle los permisos necesarios. Luego, el cliente debe proporcionar las credenciales a la empresa asociada para que inicie sesión y realice las tareas requeridas.",
            "C. El cliente debe crear un rol de IAM y asignarle los permisos necesarios. La empresa asociada debe utilizar el ARN del rol de IAM al solicitar acceso para realizar las tareas requeridas.",
            "D. El cliente debe crear un rol de IAM y asignarle los permisos necesarios. La empresa asociada debe utilizar el ARN del rol de IAM, incluyendo el ID externo en la política de confianza del rol de IAM, al solicitar acceso para realizar las tareas requeridas."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "127.- Una empresa de entregas necesita migrar su aplicación de planificación de rutas de terceros a AWS. El proveedor externo proporciona una imagen Docker compatible desde un registro público. La imagen puede ejecutarse en tantos contenedores como sea necesario para generar el mapa de rutas. La empresa ha dividido el área de entrega en secciones con centros de distribución para que los conductores recorran la menor distancia posible desde los centros hasta los clientes. Para reducir el tiempo necesario para generar los mapas de rutas, cada sección usa su propio conjunto de contenedores Docker con una configuración personalizada que procesa pedidos solo en el área de la sección. La empresa necesita la capacidad de asignar recursos de manera rentable según el número de contenedores en ejecución. ¿Qué solución cumplirá con estos requisitos con el MENOR esfuerzo operativo?",
        "opciones": [
            "A. Crear un clúster de Amazon Elastic Kubernetes Service (Amazon EKS) en Amazon EC2. Usar la CLI de Amazon EKS para iniciar la aplicación de planificación en pods mediante la opción --tags para asignar una etiqueta personalizada al pod.",
            "B. Crear un clúster de Amazon Elastic Kubernetes Service (Amazon EKS) en AWS Fargate. Usar la CLI de Amazon EKS para iniciar la aplicación de planificación. Usar la API tag-resource de AWS CLI para asignar una etiqueta personalizada al pod.",
            "C. Crear un clúster de Amazon Elastic Container Service (Amazon ECS) en Amazon EC2. Usar la CLI de AWS con run-tasks configurado en true para iniciar la aplicación de planificación mediante la opción --tags para asignar una etiqueta personalizada a la tarea.",
            "D. Crear un clúster de Amazon Elastic Container Service (Amazon ECS) en AWS Fargate. Usar el comando run-task de AWS CLI y configurar enableECSManagedTags en true para iniciar la aplicación de planificación. Usar la opción --tags para asignar una etiqueta personalizada a la tarea."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "128.- Una empresa de software aloja una aplicación en AWS con recursos en múltiples cuentas y regiones de AWS. La aplicación se ejecuta en un grupo de instancias de Amazon EC2 dentro de una VPC de aplicación ubicada en la región us-east-1 con un bloque de direcciones IPv4 CIDR 10.10.0.0/16. En una cuenta de AWS diferente, existe una VPC de servicios compartidos ubicada en la región us-east-2 con un bloque de direcciones IPv4 CIDR 10.10.10.0/24. Cuando un ingeniero de la nube intenta establecer una conexión de VPC Peering entre la VPC de aplicación y la VPC de servicios compartidos usando AWS CloudFormation, se recibe un mensaje de error que indica un fallo en el emparejamiento. ¿Qué factores podrían estar causando este error? (Elige dos).",
        "opciones": [
            "A. Los rangos de direcciones IPv4 CIDR de las dos VPC se superponen.",
            "B. Las VPC no están en la misma región.",
            "C. Una o ambas cuentas no tienen acceso a una Internet Gateway.",
            "D. Una de las VPC no fue compartida a través de AWS Resource Access Manager.",
            "E. El rol de IAM en la cuenta aceptadora del emparejamiento no tiene los permisos correctos."
        ],
        "respuestas_correctas": [
            "E",
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "129.- Una auditoría externa de la aplicación serverless de una empresa revela que las políticas de IAM otorgan demasiados permisos. Estas políticas están adjuntas a los roles de ejecución de AWS Lambda. Cientos de funciones Lambda tienen permisos amplios, como acceso total a los buckets de Amazon S3 y a las tablas de Amazon DynamoDB. La empresa quiere que cada función tenga solo los permisos mínimos necesarios para completar su tarea. Un arquitecto de soluciones debe determinar qué permisos necesita cada función Lambda. ¿Qué debe hacer el arquitecto de soluciones para cumplir con este requisito con el mínimo esfuerzo?",
        "opciones": [
            "A. Configurar Amazon CodeGuru para perfilar las funciones Lambda y buscar llamadas a API de AWS. Crear un inventario de las llamadas a API y los recursos requeridos por cada función Lambda. Crear nuevas políticas de acceso de IAM para cada función Lambda. Revisar las nuevas políticas para asegurarse de que cumplan con los requisitos comerciales de la empresa.",
            "B. Activar AWS CloudTrail para la cuenta de AWS. Usar AWS IAM Access Analyzer para generar políticas de acceso de IAM basadas en la actividad registrada en los registros de CloudTrail. Revisar las políticas generadas para asegurarse de que cumplan con los requisitos comerciales de la empresa.",
            "C. Activar AWS CloudTrail para la cuenta de AWS. Crear un script para analizar los registros de CloudTrail, buscar llamadas a la API de AWS por función de ejecución de Lambda y generar un informe resumido. Revisar el informe y crear políticas de acceso de IAM que proporcionen permisos más restrictivos para cada función Lambda.",
            "D. Activar AWS CloudTrail para la cuenta de AWS. Exportar los registros de CloudTrail a Amazon S3. Usar Amazon EMR para procesar los registros de CloudTrail en S3 y generar un informe de las llamadas a la API y los recursos utilizados por cada rol de ejecución. Crear una nueva política de acceso de IAM para cada rol. Exportar las políticas generadas a un bucket de S3. Revisar las políticas generadas para asegurarse de que cumplan con los requisitos comerciales de la empresa."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "130.- Un arquitecto de soluciones debe analizar las instancias de Amazon EC2 y los volúmenes de Amazon EBS de una empresa para determinar si los recursos se están utilizando de manera eficiente. La empresa ejecuta varias instancias grandes y de alta memoria para alojar clústeres de bases de datos en configuraciones activo/pasivo. La utilización de estas instancias varía según las aplicaciones que usan las bases de datos, y la empresa no ha identificado un patrón. El arquitecto de soluciones debe analizar el entorno y tomar medidas en función de los hallazgos. ¿Qué solución cumple mejor con estos requisitos de la manera más rentable?",
        "opciones": [
            "A. Crear un panel de control usando AWS Systems Manager OpsCenter. Configurar visualizaciones para las métricas de Amazon CloudWatch asociadas con las instancias de EC2 y sus volúmenes de EBS. Revisar el panel periódicamente e identificar patrones de uso. Ajustar el tamaño de las instancias de EC2 en función de los picos en las métricas.",
            "B. Activar la monitorización detallada de Amazon CloudWatch para las instancias de EC2 y sus volúmenes de EBS. Crear y revisar un panel de métricas, identificar patrones de uso y ajustar el tamaño de las instancias de EC2 en función de los picos en las métricas.",
            "C. Instalar el agente de Amazon CloudWatch en cada instancia de EC2. Activar AWS Compute Optimizer y dejarlo funcionando por al menos 12 horas. Revisar las recomendaciones de Compute Optimizer y ajustar el tamaño de las instancias de EC2 según lo indicado.",
            "D. Registrarse en el plan AWS Enterprise Support. Activar AWS Trusted Advisor, esperar 12 horas, revisar las recomendaciones de Trusted Advisor y ajustar el tamaño de las instancias de EC2 según lo indicado."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "131.- Una empresa utiliza AWS Organizations para una configuración de múltiples cuentas en la nube de AWS. La empresa usa AWS Control Tower para la gobernanza y AWS Transit Gateway para la conectividad de VPC entre cuentas. En una cuenta de aplicación de AWS, el equipo de la empresa ha desplegado una aplicación web que usa AWS Lambda y Amazon RDS. Los administradores de bases de datos de la empresa tienen una cuenta DBA separada y utilizan esta cuenta para gestionar centralmente todas las bases de datos en la organización. Los administradores de bases de datos usan una instancia Amazon EC2 que está desplegada en la cuenta DBA para acceder a una base de datos RDS que está desplegada en la cuenta de la aplicación. El equipo de la aplicación ha almacenado las credenciales de la base de datos como secretos en AWS Secrets Manager en la cuenta de la aplicación. El equipo de la aplicación está compartiendo manualmente los secretos con los administradores de bases de datos. Los secretos están cifrados por la clave administrada por AWS por defecto para Secrets Manager en la cuenta de la aplicación. Un arquitecto de soluciones necesita implementar una solución que le dé acceso a los administradores de bases de datos a la base de datos y elimine la necesidad de compartir manualmente los secretos. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Usar AWS Resource Access Manager (AWS RAM) para compartir los secretos de la cuenta de la aplicación con la cuenta DBA. En la cuenta DBA, crear un rol IAM llamado DBA-Admin. Otorgar al rol los permisos necesarios para acceder a los secretos compartidos. Adjuntar el rol DBA-Admin a la instancia EC2 para acceder a los secretos entre cuentas.",
            "B. En la cuenta de la aplicación, crear un rol IAM llamado DBA-Secret. Otorgar al rol los permisos necesarios para acceder a los secretos. En la cuenta DBA, crear un rol IAM llamado DBA-Admin. Otorgar al rol DBA-Admin los permisos necesarios para asumir el rol DBA-Secret en la cuenta de la aplicación. Adjuntar el rol DBA-Admin a la instancia EC2 para acceder a los secretos entre cuentas.",
            "C. En la cuenta DBA, crear un rol IAM llamado DBA-Admin. Otorgar al rol los permisos necesarios para acceder a los secretos y la clave administrada por AWS por defecto en la cuenta de la aplicación. En la cuenta de la aplicación, adjuntar políticas basadas en recursos a la clave para permitir el acceso desde la cuenta DBA. Adjuntar el rol DBA-Admin a la instancia EC2 para acceder a los secretos entre cuentas.",
            "D. En la cuenta DBA, crear un rol IAM llamado DBA-Admin. Otorgar al rol los permisos necesarios para acceder a los secretos en la cuenta de la aplicación. Adjuntar un SCP a la cuenta de la aplicación para permitir el acceso a los secretos desde la cuenta DBA. Adjuntar el rol DBA-Admin a la instancia EC2 para acceder a los secretos entre cuentas."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "132.- Una empresa administra múltiples cuentas de AWS mediante AWS Organizations. Bajo la OU raíz, la empresa tiene dos OUs: Research y DataOps. Debido a requisitos regulatorios, todos los recursos que la empresa implemente en la organización debe residir en la región ap-northeast-1. Además, las instancias de EC2 que la empresa implemente en la OU DataOps deben usar una lista predefinida de tipos de instancias. Un arquitecto de soluciones debe implementar una solución que aplique estas restricciones mientras maximiza la eficiencia operativa y minimiza el mantenimiento continuo. ¿Qué combinación de pasos cumplirá con estos requisitos? (Elija dos).",
        "opciones": [
            "A. Crear un IAM role en una cuenta bajo la OU DataOps. Usar la clave de condición ec2:InstanceType en una política inline en el rol para restringir el acceso a tipos de instancias específicos.",
            "B. Crear un IAM user en todas las cuentas bajo la OU raíz. Usar la clave de condición aws:RequestedRegion en una política inline en cada usuario para restringir el acceso a todas las regiones de AWS excepto ap-northeast-1.",
            "C. Crear un SCP. Usar la clave de condición aws:RequestedRegion para restringir el acceso a todas las regiones de AWS excepto ap-northeast-1. Aplicar el SCP a la OU raíz.",
            "D. Crear un SCP. Usar la clave de condición ec2:Region para restringir el acceso a todas las regiones de AWS excepto ap-northeast-1. Aplicar el SCP a la OU raíz, la OU DataOps y la OU Research.",
            "E. Crear un SCP. Usar la clave de condición ec2:InstanceType para restringir el acceso a tipos de instancias específicos. Aplicar el SCP a la OU DataOps."
        ],
        "respuestas_correctas": [
            "E",
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "133.- Una empresa ejecuta una aplicación sin servidor en una sola Región de AWS. La aplicación accede a URLs externas y extrae metadatos de esos sitios. La empresa utiliza un tema de Amazon Simple Notification Service (Amazon SNS) para publicar URLs en una cola de Amazon Simple Queue Service (Amazon SQS). Una función de AWS Lambda usa la cola como fuente de eventos y procesa las URLs de la cola. Los resultados se guardan en un bucket de Amazon S3. La empresa quiere procesar cada URL en otras Regiones para comparar posibles diferencias en la localización del sitio. Las URLs deben publicarse desde la Región existente. Los resultados deben escribirse en el bucket de S3 existente en la Región actual. ¿Qué combinación de cambios producirá un despliegue multi-Región que cumpla con estos requisitos? (Elija dos.)",
        "opciones": [
            "A. Desplegar la cola de SQS con la función Lambda en otras Regiones.",
            "B. Suscribir el tema de SNS en cada Región a la cola de SQS.",
            "C. Suscribir la cola de SQS en cada Región al tema de SNS.",
            "D. Configurar la cola de SQS para publicar URLs en los temas de SNS de cada Región.",
            "E. Desplegar el tema de SNS y la función Lambda en otras Regiones."
        ],
        "respuestas_correctas": [
            "C",
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "134.- Una empresa ejecuta una aplicación ETL sin estado propietaria en instancias de Amazon EC2 Linux. La aplicación es un binario de Linux y no se puede modificar el código fuente. La aplicación es de un solo hilo, usa 2 GB de RAM y es altamente intensiva en CPU. La aplicación está programada para ejecutarse cada 4 horas y corre hasta 20 minutos. Un arquitecto de soluciones quiere revisar la arquitectura de la solución. ¿Qué estrategia debería usar el arquitecto de soluciones?",
        "opciones": [
            "A. Usar AWS Lambda para ejecutar la aplicación. Usar Amazon CloudWatch Logs para invocar la función Lambda cada 4 horas.",
            "B. Usar AWS Batch para ejecutar la aplicación. Usar una máquina de estados de AWS Step Functions para invocar el trabajo de AWS Batch cada 4 horas.",
            "C. Usar AWS Fargate para ejecutar la aplicación. Usar Amazon EventBridge (Amazon CloudWatch Events) para invocar la tarea Fargate cada 4 horas.",
            "D. Usar Amazon EC2 Spot Instances para ejecutar la aplicación. Usar AWS CodeDeploy para implementar y ejecutar la aplicación cada 4 horas."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "135.- Una empresa está creando una secuela de un popular juego en línea. Un gran número de usuarios de todo el mundo jugará el juego durante la primera semana después de su lanzamiento. Actualmente, el juego consta de los siguientes componentes desplegados en una sola Región de AWS: \n• Un bucket de Amazon S3 que almacena los activos del juego\n• Una tabla de Amazon DynamoDB que almacena las puntuaciones de los jugadores Un arquitecto de soluciones necesita diseñar una solución multi-Región que reduzca la latencia, mejore la fiabilidad y requiera el menor esfuerzo para implementar. \n¿Qué debe hacer el arquitecto de soluciones para cumplir con estos requisitos?",
        "opciones": [
            "A. Crear una distribución de Amazon CloudFront para servir los activos desde el bucket de S3. Configurar la replicación entre regiones de S3. Crear una nueva tabla de DynamoDB en una nueva Región. Usar la nueva tabla como objetivo de réplica para las tablas globales de DynamoDB.",
            "B. Crear una distribución de Amazon CloudFront para servir los activos desde el bucket de S3. Configurar la replicación dentro de la misma región de S3. Crear una nueva tabla de DynamoDB en una nueva Región. Configurar la replicación asincrónica entre las tablas de DynamoDB usando AWS Database Migration Service (AWS DMS) con captura de datos de cambios (CDC).",
            "C. Crear otro bucket de S3 en una nueva Región y configurar la replicación entre regiones de S3 entre los buckets. Crear una distribución de Amazon CloudFront y configurar la conmutación por error de orígenes con dos orígenes accediendo a los buckets de S3 en cada Región. Configurar tablas globales de DynamoDB habilitando Amazon DynamoDB Streams, y agregar una tabla réplica en una nueva Región.",
            "D. Crear otro bucket de S3 en la misma Región y configurar la replicación dentro de la misma región de S3 entre los buckets. Crear una distribución de Amazon CloudFront y configurar la conmutación por error de orígenes con dos orígenes accediendo a los buckets de S3. Crear una nueva tabla de DynamoDB en una nueva Región. Usar la nueva tabla como objetivo de réplica para las tablas globales de DynamoDB."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "136.- Una empresa tiene una aplicación web local que proporciona información sobre bienes raíces para posibles arrendatarios y compradores. La web utiliza un backend en Java y una base de datos NoSQL MongoDB para almacenar los datos de los suscriptores. La empresa necesita migrar toda la aplicación a AWS con una estructura similar. La aplicación debe desplegarse para alta disponibilidad y la empresa no puede hacer cambios en la aplicación. ¿Qué solución cumple con estos requisitos?",
        "opciones": [
            "A. Utilizar un clúster de Amazon Aurora como base de datos para los datos de los suscriptores. Desplegar instancias de Amazon EC2 en un grupo de Auto Scaling en múltiples Zonas de Disponibilidad para la aplicación backend en Java.",
            "B. Utilizar MongoDB en instancias de Amazon EC2 como base de datos para los datos de los suscriptores. Desplegar instancias de EC2 en un grupo de Auto Scaling en una sola Zona de Disponibilidad para la aplicación backend en Java.",
            "C. Configurar Amazon DocumentDB (con compatibilidad con MongoDB) con instancias adecuadamente dimensionadas en múltiples Zonas de Disponibilidad como base de datos para los datos de los suscriptores. Desplegar instancias de Amazon EC2 en un grupo de Auto Scaling en múltiples Zonas de Disponibilidad para la aplicación backend en Java.",
            "D. Configurar Amazon DocumentDB (con compatibilidad con MongoDB) en modo de capacidad bajo demanda en múltiples Zonas de Disponibilidad como base de datos para los datos de los suscriptores. Desplegar instancias de Amazon EC2 en un grupo de Auto Scaling en múltiples Zonas de Disponibilidad para la aplicación backend en Java."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "137.- Una empresa de marketing digital tiene varias cuentas de AWS que pertenecen a distintos equipos. El equipo creativo usa un bucket de Amazon S3 en su cuenta de AWS para almacenar de manera segura imágenes y archivos multimedia que se usan como contenido en las campañas de marketing de la empresa. El equipo creativo quiere compartir el bucket de S3 con el equipo de estrategia para que este último pueda ver los objetos. Un arquitecto de soluciones ha creado un rol IAM llamado strategy_reviewer en la cuenta de Strategy. También ha configurado una clave personalizada de AWS Key Management Service (KMS) en la cuenta de Creative y ha asociado esa clave con el bucket de S3. Sin embargo, cuando los usuarios de la cuenta de Strategy asumen el rol IAM e intentan acceder a los objetos del bucket de S3, reciben un error de Access Denied. El arquitecto de soluciones debe asegurarse de que los usuarios en la cuenta de Strategy puedan acceder al bucket de S3. La solución debe proporcionar solo los permisos mínimos necesarios para estos usuarios. ¿Qué combinación de pasos debe tomar el arquitecto de soluciones para cumplir con estos requisitos? (Elija tres opciones.)",
        "opciones": [
            "A. Crear una política de bucket que incluya permisos de lectura para el bucket de S3. Establecer el principal de la política de bucket al ID de cuenta de la cuenta de Strategy.",
            "B. Actualizar el rol strategy_reviewer IAM para otorgar permisos completos sobre el bucket de S3 y para otorgar permisos de descifrado para la clave personalizada de KMS.",
            "C. Actualizar la política de clave de KMS personalizada en la cuenta de Creative para otorgar permisos de descifrado al rol strategy_reviewer IAM.",
            "D. Crear una política de bucket que incluya permisos de lectura para el bucket de S3. Establecer el principal de la política de bucket a un usuario anónimo.",
            "E. Actualizar la política de clave de KMS personalizada en la cuenta de Creative para otorgar permisos de cifrado al rol strategy_reviewer IAM.",
            "F. Actualizar el rol strategy_reviewer IAM para otorgar permisos de lectura sobre el bucket de S3 y para otorgar permisos de descifrado para la clave personalizada de KMS."
        ],
        "respuestas_correctas": [
            "C",
            "F",
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "138.- Una empresa de ciencias de la vida está utilizando una combinación de herramientas de código abierto para gestionar flujos de trabajo de análisis de datos y contenedores Docker ejecutándose en servidores en su centro de datos local para procesar datos genómicos. Los datos de secuenciación se generan y almacenan en una red de almacenamiento de área local (SAN), y luego los datos se procesan. Los equipos de investigación y desarrollo están teniendo problemas de capacidad y han decidido reestructurar su plataforma de análisis genómico en AWS para escalar según las demandas de carga de trabajo y reducir el tiempo de respuesta de semanas a días. La empresa tiene una conexión de alta velocidad AWS Direct Connect. Los secuenciadores generarán alrededor de 200 GB de datos por cada genoma, y los trabajos individuales pueden tardar varias horas en procesar los datos con la capacidad de cómputo ideal. El resultado final se almacenará en Amazon S3. La empresa espera entre 10 y 15 solicitudes de trabajos cada día. ¿Qué solución cumple con estos requisitos?",
        "opciones": [
            "A. Usar dispositivos AWS Snowball Edge programados regularmente para transferir los datos de secuenciación a AWS. Cuando AWS reciba el dispositivo Snowball Edge y los datos se carguen en Amazon S3, usar eventos S3 para activar una función de AWS Lambda para procesar los datos.",
            "B. Usar AWS Data Pipeline para transferir los datos de secuenciación a Amazon S3. Usar eventos S3 para activar un grupo de Auto Scaling de Amazon EC2 para lanzar instancias EC2 con AMI personalizadas que ejecuten los contenedores Docker para procesar los datos.",
            "C. Usar AWS DataSync para transferir los datos de secuenciación a Amazon S3. Usar eventos S3 para activar una función de AWS Lambda que inicie un flujo de trabajo de AWS Step Functions. Almacenar las imágenes Docker en Amazon Elastic Container Registry (Amazon ECR) y activar AWS Batch para ejecutar el contenedor y procesar los datos de secuenciación.",
            "D. Usar un gateway de archivo AWS Storage Gateway para transferir los datos de secuenciación a Amazon S3. Usar eventos S3 para activar un trabajo de AWS Batch que se ejecute en instancias EC2 de Amazon que ejecuten los contenedores Docker para procesar los datos."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "139.- Una empresa ejecuta una aplicación de gestión de contenido en una única instancia de Amazon EC2 con Windows en un entorno de desarrollo. La aplicación lee y escribe contenido estático en un volumen de 2 TB de Amazon Elastic Block Store (Amazon EBS) que está adjunto a la instancia como el dispositivo raíz. La empresa planea desplegar esta aplicación en producción como una solución de alta disponibilidad y tolerancia a fallos, que se ejecute en al menos tres instancias de EC2 a través de múltiples Zonas de Disponibilidad. Un arquitecto de soluciones debe diseñar una solución que una todas las instancias que ejecutan la aplicación a un dominio de Active Directory. La solución también debe implementar ACLs de Windows para controlar el acceso a los contenidos de los archivos. La aplicación siempre debe mantener exactamente el mismo contenido en todas las instancias en ejecución en cualquier momento dado. ¿Qué solución cumplirá con estos requisitos con el MENOR esfuerzo de gestión?",
        "opciones": [
            "A. Crear un Amazon Elastic File System (Amazon EFS) para compartir archivos. Crear un grupo de Auto Scaling que se extienda a través de tres Zonas de Disponibilidad y mantenga un tamaño mínimo de tres instancias. Implementar un script de datos de usuario para instalar la aplicación, unir la instancia al dominio de AD y montar el sistema de archivos EFS.",
            "B. Crear una nueva AMI de la instancia EC2 actual que se está ejecutando. Crear un sistema de archivos Amazon FSx for Lustre. Crear un grupo de Auto Scaling que se extienda a través de tres Zonas de Disponibilidad y mantenga un tamaño mínimo de tres instancias. Implementar un script de datos de usuario para unir la instancia al dominio de AD y montar el sistema de archivos FSx for Lustre.",
            "C. Crear un sistema de archivos Amazon FSx for Windows File Server. Crear un grupo de Auto Scaling que se extienda a través de tres Zonas de Disponibilidad y mantenga un tamaño mínimo de tres instancias. Implementar un script de datos de usuario para instalar la aplicación y montar el sistema de archivos FSx for Windows File Server. Realizar unirse al dominio de manera continua para unir la instancia al dominio de AD.",
            "D. Crear una nueva AMI de la instancia EC2 que se está ejecutando. Crear un sistema de archivos Amazon Elastic File System (Amazon EFS). Crear un grupo de Auto Scaling que se extienda a través de tres Zonas de Disponibilidad y mantenga un tamaño mínimo de tres instancias. Realizar unirse al dominio de manera continua para unir la instancia al dominio de AD."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "140.- Una empresa que ofrece software como servicio (SaaS) proporciona una solución de gestión de casos a los clientes como parte de la solución. La empresa usa un servidor independiente de Simple Mail Transfer Protocol (SMTP) para enviar mensajes de correo electrónico desde una aplicación. La aplicación también almacena una plantilla de correo electrónico para los mensajes de confirmación que llenan los datos del cliente antes de que la aplicación envíe el mensaje de correo electrónico al cliente. La empresa planea migrar esta funcionalidad de mensajería a la nube de AWS y necesita minimizar la sobrecarga operativa. ¿Qué solución cumplirá con estos requisitos de la manera MÁS rentable?",
        "opciones": [
            "A. Configurar un servidor SMTP en instancias de Amazon EC2 utilizando una AMI del AWS Marketplace. Almacenar la plantilla de correo electrónico en un bucket de Amazon S3. Crear una función de AWS Lambda para recuperar la plantilla del bucket de S3 y combinar los datos del cliente de la aplicación con la plantilla. Usar un SDK en la función Lambda para enviar el mensaje de correo electrónico.",
            "B. Configurar Amazon Simple Email Service (Amazon SES) para enviar mensajes de correo electrónico. Almacenar la plantilla de correo electrónico en un bucket de Amazon S3. Crear una función de AWS Lambda para recuperar la plantilla del bucket de S3 y combinar los datos del cliente de la aplicación con la plantilla. Usar un SDK en la función Lambda para enviar el mensaje de correo electrónico.",
            "C. Configurar un servidor SMTP en instancias de Amazon EC2 utilizando una AMI del AWS Marketplace. Almacenar la plantilla de correo electrónico en Amazon Simple Email Service (Amazon SES) con parámetros para los datos del cliente. Crear una función de AWS Lambda para llamar a la plantilla SES y pasar los datos del cliente para reemplazar los parámetros. Usar el servidor SMTP del AWS Marketplace para enviar el mensaje de correo electrónico.",
            "D. Configurar Amazon Simple Email Service (Amazon SES) para enviar mensajes de correo electrónico. Almacenar la plantilla de correo electrónico en Amazon SES con parámetros para los datos del cliente. Crear una función de AWS Lambda para llamar a la operación API SendTemplatedEmail y pasar los datos del cliente para reemplazar los parámetros y el destino del correo electrónico."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "141.- Una empresa está procesando videos en la nube de AWS utilizando instancias de Amazon EC2 en un grupo de Auto Scaling. Toma 30 minutos procesar un video. Varias instancias de EC2 se escalan hacia dentro y hacia fuera dependiendo del número de videos en una cola de Amazon Simple Queue Service (Amazon SQS). La empresa ha configurado la cola de SQS con una política de reenvío que especifica una cola de mensajes muertos como objetivo y un valor maxReceiveCount de 1. La empresa ha configurado el tiempo de visibilidad de la cola de SQS a 1 hora. La empresa ha configurado una alarma de Amazon CloudWatch para notificar al equipo de desarrollo cuando hay mensajes en la cola de mensajes muertos. Varias veces al día, el equipo de desarrollo recibe notificaciones de que hay mensajes en la cola de mensajes muertos y que los videos no se han procesado correctamente. Una investigación no encuentra errores en los registros de la aplicación. ¿Cómo puede la empresa solucionar este problema?",
        "opciones": [
            "A. Activar la protección contra terminación para las instancias de EC2.",
            "B. Actualizar el tiempo de visibilidad para la cola de SQS a 3 horas.",
            "C. Configurar la protección contra la reducción de escala para las instancias durante el procesamiento.",
            "D. Actualizar la política de reenvío y establecer maxReceiveCount a 0."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "142.- Una empresa ha desarrollado APIs que usan Amazon API Gateway con puntos finales regionales. Las APIs llaman a funciones AWS Lambda que utilizan los mecanismos de autenticación de API Gateway. Después de una revisión de diseño, un arquitecto de soluciones identifica un conjunto de APIs que no requieren acceso público. El arquitecto de soluciones debe diseñar una solución para hacer que el conjunto de APIs sea accesible solo desde una VPC. Todas las APIs deben ser llamadas con un usuario autenticado. ¿Qué solución cumplirá estos requisitos con el MENOR esfuerzo?",
        "opciones": [
            "A. Crear un Application Load Balancer (ALB) interno. Crear un grupo de destino. Seleccionar la función Lambda que se va a llamar. Usar el nombre DNS del ALB para llamar a la API desde la VPC.",
            "B. Eliminar la entrada DNS asociada con la API en API Gateway. Crear una zona alojada en Amazon Route 53. Crear un registro CNAME en la zona alojada. Actualizar la API en API Gateway con el registro CNAME. Usar el registro CNAME para llamar a la API desde la VPC.",
            "C. Actualizar el punto final de la API de regional a privado en API Gateway. Crear un punto final de interfaz VPC en la VPC. Crear una política de recursos y adjuntarla a la API. Usar el punto final VPC para llamar a la API desde la VPC.",
            "D. Desplegar las funciones Lambda dentro de la VPC. Provisionar una instancia de EC2 e instalar un servidor Apache. Desde el servidor Apache, llamar a las funciones Lambda. Usar el registro CNAME interno de la instancia de EC2 para llamar a la API desde la VPC."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "143.- Un servicio meteorológico proporciona mapas meteorológicos de alta resolución desde una aplicación web alojada en AWS en la región eu-west-1. Los mapas meteorológicos se actualizan con frecuencia y se almacenan en Amazon S3 junto con contenido HTML estático. La aplicación web está frente a Amazon CloudFront. La empresa se expandió recientemente para atender a usuarios en la región us-east-1, y estos nuevos usuarios informan que la visualización de sus respectivos mapas meteorológicos es lenta en ocasiones. ¿Qué combinación de pasos resolverá los problemas de rendimiento en us-east-1? (Elija dos.)",
        "opciones": [
            "A. Configurar el punto de enlace de AWS Global Accelerator para el bucket de S3 en eu-west-1. Configurar grupos de puntos de enlace para los puertos TCP 80 y 443 en us-east-1.",
            "B. Crear un nuevo bucket de S3 en us-east-1. Configurar la replicación cruzada de S3 para sincronizar desde el bucket de S3 en eu-west-1.",
            "C. Usar Lambda@Edge para modificar las solicitudes de América del Norte para que utilicen el punto de enlace de S3 Transfer Acceleration en us-east-1.",
            "D. Usar Lambda@Edge para modificar las solicitudes de América del Norte para que utilicen el bucket de S3 en us-east-1.",
            "E. Configurar el punto de enlace de AWS Global Accelerator para us-east-1 como origen en la distribución de CloudFront. Usar Lambda@Edge para modificar las solicitudes de América del Norte para que utilicen el nuevo origen."
        ],
        "respuestas_correctas": [
            "D",
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "144.- Un arquitecto de soluciones está investigando un problema en el que una empresa no puede establecer nuevas sesiones en Amazon Workspaces. Un análisis inicial indica que el problema involucra los perfiles de usuario. El entorno de Amazon Workspaces está configurado para usar Amazon FSx for Windows File Server como el almacenamiento compartido de perfiles. El sistema de archivos de FSx for Windows File Server está configurado con 10 TB de almacenamiento. El arquitecto de soluciones descubre que el sistema de archivos ha alcanzado su capacidad máxima. El arquitecto de soluciones debe asegurarse de que los usuarios puedan recuperar el acceso. La solución también debe prevenir que el problema ocurra nuevamente. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Eliminar los perfiles de usuario antiguos para crear espacio. Migrar los perfiles de usuario a un sistema de archivos Amazon FSx for Lustre.",
            "B. Aumentar la capacidad utilizando el comando update-file-system. Implementar una métrica de Amazon CloudWatch que monitoree el espacio libre. Usar Amazon EventBridge para invocar una función AWS Lambda y aumentar la capacidad según sea necesario.",
            "C. Monitorear el sistema de archivos utilizando la métrica FreeStorageCapacity en Amazon CloudWatch. Usar AWS Step Functions para aumentar la capacidad según sea necesario.",
            "D. Eliminar los perfiles de usuario antiguos para crear espacio. Crear un sistema de archivos adicional FSx for Windows File Server. Actualizar la redirección de perfiles de usuario para que el 50% de los usuarios utilicen el nuevo sistema de archivos."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "145.- Una empresa internacional de entregas alberga un sistema de gestión de entregas en AWS. Los conductores usan el sistema para cargar la confirmación de la entrega. La confirmación incluye la firma del destinatario o una foto del paquete con el destinatario. El dispositivo móvil del conductor sube las firmas y fotos a través de FTP a una única instancia de Amazon EC2. Cada dispositivo móvil guarda un archivo en un directorio según el usuario que haya iniciado sesión, y el nombre del archivo coincide con el número de entrega. La instancia EC2 luego agrega metadatos al archivo después de consultar una base de datos central para obtener información sobre la entrega. El archivo se coloca en Amazon S3 para su archivo. A medida que la empresa se expande, los conductores informan que el sistema está rechazando conexiones. El servidor FTP tiene problemas debido a conexiones interrumpidas y problemas de memoria. En respuesta a estos problemas, un ingeniero de sistemas programa una tarea cron para reiniciar la instancia EC2 cada 30 minutos. El equipo de facturación informa que los archivos no siempre están en el archivo y que el sistema central no siempre se actualiza. Un arquitecto de soluciones debe diseñar una solución que maximice la escalabilidad para garantizar que el archivo siempre reciba los archivos y que los sistemas siempre estén actualizados. No se pueden modificar los dispositivos móviles, por lo que la empresa no puede implementar una nueva aplicación. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Crear una AMI de la instancia EC2 existente. Crear un grupo de Auto Scaling de instancias EC2 detrás de un Application Load Balancer. Configurar el grupo de Auto Scaling para que tenga un mínimo de tres instancias.",
            "B. Usar AWS Transfer Family para crear un servidor FTP que coloque los archivos en Amazon Elastic File System (Amazon EFS). Montar el volumen EFS en la instancia EC2 existente. Señalar a la instancia EC2 a la nueva ruta para el procesamiento de archivos.",
            "C. Usar AWS Transfer Family para crear un servidor FTP que coloque los archivos en Amazon S3. Usar una notificación de evento S3 a través de Amazon Simple Notification Service (Amazon SNS) para invocar una función AWS Lambda. Configurar la función Lambda para agregar los metadatos y actualizar el sistema de entrega.",
            "D. Actualizar los dispositivos móviles para que coloquen los archivos directamente en Amazon S3. Usar una notificación de evento S3 a través de Amazon Simple Queue Service (Amazon SQS) para invocar una función AWS Lambda. Configurar la función Lambda para agregar los metadatos y actualizar el sistema de entrega."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "146.- Una empresa está ejecutando una aplicación en la nube de AWS. La aplicación se ejecuta en contenedores en un clúster de Amazon Elastic Container Service (Amazon ECS). Las tareas de ECS usan el tipo de lanzamiento Fargate. Los datos de la aplicación son relacionales y se almacenan en Amazon Aurora MySQL. Para cumplir con los requisitos regulatorios, la aplicación debe poder recuperarse en una región de AWS separada en caso de una falla de la aplicación. En caso de una falla, no se puede perder ningún dato. ¿Qué solución cumplirá con estos requisitos con la MENOR cantidad de sobrecarga operativa?",
        "opciones": [
            "A. Proveer una réplica de Aurora en una región diferente.",
            "B. Configurar AWS DataSync para la replicación continua de los datos a una región diferente.",
            "C. Configurar AWS Database Migration Service (AWS DMS) para realizar una replicación continua de los datos a una región diferente.",
            "D. Usar Amazon Data Lifecycle Manager (Amazon DLM) para programar una instantánea cada 5 minutos."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "147-Una empresa de servicios financieros recibe un flujo de datos regular de su socio de servicio de tarjetas de crédito. Aproximadamente 5,000 registros se envían cada 15 minutos en texto sin formato, entregados a través de HTTPS directamente en un cubo de Amazon S3 con cifrado del lado del servidor. Este flujo de datos contiene información sensible del número de cuenta primaria de la tarjeta de crédito (PAN). La empresa necesita enmascarar automáticamente el PAN antes de enviar los datos a otro cubo de S3 para un procesamiento interno adicional. La empresa también necesita eliminar y fusionar campos específicos, y luego transformar el registro en formato JSON. Además, es probable que se agreguen flujos adicionales en el futuro, por lo que cualquier diseño debe ser fácilmente ampliable. ¿Qué soluciones cumplirán con estos requisitos?",
        "opciones": [
            "A. Invocar una función AWS Lambda al entregar el archivo que extrae cada registro y lo escribe en una cola de Amazon SQS. Invocar otra función Lambda cuando lleguen nuevos mensajes a la cola SQS para procesar los registros, escribiendo los resultados en una ubicación temporal en Amazon S3. Invocar una función Lambda final una vez que la cola SQS esté vacía para transformar los registros en formato JSON y enviar los resultados a otro cubo de S3 para el procesamiento interno.",
            "B. Invocar una función AWS Lambda al entregar el archivo que extrae cada registro y lo escribe en una cola de Amazon SQS. Configurar una aplicación de contenedor AWS Fargate para que escale automáticamente a una sola instancia cuando la cola SQS contenga mensajes. Hacer que la aplicación procese cada registro y transforme el registro en formato JSON. Cuando la cola esté vacía, enviar los resultados a otro cubo de S3 para el procesamiento interno y reducir la instancia de AWS Fargate.",
            "C. Crear un rastreador de AWS Glue y un clasificador personalizado basado en los formatos de flujo de datos y crear una definición de tabla que coincida. Invocar una función AWS Lambda al entregar el archivo para iniciar un trabajo de AWS Glue ETL para transformar todo el registro según los requisitos de procesamiento y transformación. Definir el formato de salida como JSON. Una vez completado, hacer que el trabajo ETL envíe los resultados a otro cubo de S3 para el procesamiento interno.",
            "D. Crear un rastreador de AWS Glue y un clasificador personalizado basado en los formatos de flujo de datos y crear una definición de tabla que coincida. Realizar una consulta de Amazon Athena al entregar el archivo para iniciar un trabajo de AWS EMR ETL para transformar todo el registro según los requisitos de procesamiento y transformación. Definir el formato de salida como JSON. Una vez completado, enviar los resultados a otro cubo de S3 para el procesamiento interno y reducir el clúster de EMR."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "148.- Una empresa desea usar AWS para crear una solución de continuidad de negocio en caso de que falle la aplicación principal en sus servidores locales. La aplicación se ejecuta en servidores físicos que también ejecutan otras aplicaciones. La aplicación local que la empresa planea migrar utiliza una base de datos MySQL como almacén de datos. Todas las aplicaciones locales de la empresa usan sistemas operativos compatibles con Amazon EC2. ¿Qué solución logrará el objetivo de la empresa con la MENOR sobrecarga operativa?",
        "opciones": [
            "A. Instalar el AWS Replication Agent en los servidores de origen, incluidos los servidores MySQL. Configurar la replicación para todos los servidores. Lanzar instancias de prueba para simulacros regulares. Realizar un corte a las instancias de prueba para realizar el failover de la carga de trabajo en caso de un evento de fallo.",
            "B. Instalar el AWS Replication Agent en los servidores de origen, incluidos los servidores MySQL. Inicializar AWS Elastic Disaster Recovery en la región de destino de AWS. Definir la configuración de lanzamiento. Realizar con frecuencia el failover y el fallback desde el punto de tiempo más reciente.",
            "C. Crear servidores de replicación de AWS Database Migration Service (AWS DMS) y un clúster de base de datos Amazon Aurora MySQL en el destino para alojar la base de datos. Crear una tarea de replicación de DMS para copiar los datos existentes al clúster de base de datos de destino. Crear una tarea de captura de datos de cambios (CDC) de AWS Schema Conversion Tool (AWS SCT) para mantener los datos sincronizados. Instalar el resto del software en instancias EC2 comenzando con una AMI base compatible.",
            "D. Desplegar un AWS Storage Gateway Volume Gateway en las instalaciones. Montar volúmenes en todos los servidores locales. Instalar la aplicación y la base de datos MySQL en los nuevos volúmenes. Tomar instantáneas regulares. Instalar todo el software en instancias EC2 comenzando con una AMI base compatible. Lanzar un Volume Gateway en una instancia EC2. Restaurar los volúmenes desde la última instantánea. Montar los nuevos volúmenes en las instancias EC2 en caso de un evento de falla."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "149.- Una empresa está sujeta a auditorías regulatorias de su información financiera. Los auditores externos, que utilizan una única cuenta de AWS, necesitan acceso a la cuenta de AWS de la empresa. Un arquitecto de soluciones debe proporcionar a los auditores un acceso seguro y de solo lectura a la cuenta de AWS de la empresa. La solución debe cumplir con las mejores prácticas de seguridad de AWS. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. En la cuenta de AWS de la empresa, cree políticas de recursos para todos los recursos de la cuenta para otorgar acceso a la cuenta de AWS de los auditores. Asigne un ID externo único a la política de recursos.",
            "B. En la cuenta de AWS de la empresa, cree un rol IAM que confíe en la cuenta de AWS de los auditores. Cree una política IAM que tenga los permisos requeridos. Adjunte la política al rol. Asigne un ID externo único a la política de confianza del rol.",
            "C. En la cuenta de AWS de la empresa, cree un usuario IAM. Adjunte las políticas IAM requeridas al usuario IAM. Cree claves de acceso API para el usuario IAM. Comparta las claves de acceso con los auditores.",
            "D. En la cuenta de AWS de la empresa, cree un grupo IAM que tenga los permisos requeridos. Cree un usuario IAM en la cuenta de la empresa para cada auditor. Añada los usuarios IAM al grupo IAM."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "150.- Una empresa tiene una plataforma de trading sensible a la latencia que utiliza Amazon DynamoDB como almacenamiento en el backend. La empresa configuró la tabla de DynamoDB para usar el modo de capacidad bajo demanda. Un arquitecto de soluciones necesita diseñar una solución para mejorar el rendimiento de la plataforma de trading. La nueva solución debe garantizar alta disponibilidad para la plataforma de trading. ¿Qué solución cumplirá con estos requisitos con la MENOR latencia?",
        "opciones": [
            "A. Crear un clúster de DynamoDB Accelerator (DAX) de dos nodos. Configurar la aplicación para leer y escribir datos utilizando DAX.",
            "B. Crear un clúster de DynamoDB Accelerator (DAX) de tres nodos. Configurar la aplicación para leer datos utilizando DAX y escribir datos directamente en la tabla de DynamoDB.",
            "C. Crear un clúster de DynamoDB Accelerator (DAX) de tres nodos. Configurar la aplicación para leer datos directamente de la tabla de DynamoDB y escribir datos utilizando DAX.",
            "D. Crear un clúster de DynamoDB Accelerator (DAX) de un solo nodo. Configurar la aplicación para leer datos utilizando DAX y escribir datos directamente en la tabla de DynamoDB."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "151.- Una empresa ha migrado una aplicación desde sus instalaciones a AWS. El frontend de la aplicación es un sitio web estático que se ejecuta en dos instancias EC2 detrás de un Application Load Balancer (ALB) El backend es una aplicación en Python que se ejecuta en tres instancias EC2 detrás de otro ALB Las instancias EC2 son de propósito general, On-Demand, dimensionadas según las especificaciones locales para el uso máximo de la aplicación. La aplicación procesa cientos de miles de solicitudes al mes, pero se usa principalmente durante la hora del almuerzo, recibiendo tráfico mínimo el resto del día. Un arquitecto de soluciones debe optimizar el costo de la infraestructura sin afectar la disponibilidad de la aplicación. ¿Qué combinación de pasos cumplirá con estos requisitos? (Elige dos)",
        "opciones": [
            "A. Cambiar todas las instancias EC2 a instancias optimizadas para cómputo con el mismo número de núcleos que las instancias actuales.",
            "B. Mover el frontend de la aplicación a un sitio web estático alojado en Amazon S3.",
            "C. Implementar el frontend de la aplicación en AWS Elastic Beanstalk. Usar el mismo tipo de instancia para los nodos.",
            "D. Cambiar todas las instancias backend de EC2 a Spot Instances.",
            "E. Implementar la aplicación backend de Python en instancias EC2 burstables de propósito general con el mismo número de núcleos que las instancias actuales."
        ],
        "respuestas_correctas": [
            "E",
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "152.- Una empresa está ejecutando una plataforma de venta de entradas para eventos en AWS y desea optimizar la rentabilidad de la plataforma. La plataforma se implementa en Amazon Elastic Kubernetes Service (Amazon EKS) utilizando instancias de Amazon EC2 y está respaldada por una instancia de Amazon RDS para MySQL. La empresa está desarrollando nuevas funcionalidades de la aplicación para ejecutarse en Amazon EKS con AWS Fargate. La plataforma experimenta picos altos de demanda de forma poco frecuente. Los aumentos en la demanda dependen de las fechas de los eventos. ¿Cuál de las siguientes soluciones proporcionará la configuración MÁS rentable para la plataforma?",
        "opciones": [
            "A. Comprar Instancias Reservadas Estándar para las instancias de EC2 que el clúster de EKS utiliza en su carga base. Escalar el clúster con instancias Spot para manejar los picos. Comprar Instancias Reservadas de 1 año con pago total anticipado para la base de datos, para cumplir con la carga máxima prevista durante el año.",
            "B. Comprar Compute Savings Plans para la carga media prevista del clúster de EKS. Escalar el clúster con Reservas de Capacidad On-Demand basadas en las fechas de los eventos para los picos. Comprar Instancias Reservadas de 1 año sin pago inicial para la base de datos, para cumplir con la carga base prevista. Escalar temporalmente las réplicas de lectura de la base de datos durante los picos.",
            "C. Comprar EC2 Instance Savings Plans para la carga base prevista del clúster de EKS. Escalar el clúster con instancias Spot para manejar los picos. Comprar Instancias Reservadas de 1 año con pago total anticipado para la base de datos, para cumplir con la carga base prevista. Escalar manualmente la instancia de la base de datos de forma temporal durante los picos.",
            "D. Comprar Compute Savings Plans para la carga base prevista del clúster de EKS. Escalar el clúster con instancias Spot para manejar los picos. Comprar Instancias Reservadas de 1 año con pago total anticipado para la base de datos, para cumplir con la carga base prevista. Escalar manualmente la instancia de la base de datos de forma temporal durante los picos."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "153.- Una empresa ha implementado una aplicación en AWS Elastic Beanstalk. La aplicación utiliza Amazon Aurora como capa de base de datos. Una distribución de Amazon CloudFront atiende las solicitudes web e incluye el nombre de dominio de Elastic Beanstalk como el servidor de origen. La distribución está configurada con un nombre de dominio alternativo que los visitantes usan para acceder a la aplicación. Cada semana, la empresa saca la aplicación de servicio para mantenimiento rutinario. Durante el tiempo en que la aplicación no está disponible, la empresa quiere que los visitantes reciban un mensaje informativo en lugar de un mensaje de error de CloudFront. Un arquitecto de soluciones crea un bucket de Amazon S3 como el primer paso del proceso. ¿Qué combinación de pasos debe seguir el arquitecto de soluciones a continuación para cumplir con los requisitos? (Elige tres).",
        "opciones": [
            "A. Subir contenido informativo estático al bucket de S3.",
            "B. Crear una nueva distribución de CloudFront. Establecer el bucket de S3 como el origen.",
            "C. Establecer el bucket de S3 como un segundo origen en la distribución original de CloudFront. Configurar la distribución y el bucket de S3 para usar una identidad de acceso de origen (OAI).",
            "D. Durante el mantenimiento semanal, editar el comportamiento de caché predeterminado para usar el origen S3. Revertir el cambio cuando se complete el mantenimiento.",
            "E. Durante el mantenimiento semanal, crear un comportamiento de caché para el origen S3 en la nueva distribución. Establecer el patrón de ruta en \\. Establecer la precedencia en 0. Eliminar el comportamiento de caché cuando finalice el mantenimiento.",
            "F. Durante el mantenimiento semanal, configurar Elastic Beanstalk para servir tráfico desde el bucket de S3."
        ],
        "respuestas_correctas": [
            "C",
            "D",
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "154.- Una empresa permite a los usuarios subir imágenes desde una aplicación personalizada. El proceso de carga invoca una función AWS Lambda que procesa y almacena la imagen en un bucket de Amazon S3. La aplicación invoca la función Lambda utilizando un ARN de versión específica de la función. La función Lambda recibe parámetros de procesamiento de imágenes a través de variables de entorno. La empresa ajusta frecuentemente estas variables para optimizar los resultados, probando diferentes parámetros y publicando una nueva versión de la función tras validar los resultados. Este proceso requiere modificar la aplicación constantemente para invocar el nuevo ARN de versión, lo que interrumpe a los usuarios. Un arquitecto de soluciones debe simplificar este proceso para minimizar interrupciones. ¿Qué solución cumple con estos requisitos con el MENOR esfuerzo operativo?",
        "opciones": [
            "A. Modificar directamente las variables de entorno de la versión publicada de Lambda. Usar la versión $LATEST para probar los parámetros de procesamiento de imágenes.",
            "B. Crear una tabla de Amazon DynamoDB para almacenar los parámetros de procesamiento de imágenes. Modificar la función Lambda para recuperar los parámetros desde la tabla DynamoDB.",
            "C. Codificar los parámetros de procesamiento dentro de la función Lambda y eliminar las variables de entorno. Publicar una nueva versión de la función cuando se actualicen los parámetros.",
            "D. Crear un alias de función Lambda. Modificar la aplicación para que use el ARN del alias en lugar de un ARN de versión específica. Reconfigurar el alias para apuntar a la nueva versión de la función cuando finalicen las pruebas."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "155.- Una compañía global de medios está planeando un despliegue multi-Región de una aplicación. Las tablas globales de Amazon DynamoDB respaldarán el despliegue para mantener una experiencia de usuario consistente en los dos continentes donde se concentran los usuarios. Cada despliegue contará con un Application Load Balancer (ALB) público. La compañía gestiona el DNS público de forma interna y desea que la aplicación esté disponible a través de un dominio apex. ¿Qué solución cumplirá con estos requisitos con el menor esfuerzo?",
        "opciones": [
            "A. Migre el DNS público a Amazon Route 53. Cree registros CNAME para el dominio apex que apunten al ALB. Utilice una política de enrutamiento por geolocalización para dirigir el tráfico según la ubicación del usuario.",
            "B. Coloque un Network Load Balancer (NLB) delante del ALB. Migre el DNS público a Amazon Route 53. Cree un registro CNAME para el dominio apex que apunte a la dirección IP estática del NLB. Utilice una política de enrutamiento por geolocalización para dirigir el tráfico según la ubicación del usuario.",
            "C. Cree un acelerador de AWS Global Accelerator con múltiples grupos de endpoints que apunten a endpoints en las regiones de AWS apropiadas. Utilice la dirección IP estática del acelerador para crear un registro en el DNS público para el dominio apex.",
            "D. Cree una API de Amazon API Gateway respaldada por AWS Lambda en una de las regiones de AWS. Configure una función Lambda para enrutar el tráfico a los despliegues de la aplicación utilizando el método round robin. Cree registros CNAME para el dominio apex que apunten a la URL de la API."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "156.- Una empresa está desarrollando una nueva API sin servidor utilizando Amazon API Gateway y AWS Lambda. La empresa integró las funciones Lambda con API Gateway para utilizar varias bibliotecas compartidas y clases personalizadas. Un arquitecto de soluciones necesita simplificar la implementación de la solución y optimizar la reutilización del código. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Implementar las bibliotecas compartidas y las clases personalizadas en una imagen de Docker. Almacenar la imagen en un bucket de S3. Crear una capa de Lambda que utilice la imagen de Docker como origen. Implementar las funciones Lambda de la API como paquetes Zip. Configurar los paquetes para usar la capa de Lambda.",
            "B. Implementar las bibliotecas compartidas y las clases personalizadas en una imagen de Docker. Cargar la imagen en Amazon Elastic Container Registry (Amazon ECR). Crear una capa de Lambda que utilice la imagen de Docker como origen. Implementar las funciones Lambda de la API como paquetes Zip. Configurar los paquetes para usar la capa de Lambda.",
            "C. Implementar las bibliotecas compartidas y las clases personalizadas en un contenedor de Docker en Amazon Elastic Container Service (Amazon ECS) utilizando el tipo de lanzamiento AWS Fargate. Implementar las funciones Lambda de la API como paquetes Zip. Configurar los paquetes para usar el contenedor implementado como una capa de Lambda.",
            "D. Implementar las bibliotecas compartidas, las clases personalizadas y el código de las funciones Lambda de la API en una imagen de Docker. Cargar la imagen en Amazon Elastic Container Registry (Amazon ECR). Configurar las funciones Lambda de la API para usar la imagen de Docker como paquete de implementación."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "157-Una empresa de manufactura está construyendo una solución de inspección para su fábrica. Tiene cámaras IP al final de cada línea de ensamblaje Ha utilizado Amazon SageMaker para entrenar un modelo de aprendizaje automático (ML) que identifica defectos en imágenes estáticas. Desea proporcionar retroalimentación local a los trabajadores cuando se detecta un defecto La solución debe funcionar incluso si la conectividad a internet falla. La empresa tiene un servidor Linux local que aloja una API para proporcionar retroalimentación a los trabajadores. ¿Cómo debe la empresa desplegar el modelo de ML para cumplir con estos requisitos?",
        "opciones": [
            "A. Configurar un Amazon Kinesis video stream desde cada cámara IP hacia AWS. Usar instancias Amazon EC2 para capturar imágenes y subirlas a un bucket de Amazon S3. Implementar un endpoint de SageMaker con el modelo de ML. Invocar una función AWS Lambda cuando se suban nuevas imágenes y configurarla para llamar a la API local si se detecta un defecto.",
            "B. Desplegar AWS IoT Greengrass en el servidor local. Implementar el modelo de ML en el servidor Greengrass. Crear un componente Greengrass para capturar imágenes de las cámaras y ejecutar inferencias. Configurar el componente para llamar a la API local cuando se detecte un defecto.",
            "C. Pedir un dispositivo AWS Snowball. Implementar un endpoint de SageMaker con el modelo de ML y una instancia EC2 en el dispositivo Snowball. Capturar imágenes de las cámaras y ejecutar inferencias desde la instancia EC2. Configurar la instancia para llamar a la API local cuando se detecte un defecto.",
            "D. Implementar dispositivos Amazon Monitron en cada cámara IP. Implementar un Amazon Monitron Gateway en las instalaciones. Implementar el modelo de ML en los dispositivos Monitron. Usar alarmas de estado de salud de Amazon Monitron para invocar una función Lambda que llame a la API local cuando se detecte un defecto."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "158.- Un arquitecto de soluciones debe crear un caso de negocio para la migración del centro de datos local de una empresa a la nube de AWS. El arquitecto de soluciones utilizará una exportación de la base de datos de gestión de la configuración (CMDB) de todos los servidores de la empresa para crear el caso. ¿Qué solución cumplirá estos requisitos de la manera MÁS rentable?",
        "opciones": [
            "A. Utilice AWS Well-Architected Tool para importar los datos de la CMDB, realizar un análisis y generar recomendaciones.",
            "B. Utilice Migration Evaluator para realizar un análisis. Utilice la plantilla de importación de datos para cargar los datos de la exportación de la CMDB.",
            "C. Implemente reglas de coincidencia de recursos. Utilice la exportación de la CMDB y la AWS Price List Bulk API para consultar en bloque los datos de la CMDB contra los servicios de AWS.",
            "D. Utilice AWS Application Discovery Service para importar los datos de la CMDB y realizar un análisis."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "159.- Una empresa tiene un sitio web que se ejecuta en instancias de Amazon EC2 detrás de un Application Load Balancer (ALB). Las instancias están en un grupo de Auto Scaling. El ALB está asociado con un AWS WAF web ACL. El sitio web a menudo sufre ataques en la capa de aplicación. Estos ataques generan aumentos repentinos y significativos en el tráfico del servidor de la aplicación. Los registros de acceso muestran que cada ataque se origina desde diferentes direcciones IP. Un arquitecto de soluciones necesita implementar una solución para mitigar estos ataques. ¿Qué solución cumplirá con estos requisitos con el menor esfuerzo operativo?",
        "opciones": [
            "A. Crear una alarma de Amazon CloudWatch que monitoree el acceso al servidor. Establecer un umbral basado en el acceso por dirección IP. Configurar una acción de alarma que agregue la dirección IP a la lista de denegación (deny list) del web ACL de AWS WAF.",
            "B. Implementar AWS Shield Advanced además de AWS WAF. Agregar el ALB como un recurso protegido.",
            "C. Crear una alarma de Amazon CloudWatch que monitoree direcciones IP de usuarios. Establecer un umbral basado en el acceso por dirección IP. Configurar la alarma para invocar una función AWS Lambda que agregue una regla de denegación en la tabla de enrutamiento de la subred del servidor de la aplicación para cualquier dirección IP que active la alarma.",
            "D. Inspeccionar los registros de acceso para encontrar un patrón de direcciones IP que lanzaron los ataques. Usar una política de enrutamiento geolocalizado de Amazon Route 53 para denegar tráfico desde los países que hospedan esas direcciones IP"
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "160.- Una empresa tiene una aplicación crítica en la que la capa de datos está desplegada en una sola Región de AWS. La capa de datos utiliza una tabla de Amazon DynamoDB y un clúster de Amazon Aurora MySQL. La versión actual del motor de Aurora MySQL admite bases de datos globales. La capa de aplicación ya está desplegada en dos Regiones. Política de la empresa Las aplicaciones críticas deben tener componentes de aplicación y datos desplegados en dos Regiones RTO y RPO deben ser de unos pocos minutos. Un arquitecto de soluciones debe recomendar una solución para que la capa de datos cumpla con la política de la empresa. ¿Qué combinación de pasos cumplirá con estos requisitos? (Elige dos.)",
        "opciones": [
            "A. Agregar otra Región al clúster de Amazon Aurora MySQL.",
            "B. Agregar otra Región a cada tabla en el clúster de Amazon Aurora MySQL.",
            "C. Configurar copias de seguridad programadas entre Regiones para la tabla de DynamoDB y el clúster de Amazon Aurora MySQL.",
            "D. Convertir la tabla de DynamoDB en una tabla global, agregando otra Región a su configuración.",
            "E. Usar Amazon Route 53 Application Recovery Controller para automatizar la copia de seguridad y recuperación de la base de datos en la Región secundaria."
        ],
        "respuestas_correctas": [
            "D",
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "161.- Una empresa de telecomunicaciones está ejecutando una aplicación en AWS. La empresa ha configurado una conexión AWS Direct Connect entre su centro de datos local y AWS. La aplicación se ha desplegado en instancias de Amazon EC2 en múltiples Zonas de Disponibilidad (AZ) detrás de un Application Load Balancer (ALB) interno. Los clientes de la empresa se conectan desde la red local utilizando HTTPS, y la terminación de TLS ocurre en el ALB. La empresa tiene múltiples grupos de destino (target groups) y utiliza enrutamiento basado en rutas para reenviar solicitudes en función del path de la URL. La empresa planea implementar un firewall local con una lista de permitidos (allow list) basada en direcciones IP. Un arquitecto de soluciones debe diseñar una solución que permita el flujo de tráfico desde la red local hacia AWS para que los clientes puedan seguir accediendo a la aplicación. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Configurar el ALB existente para usar direcciones IP estáticas. Asignar direcciones IP en múltiples Zonas de Disponibilidad al ALB. Agregar las direcciones IP del ALB al firewall.",
            "B. Crear un Network Load Balancer (NLB). Asociar el NLB con direcciones IP estáticas en múltiples Zonas de Disponibilidad. Crear un grupo de destino tipo ALB para el NLB y agregar el ALB existente. Agregar las direcciones IP del NLB al firewall. Actualizar los clientes para que se conecten al NLB.",
            "C. Crear un Network Load Balancer (NLB). Asociar el NLB con direcciones IP estáticas en múltiples Zonas de Disponibilidad. Agregar los grupos de destino existentes al NLB. Actualizar los clientes para que se conecten al NLB. Eliminar el ALB. Agregar las direcciones IP del NLB al firewall.",
            "D. Crear un Gateway Load Balancer (GWLB). Asignar direcciones IP estáticas al GWLB en múltiples Zonas de Disponibilidad. Crear un grupo de destino tipo ALB para el GWLB y agregar el ALB existente. Agregar las direcciones IP del GWLB al firewall. Actualizar los clientes para que se conecten al GWLB."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "162.- Una empresa ejecuta una aplicación en una flota de instancias de Amazon EC2 que están en subredes privadas detrás de un Application Load Balancer (ALB) orientado a internet. El ALB es el origen de una distribución de Amazon CloudFront. Un ACL web de AWS WAF con varias reglas administradas por AWS está asociado con la distribución de CloudFront. La empresa necesita una solución para evitar que el tráfico de internet acceda directamente al ALB. ¿Qué solución cumplirá con estos requisitos con el MENOR esfuerzo operativo?",
        "opciones": [
            "A. Crear un nuevo ACL web con las mismas reglas del ACL web existente y asociarlo al ALB.",
            "B. Asociar el ACL web existente con el ALB.",
            "C. Agregar una regla de grupo de seguridad al ALB para permitir tráfico solo desde la lista de prefijos administrada por AWS para CloudFront.",
            "D. Agregar una regla de grupo de seguridad al ALB para permitir solo las distintas direcciones IP de CloudFront."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "163.- Una empresa está ejecutando una aplicación que utiliza un clúster de Amazon ElastiCache para Redis como capa de caché. Una auditoría de seguridad reciente reveló que la empresa ha configurado el cifrado en reposo para ElastiCache. Sin embargo, la empresa no configuró ElastiCache para utilizar cifrado en tránsito. Además, los usuarios pueden acceder a la caché sin autenticación. Un arquitecto de soluciones debe realizar cambios para requerir la autenticación de usuarios y para garantizar que la empresa esté utilizando cifrado de extremo a extremo. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Crear un token de autenticación (AUTH). Almacenar el token en AWS Systems Manager Parameter Store, como un parámetro cifrado. Crear un nuevo clúster con AUTH y configurar el cifrado en tránsito. Actualizar la aplicación para recuperar el token AUTH desde Parameter Store cuando sea necesario y utilizar el token AUTH para la autenticación.",
            "B. Crear un token de autenticación (AUTH). Almacenar el token en AWS Secrets Manager. Configurar el clúster existente para utilizar el token AUTH y configurar el cifrado en tránsito. Actualizar la aplicación para recuperar el token AUTH desde Secrets Manager cuando sea necesario y utilizar el token AUTH para la autenticación.",
            "C. Crear un certificado SSL. Almacenar el certificado en AWS Secrets Manager. Crear un nuevo clúster y configurar el cifrado en tránsito. Actualizar la aplicación para recuperar el certificado SSL desde Secrets Manager cuando sea necesario y utilizar el certificado para la autenticación.",
            "D. Crear un certificado SSL. Almacenar el certificado en AWS Systems Manager Parameter Store, como un parámetro avanzado cifrado. Actualizar el clúster existente para configurar el cifrado en tránsito. Actualizar la aplicación para recuperar el certificado SSL desde Parameter Store cuando sea necesario y utilizar el certificado para la autenticación."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "164.- Una empresa está ejecutando una carga de trabajo de cómputo utilizando Amazon EC2 Spot Instances que están en un Auto Scaling group. La plantilla de lanzamiento utiliza dos grupos de colocación (placement groups) y un solo tipo de instancia. Recientemente, un sistema de monitoreo informó fallos en el lanzamiento de instancias del Auto Scaling, los cuales se correlacionaron con tiempos de espera más largos para los usuarios del sistema. La empresa necesita mejorar la fiabilidad general de la carga de trabajo. ¿Qué solución cumplirá con este requisito?",
        "opciones": [
            "A. Reemplazar la plantilla de lanzamiento con una configuración de lanzamiento para usar un Auto Scaling group que utilice la selección de tipo de instancia basada en atributos.",
            "B. Crear una nueva versión de la plantilla de lanzamiento que utilice la selección de tipo de instancia basada en atributos. Configurar el Auto Scaling group para usar la nueva versión de la plantilla de lanzamiento.",
            "C. Actualizar el Auto Scaling group de la plantilla de lanzamiento para aumentar el número de grupos de colocación.",
            "D. Actualizar la plantilla de lanzamiento para usar un tipo de instancia más grande."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "165.- Una empresa está migrando una carga de trabajo de procesamiento de documentos a AWS. La empresa ha actualizado muchas aplicaciones para usar de manera nativa la API de Amazon S3 para almacenar, recuperar y modificar los documentos que un servidor de procesamiento genera a una tasa de aproximadamente 5 documentos por segundo. Después de que se termine el procesamiento de los documentos, los clientes pueden descargar los documentos directamente desde Amazon S3. Durante la migración, la empresa descubrió que no podía actualizar de inmediato el servidor de procesamiento que genera muchos documentos para admitir la API de S3. El servidor ejecuta Linux y requiere un acceso local rápido a los archivos que genera y modifica. Cuando el servidor termina el procesamiento, los archivos deben estar disponibles para el público para su descarga en un plazo de 30 minutos. ¿Qué solución cumplirá con estos requisitos con el MENOR esfuerzo?",
        "opciones": [
            "A. Migrar la aplicación a una función de AWS Lambda. Usar el AWS SDK para Java para generar, modificar y acceder a los archivos que la empresa almacena directamente en Amazon S3.",
            "B. Configurar un Amazon S3 File Gateway y configurar un compartido de archivos vinculado al almacén de documentos. Montar el compartido de archivos en una instancia de Amazon EC2 mediante NFS. Cuando ocurran cambios en Amazon S3, iniciar una llamada a la API RefreshCache para actualizar el S3 File Gateway.",
            "C. Configurar Amazon FSx for Lustre con una política de importación y exportación. Vincular el nuevo sistema de archivos a un bucket de S3. Instalar el cliente Lustre y montar el almacén de documentos en una instancia de Amazon EC2 mediante NFS.",
            "D. Configurar AWS DataSync para conectar una instancia de Amazon EC2. Configurar una tarea para sincronizar los archivos generados hacia y desde Amazon S3."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "166.- Una empresa de mensajería está ejecutando una solución serverless en la nube de AWS. La solución administra datos de usuarios, información de entregas y detalles de compras anteriores. La solución se compone de varios microservicios. El servicio central de usuarios almacena datos sensibles en una tabla de Amazon DynamoDB. Varios de los otros microservicios almacenan una copia de partes de esos datos sensibles en diferentes servicios de almacenamiento. La empresa necesita tener la capacidad de eliminar la información de un usuario cuando se le solicite. Tan pronto como el servicio central de usuarios elimina a un usuario, cada microservicio debe también eliminar inmediatamente su copia de los datos. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Activar DynamoDB Streams en la tabla de DynamoDB. Crear un disparador de AWS Lambda para el stream de DynamoDB que publique eventos sobre la eliminación del usuario en una cola de Amazon Simple Queue Service (Amazon SQS). Configurar cada microservicio para que consulte la cola y elimine al usuario de la tabla de DynamoDB.",
            "B. Configurar notificaciones de eventos en DynamoDB en la tabla. Crear un tema de Amazon Simple Notification Service (Amazon SNS) como destino de la notificación de eventos de DynamoDB. Configurar cada microservicio para suscribirse al tema SNS y eliminar al usuario de la tabla de DynamoDB.",
            "C. Configurar el servicio central de usuarios para que publique un evento en un bus de eventos personalizado de Amazon EventBridge cuando se elimine un usuario. Crear una regla de EventBridge para cada microservicio que coincida con el patrón del evento de eliminación del usuario e invoque la lógica en el microservicio para eliminar la copia del usuario en su almacenamiento respectivo.",
            "D. Configurar el servicio central de usuarios para que publique un mensaje en una cola de Amazon Simple Queue Service (Amazon SQS) cuando se elimine un usuario. Configurar cada microservicio para que cree un filtro de eventos en la cola SQS y elimine al usuario de la tabla de DynamoDB."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "167.- Una empresa está ejecutando una aplicación web en una VPC. La aplicación web se ejecuta en un grupo de instancias de Amazon EC2 detrás de un Application Load Balancer (ALB). El ALB está utilizando AWS WAF. Un cliente externo necesita conectarse a la aplicación web. La empresa debe proporcionar direcciones IP a todos los clientes externos. ¿Qué solución cumplirá con estos requisitos con el MENOR esfuerzo operativo?",
        "opciones": [
            "A. Reemplazar el ALB con un Network Load Balancer (NLB). Asignar una Elastic IP al NLB.",
            "B. Asignar una Elastic IP. Asignar la Elastic IP al ALB. Proporcionar la Elastic IP al cliente.",
            "C. Crear un AWS Global Accelerator estándar. Especificar el ALB como el punto final del acelerador. Proporcionar las direcciones IP del acelerador al cliente.",
            "D. Configurar una distribución de Amazon CloudFront. Establecer el ALB como origen. Hacer ping al nombre DNS de la distribución para determinar la dirección IP pública de la distribución. Proporcionar la dirección IP al cliente."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "168.- Una empresa tiene algunas cuentas de AWS para desarrollo y quiere migrar su aplicación de producción a AWS. La empresa necesita imponer el cifrado en reposo de Amazon Elastic Block Store (Amazon EBS) en las cuentas de producción actuales y futuras. La solución debe incluir modelos predefinidos y mecanismos de control. ¿Qué combinación de pasos cumplirá con estos requisitos? (Elija tres.)",
        "opciones": [
            "A. Usar AWS CloudFormation StackSets para implementar reglas de AWS Config en las cuentas de producción.",
            "B. Crear una nueva zona de aterrizaje (landing zone) de AWS Control Tower en una cuenta de desarrollador existente. Crear OU (unidades organizativas) para las cuentas. Agregar las cuentas de producción y desarrollo a las OUs de producción y desarrollo, respectivamente.",
            "C. Crear una nueva zona de aterrizaje de AWS Control Tower en la cuenta de administración de la empresa. Agregar las cuentas de producción y desarrollo a las OUs de producción y desarrollo, respectivamente.",
            "D. Invitar cuentas existentes a unirse a la organización en AWS Organizations. Crear SCPs (Service Control Policies) para garantizar el cumplimiento.",
            "E. Crear un mecanismo de control (guardrail) desde la cuenta de administración para detectar el cifrado de EBS.",
            "F. Crear un mecanismo de control (guardrail) para la OU de producción para detectar el cifrado de EBS."
        ],
        "respuestas_correctas": [
            "F",
            "D",
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "169.- Una empresa está ejecutando una aplicación web crítica con estado en dos instancias de Amazon EC2 con Linux, ubicadas detrás de un Application Load Balancer (ALB), y cuenta con una base de datos Amazon RDS para MySQL. La empresa administra los registros DNS de la aplicación en Amazon Route 53. Un arquitecto de soluciones debe recomendar una solución para mejorar la resiliencia de la aplicación. La solución debe cumplir los siguientes objetivos: Capa de la aplicación: RPO de 2 minutos y RTO de 30 minutos. Capa de la base de datos: RPO de 5 minutos y RTO de 30 minutos. La empresa no desea realizar cambios significativos en la arquitectura actual de la aplicación y debe garantizar una latencia óptima tras una conmutación por error. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Configurar las instancias de EC2 para usar AWS Elastic Disaster Recovery. Crear una réplica de lectura en otra Región para la instancia de RDS. Crear un ALB en una segunda Región de AWS. Crear un endpoint de AWS Global Accelerator y asociarlo con los ALB. Actualizar los registros DNS para que apunten al endpoint de Global Accelerator.",
            "B. Configurar las instancias de EC2 para usar Amazon Data Lifecycle Manager (Amazon DLM) para tomar snapshots de los volúmenes EBS. Configurar respaldos automatizados en RDS.Configurar la replicación de los respaldos a una segunda Región de AWS. Crear un ALB en la segunda Región. Crear un endpoint de AWS Global Accelerator y asociarlo con los ALB. Actualizar los registros DNS para que apunten al endpoint de Global Accelerator.",
            "C. Crear un plan de respaldos en AWS Backup para las instancias de EC2 y la instancia de RDS. Configurar la replicación de los respaldos a una segunda Región de AWS. Crear un ALB en la segunda Región. Configurar una distribución de Amazon CloudFront frente al ALB. Actualizar los registros DNS para que apunten a CloudFront.",
            "D. Configurar las instancias de EC2 para usar Amazon Data Lifecycle Manager (Amazon DLM) para tomar snapshots de los volúmenes EBS. Crear una réplica de lectura en otra Región para la instancia de RDS. Crear un ALB en una segunda Región de AWS. Crear un endpoint de AWS Global Accelerator y asociarlo con los ALB."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "170.- Un arquitecto de soluciones quiere optimizar costos y dimensionar adecuadamente las instancias de Amazon EC2 en una sola cuenta de AWS. El arquitecto de soluciones quiere asegurarse de que las instancias estén optimizadas según las métricas de CPU, memoria y red. ¿Qué combinación de pasos debe seguir el arquitecto de soluciones para cumplir con estos requisitos? (Elige dos.)",
        "opciones": [
            "A. Comprar AWS Business Support o AWS Enterprise Support para la cuenta.",
            "B. Activar AWS Trusted Advisor y revisar las recomendaciones de Instancias de Amazon EC2 con baja utilización.",
            "C. Instalar el agente de Amazon CloudWatch y configurar la recopilación de métricas de memoria en las instancias de EC2.",
            "D. Configurar AWS Compute Optimizer en la cuenta de AWS para recibir hallazgos y recomendaciones de optimización.",
            "E. Crear un EC2 Instance Savings Plan para las regiones de AWS, familias de instancias y sistemas operativos de interés."
        ],
        "respuestas_correctas": [
            "D",
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "171.- Una empresa usa un repositorio de AWS CodeCommit y debe almacenar una copia de respaldo de los datos en un segundo AWS Region. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Configurar AWS Elastic Disaster Recovery para replicar los datos del repositorio de CodeCommit en la segunda región.",
            "B. Usar AWS Backup para respaldar el repositorio de CodeCommit en un programa horario por hora. Crear una copia entre regiones en la segunda región.",
            "C. Crear una regla de Amazon EventBridge para invocar AWS CodeBuild cuando la empresa haga un push al repositorio. Usar CodeBuild para clonar el repositorio, crear un archivo .zip con el contenido y copiarlo en un bucket de S3 en la segunda región.",
            "D. Crear un flujo de trabajo de AWS Step Functions con un programa horario por hora para tomar una instantánea del repositorio de CodeCommit. Configurar el flujo de trabajo para copiar la instantánea en un bucket de S3 en la segunda región."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "172.- Una empresa tiene varias unidades de negocio, cada una con cuentas separadas en AWS. Cada unidad de negocio gestiona su propia red con varias VPC que tienen rangos CIDR que se superponen. El equipo de marketing de la empresa ha creado una nueva aplicación interna y desea que la aplicación sea accesible para todas las demás unidades de negocio. La solución debe utilizar únicamente direcciones IP privadas. ¿Qué solución cumplirá con estos requisitos con la MENOR sobrecarga operativa?",
        "opciones": [
            "A. Indicar a cada unidad de negocio que agregue un rango CIDR secundario único a la VPC de la unidad. Realizar el peering de las VPC y utilizar una NAT gateway privada en el rango secundario para enrutar el tráfico hacia el equipo de marketing.",
            "B. Crear una instancia de Amazon EC2 que sirva como un dispositivo virtual en la VPC de la cuenta de marketing. Establecer una conexión VPN de sitio a sitio de AWS entre el equipo de marketing y la VPC de cada unidad de negocio. Realizar NAT donde sea necesario.",
            "C. Crear un servicio de endpoint de AWS PrivateLink para compartir la aplicación de marketing. Otorgar permisos a cuentas de AWS específicas para conectarse al servicio. Crear endpoints de interfaz VPC en las otras cuentas para acceder a la aplicación utilizando direcciones IP privadas.",
            "D. Crear un Network Load Balancer (NLB) frente a la aplicación de marketing en una subred privada. Crear una API de Amazon API Gateway. Utilizar la integración privada de API Gateway para conectar la API al NLB. Activar la autorización mediante IAM para la API. Otorgar acceso a las cuentas de las otras unidades de negocio."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "173.- Una empresa necesita auditar la postura de seguridad de una cuenta de AWS recientemente adquirida. El equipo de seguridad de datos de la empresa requiere una notificación solo cuando un bucket de Amazon S3 se vuelva público. La empresa ya ha configurado un tema de Amazon SNS con la dirección de correo electrónico del equipo de seguridad de datos suscrito. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Crear una notificación de eventos de S3 en todos los buckets para el evento isPublic. Seleccionar el tema de SNS como destino para las notificaciones de eventos.",
            "B. Crear un analizador en AWS Identity and Access Management Access Analyzer. Crear una regla de Amazon EventBridge para el tipo de evento Access Analyzer Finding con un filtro para isPublic: true. Seleccionar el tema de SNS como destino de la regla de EventBridge.",
            "C. Crear una regla de Amazon EventBridge para el tipo de evento Bucket-Level API Call via CloudTrail con un filtro para PutBucketPolicy. Seleccionar el tema de SNS como destino de la regla de EventBridge.",
            "D. Activar AWS Config y agregar la regla cloudtrail-s3-dataevents-enabled. Crear una regla de Amazon EventBridge para el tipo de evento Config Rules Re-evaluation Status con un filtro para NON_COMPLIANT. Seleccionar el tema de SNS como destino de la regla de EventBridge."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "174.- Un arquitecto de soluciones necesita evaluar el portafolio de aplicaciones y bases de datos de una empresa recientemente adquirida. Debe crear un caso de negocio para migrar el portafolio a AWS. La empresa adquirida ejecuta aplicaciones en un centro de datos on-premises que no está bien documentado. No se puede determinar de inmediato cuántas aplicaciones y bases de datos existen. El tráfico de las aplicaciones es variable, y algunas son procesos por lotes que se ejecutan al final de cada mes. El arquitecto de soluciones debe obtener una mejor comprensión del portafolio antes de iniciar la migración a AWS. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Usar AWS Server Migration Service (AWS SMS) y AWS Database Migration Service (AWS DMS) para evaluar la migración. Usar AWS Service Catalog para comprender las dependencias de aplicaciones y bases de datos.",
            "B. Usar AWS Application Migration Service. Ejecutar agentes en la infraestructura on-premises. Administrar los agentes con AWS Migration Hub. Usar AWS Storage Gateway para evaluar necesidades de almacenamiento local y dependencias de bases de datos.",
            "C. Usar Migration Evaluator para generar una lista de servidores. Construir un informe para un caso de negocio. Usar AWS Migration Hub para ver el portafolio. Usar AWS Application Discovery Service para comprender las dependencias de aplicaciones.",
            "D. Usar AWS Control Tower en la cuenta de destino para generar un portafolio de aplicaciones. Usar AWS Server Migration Service (AWS SMS) para generar informes detallados y un caso de negocio. Usar una landing zone para cuentas y recursos centrales."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "175.- Una empresa tiene una aplicación que se ejecuta como un ReplicaSet de múltiples pods en un clúster de Amazon Elastic Kubernetes Service (Amazon EKS). El clúster de EKS tiene nodos en múltiples zonas de disponibilidad. La aplicación genera muchos archivos pequeños que deben ser accesibles en todas las instancias en ejecución de la aplicación. La empresa necesita realizar copias de seguridad de los archivos y retenerlas durante 1 año. ¿Qué solución cumplirá con estos requisitos proporcionando el almacenamiento más rápido?",
        "opciones": [
            "A. Crear un sistema de archivos Amazon Elastic File System (Amazon EFS) y un punto de montaje para cada subred que contenga nodos en el clúster de EKS. Configurar el ReplicaSet para montar el sistema de archivos. Configurar la aplicación para almacenar archivos en el sistema de archivos. Configurar AWS Backup para realizar copias de seguridad y retener los datos durante 1 año.",
            "B. Crear un volumen de Amazon Elastic Block Store (Amazon EBS). Habilitar la función EBS Multi-Attach. Configurar el ReplicaSet para montar el volumen EBS. Configurar la aplicación para almacenar archivos en el volumen EBS. Configurar AWS Backup para realizar copias de seguridad y retener los datos durante 1 año.",
            "C. Crear un bucket de Amazon S3. Configurar el ReplicaSet para montar el bucket de S3. Configurar la aplicación para almacenar archivos en el bucket de S3. Configurar S3 Versioning para retener copias de los datos. Configurar una política de ciclo de vida de S3 para eliminar los objetos después de 1 año.",
            "D. Configurar el ReplicaSet para usar el almacenamiento disponible en cada uno de los pods de la aplicación y almacenar los archivos localmente. Usar una herramienta de terceros para realizar copias de seguridad del clúster de EKS durante 1 año."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "176.- Una empresa opera un centro de servicio al cliente que recibe llamadas y automáticamente envía a todos los clientes una encuesta interactiva bidireccional por mensaje de texto. Las aplicaciones que dan soporte al centro de servicio al cliente se ejecutan en máquinas on-premises en un centro de datos propio. Sin embargo, el hardware es antiguo y la empresa está experimentando tiempo de inactividad con el sistema. La empresa quiere migrar el sistema a AWS para mejorar la confiabilidad. ¿Qué solución cumplirá con estos requisitos con el MENOR esfuerzo operativo continuo?",
        "opciones": [
            "A. Usar Amazon Connect para reemplazar el hardware antiguo del centro de llamadas. Usar Amazon Pinpoint para enviar encuestas por mensaje de texto a los clientes.",
            "B. Usar Amazon Connect para reemplazar el hardware antiguo del centro de llamadas. Usar Amazon Simple Notification Service (Amazon SNS) para enviar encuestas por mensaje de texto a los clientes.",
            "C. Migrar el software del centro de llamadas a instancias de Amazon EC2 en un Auto Scaling group. Usar las instancias de EC2 para enviar encuestas por mensaje de texto a los clientes.",
            "D. Usar Amazon Pinpoint para reemplazar el hardware antiguo del centro de llamadas y para enviar encuestas por mensaje de texto a los clientes."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "177.- Una empresa está construyendo un centro de llamadas utilizando Amazon Connect. El equipo de operaciones de la empresa está definiendo una estrategia de recuperación ante desastres (DR) entre Regiones de AWS. El centro de contacto cuenta con docenas de flujos de contacto, cientos de usuarios y docenas de números telefónicos reclamados. ¿Qué solución proporcionará DR con el RTO MÁS BAJO?",
        "opciones": [
            "A. Crear una función AWS Lambda que verifique la disponibilidad de la instancia de Amazon Connect y envíe una notificación al equipo de operaciones en caso de que no esté disponible. Crear una regla de Amazon EventBridge para invocar la función Lambda cada 5 minutos. Después de la notificación, instruir al equipo de operaciones para que use la Consola de Administración de AWS y aprovisione una nueva instancia de Amazon Connect en una segunda Región. Desplegar los flujos de contacto, usuarios y números telefónicos reclamados mediante una plantilla de AWS CloudFormation.",
            "B. Aprovisionar una nueva instancia de Amazon Connect que incluya todos los usuarios existentes en una segunda Región. Crear una función AWS Lambda para verificar la disponibilidad de la instancia de Amazon Connect. Configurar una regla de Amazon EventBridge para invocar la función Lambda cada 5 minutos. En caso de detectar un problema, configurar la función Lambda para desplegar una plantilla de AWS CloudFormation que aprovisione los flujos de contacto y los números reclamados en la segunda Región.",
            "C. Aprovisionar una nueva instancia de Amazon Connect que incluya todos los flujos de contacto existentes y los números telefónicos reclamados en una segunda Región. Crear un chequeo de salud de Amazon Route 53 para la URL de la instancia de Amazon Connect. Crear una alarma de Amazon CloudWatch para los chequeos de salud fallidos. Crear una función AWS Lambda que despliegue una plantilla de AWS CloudFormation para aprovisionar todos los usuarios. Configurar la alarma para invocar la función Lambda.",
            "D. Aprovisionar una nueva instancia de Amazon Connect que incluya todos los usuarios y flujos de contacto existentes en una segunda Región. Crear un chequeo de salud de Amazon Route 53 para la URL de la instancia de Amazon Connect. Crear una alarma de Amazon CloudWatch para los chequeos de salud fallidos. Crear una función AWS Lambda que despliegue una plantilla de AWS CloudFormation para aprovisionar los números telefónicos reclamados. Configurar la alarma para invocar la función Lambda."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "178.- Una empresa ejecuta una aplicación en AWS. La empresa recopila datos de varias fuentes y utiliza algoritmos propios para realizar transformaciones y agregaciones de datos. Luego de completar los procesos ETL, la empresa almacena los resultados en tablas de Amazon Redshift. Posteriormente, la empresa vende estos datos a otras compañías. Actualmente, la empresa descarga los datos de las tablas de Amazon Redshift en forma de archivos y los transmite a los clientes mediante FTP. Sin embargo, el número de clientes ha crecido significativamente, lo que ha dificultado su gestión. La empresa ahora planea utilizar AWS Data Exchange para crear un producto de datos y compartir la información con sus clientes. Se deben cumplir los siguientes requisitos: Verificar la identidad de los clientes antes de compartir los datos. Los clientes deben tener acceso a los datos más recientes cuando se publiquen. Se debe minimizar la sobrecarga operativa. ¿Qué solución cumplirá con estos requisitos con el menor esfuerzo operativo?",
        "opciones": [
            "A. Usar AWS Data Exchange for APIs para compartir los datos con los clientes. Configurar la verificación de suscripción. En la cuenta de AWS del proveedor de datos, crear una integración de Amazon API Gateway Data API con Amazon Redshift. Exigir a los clientes que se suscriban al producto de datos.",
            "B. En la cuenta de AWS del proveedor de datos, crear un AWS Data Exchange datashare conectando AWS Data Exchange al clúster de Redshift. Configurar la verificación de suscripción. Exigir a los clientes que se suscriban al producto de datos.",
            "C. Descargar los datos desde las tablas de Amazon Redshift a un bucket de Amazon S3 periódicamente. Usar AWS Data Exchange for S3 para compartir los datos con los clientes. Configurar la verificación de suscripción. Exigir a los clientes que se suscriban al producto de datos.",
            "D. Publicar los datos de Amazon Redshift en Open Data en AWS Data Exchange. Requerir que los clientes se suscriban al producto de datos en AWS Data Exchange. En la cuenta de AWS del proveedor de datos, adjuntar políticas basadas en recursos de IAM a las tablas de Amazon Redshift para permitir acceso solo a cuentas de AWS verificadas."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "179.- Un arquitecto de soluciones está diseñando una solución para procesar eventos. La solución debe escalar automáticamente según la cantidad de eventos recibidos. Si ocurre un error de procesamiento, el evento debe moverse a una cola separada para su revisión. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Enviar los detalles del evento a un tema de Amazon Simple Notification Service (Amazon SNS). Configurar una función AWS Lambda como suscriptor del tema para procesar los eventos. Agregar un destino de fallo a la función. Definir una cola de Amazon Simple Queue Service (Amazon SQS) como destino.",
            "B. Publicar eventos en una cola de Amazon Simple Queue Service (Amazon SQS). Crear un grupo de Auto Scaling de Amazon EC2. Configurar el Auto Scaling group para escalar según la métrica ApproximateAgeOfOldestMessage de la cola. Configurar la aplicación para escribir los mensajes con error en una dead-letter queue (DLQ).",
            "C. Escribir eventos en una tabla de Amazon DynamoDB. Configurar un stream de DynamoDB para la tabla. Configurar el stream para invocar una función AWS Lambda. Configurar la función Lambda para procesar los eventos.",
            "D. Publicar eventos en un bus de eventos de Amazon EventBridge. Crear y ejecutar una aplicación en una instancia de Amazon EC2 con un Auto Scaling group detrás de un Application Load Balancer (ALB). Configurar el ALB como el destino del bus de eventos. Configurar el bus de eventos para reintentar los eventos. Escribir mensajes en una dead-letter queue (DLQ) si la aplicación no puede procesarlos."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "180.- Una empresa ejecuta un motor de procesamiento en la nube de AWS. Este motor procesa datos ambientales de centros logísticos para calcular un índice de sostenibilidad. La empresa tiene millones de dispositivos en centros logísticos distribuidos por toda Europa. Los dispositivos envían información al motor de procesamiento a través de una API RESTful. La API experimenta ráfagas de tráfico impredecibles. La empresa debe implementar una solución para procesar todos los datos que los dispositivos envían al motor de procesamiento. La pérdida de datos es inaceptable. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Crear un Application Load Balancer (ALB) para la API RESTful. Crear una cola en Amazon Simple Queue Service (Amazon SQS). Crear un listener y un grupo de destino para el ALB. Agregar la cola de SQS como el destino. Usar un contenedor en Amazon Elastic Container Service (Amazon ECS) con el tipo de lanzamiento Fargate para procesar los mensajes en la cola.",
            "B. Crear una API HTTP de Amazon API Gateway que implemente la API RESTful. Crear una cola en Amazon Simple Queue Service (Amazon SQS). Crear una integración de servicio de API Gateway con la cola de SQS. Crear una función de AWS Lambda para procesar los mensajes en la cola de SQS.",
            "C. Crear una API REST de Amazon API Gateway que implemente la API RESTful. Crear un grupo de instancias Amazon EC2 en un Auto Scaling group. Crear una integración proxy del grupo de Auto Scaling con API Gateway. Usar las instancias de EC2 para procesar los datos entrantes.",
            "D. Crear una distribución de Amazon CloudFront para la API RESTful. Crear un flujo de datos en Amazon Kinesis Data Streams. Configurar el flujo de datos como el origen de la distribución. Crear una función de AWS Lambda para consumir y procesar los datos en el flujo de datos."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "181.- Una empresa está diseñando su configuración de red en la nube de AWS. La empresa utiliza AWS Organizations para gestionar una configuración de múltiples cuentas. La empresa tiene tres Unidades Organizacionales (OU), y cada OU contiene más de 100 cuentas de AWS. Cada cuenta tiene una única VPC, y todas las VPCs de cada OU están en la misma región de AWS. Los rangos CIDR de todas las cuentas de AWS no se superponen. La empresa necesita implementar una solución en la que las VPCs en la misma OU puedan comunicarse entre sí, pero no puedan comunicarse con las VPCs de otras OUs. ¿Qué solución cumplirá con estos requisitos con la menor sobrecarga operativa?",
        "opciones": [
            "A. Crear un conjunto de AWS CloudFormation stack sets que establezca VPC peering entre cuentas de cada OU. Provisionar el conjunto de stacks en cada OU.",
            "B. En cada OU, crear una cuenta de red dedicada que tenga una única VPC. Compartir esta VPC con todas las demás cuentas en la OU mediante AWS Resource Access Manager (AWS RAM). Crear una conexión de VPC peering entre la cuenta de red y cada cuenta de la OU.",
            "C. Provisionar un transit gateway en una cuenta de cada OU. Compartir el transit gateway a través de la organización utilizando AWS Resource Access Manager (AWS RAM). Crear VPC attachments del transit gateway para cada VPC.",
            "D. En cada OU, crear una cuenta de red dedicada que tenga una única VPC. Establecer una conexión VPN entre la cuenta de red y las otras cuentas de la OU. Usar software de enrutamiento de terceros para enrutar el tráfico transitivo entre las VPCs."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "182.- Una empresa está migrando una aplicación a AWS. Desea utilizar servicios completamente gestionados tanto como sea posible durante la migración. La empresa necesita almacenar grandes documentos importantes dentro de la aplicación con los siguientes requisitos: Los datos deben ser altamente durables y disponibles. Los datos deben estar siempre encriptados tanto en reposo como en tránsito. La clave de encriptación debe ser gestionada por la empresa y rotada periódicamente. ¿Cuál de las siguientes soluciones debería recomendar el arquitecto de soluciones?",
        "opciones": [
            "A. Desplegar el Storage Gateway en AWS en modo file gateway. Usar Amazon EBS con encriptación de volúmenes usando una clave AWS KMS para encriptar los volúmenes del Storage Gateway.",
            "B. Usar Amazon S3 con una política de bucket para forzar HTTPS en las conexiones al bucket y para forzar la encriptación del lado del servidor con AWS KMS para la encriptación de los objetos.",
            "C. Usar Amazon DynamoDB con SSL para conectar a DynamoDB. Usar una clave AWS KMS para encriptar los objetos de DynamoDB en reposo.",
            "D. Desplegar instancias con volúmenes de Amazon EBS adjuntos para almacenar estos datos. Usar encriptación de volúmenes EBS con una clave AWS KMS para encriptar los datos."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "183.- La API pública de una empresa se ejecuta como tareas en Amazon Elastic Container Service (Amazon ECS). Las tareas se ejecutan en AWS Fargate detrás de un Application Load Balancer (ALB) y están configuradas con Service Auto Scaling para las tareas en función de la utilización de la CPU. Este servicio ha estado funcionando bien durante varios meses. Recientemente, el rendimiento de la API se desaceleró y volvió inutilizable la aplicación. La empresa descubrió que se habían producido un número significativo de ataques de inyección SQL contra la API y que el servicio de API había escalado a su cantidad máxima. Un arquitecto de soluciones debe implementar una solución que prevenga que los ataques de inyección SQL lleguen al servicio de la API de ECS. La solución debe permitir que el tráfico legítimo pase y maximizar la eficiencia operativa. ¿Qué solución cumple con estos requisitos?",
        "opciones": [
            "A. Crear una nueva AWS WAF web ACL para monitorear las solicitudes HTTP y HTTPS que se reenvían al ALB frente a las tareas de ECS.",
            "B. Crear una nueva implementación de AWS WAF Bot Control. Agregar una regla en el grupo de reglas gestionadas de AWS WAF Bot Control para monitorear el tráfico y permitir solo el tráfico legítimo hacia el ALB frente a las tareas de ECS.",
            "C. Crear una nueva AWS WAF web ACL. Agregar una nueva regla que bloquee las solicitudes que coincidan con el SQL database rule group. Configurar la web ACL para permitir todo el tráfico que no coincida con esas reglas. Adjuntar la web ACL al ALB frente a las tareas de ECS.",
            "D. Crear una nueva AWS WAF web ACL. Crear un nuevo IP set vacío en AWS WAF. Agregar una nueva regla a la web ACL para bloquear solicitudes que provengan de direcciones IP en el nuevo IP set. Crear una función AWS Lambda que analice los registros de la API en busca de direcciones IP que envíen ataques de inyección SQL y agregar esas direcciones IP al IP set. Adjuntar la web ACL al ALB frente a las tareas de ECS."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "184.- Una empresa ambiental está desplegando sensores en las principales ciudades de un país para medir la calidad del aire. Los sensores se conectan a AWS IoT Core para ingerir lecturas de datos de series temporales. La empresa almacena los datos en Amazon DynamoDB. Para la continuidad del negocio, la empresa debe tener la capacidad de ingerir y almacenar datos en dos Regiones de AWS. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Crear una política de enrutamiento de conmutación por error de alias de Amazon Route 53 con valores para los endpoints de datos de AWS IoT Core en ambas Regiones. Migrar los datos a tablas globales de Amazon Aurora.",
            "B. Crear una configuración de dominio para AWS IoT Core en cada Región. Crear una política de enrutamiento basada en la latencia de Amazon Route 53. Usar los endpoints de datos de AWS IoT Core en ambas Regiones como valores. Migrar los datos a Amazon MemoryDB para Redis y configurar la replicación entre regiones.",
            "C. Crear una configuración de dominio para AWS IoT Core en cada Región. Crear una comprobación de estado de Amazon Route 53 que evalúe el estado de la configuración del dominio. Crear una política de enrutamiento de conmutación por error con valores para el nombre de dominio de las configuraciones de dominio de AWS IoT Core. Actualizar la tabla de DynamoDB a una tabla global.",
            "D. Crear una política de enrutamiento basada en la latencia de Amazon Route 53. Usar los endpoints de datos de AWS IoT Core en ambas Regiones como valores. Configurar transmisiones de DynamoDB y replicación de datos entre regiones."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "185.- Una empresa utiliza AWS Organizations para una configuración de múltiples cuentas en la nube de AWS. El equipo de finanzas de la empresa tiene una aplicación de procesamiento de datos que usa AWS Lambda y Amazon DynamoDB. El equipo de marketing de la empresa quiere acceder a los datos almacenados en la tabla de DynamoDB. La tabla de DynamoDB contiene datos confidenciales. El equipo de marketing solo debe tener acceso a atributos específicos de los datos en la tabla de DynamoDB. El equipo de finanzas y el equipo de marketing tienen cuentas de AWS separadas. ¿Qué debe hacer un arquitecto de soluciones para proporcionar al equipo de marketing el acceso adecuado a la tabla de DynamoDB?",
        "opciones": [
            "A. Crear una SCP para otorgar al equipo de marketing acceso a los atributos específicos de la tabla DynamoDB. Adjuntar la SCP a la OU del equipo de finanzas.",
            "B. Crear un rol de IAM en la cuenta del equipo de finanzas usando condiciones de políticas de IAM para atributos específicos de DynamoDB (control de acceso detallado). Establecer una relación de confianza con la cuenta del equipo de marketing. En la cuenta del equipo de marketing, crear un rol de IAM que tenga permisos para asumir el rol de IAM en la cuenta del equipo de finanzas.",
            "C. Crear una política de IAM basada en recursos que incluya condiciones para atributos específicos de DynamoDB (control de acceso detallado). Adjuntar la política a la tabla DynamoDB. En la cuenta del equipo de marketing, crear un rol de IAM que tenga permisos para acceder a la tabla de DynamoDB en la cuenta del equipo de finanzas.",
            "D. Crear un rol de IAM en la cuenta del equipo de finanzas para acceder a la tabla de DynamoDB. Usar un límite de permisos de IAM para limitar el acceso a los atributos específicos. En la cuenta del equipo de marketing, crear un rol de IAM que tenga permisos para asumir el rol de IAM en la cuenta del equipo de finanzas."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "186.- Un arquitecto de soluciones está creando una aplicación que almacena objetos en un bucket de Amazon S3. El arquitecto de soluciones debe desplegar la aplicación en dos Regiones de AWS que se utilizarán simultáneamente. Los objetos en los dos buckets de S3 deben mantenerse sincronizados entre sí. ¿Qué combinación de pasos cumplirá con estos requisitos con el MENOR esfuerzo operativo? (Elija tres.)",
        "opciones": [
            "A. Crear un S3 Multi-Region Access Point. Cambiar la aplicación para que haga referencia al Multi-Region Access Point.",
            "B. Configurar S3 Cross-Region Replication (CRR) bidireccional entre los dos buckets de S3.",
            "C. Modificar la aplicación para almacenar objetos en cada bucket de S3.",
            "D. Crear una regla de ciclo de vida de S3 para cada bucket de S3 para copiar objetos de un bucket de S3 al otro.",
            "E. Activar la versionado de S3 para cada bucket de S3.",
            "F. Configurar una notificación de evento para cada bucket de S3 que invoque una función de AWS Lambda para copiar objetos de un bucket de S3 al otro."
        ],
        "respuestas_correctas": [
            "E",
            "B",
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "187.- Una empresa tiene una plataforma IoT que se ejecuta en un entorno local. La plataforma consiste en un servidor que se conecta a dispositivos IoT utilizando el protocolo MQTT. La plataforma recopila datos de telemetría de los dispositivos al menos una vez cada 5 minutos. La plataforma también almacena metadatos de los dispositivos en un clúster de MongoDB. Una aplicación instalada en una máquina local ejecuta trabajos periódicos para agregar y transformar los datos de telemetría y los metadatos de los dispositivos. La aplicación crea informes que los usuarios visualizan mediante otra aplicación web que se ejecuta en la misma máquina local. Los trabajos periódicos tardan entre 120 y 600 segundos en ejecutarse. Sin embargo, la aplicación web siempre está en ejecución. La empresa está moviendo la plataforma a AWS y debe reducir la sobrecarga operativa de la pila. ¿Qué combinación de pasos cumplirá con estos requisitos con la MENOR sobrecarga operativa? (Elija tres.)",
        "opciones": [
            "A. Usar funciones AWS Lambda para conectar con los dispositivos IoT.",
            "B. Configurar los dispositivos IoT para publicar en AWS IoT Core.",
            "C. Escribir los metadatos en una base de datos MongoDB autogestionada en una instancia de Amazon EC2.",
            "D. Escribir los metadatos en Amazon DocumentDB (con compatibilidad con MongoDB).",
            "E. Usar máquinas de estado de AWS Step Functions con tareas de AWS Lambda para preparar los informes y escribir los informes en Amazon S3. Usar Amazon CloudFront con un origen S3 para servir los informes.",
            "F. Usar un clúster de Amazon Elastic Kubernetes Service (Amazon EKS) con instancias de Amazon EC2 para preparar los informes. Usar un controlador de ingreso en el clúster EKS para servir los informes."
        ],
        "respuestas_correctas": [
            "E",
            "D",
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "188.- Una empresa global de manufactura planea migrar la mayoría de sus aplicaciones a AWS. Sin embargo, la empresa está preocupada por las aplicaciones que deben permanecer dentro de un país específico o en el centro de datos central de la empresa debido a los requisitos regulatorios de datos o los requisitos de latencia de un solo dígito de milisegundos. La empresa también está preocupada por las aplicaciones que hospeda en algunos de sus sitios de fábrica, donde existe infraestructura de red limitada. La empresa desea una experiencia consistente para los desarrolladores para que puedan crear aplicaciones una vez y desplegarlas en las instalaciones, en la nube o en una arquitectura híbrida. Los desarrolladores deben poder usar las mismas herramientas, API y servicios con los que están familiarizados. ¿Qué solución proporcionará una experiencia híbrida consistente para cumplir con estos requisitos?",
        "opciones": [
            "A. Migrar todas las aplicaciones a la región de AWS más cercana que cumpla con los requisitos. Configurar una conexión AWS Direct Connect entre el centro de datos central de la empresa y AWS. Desplegar un gateway de Direct Connect.",
            "B. Usar dispositivos AWS Snowball Edge Storage Optimized para las aplicaciones que tienen requisitos regulatorios de datos o de latencia de un solo dígito de milisegundos. Mantener los dispositivos en las instalaciones. Desplegar AWS Wavelength para hospedar las cargas de trabajo en los sitios de la fábrica.",
            "C. Instalar AWS Outposts para las aplicaciones que tienen requisitos regulatorios de datos o de latencia de un solo dígito de milisegundos. Usar dispositivos AWS Snowball Edge Compute Optimized para hospedar las cargas de trabajo en los sitios de la fábrica.",
            "D. Migrar las aplicaciones que tienen requisitos regulatorios de datos o de latencia de un solo dígito de milisegundos a una AWS Local Zone. Desplegar AWS Wavelength para hospedar las cargas de trabajo en los sitios de la fábrica."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "189.- Una empresa está actualizando una aplicación que los clientes utilizan para hacer pedidos en línea. El número de ataques a la aplicación por parte de actores malintencionados ha aumentado recientemente. La empresa alojará la aplicación actualizada en un Amazon Elastic Container Service (Amazon ECS). La empresa usará Amazon DynamoDB para almacenar los datos de la aplicación. Un Application Load Balancer (ALB) público proporcionará acceso a los usuarios finales a la aplicación. La empresa debe prevenir ataques y asegurar la continuidad del negocio con interrupciones mínimas del servicio durante un ataque en curso. ¿Qué combinación de pasos cumplirá estos requisitos de manera MÁS rentable? (Elija dos.)",
        "opciones": [
            "A. Crear una distribución de Amazon CloudFront con el ALB como origen. Añadir un encabezado personalizado y un valor aleatorio en el dominio de CloudFront. Configurar el ALB para reenviar condicionalmente el tráfico si el encabezado y el valor coinciden.",
            "B. Desplegar la aplicación en dos Regiones de AWS. Configurar Amazon Route 53 para enrutar a ambas regiones con igual peso.",
            "C. Configurar auto escalado para las tareas de Amazon ECS. Crear un clúster de DynamoDB Accelerator (DAX).",
            "D. Configurar Amazon ElastiCache para reducir la carga en DynamoDB.",
            "E. Desplegar un AWS WAF web ACL que incluya un grupo de reglas adecuado. Asociar el web ACL con la distribución de Amazon CloudFront."
        ],
        "respuestas_correctas": [
            "E",
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "190.- Una empresa ejecuta una aplicación web en AWS. La aplicación web entrega contenido estático desde un bucket de Amazon S3 que está detrás de una distribución de Amazon CloudFront. La aplicación sirve contenido dinámico mediante un Application Load Balancer (ALB) que distribuye las solicitudes a una flota de instancias de Amazon EC2 en grupos de escalado automático. La aplicación usa un nombre de dominio configurado en Amazon Route 53. Algunos usuarios informaron problemas ocasionales cuando intentaron acceder al sitio web durante las horas pico. Un equipo de operaciones encontró que el ALB a veces devolvía errores HTTP 503 Servicio no disponible. La empresa desea mostrar una página de mensaje de error personalizado cuando ocurran estos errores. La página debe mostrarse inmediatamente para este código de error. ¿Qué solución cumplirá con estos requisitos con la MENOR sobrecarga operativa?",
        "opciones": [
            "A. Configurar una política de enrutamiento de conmutación por error de Route 53. Configurar una verificación de estado para determinar el estado del punto final del ALB y conmutar por error al punto final del bucket S3 de conmutación por error.",
            "B. Crear una segunda distribución de CloudFront y un sitio web estático de S3 para alojar la página de error personalizada. Configurar una política de enrutamiento de conmutación por error de Route 53. Usar una configuración activa-pasiva entre las dos distribuciones.",
            "C. Crear un grupo de orígenes de CloudFront que tenga dos orígenes. Establecer el punto final del ALB como origen principal. Para el origen secundario, establecer un bucket de S3 configurado para alojar un sitio web estático. Configurar la conmutación por error de origen para la distribución de CloudFront. Actualizar el sitio web estático de S3 para incorporar la página de error personalizada.",
            "D. Crear una función de CloudFront que valide cada código de respuesta HTTP que devuelve el ALB. Crear un sitio web estático en un bucket de S3. Subir la página de error personalizada al bucket de S3 como conmutación por error. Actualizar la función para leer el bucket de S3 y servir la página de error a los usuarios finales."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "191.- Una empresa está planeando migrar una aplicación a AWS. La aplicación se ejecuta como un contenedor Docker y utiliza un recurso compartido de archivos NFS versión 4. Un arquitecto de soluciones debe diseñar una solución segura y escalable para contenedores que no requiera la provisión o gestión de la infraestructura subyacente. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Desplegar los contenedores de la aplicación utilizando Amazon Elastic Container Service (Amazon ECS) con el tipo de lanzamiento Fargate. Usar Amazon Elastic File System (Amazon EFS) para almacenamiento compartido. Referenciar el ID del sistema de archivos EFS, el punto de montaje del contenedor y el rol IAM de autorización de EFS en la definición de tarea de ECS.",
            "B. Desplegar los contenedores de la aplicación utilizando Amazon Elastic Container Service (Amazon ECS) con el tipo de lanzamiento Fargate. Usar Amazon FSx for Lustre para almacenamiento compartido. Referenciar el ID del sistema de archivos FSx for Lustre, el punto de montaje del contenedor y el rol IAM de autorización de FSx for Lustre en la definición de tarea de ECS.",
            "C. Desplegar los contenedores de la aplicación utilizando Amazon Elastic Container Service (Amazon ECS) con el tipo de lanzamiento Amazon EC2 y con auto escalado activado. Usar Amazon Elastic File System (Amazon EFS) para almacenamiento compartido. Montar el sistema de archivos EFS en las instancias de contenedor ECS. Agregar el rol IAM de autorización de EFS al perfil de instancia EC2.",
            "D. Desplegar los contenedores de la aplicación utilizando Amazon Elastic Container Service (Amazon ECS) con el tipo de lanzamiento Amazon EC2 y con auto escalado activado. Usar volúmenes de Amazon Elastic Block Store (Amazon EBS) con Multi-Attach habilitado para almacenamiento compartido. Adjuntar los volúmenes EBS a las instancias de contenedor ECS. Agregar el rol IAM de autorización de EBS al perfil de instancia EC2."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "192.- Una empresa está ejecutando una aplicación en la nube de AWS. La lógica empresarial principal se ejecuta en un conjunto de instancias Amazon EC2 en un grupo de Auto Scaling. Un Application Load Balancer (ALB) distribuye el tráfico a las instancias EC2. El registro de Amazon Route 53 api.example.com está apuntando al ALB. El equipo de desarrollo de la empresa realiza actualizaciones importantes en la lógica empresarial. La empresa tiene una regla que establece que cuando se implementan cambios, solo el 10% de los clientes puede recibir la nueva lógica durante una ventana de pruebas. Un cliente debe usar la misma versión de la lógica empresarial durante la ventana de pruebas. ¿Cómo debería la empresa implementar las actualizaciones para cumplir con estos requisitos?",
        "opciones": [
            "A. Crear un segundo ALB y desplegar la nueva lógica en un conjunto de instancias EC2 en un nuevo grupo de Auto Scaling. Configurar el ALB para distribuir el tráfico a las instancias EC2. Actualizar el registro de Route 53 para usar el enrutamiento ponderado y apuntar el registro a ambos ALBs.",
            "B. Crear un segundo grupo de destino que sea referenciado por el ALB. Desplegar la nueva lógica en instancias EC2 en este nuevo grupo de destino. Actualizar la regla del oyente del ALB para usar grupos de destino ponderados. Configurar la persistencia de sesión en el grupo de destino del ALB.",
            "C. Crear una nueva configuración de lanzamiento para el grupo de Auto Scaling. Especificar la configuración de lanzamiento para usar la política AutoScalingRollingUpdate, y establecer la opción MaxBatchSize a 10. Reemplazar la configuración de lanzamiento en el grupo de Auto Scaling. Desplegar los cambios.",
            "D. Crear un segundo grupo de Auto Scaling que sea referenciado por el ALB. Desplegar la nueva lógica en un conjunto de instancias EC2 en este nuevo grupo de Auto Scaling. Cambiar el algoritmo de enrutamiento del ALB a least outstanding requests (LOR). Configurar la persistencia de sesión en el ALB."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "193.- Una gran empresa educativa introdujo recientemente Amazon Workspaces para proporcionar acceso a aplicaciones internas en varias universidades. La empresa está almacenando los perfiles de los usuarios en un sistema de archivos Amazon FSx para Windows File Server. El sistema de archivos está configurado con un alias DNS y está conectado a un Active Directory autogestionado. A medida que más usuarios comienzan a utilizar Workspaces, el tiempo de inicio de sesión aumenta a niveles inaceptables. Una investigación revela una degradación en el rendimiento del sistema de archivos. La empresa creó el sistema de archivos en almacenamiento HDD con un rendimiento de 16 MBps. Un arquitecto de soluciones debe mejorar el rendimiento del sistema de archivos durante una ventana de mantenimiento definida. ¿Qué debe hacer el arquitecto de soluciones para cumplir con estos requisitos con el MENOR esfuerzo administrativo?",
        "opciones": [
            "A. Usar AWS Backup para crear una copia de seguridad en el tiempo del sistema de archivos. Restaurar la copia de seguridad en un nuevo sistema de archivos FSx para Windows File Server. Seleccionar SSD como tipo de almacenamiento. Seleccionar 32 MBps como capacidad de rendimiento. Cuando se complete el proceso de copia de seguridad y restauración, ajustar el alias DNS en consecuencia. Eliminar el sistema de archivos original.",
            "B. Desconectar a los usuarios del sistema de archivos. En la consola de Amazon FSx, actualizar la capacidad de rendimiento a 32 MBps. Actualizar el tipo de almacenamiento a SSD. Reconectar a los usuarios al sistema de archivos.",
            "C. Implementar un agente AWS DataSync en una nueva instancia de Amazon EC2. Crear una tarea. Configurar el sistema de archivos existente como la ubicación de origen. Configurar un nuevo sistema de archivos FSx para Windows File Server con almacenamiento SSD y 32 MBps de rendimiento como la ubicación de destino. Programar la tarea. Cuando la tarea esté completa, ajustar el alias DNS en consecuencia. Eliminar el sistema de archivos original.",
            "D. Habilitar las copias sombra en el sistema de archivos existente mediante un comando de Windows PowerShell. Programar el trabajo de copia sombra para crear una copia de seguridad en el tiempo del sistema de archivos. Elegir restaurar versiones anteriores. Crear un nuevo sistema de archivos FSx para Windows File Server con almacenamiento SSD y 32 MBps de rendimiento. Cuando se complete el trabajo de copia, ajustar el alias DNS. Eliminar el sistema de archivos original."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "194.- Una empresa aloja una aplicación en AWS. La aplicación lee y escribe objetos que se almacenan en un único bucket de Amazon S3. La empresa debe modificar la aplicación para desplegarla en dos Regiones de AWS. ¿Qué solución cumplirá con estos requisitos con el MENOR esfuerzo operativo?",
        "opciones": [
            "A. Configurar una distribución de Amazon CloudFront con el bucket S3 como origen. Desplegar la aplicación en una segunda región. Modificar la aplicación para usar la distribución de CloudFront. Usar AWS Global Accelerator para acceder a los datos en el bucket S3.",
            "B. Crear un nuevo bucket S3 en una segunda región. Configurar replicación entre regiones S3 bidireccional (CRR) entre el bucket original y el nuevo bucket S3. Configurar un Punto de acceso multi-región S3 que utilice ambos buckets S3. Desplegar la aplicación modificada en ambas regiones.",
            "C. Crear un nuevo bucket S3 en una segunda región. Desplegar la aplicación en la segunda región. Configurar la aplicación para usar el nuevo bucket S3. Configurar replicación entre regiones S3 (CRR) desde el bucket original hasta el nuevo bucket S3.",
            "D. Configurar un punto final de gateway S3 con el bucket S3 como origen. Desplegar la aplicación en una segunda región. Modificar la aplicación para usar el nuevo punto final de gateway S3. Usar S3 Intelligent-Tiering en el bucket S3."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "195.- Una empresa de juegos en línea necesita reubicar su plataforma de juegos en AWS. La aplicación de juegos de la empresa requiere procesamiento de alto rendimiento (HPC) y tiene una tabla de clasificación que cambia con frecuencia. Una instancia de Ubuntu optimizada para la generación de cómputo alberga una aplicación de Node.js para la visualización del juego. El estado del juego se rastrea en una instancia de Redis local. La empresa necesita una estrategia de migración que optimice el rendimiento de la aplicación. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Crear un grupo de Auto Scaling de instancias m5.large de Amazon EC2 Spot detrás de un Application Load Balancer. Usar un clúster de Amazon ElastiCache for Redis para mantener la tabla de clasificación.",
            "B. Crear un grupo de Auto Scaling de instancias c5.large de Amazon EC2 Spot detrás de un Application Load Balancer. Usar un clúster de Amazon OpenSearch Service para mantener la tabla de clasificación.",
            "C. Crear un grupo de Auto Scaling de instancias c5.large de Amazon EC2 On-Demand detrás de un Application Load Balancer. Usar un clúster de Amazon ElastiCache for Redis para mantener la tabla de clasificación.",
            "D. Crear un grupo de Auto Scaling de instancias m5.large de Amazon EC2 On-Demand detrás de un Application Load Balancer. Usar una tabla de Amazon DynamoDB para mantener la tabla de clasificación."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "196.- Un arquitecto de soluciones está diseñando una aplicación para aceptar entradas de hojas de tiempo de los empleados en sus dispositivos móviles. Las hojas de tiempo se enviarán semanalmente, y la mayoría de las presentaciones ocurrirán los viernes. Los datos deben almacenarse en un formato que permita a los administradores de nómina ejecutar informes mensuales. La infraestructura debe ser altamente disponible y escalar para igualar la tasa de datos entrantes y solicitudes de informes. ¿Qué combinación de pasos cumple con estos requisitos mientras minimiza el esfuerzo operativo? (Elija dos.)",
        "opciones": [
            "A. Desplegar la aplicación en Amazon EC2 On-Demand Instances con balanceo de carga entre varias Zonas de Disponibilidad. Usar Amazon EC2 Auto Scaling programado para agregar capacidad antes del alto volumen de envíos los viernes.",
            "B. Desplegar la aplicación en un contenedor utilizando Amazon Elastic Container Service (Amazon ECS) con balanceo de carga entre varias Zonas de Disponibilidad. Usar Service Auto Scaling programado para agregar capacidad antes del alto volumen de envíos los viernes.",
            "C. Desplegar el frontend de la aplicación en un bucket de Amazon S3 servido por Amazon CloudFront. Desplegar el backend de la aplicación usando Amazon API Gateway con una integración de proxy de AWS Lambda.",
            "D. Almacenar los datos de presentación de las hojas de tiempo en Amazon Redshift. Usar Amazon QuickSight para generar los informes utilizando Amazon Redshift como fuente de datos.",
            "E. Almacenar los datos de presentación de las hojas de tiempo en Amazon S3. Usar Amazon Athena y Amazon QuickSight para generar los informes utilizando Amazon S3 como fuente de datos."
        ],
        "respuestas_correctas": [
            "C",
            "E"
        ],
        "imagenes": []
    },
    {
        "pregunta": "197.- Una empresa está almacenando datos sensibles en un bucket de Amazon S3. La empresa debe registrar todas las actividades de los objetos en el bucket S3 y debe conservar los registros durante 5 años. El equipo de seguridad de la empresa también debe recibir una notificación por correo electrónico cada vez que se intente eliminar datos en el bucket S3. ¿Qué combinación de pasos cumplirá con estos requisitos de la manera MÁS rentable? (Elija tres.)",
        "opciones": [
            "A. Configurar AWS CloudTrail para registrar eventos de datos de S3.",
            "B. Configurar registro de acceso del servidor S3 para el bucket S3.",
            "C. Configurar Amazon S3 para enviar eventos de eliminación de objetos a Amazon Simple Email Service (Amazon SES).",
            "D. Configurar Amazon S3 para enviar eventos de eliminación de objetos a un bus de eventos de Amazon EventBridge que publique en un tema de Amazon Simple Notification Service (Amazon SNS).",
            "E. Configurar Amazon S3 para enviar los registros a Amazon Timestream con nivel de almacenamiento de datos.",
            "F. Configurar un nuevo bucket S3 para almacenar los registros con una política de ciclo de vida de S3."
        ],
        "respuestas_correctas": [
            "F",
            "D",
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "198.- Una empresa está construyendo un entorno híbrido que incluye servidores en un centro de datos local y en la nube de AWS. La empresa ha desplegado instancias de Amazon EC2 en tres VPCs. Cada VPC está en una región de AWS diferente. La empresa ha establecido una conexión de AWS Direct Connect al centro de datos desde la región más cercana al centro de datos. La empresa necesita que los servidores en el centro de datos local tengan acceso a las instancias de EC2 en las tres VPCs. Los servidores en el centro de datos local también deben tener acceso a los servicios públicos de AWS. ¿Qué combinación de pasos cumplirá con estos requisitos con el menor costo? (Elija dos.)",
        "opciones": [
            "A. Crear una puerta de enlace Direct Connect en la región más cercana al centro de datos. Adjuntar la conexión de Direct Connect a la puerta de enlace Direct Connect. Usar la puerta de enlace Direct Connect para conectar las VPCs en las otras dos regiones.",
            "B. Configurar conexiones adicionales de Direct Connect desde el centro de datos local a las otras dos regiones.",
            "C. Crear una interfaz virtual privada (VIF). Establecer una conexión de VPN de sitio a sitio sobre la VIF privada para las VPCs en las otras dos regiones.",
            "D. Crear una interfaz virtual pública (VIF). Establecer una conexión de VPN de sitio a sitio sobre la VIF pública para las VPCs en las otras dos regiones.",
            "E. Usar emparejamiento de VPC para establecer una conexión entre las VPCs a través de las regiones. Crear una interfaz virtual privada con la conexión de Direct Connect existente para conectarse a las VPCs emparejadas."
        ],
        "respuestas_correctas": [
            "D",
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "199.- Una empresa está utilizando una organización en AWS Organizations para gestionar cientos de cuentas de AWS. Un arquitecto de soluciones está trabajando en una solución para proporcionar protección base para las 10 principales vulnerabilidades de aplicaciones web según el Open Web Application Security Project (OWASP). El arquitecto de soluciones está utilizando AWS WAF para todas las distribuciones existentes y nuevas de Amazon CloudFront desplegadas dentro de la organización. ¿Qué combinación de pasos debe seguir el arquitecto de soluciones para proporcionar la protección base? (Elija tres.)",
        "opciones": [
            "A. Habilitar AWS Config en todas las cuentas.",
            "B. Habilitar Amazon GuardDuty en todas las cuentas.",
            "C. Habilitar todas las características para la organización.",
            "D. Usar AWS Firewall Manager para desplegar reglas de AWS WAF en todas las cuentas para todas las distribuciones de CloudFront.",
            "E. Usar AWS Shield Advanced para desplegar reglas de AWS WAF en todas las cuentas para todas las distribuciones de CloudFront.",
            "F. Usar AWS Security Hub para desplegar reglas de AWS WAF en todas las cuentas para todas las distribuciones de CloudFront."
        ],
        "respuestas_correctas": [
            "C",
            "D",
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "200.- Un arquitecto de soluciones ha implementado una solución de identidad federada SAML 2.0 con el proveedor de identidad (IdP) local de la empresa para autenticar el acceso de los usuarios al entorno de AWS. Cuando el arquitecto de soluciones prueba la autenticación a través del portal de identidad federada, se concede el acceso al entorno de AWS. Sin embargo, cuando los usuarios de prueba intentan autenticarse a través del portal de identidad federada, no pueden acceder al entorno de AWS. ¿Qué elementos debe verificar el arquitecto de soluciones para asegurarse de que la federación de identidades esté configurada correctamente? (Elija tres.)",
        "opciones": [
            "A. La política de permisos del usuario de IAM ha permitido el uso de la federación SAML para ese usuario.",
            "B. La política de confianza de los roles de IAM creados para los usuarios federados o los grupos federados ha establecido el proveedor SAML como principal.",
            "C. Los usuarios de prueba no están en el grupo AWSFederatedUsers en el IdP de la empresa.",
            "D. El portal web llama a la API AWS STS AssumeRoleWithSAML con el ARN del proveedor SAML, el ARN del rol de IAM y la afirmación SAML del IdP.",
            "E. El nombre de host DNS del IdP local es accesible desde las VPC del entorno de AWS.",
            "F. El IdP de la empresa define afirmaciones SAML que mapean correctamente los usuarios o grupos en la empresa a los roles de IAM con los permisos apropiados."
        ],
        "respuestas_correctas": [
            "C",
            "E",
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "201.- Un arquitecto de soluciones necesita mejorar una aplicación que está alojada en la nube de AWS. La aplicación utiliza una instancia de base de datos Amazon Aurora MySQL que está experimentando conexiones sobrecargadas. La mayoría de las operaciones de la aplicación insertan registros en la base de datos. Actualmente, la aplicación almacena credenciales en un archivo de configuración basado en texto. El arquitecto de soluciones debe implementar una solución para que la aplicación pueda manejar la carga actual de conexiones. La solución debe mantener las credenciales seguras y proporcionar la capacidad de rotarlas automáticamente de manera regular. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Implementar una capa de Amazon RDS Proxy frente a la instancia de la base de datos. Almacenar las credenciales de conexión como un secreto en AWS Secrets Manager.",
            "B. Implementar una capa de Amazon RDS Proxy frente a la instancia de la base de datos. Almacenar las credenciales de conexión en AWS Systems Manager Parameter Store.",
            "C. Crear una Aurora Replica. Almacenar las credenciales de conexión como un secreto en AWS Secrets Manager.",
            "D. Crear una Aurora Replica. Almacenar las credenciales de conexión en AWS Systems Manager Parameter Store."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "202.- Una empresa necesita construir una solución de recuperación ante desastres (DR) para su sitio web de comercio electrónico. La aplicación web está alojada en una flota de instancias de Amazon EC2 t3.large y utiliza una instancia de base de datos Amazon RDS para MySQL. Las instancias de EC2 están en un grupo de Auto Scaling que se extiende a través de múltiples zonas de disponibilidad. En caso de un desastre, la aplicación web debe conmutarse a la infraestructura secundaria con un RPO de 30 segundos y un RTO de 10 minutos. ¿Qué solución cumplirá estos requisitos de manera más rentable?",
        "opciones": [
            "A. Usar infraestructura como código (IaC) para aprovisionar la nueva infraestructura en la región de recuperación ante desastres (DR). Crear una réplica de lectura entre regiones para la instancia de base de datos. Configurar un plan de respaldo en AWS Backup para crear copias de seguridad entre regiones para las instancias de EC2 y la instancia de base de datos. Crear una expresión cron para realizar copias de seguridad de las instancias de EC2 y la base de datos cada 30 segundos en la región de DR. Recuperar las instancias de EC2 desde la última copia de seguridad de EC2. Usar una política de enrutamiento por geolocalización de Amazon Route 53 para conmutar automáticamente a la región de DR en caso de desastre.",
            "B. Usar infraestructura como código (IaC) para aprovisionar la nueva infraestructura en la región de DR. Crear una réplica de lectura entre regiones para la instancia de base de datos. Configurar AWS Elastic Disaster Recovery para replicar continuamente las instancias de EC2 a la región de DR. Ejecutar las instancias de EC2 con la capacidad mínima en la región de DR. Usar una política de enrutamiento de conmutación por error de Amazon Route 53 para conmutar automáticamente a la región de DR en caso de desastre. Aumentar la capacidad deseada del grupo de Auto Scaling.",
            "C. Configurar un plan de respaldo en AWS Backup para crear copias de seguridad entre regiones para las instancias de EC2 y la base de datos. Crear una expresión cron para realizar copias de seguridad de las instancias de EC2 y la base de datos cada 30 segundos en la región de DR. Usar infraestructura como código (IaC) para aprovisionar la nueva infraestructura en la región de DR. Restaurar manualmente los datos respaldados en nuevas instancias. Usar una política de enrutamiento simple de Amazon Route 53 para conmutar automáticamente a la región de DR en caso de desastre.",
            "D. Usar infraestructura como código (IaC) para aprovisionar la nueva infraestructura en la región de DR. Crear una base de datos global de Amazon Aurora. Configurar AWS Elastic Disaster Recovery para replicar continuamente las instancias de EC2 a la región de DR. Ejecutar el grupo de Auto Scaling de instancias de EC2 a plena capacidad en la región de DR. Usar una política de enrutamiento de conmutación por error de Amazon Route 53 para conmutar automáticamente a la región de DR en caso de desastre."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "203.- Una empresa está planificando una migración única de una base de datos MySQL local a Amazon Aurora MySQL en la región us-east-1. La conexión a Internet actual de la empresa tiene un ancho de banda limitado. La base de datos MySQL local tiene un tamaño de 60 TB. La empresa estima que tomará un mes transferir los datos a AWS utilizando la conexión de Internet actual. La empresa necesita una solución de migración que transfiera la base de datos más rápidamente. ¿Qué solución migrará la base de datos en el MENOR tiempo posible?",
        "opciones": [
            "A. Solicitar una conexión AWS Direct Connect de 1 Gbps entre el centro de datos local y AWS. Usar AWS Database Migration Service (AWS DMS) para migrar la base de datos MySQL local a Aurora MySQL.",
            "B. Usar AWS DataSync con la conexión de Internet actual para acelerar la transferencia de datos entre el centro de datos local y AWS. Usar AWS Application Migration Service para migrar la base de datos MySQL local a Aurora MySQL.",
            "C. Pedir un dispositivo AWS Snowball Edge. Cargar los datos en un Amazon S3 usando la interfaz de S3. Usar AWS Database Migration Service (AWS DMS) para migrar los datos de Amazon S3 a Aurora MySQL.",
            "D. Pedir un dispositivo AWS Snowball. Cargar los datos en un Amazon S3 usando el S3 Adapter for Snowball. Usar AWS Application Migration Service para migrar los datos de Amazon S3 a Aurora MySQL."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "204.- Una empresa tiene una aplicación en AWS Cloud. La aplicación se ejecuta en una flota de 20 instancias de Amazon EC2. Las instancias de EC2 son persistentes y almacenan datos en varios volúmenes adjuntos de Amazon Elastic Block Store (Amazon EBS). La empresa debe mantener copias de seguridad en una región separada de AWS. La empresa debe poder recuperar las instancias de EC2 y su configuración dentro de 1 día hábil, con pérdida de no más de 1 día de datos. La empresa tiene un personal limitado y necesita una solución de respaldo que optimice la eficiencia operativa y los costos. La empresa ya ha creado una plantilla de AWS CloudFormation que puede desplegar la configuración de red requerida en una región secundaria. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Crear una segunda plantilla de CloudFormation que pueda recrear las instancias de EC2 en la región secundaria. Ejecutar instantáneas diarias de múltiples volúmenes utilizando AWS Systems Manager Automation runbooks. Copiar las instantáneas a la región secundaria. En caso de fallo, lanzar las plantillas de CloudFormation, restaurar los volúmenes de EBS desde las instantáneas y transferir el uso a la región secundaria.",
            "B. Usar Amazon Data Lifecycle Manager (Amazon DLM) para crear instantáneas diarias de múltiples volúmenes de los volúmenes de EBS. En caso de fallo, lanzar la plantilla de CloudFormation y usar Amazon DLM para restaurar los volúmenes de EBS y transferir el uso a la región secundaria.",
            "C. Usar AWS Backup para crear un plan de respaldo programado diario para las instancias de EC2. Configurar la tarea de respaldo para copiar las copias de seguridad a un almacén en la región secundaria. En caso de fallo, lanzar la plantilla de CloudFormation, restaurar los volúmenes e instancias desde el almacén de respaldo y transferir el uso a la región secundaria.",
            "D. Desplegar instancias de EC2 del mismo tamaño y configuración en la región secundaria. Configurar AWS DataSync para copiar los datos diariamente desde la región primaria a la región secundaria. En caso de fallo, lanzar la plantilla de CloudFormation y transferir el uso a la región secundaria."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "205.- Una empresa está diseñando un nuevo sitio web que aloja contenido estático. El sitio web permitirá a los usuarios cargar y descargar archivos grandes. Según los requisitos de la empresa, todos los datos deben estar cifrados en tránsito y en reposo. Un arquitecto de soluciones está construyendo la solución utilizando Amazon S3 y Amazon CloudFront. ¿Qué combinación de pasos cumplirá con los requisitos de cifrado? (Elija tres.)",
        "opciones": [
            "A. Activar el cifrado del lado del servidor de S3 para el bucket de S3 que utiliza la aplicación web.",
            "B. Agregar un atributo de política de aws:SecureTransport: true para las operaciones de lectura y escritura en los ACLs de S3.",
            "C. Crear una política de bucket que niegue cualquier operación no cifrada en el bucket de S3 que utiliza la aplicación web.",
            "D. Configurar el cifrado en reposo en CloudFront utilizando cifrado del lado del servidor con claves AWS KMS (SSE-KMS).",
            "E. Configurar la redirección de solicitudes HTTP a HTTPS en CloudFront.",
            "F. Usar la opción RequireSSL al crear URLs firmadas para el bucket de S3 que utiliza la aplicación web."
        ],
        "respuestas_correctas": [
            "C",
            "E",
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "206.- Una empresa está implementando una arquitectura sin servidor utilizando funciones AWS Lambda que necesitan acceder a una instancia de base de datos Microsoft SQL Server en Amazon RDS. La empresa tiene entornos separados para desarrollo y producción, incluidos un clon del sistema de bases de datos. A los desarrolladores de la empresa se les permite acceder a las credenciales para la base de datos de desarrollo. Sin embargo, las credenciales para la base de datos de producción deben ser cifradas con una clave a la que solo los miembros del grupo de usuarios de IAM del equipo de seguridad de TI puedan acceder. Esta clave debe ser rotada de manera regular. ¿Qué debe hacer un arquitecto de soluciones en el entorno de producción para cumplir con estos requisitos?",
        "opciones": [
            "A. Almacenar las credenciales de la base de datos en AWS Systems Manager Parameter Store utilizando un parámetro SecureString cifrado por una clave gestionada por el cliente de AWS Key Management Service (AWS KMS). Adjuntar un rol a cada función Lambda para proporcionar acceso al parámetro SecureString. Restringir el acceso al parámetro SecureString y a la clave gestionada por el cliente para que solo el equipo de seguridad de TI pueda acceder al parámetro y a la clave.",
            "B. Cifrar las credenciales de la base de datos utilizando la clave predeterminada de AWS Key Management Service (AWS KMS) para Lambda. Almacenar las credenciales en las variables de entorno de cada función Lambda. Cargar las credenciales desde las variables de entorno en el código de Lambda. Restringir el acceso a la clave KMS para que solo el equipo de seguridad de TI pueda acceder a la clave.",
            "C. Almacenar las credenciales de la base de datos en las variables de entorno de cada función Lambda. Cifrar las variables de entorno utilizando una clave gestionada por el cliente de AWS Key Management Service (AWS KMS). Restringir el acceso a la clave gestionada por el cliente para que solo el equipo de seguridad de TI pueda acceder a la clave.",
            "D. Almacenar las credenciales de la base de datos en AWS Secrets Manager como un secreto asociado con una clave gestionada por el cliente de AWS Key Management Service (AWS KMS). Adjuntar un rol a cada función Lambda para proporcionar acceso al secreto. Restringir el acceso al secreto y a la clave gestionada por el cliente para que solo el equipo de seguridad de TI pueda acceder al secreto y a la clave."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "207.- Una empresa de comercio electrónico está migrando su aplicación heredada en .NET que se ejecuta en instalaciones locales a AWS. La aplicación se ejecuta en servidores web frontend con balanceo de carga, servidores de aplicaciones con balanceo de carga y una base de datos Microsoft SQL Server. La empresa desea utilizar servicios gestionados de AWS siempre que sea posible y no desea reescribir la aplicación. Un arquitecto de soluciones necesita implementar una solución para resolver los problemas de escalabilidad y minimizar los costos de licencias a medida que la aplicación escala. ¿Qué solución cumplirá con estos requisitos de la manera más rentable?",
        "opciones": [
            "A. Desplegar instancias de Amazon EC2 en un grupo de Auto Scaling detrás de un Application Load Balancer para el nivel web y el nivel de aplicación. Usar Amazon Aurora PostgreSQL con Babelfish activado para replatformar la base de datos SQL Server.",
            "B. Crear imágenes de todos los servidores utilizando AWS Database Migration Service (AWS DMS). Desplegar instancias de Amazon EC2 basadas en las importaciones locales. Desplegar las instancias en un grupo de Auto Scaling detrás de un Network Load Balancer para el nivel web y el nivel de aplicación. Usar Amazon DynamoDB como el nivel de base de datos.",
            "C. Contenerizar el nivel frontend web y el nivel de aplicación. Provisionar un clúster de Amazon Elastic Kubernetes Service (Amazon EKS). Crear un grupo de Auto Scaling detrás de un Network Load Balancer para el nivel web y el nivel de aplicación. Usar Amazon RDS para SQL Server para alojar la base de datos.",
            "D. Separar las funciones de la aplicación en AWS Lambda functions. Usar Amazon API Gateway para el nivel frontend web y el nivel de aplicación. Migrar los datos a Amazon S3. Usar Amazon Athena para consultar los datos."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "208- Un proveedor de software como servicio (SaaS) expone APIs a través de un Application Load Balancer (ALB). El ALB se conecta a un clúster de Amazon Elastic Kubernetes Service (Amazon EKS) desplegado en la región us-east-1. Las APIs expuestas contienen el uso de algunos métodos REST no estándar: LINK, UNLINK, LOCK y UNLOCK. Usuarios fuera de los Estados Unidos reportan tiempos de respuesta largos e inconsistentes para estas APIs. Un arquitecto de soluciones necesita resolver este problema con una solución que minimice el esfuerzo operativo. ¿Cuál solución cumple con estos requisitos?",
        "opciones": [
            "A. Añadir una distribución de Amazon CloudFront. Configurar el ALB como el origen.",
            "B. Añadir un punto de enlace de Amazon API Gateway optimizado para borde para exponer las APIs. Configurar el ALB como el objetivo.",
            "C. Añadir un acelerador en AWS Global Accelerator. Configurar el ALB como el origen.",
            "D. Desplegar las APIs en dos regiones adicionales de AWS: eu-west-1 y ap-southeast-2. Añadir registros de enrutamiento basado en latencia en Amazon Route 53."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "209.- Una empresa ejecuta una aplicación IoT en la nube de AWS. La empresa tiene millones de sensores que recopilan datos de casas en los Estados Unidos. Los sensores usan el protocolo MQTT para conectarse y enviar datos a un broker MQTT personalizado. El broker MQTT almacena los datos en una única instancia de Amazon EC2. Los sensores se conectan al broker a través del dominio llamado iot.example.com. La empresa usa Amazon Route 53 como su servicio DNS. Los datos se almacenan en Amazon DynamoDB. En varias ocasiones, la cantidad de datos ha sobrecargado el broker MQTT y ha resultado en pérdida de datos de los sensores. La empresa debe mejorar la confiabilidad de la solución. ¿Qué solución cumple con estos requisitos?",
        "opciones": [
            "A. Crear un Application Load Balancer (ALB) y un grupo de Auto Scaling para el broker MQTT. Usar el grupo de Auto Scaling como el destino para el ALB. Actualizar el registro DNS en Route 53 a un registro de alias. Apuntar el registro de alias al ALB. Usar el broker MQTT para almacenar los datos.",
            "B. Configurar AWS IoT Core para recibir los datos de los sensores. Crear y configurar un dominio personalizado para conectarse a AWS IoT Core. Actualizar el registro DNS en Route 53 para que apunte al punto de enlace AWS IoT Core Data-ATS. Configurar una regla de AWS IoT para almacenar los datos.",
            "C. Crear un Network Load Balancer (NLB). Establecer el broker MQTT como el destino. Crear un AWS Global Accelerator. Establecer el NLB como el punto de enlace para el acelerador. Actualizar el registro DNS en Route 53 a un registro de respuesta múltiple. Establecer las direcciones IP del Global Accelerator como valores. Usar el broker MQTT para almacenar los datos.",
            "D. Configurar AWS IoT Greengrass para recibir los datos de los sensores. Actualizar el registro DNS en Route 53 para que apunte al punto de enlace de AWS IoT Greengrass. Configurar una regla de AWS IoT para invocar una función de AWS Lambda para almacenar los datos."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "210.- Una empresa tiene instancias de Amazon EC2 basadas en Linux. Los usuarios deben acceder a las instancias mediante SSH con pares de claves EC2. Cada máquina requiere un par de claves EC2 único. La empresa desea implementar una política de rotación de claves que, bajo solicitud, rote automáticamente todos los pares de claves EC2 y mantenga las claves en un lugar seguro y cifrado. La empresa acepta menos de 1 minuto de tiempo de inactividad durante la rotación de claves. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Almacenar todas las claves en AWS Secrets Manager. Definir un horario de rotación de Secrets Manager para invocar una función de AWS Lambda que genere nuevos pares de claves. Reemplazar las claves públicas en las instancias de EC2. Actualizar las claves privadas en Secrets Manager.",
            "B. Almacenar todas las claves en Parameter Store, una capacidad de AWS Systems Manager, como una cadena. Definir una ventana de mantenimiento de Systems Manager para invocar una función de AWS Lambda que genere nuevos pares de claves. Reemplazar las claves públicas en las instancias de EC2. Actualizar las claves privadas en Parameter Store.",
            "C. Importar los pares de claves EC2 en AWS Key Management Service (AWS KMS). Configurar la rotación automática de claves para estos pares de claves. Crear una regla programada en Amazon EventBridge para invocar una función de AWS Lambda para iniciar la rotación de claves en AWS KMS.",
            "D. Agregar todas las instancias de EC2 a Fleet Manager, una capacidad de AWS Systems Manager. Definir una ventana de mantenimiento de Systems Manager para emitir un documento de Systems Manager Run Command para generar nuevos pares de claves y rotar las claves públicas en todas las instancias en Fleet Manager."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "211.- Una empresa quiere migrar a AWS. La empresa está ejecutando miles de máquinas virtuales (VM) en un entorno VMware ESXi. La empresa no tiene una base de datos de gestión de configuraciones y tiene poco conocimiento sobre la utilización del portafolio de VMware. Un arquitecto de soluciones debe proporcionar a la empresa un inventario preciso para que la empresa pueda planificar una migración rentable. ¿Qué solución cumplirá con estos requisitos con el MENOR esfuerzo operativo?",
        "opciones": [
            "A. Utilizar AWS Systems Manager Patch Manager para desplegar Migration Evaluator en cada máquina virtual. Revisar los datos recopilados en Amazon QuickSight. Identificar los servidores que tienen alta utilización. Eliminar los servidores con alta utilización de la lista de migración. Importar los datos a AWS Migration Hub.",
            "B. Exportar el portafolio de VMware a un archivo .csv. Verificar la utilización del disco de cada servidor. Eliminar los servidores con alta utilización. Exportar los datos a AWS Application Migration Service. Utilizar AWS Server Migration Service (AWS SMS) para migrar los servidores restantes.",
            "C. Desplegar el recolector sin agente de Migration Evaluator en el hipervisor ESXi. Revisar los datos recopilados en Migration Evaluator. Identificar servidores inactivos. Eliminar los servidores inactivos de la lista de migración. Importar los datos a AWS Migration Hub.",
            "D. Desplegar el agente de AWS Application Migration Service en cada VM. Cuando se recopilen los datos, utilizar Amazon Redshift para importar y analizar los datos. Usar Amazon QuickSight para la visualización de los datos."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "212.- Una empresa ejecuta un microservicio como una función de AWS Lambda. El microservicio escribe datos en una base de datos SQL local que admite un número limitado de conexiones concurrentes. Cuando el número de invocaciones de la función Lambda es demasiado alto, la base de datos se cae y causa tiempo de inactividad en la aplicación. La empresa tiene una conexión AWS Direct Connect entre la VPC de la empresa y el centro de datos local. La empresa desea proteger la base de datos contra caídas. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Escribir los datos en una cola de Amazon Simple Queue Service (Amazon SQS). Configurar la función Lambda para leer de la cola y escribir en la base de datos existente. Establecer un límite de concurrencia reservada en la función Lambda que sea menor que el número de conexiones que la base de datos admite.",
            "B. Crear un nuevo clúster de base de datos Amazon Aurora Serverless. Usar AWS DataSync para migrar los datos de la base de datos existente a Aurora Serverless. Reconfigurar la función Lambda para escribir en Aurora.",
            "C. Crear una instancia de base de datos Amazon RDS Proxy. Adjuntar la instancia de RDS Proxy a la instancia de base de datos Amazon RDS. Reconfigurar la función Lambda para escribir en la instancia de RDS Proxy.",
            "D. Escribir los datos en un tema de Amazon Simple Notification Service (Amazon SNS). Invocar la función Lambda para escribir en la base de datos existente cuando el tema reciba nuevos mensajes. Configurar la concurrencia provisionada para la función Lambda de manera que sea igual al número de conexiones que la base de datos admite."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "213.- Una empresa utiliza una solución de visualización de datos Grafana que se ejecuta en una única instancia de Amazon EC2 para monitorear la salud de las cargas de trabajo de AWS de la empresa. La empresa ha invertido tiempo y esfuerzo para crear tableros que desean preservar. Los tableros deben ser altamente disponibles y no pueden estar caídos por más de 10 minutos. La empresa necesita minimizar el mantenimiento continuo. ¿Qué solución cumplirá con estos requisitos con el MENOR esfuerzo operativo?",
        "opciones": [
            "A. Migrar a Amazon CloudWatch Dashboards. Recrear los tableros para que coincidan con los existentes de Grafana. Usar tableros automáticos siempre que sea posible.",
            "B. Crear un Amazon Managed Grafana workspace. Configurar una nueva fuente de datos de Amazon CloudWatch. Exportar los tableros desde la instancia de Grafana existente. Importar los tableros en el nuevo espacio de trabajo.",
            "C. Crear una AMI con Grafana preinstalado. Almacenar los tableros existentes en Amazon Elastic File System (Amazon EFS). Crear un grupo de Auto Scaling que use la nueva AMI. Establecer el número mínimo, deseado y máximo de instancias en uno. Crear un Application Load Balancer que sirva al menos dos zonas de disponibilidad.",
            "D. Configurar AWS Backup para hacer una copia de seguridad de la instancia de EC2 que ejecuta Grafana una vez por hora. Restaurar la instancia de EC2 desde la última instantánea en una zona de disponibilidad alternativa cuando sea necesario."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "214.- Una empresa necesita migrar su base de datos de transacciones de clientes desde un entorno local a AWS. La base de datos reside en una instancia de Oracle DB que se ejecuta en un servidor Linux. De acuerdo con un nuevo requisito de seguridad, la empresa debe rotar la contraseña de la base de datos cada año. ¿Qué solución cumplirá con estos requisitos con el MENOR esfuerzo operativo?",
        "opciones": [
            "A. Convertir la base de datos a Amazon DynamoDB utilizando la AWS Schema Conversion Tool (AWS SCT). Almacenar la contraseña en AWS Systems Manager Parameter Store. Crear una alarma de Amazon CloudWatch para invocar una función de AWS Lambda para la rotación anual de la contraseña.",
            "B. Migrar la base de datos a Amazon RDS para Oracle. Almacenar la contraseña en AWS Secrets Manager. Activar la rotación automática. Configurar un calendario de rotación anual.",
            "C. Migrar la base de datos a una instancia de Amazon EC2. Usar AWS Systems Manager Parameter Store para almacenar y rotar la cadena de conexión utilizando una función de AWS Lambda en un calendario anual.",
            "D. Migrar la base de datos a Amazon Neptune utilizando la AWS Schema Conversion Tool (AWS SCT). Crear una alarma de Amazon CloudWatch para invocar una función de AWS Lambda para la rotación anual de la contraseña."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "215.- Un arquitecto de soluciones está diseñando una estructura de cuentas de AWS para una empresa que consta de varios equipos. Todos los equipos trabajarán en la misma región de AWS. La empresa necesita una VPC que esté conectada a la red local. La empresa espera menos de 50 Mbps de tráfico total hacia y desde la red local. ¿Qué combinación de pasos cumplirá estos requisitos de manera MÁS rentable? (Elija dos.)",
        "opciones": [
            "A. Crear una plantilla de AWS CloudFormation que aprovisione una VPC y las subredes requeridas. Desplegar la plantilla en cada cuenta de AWS.",
            "B. Crear una plantilla de AWS CloudFormation que aprovisione una VPC y las subredes requeridas. Desplegar la plantilla en una cuenta de servicios compartidos. Compartir las subredes utilizando AWS Resource Access Manager.",
            "C. Usar AWS Transit Gateway junto con una VPN de sitio a sitio para la conectividad a la red local. Compartir el Transit Gateway utilizando AWS Resource Access Manager.",
            "D. Usar AWS VPN de sitio a sitio para la conectividad a la on-premises.",
            "E. Usar AWS Direct Connect para la conectividad a la red local."
        ],
        "respuestas_correctas": [
            "D",
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "216.- Un arquitecto de soluciones en una empresa grande necesita configurar la seguridad de la red para el tráfico saliente hacia Internet desde todas las cuentas de AWS dentro de una organización en AWS Organizations. La organización tiene más de 100 cuentas de AWS, y las cuentas se enrutan entre sí mediante un AWS Transit Gateway centralizado. Cada cuenta tiene tanto una puerta de enlace a Internet (Internet Gateway) como una puerta de enlace NAT (NAT Gateway) para el tráfico saliente hacia Internet. La empresa despliega recursos únicamente en una sola Región de AWS. La empresa necesita la capacidad de agregar un filtrado basado en reglas gestionado centralmente para todo el tráfico saliente hacia Internet en todas las cuentas de AWS en la organización. La carga máxima de tráfico saliente no superará los 25 Gbps en cada Zona de Disponibilidad. ¿Qué solución cumple con estos requisitos?",
        "opciones": [
            "A. Crear una nueva VPC para el tráfico saliente hacia Internet. Conectar el transit gateway existente a la nueva VPC. Configurar una nueva puerta de enlace NAT. Crear un grupo de Auto Scaling de instancias Amazon EC2 que ejecute un proxy de Internet de código abierto para el filtrado basado en reglas a través de todas las Zonas de Disponibilidad en la región. Modificar todas las rutas predeterminadas para que apunten al grupo de Auto Scaling del proxy.",
            "B. Crear una nueva VPC para el tráfico saliente hacia Internet. Conectar el transit gateway existente a la nueva VPC. Configurar una nueva puerta de enlace NAT. Usar un AWS Network Firewall para el filtrado basado en reglas. Crear puntos de enlace de Network Firewall en cada Zona de Disponibilidad. Modificar todas las rutas predeterminadas para que apunten a los puntos de enlace de Network Firewall.",
            "C. Crear un AWS Network Firewall para el filtrado basado en reglas en cada cuenta de AWS. Modificar todas las rutas predeterminadas para que apunten a los firewalls de Network Firewall en cada cuenta.",
            "D. En cada cuenta de AWS, crear un grupo de Auto Scaling de instancias de Amazon EC2 optimizadas para red que ejecuten un proxy de Internet de código abierto para el filtrado basado en reglas. Modificar todas las rutas predeterminadas para que apunten al grupo de Auto Scaling del proxy."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "217.- Una empresa utiliza un balanceador de carga para distribuir el tráfico a las instancias de Amazon EC2 en una única zona de disponibilidad. La empresa está preocupada por la seguridad y quiere que un arquitecto de soluciones reorganice la solución para cumplir con los siguientes requisitos: • Las solicitudes entrantes deben ser filtradas para detectar ataques comunes de vulnerabilidad. • Las solicitudes rechazadas deben enviarse a una aplicación de auditoría de terceros. • Todos los recursos deben ser altamente disponibles. ¿Qué solución cumple con estos requisitos?",
        "opciones": [
            "A. Configurar un grupo de Auto Scaling Multi-AZ utilizando la AMI de la aplicación. Crear un Application Load Balancer (ALB) y seleccionar el grupo de Auto Scaling previamente creado como el destino. Usar Amazon Inspector para monitorear el tráfico hacia el ALB y las instancias de EC2. Crear un web ACL en WAF. Crear un AWS WAF usando el web ACL y ALB. Usar una función de AWS Lambda para enviar frecuentemente el informe de Amazon Inspector a la aplicación de auditoría de terceros.",
            "B. Configurar un Application Load Balancer (ALB) y agregar las instancias de EC2 como destinos. Crear un web ACL en WAF. Crear un AWS WAF utilizando el web ACL y el nombre de ALB, y habilitar el registro con Amazon CloudWatch Logs. Usar una función de AWS Lambda para enviar frecuentemente los registros a la aplicación de auditoría de terceros.",
            "C. Configurar un Application Load Balancer (ALB) junto con un grupo de destino agregando las instancias de EC2 como destinos. Crear un Amazon Kinesis Data Firehose con el destino de la aplicación de auditoría de terceros. Crear un web ACL en WAF. Crear un AWS WAF utilizando el web ACL y ALB, luego habilitar el registro seleccionando Kinesis Data Firehose como el destino. Suscribirse a las reglas administradas de AWS en AWS Marketplace, eligiendo WAF como el suscriptor.",
            "D. Configurar un grupo de Auto Scaling Multi-AZ utilizando la AMI de la aplicación. Crear un Application Load Balancer (ALB) y seleccionar el grupo de Auto Scaling previamente creado como el destino. Crear un Amazon Kinesis Data Firehose con un destino de la aplicación de auditoría de terceros. Crear un web ACL en WAF. Crear un AWS WAF utilizando el WebACL y ALB, luego habilitar el registro seleccionando Kinesis Data Firehose como el destino. Suscribirse a las reglas administradas de AWS en AWS Marketplace, eligiendo WAF como el suscriptor."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "218.- Una empresa está ejecutando una aplicación en la nube de AWS. La aplicación consta de microservicios que se ejecutan en una flota de instancias de Amazon EC2 en múltiples zonas de disponibilidad detrás de un Application Load Balancer. La empresa recientemente agregó una nueva API REST que fue implementada en Amazon API Gateway. Algunos de los microservicios más antiguos que se ejecutan en las instancias de EC2 necesitan llamar a esta nueva API. La empresa no quiere que la API sea accesible desde Internet público y no desea que los datos propietarios crucen Internet público. ¿Qué debería hacer un arquitecto de soluciones para cumplir con estos requisitos?",
        "opciones": [
            "A. Crear una conexión AWS Site-to-Site VPN entre la VPC y API Gateway. Usar API Gateway para generar una clave de API única para cada microservicio. Configurar los métodos de la API para que requieran la clave.",
            "B. Crear un endpoint VPC de interfaz para API Gateway, y establecer una política de endpoint para permitir solo el acceso a la API específica. Añadir una política de recursos a API Gateway para permitir solo el acceso desde el endpoint VPC. Cambiar el tipo de endpoint de API Gateway a privado.",
            "C. Modificar API Gateway para usar autenticación IAM. Actualizar la política IAM para el rol IAM que está asignado a las instancias de EC2 para permitir el acceso a API Gateway. Mover API Gateway a una nueva VPC. Desplegar un transit gateway y conectar las VPCs.",
            "D. Crear un acelerador en AWS Global Accelerator, y conectar el acelerador a API Gateway. Actualizar la tabla de rutas para todas las subredes de la VPC con una ruta al IP del endpoint creado por Global Accelerator. Añadir una clave de API para cada servicio que use para autenticación."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "219.- Una empresa ha configurado toda su infraestructura en AWS. La empresa utiliza Amazon EC2 para alojar su sitio web de comercio electrónico y Amazon S3 para almacenar datos estáticos. Tres ingenieros en la empresa gestionan la administración y desarrollo de la nube a través de una cuenta de AWS. Ocasionalmente, un ingeniero altera la configuración de un grupo de seguridad de EC2 de otro ingeniero, lo que provoca problemas de no cumplimiento en el entorno. Un arquitecto de soluciones debe configurar un sistema que realice un seguimiento de los cambios que hacen los ingenieros. El sistema debe enviar alertas cuando los ingenieros realicen cambios no conformes con las configuraciones de seguridad de las instancias de EC2. ¿Cuál es la manera más RÁPIDA para que el arquitecto de soluciones cumpla con estos requisitos?",
        "opciones": [
            "A. Configurar AWS Organizations para la empresa. Aplicar SCP (Service Control Policies) para gobernar y realizar un seguimiento de los cambios no conformes en los grupos de seguridad realizados en la cuenta de AWS.",
            "B. Habilitar AWS CloudTrail para capturar los cambios en los grupos de seguridad de EC2. Habilitar las reglas de Amazon CloudWatch para proporcionar alertas cuando se detecten configuraciones de seguridad no conformes.",
            "C. Habilitar SCP en la cuenta de AWS para proporcionar alertas cuando se realicen cambios no conformes en los grupos de seguridad del entorno.",
            "D. Habilitar AWS Config en los grupos de seguridad de EC2 para rastrear cualquier cambio no conforme. Enviar los cambios como alertas a través de un tema de Amazon Simple Notification Service (Amazon SNS)."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "220.- Una empresa tiene sensores IoT que monitorean los patrones de tráfico en una gran ciudad. La empresa desea leer y recopilar datos de los sensores y realizar agregaciones sobre esos datos. Un arquitecto de soluciones diseña una solución en la que los dispositivos IoT transmiten datos a Amazon Kinesis Data Streams. Varias aplicaciones están leyendo desde el flujo. Sin embargo, varios consumidores están experimentando limitaciones de velocidad y están encontrando periódicamente un error ReadProvisionedThroughputExceeded. ¿Qué acciones debe tomar el arquitecto de soluciones para resolver este problema? (Elija tres.)",
        "opciones": [
            "A. Redistribuir el flujo para aumentar el número de fragmentos en el flujo.",
            "B. Usar la Kinesis Producer Library (KPL). Ajustar la frecuencia de sondeo.",
            "C. Usar consumidores con la función de fan-out mejorado.",
            "D. Redistribuir el flujo para reducir el número de fragmentos en el flujo.",
            "E. Usar un mecanismo de reintentos de errores y retroceso exponencial en la lógica del consumidor.",
            "F. Configurar el flujo para usar particionamiento dinámico."
        ],
        "respuestas_correctas": [
            "C",
            "E",
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "221.- Una empresa utiliza AWS Organizations para administrar sus cuentas de AWS. La empresa necesita una lista de todas sus instancias de Amazon EC2 que tengan un uso subutilizado de CPU o memoria. Además, la empresa necesita recomendaciones sobre cómo reducir el tamaño de estas instancias subutilizadas. ¿Qué solución cumplirá con estos requisitos con el menor esfuerzo?",
        "opciones": [
            "A. Instalar una herramienta de monitoreo de CPU y memoria desde AWS Marketplace en todas las instancias de EC2. Almacenar los hallazgos en Amazon S3. Implementar un script en Python para identificar instancias subutilizadas. Consultar la información de precios de instancias EC2 para obtener recomendaciones sobre opciones de reducción de tamaño.",
            "B. Instalar el agente de Amazon CloudWatch en todas las instancias de EC2 mediante AWS Systems Manager. Recuperar las recomendaciones de optimización de recursos desde AWS Cost Explorer en la cuenta de administración de la organización. Utilizar las recomendaciones para reducir el tamaño de las instancias subutilizadas en todas las cuentas de la organización.",
            "C. Instalar el agente de Amazon CloudWatch en todas las instancias de EC2 mediante AWS Systems Manager. Recuperar las recomendaciones de optimización de recursos desde AWS Cost Explorer en cada cuenta de la organización. Utilizar las recomendaciones para reducir el tamaño de las instancias subutilizadas en todas las cuentas de la organización.",
            "D. Instalar el agente de Amazon CloudWatch en todas las instancias de EC2 mediante AWS Systems Manager. Crear una función de AWS Lambda para extraer el uso de CPU y memoria de todas las instancias de EC2. Almacenar los hallazgos como archivos en Amazon S3. Utilizar Amazon Athena para encontrar instancias subutilizadas. Consultar la información de precios de instancias EC2 para obtener recomendaciones sobre opciones de reducción de tamaño."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "222.- Una empresa quiere ejecutar un paquete de software de análisis de red personalizado para inspeccionar el tráfico cuando entra y sale de una VPC. La empresa ha implementado la solución utilizando AWS CloudFormation en tres instancias de Amazon EC2 dentro de un grupo de Auto Scaling. Toda la configuración de enrutamiento de red ha sido establecida para dirigir el tráfico hacia las instancias de EC2. Cada vez que el software de análisis deja de funcionar, el grupo de Auto Scaling reemplaza una instancia. Sin embargo, las rutas de red no se actualizan cuando ocurre el reemplazo de la instancia. ¿Qué combinación de pasos resolverá este problema? (Elige tres.)",
        "opciones": [
            "A. Crear alarmas basadas en métricas de verificación de estado de EC2 que hagan que el grupo de Auto Scaling reemplace la instancia fallida.",
            "B. Actualizar la plantilla de CloudFormation para instalar el agente de Amazon CloudWatch en las instancias de EC2. Configurar el agente de CloudWatch para enviar métricas de procesos de la aplicación.",
            "C. Actualizar la plantilla de CloudFormation para instalar el AWS Systems Manager Agent en las instancias de EC2. Configurar el agente de Systems Manager para enviar métricas de procesos de la aplicación.",
            "D. Crear una alarma para la métrica personalizada en Amazon CloudWatch para los escenarios de falla. Configurar la alarma para publicar un mensaje en un tema de Amazon Simple Notification Service (Amazon SNS).",
            "E. Crear una función de AWS Lambda que responda al mensaje de Amazon SNS para sacar la instancia fuera de servicio. Actualizar las rutas de red para que apunten a la nueva instancia de reemplazo.",
            "F. En la plantilla de CloudFormation, escribir una condición que actualice las rutas de red cuando se lance una instancia de reemplazo."
        ],
        "respuestas_correctas": [
            "E",
            "D",
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "223.- Una empresa está desarrollando una nueva aplicación de video bajo demanda basada en microservicios. La aplicación tendrá 5 millones de usuarios en su lanzamiento y alcanzará los 30 millones de usuarios después de 6 meses. La empresa ha implementado la aplicación en Amazon Elastic Container Service (Amazon ECS) en AWS Fargate. La aplicación fue desarrollada utilizando servicios de ECS que usan el protocolo HTTPS. Un arquitecto de soluciones necesita implementar actualizaciones en la aplicación utilizando implementaciones blue/green. La solución debe distribuir el tráfico a cada servicio de ECS a través de un balanceador de carga. Además, la aplicación debe ajustar automáticamente el número de tareas en respuesta a una alarma de Amazon CloudWatch. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Configurar los servicios de ECS para usar el tipo de implementación blue/green y un Network Load Balancer. Solicitar aumentos en la cuota del servicio para la cantidad de tareas por servicio para satisfacer la demanda.",
            "B. Configurar los servicios de ECS para usar el tipo de implementación blue/green y un Network Load Balancer. Implementar un grupo de Auto Scaling para cada servicio de ECS utilizando Cluster Autoscaler.",
            "C. Configurar los servicios de ECS para usar el tipo de implementación blue/green y un Application Load Balancer. Implementar un grupo de Auto Scaling para cada servicio de ECS utilizando Cluster Autoscaler.",
            "D. Configurar los servicios de ECS para usar el tipo de implementación blue/green y un Application Load Balancer. Implementar Service Auto Scaling para cada servicio de ECS."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "224.- Una empresa está ejecutando una aplicación contenerizada en la nube de AWS. La aplicación se ejecuta mediante Amazon Elastic Container Service (Amazon ECS) en un conjunto de instancias de Amazon EC2. Las instancias de EC2 operan dentro de un grupo de Auto Scaling. La empresa utiliza Amazon Elastic Container Registry (Amazon ECR) para almacenar sus imágenes de contenedores. Cuando se sube una nueva versión de una imagen, esta recibe una etiqueta (tag) única. La empresa necesita una solución que inspeccione las nuevas versiones de las imágenes en busca de vulnerabilidades y exposiciones comunes. La solución debe eliminar automáticamente las etiquetas (tags) de las imágenes que presenten hallazgos de gravedad Crítica o Alta. Además, la solución debe notificar al equipo de desarrollo cuando ocurra una eliminación. ¿Qué solución cumple con estos requisitos?",
        "opciones": [
            "A. Configurar el escaneo on push en el repositorio. Usar Amazon EventBridge para invocar una máquina de estado de AWS Step Functions cuando se complete un escaneo para imágenes con hallazgos de gravedad Crítica o Alta. Usar la máquina de estado de Step Functions para eliminar la etiqueta de la imagen y notificar al equipo de desarrollo mediante Amazon Simple Notification Service (Amazon SNS).",
            "B. Configurar el escaneo on push en el repositorio. Configurar los resultados del escaneo para que se envíen a una cola de Amazon Simple Queue Service (Amazon SQS). Invocar una función de AWS Lambda cuando se agregue un nuevo mensaje a la cola SQS. Usar la función Lambda para eliminar la etiqueta de la imagen con hallazgos de gravedad Crítica o Alta y notificar al equipo de desarrollo mediante Amazon Simple Email Service (Amazon SES).",
            "C. Programar una función de AWS Lambda para iniciar un escaneo manual de imágenes cada hora. Configurar Amazon EventBridge para invocar otra función Lambda cuando se complete un escaneo. Usar la segunda función Lambda para eliminar la etiqueta de la imagen con hallazgos de gravedad Crítica o Alta y notificar al equipo de desarrollo mediante Amazon Simple Notification Service (Amazon SNS).",
            "D. Configurar un escaneo periódico de imágenes en el repositorio. Configurar los resultados del escaneo para que se agreguen a una cola de Amazon Simple Queue Service (Amazon SQS). Invocar una máquina de estado de AWS Step Functions cuando se agregue un nuevo mensaje a la cola SQS. Usar la máquina de estado de Step Functions para eliminar la etiqueta de la imagen con hallazgos de gravedad Crítica o Alta y notificar al equipo de desarrollo mediante Amazon Simple Email Service (Amazon SES)."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "225.- Una empresa ejecuta muchas cargas de trabajo en AWS y utiliza AWS Organizations para gestionar sus cuentas. Las cargas de trabajo están alojadas en Amazon EC2, AWS Fargate y AWS Lambda. Algunas de estas cargas de trabajo tienen una demanda impredecible. Las cuentas registran un uso elevado en algunos meses y bajo en otros meses. La empresa quiere optimizar sus costos de cómputo durante los próximos 3 años. Un arquitecto de soluciones obtiene un promedio de uso de 6 meses para cada cuenta de la organización con el fin de calcular el consumo. ¿Qué solución proporcionará el MAYOR ahorro de costos para todo el uso de cómputo de la organización?",
        "opciones": [
            "A. Comprar Reserved Instances para la organización que coincidan con el tamaño y la cantidad de las instancias EC2 más comunes de las cuentas miembros.",
            "B. Comprar un Compute Savings Plan para la organización desde la cuenta de administración utilizando la recomendación a nivel de cuenta de administración.",
            "C. Comprar Reserved Instances para cada cuenta miembro que haya tenido un alto uso de EC2 según los datos de los últimos 6 meses.",
            "D. Comprar un EC2 Instance Savings Plan para cada cuenta miembro desde la cuenta de administración basándose en los datos de uso de EC2 de los últimos 6 meses."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "226.- Una empresa tiene cientos de cuentas de AWS y utiliza una organización en AWS Organizations para gestionar todas las cuentas. La empresa ha activado todas las funciones. El equipo de finanzas ha asignado un presupuesto diario para los costos de AWS. El equipo de finanzas debe recibir una notificación por correo electrónico si los costos de AWS de la organización superan el 80 % del presupuesto asignado. Un arquitecto de soluciones necesita implementar una solución para rastrear los costos y enviar las notificaciones. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. En la cuenta de administración de la organización, utiliza AWS Budgets para crear un presupuesto con un período diario. Agrega un umbral de alerta y establece el valor en 80 %. Usa Amazon Simple Notification Service (Amazon SNS) para notificar al equipo de finanzas.",
            "B. En la cuenta de administración de la organización, configura la función de vista organizacional para AWS Trusted Advisor. Crea un informe de vista organizacional para la optimización de costos. Establece un umbral de alerta del 80 %. Configura las preferencias de notificación. Agrega las direcciones de correo electrónico del equipo de finanzas.",
            "C. Registra la organización en AWS Control Tower. Activa la opción de control de costos (guardrail) opcional. Establece un parámetro de control (guardrail) del 80 %. Configura las preferencias de notificación del control (guardrail). Usa Amazon Simple Notification Service (Amazon SNS) para notificar al equipo de finanzas.",
            "D. Configura las cuentas miembro para guardar un informe diario de Costos y Uso de AWS en un bucket de Amazon S3 en la cuenta de administración de la organización. Usa Amazon EventBridge para programar una consulta diaria de Amazon Athena para calcular los costos de la organización. Configura Athena para enviar una alerta de Amazon CloudWatch si los costos totales superan el 80 % del presupuesto asignado. Usa Amazon Simple Notification Service (Amazon SNS) para notificar al equipo de finanzas."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "227.- Una empresa ofrece servicios de subastas de obras de arte y tiene usuarios en toda América del Norte y Europa. La empresa aloja su aplicación en instancias de Amazon EC2 en la región us-east-1. Los artistas suben fotos de sus obras como archivos de imagen de gran tamaño y alta resolución desde sus teléfonos móviles a un bucket centralizado de Amazon S3 creado en la región us-east-1. Los usuarios en Europa están reportando un rendimiento lento al subir imágenes. ¿Cómo puede un arquitecto de soluciones mejorar el rendimiento del proceso de carga de imágenes?",
        "opciones": [
            "A. Volver a implementar la aplicación para utilizar cargas multiparte en S3.",
            "B. Crear una distribución de Amazon CloudFront y apuntarla a la aplicación como un origen personalizado.",
            "C. Configurar los buckets para usar S3 Transfer Acceleration.",
            "D. Crear un grupo de Auto Scaling para las instancias EC2 y establecer una política de escalado."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "228.- Una empresa quiere contenerizar una aplicación web de múltiples niveles y migrarla desde un centro de datos local a AWS. La aplicación incluye niveles de web, aplicación y base de datos. La empresa necesita que la aplicación sea tolerante a fallos y escalable. Algunos datos de acceso frecuente deben estar siempre disponibles en todos los servidores de aplicaciones. Los servidores web de frontend necesitan persistencia de sesión y deben escalar para satisfacer los aumentos en el tráfico. ¿Qué solución cumplirá con estos requisitos con el menor esfuerzo operativo continuo?",
        "opciones": [
            "A. Ejecutar la aplicación en Amazon Elastic Container Service (Amazon ECS) en AWS Fargate. Usar Amazon Elastic File System (Amazon EFS) para los datos que se acceden con frecuencia entre los niveles web y de aplicación. Almacenar los datos de sesión del servidor web de frontend en Amazon Simple Queue Service (Amazon SQS).",
            "B. Ejecutar la aplicación en Amazon Elastic Container Service (Amazon ECS) en instancias EC2. Usar Amazon ElastiCache for Redis para almacenar en caché los datos de sesión del servidor web de frontend. Usar Amazon Elastic Block Store (Amazon EBS) con Multi-Attach en instancias EC2 distribuidas en múltiples Zonas de Disponibilidad.",
            "C. Ejecutar la aplicación en Amazon Elastic Kubernetes Service (Amazon EKS). Configurar Amazon EKS para usar grupos de nodos administrados. Usar ReplicaSets para ejecutar los servidores web y aplicaciones. Crear un sistema de archivos Amazon Elastic File System (Amazon EFS). Montar el sistema de archivos EFS en todos los pods de EKS para almacenar los datos de sesión del servidor web de frontend.",
            "D. Desplegar la aplicación en Amazon Elastic Kubernetes Service (Amazon EKS). Configurar Amazon EKS para usar grupos de nodos administrados. Ejecutar los servidores web y aplicaciones como despliegues de Kubernetes en el clúster de EKS. Almacenar los datos de sesión del servidor web de frontend en una tabla de Amazon DynamoDB. Crear un volumen Amazon Elastic File System (Amazon EFS) que todas las aplicaciones montarán en el momento de la implementación."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "229.- Un arquitecto de soluciones está planeando migrar bases de datos críticas de Microsoft SQL Server a AWS. Dado que las bases de datos son sistemas heredados, el arquitecto de soluciones moverá las bases de datos a una arquitectura de datos moderna. El arquitecto de soluciones debe migrar las bases de datos con un tiempo de inactividad casi nulo. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Usar AWS Application Migration Service y la AWS Schema Conversion Tool (AWS SCT). Realizar una actualización in situ antes de la migración. Exportar los datos migrados a Amazon Aurora Serverless después del cambio. Redirigir las aplicaciones a Amazon Aurora.",
            "B. Usar AWS Database Migration Service (AWS DMS) para reubicar la base de datos. Establecer Amazon S3 como destino. Configurar la replicación de Change Data Capture (CDC). Cuando la fuente y el destino estén completamente sincronizados, cargar los datos desde Amazon S3 en una instancia de Amazon RDS for Microsoft SQL Server.",
            "C. Usar herramientas nativas de alta disponibilidad de la base de datos. Conectar el sistema de origen a una instancia de Amazon RDS for Microsoft SQL Server. Configurar la replicación en consecuencia. Cuando la replicación de datos haya finalizado, cambiar la carga de trabajo a la instancia de Amazon RDS for Microsoft SQL Server.",
            "D. Usar AWS Application Migration Service. Reubicar el servidor de bases de datos en Amazon EC2. Cuando la replicación de datos haya finalizado, desvincular la base de datos y moverla a una instancia de Amazon RDS for Microsoft SQL Server. Volver a vincular la base de datos y luego realizar el cambio de toda la red."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "230.- Un arquitecto de soluciones de una empresa está analizando los costos de un entorno de múltiples aplicaciones. El entorno está implementado en varias Zonas de Disponibilidad dentro de una única región de AWS. Después de una reciente adquisición, la empresa administra dos organizaciones dentro de AWS Organizations. La empresa ha creado múltiples aplicaciones de proveedor de servicios como servicios de endpoint de VPC potenciados por AWS PrivateLink en una organización. En la otra organización, la empresa ha creado múltiples aplicaciones de consumidor de servicios. Los cargos por transferencia de datos son mucho más altos de lo esperado, y el arquitecto de soluciones necesita reducir los costos. El arquitecto de soluciones debe recomendar pautas para que los desarrolladores las sigan al implementar servicios. Estas pautas deben minimizar los cargos por transferencia de datos en todo el entorno. ¿Qué pautas cumplen con estos requisitos? (Elija dos opciones).",
        "opciones": [
            "A. Usar AWS Resource Access Manager para compartir las subredes que alojan las aplicaciones del proveedor de servicios con otras cuentas dentro de la organización.",
            "B. Ubicar las aplicaciones del proveedor de servicios y las aplicaciones del consumidor de servicios en cuentas de AWS dentro de la misma organización.",
            "C. Desactivar el balanceo de carga entre zonas para el Network Load Balancer en todas las implementaciones de aplicaciones del proveedor de servicios.",
            "D. Asegurar que los recursos de cómputo del consumidor de servicios utilicen el servicio de endpoint específico de la Zona de Disponibilidad mediante el nombre de DNS local del endpoint.",
            "E. Crear un Savings Plan que proporcione cobertura adecuada para el uso planificado de transferencia de datos entre Zonas de Disponibilidad de la organización."
        ],
        "respuestas_correctas": [
            "D",
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "231.- Una empresa tiene una base de datos de Microsoft SQL Server en sus instalaciones que realiza una exportación nocturna de 200 GB a un disco local. La empresa quiere mover las copias de seguridad a un almacenamiento más robusto en la nube, específicamente en Amazon S3. La empresa ha establecido una conexión de AWS Direct Connect de 10 Gbps entre el centro de datos local y AWS. ¿Cuál es la solución que cumple con estos requisitos de la manera MÁS rentable?",
        "opciones": [
            "A. Crear un nuevo bucket en S3. Desplegar una puerta de enlace de archivos de AWS Storage Gateway dentro de la VPC conectada a la conexión Direct Connect. Crear una nueva compartición de archivos SMB. Escribir las exportaciones nocturnas de la base de datos en la nueva compartición de archivos SMB.",
            "B. Crear un sistema de archivos Amazon FSx para Windows File Server de una sola zona de disponibilidad dentro de la VPC que esté conectado a la conexión Direct Connect. Crear una nueva compartición de archivos SMB. Escribir las exportaciones nocturnas de la base de datos en una compartición de archivos SMB en el sistema de archivos Amazon FSx. Habilitar copias de seguridad nocturnas.",
            "C. Crear un sistema de archivos Amazon FSx para Windows File Server de múltiples zonas de disponibilidad dentro de la VPC que esté conectado a la conexión Direct Connect. Crear una nueva compartición de archivos SMB. Escribir las exportaciones nocturnas de la base de datos en una compartición de archivos SMB en el sistema de archivos Amazon FSx. Habilitar copias de seguridad nocturnas.",
            "D. Crear un nuevo bucket en S3. Desplegar una puerta de enlace de volúmenes de AWS Storage Gateway dentro de la VPC que esté conectada a la conexión Direct Connect. Crear una nueva compartición de archivos SMB. Escribir las exportaciones nocturnas de la base de datos en la nueva compartición de archivos SMB en la puerta de enlace de volúmenes, y automatizar las copias de estos datos a un bucket en S3."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "232.- Una empresa necesita establecer una conexión desde su centro de datos local a AWS. La empresa necesita conectar todas sus VPCs ubicadas en diferentes Regiones de AWS con capacidades de enrutamiento transitivo entre las redes VPC. Además, la empresa debe reducir los costos del tráfico de salida de la red, aumentar el rendimiento del ancho de banda y proporcionar una experiencia de red consistente para los usuarios finales. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Crear una conexión de AWS Site-to-Site VPN entre el centro de datos local y una nueva VPC central. Crear conexiones de emparejamiento de VPC que inicien desde la VPC central hacia todas las demás VPCs.",
            "B. Crear una conexión de AWS Direct Connect entre el centro de datos local y AWS. Proveer un VIF de tránsito y conectarlo a una puerta de enlace de Direct Connect. Conectar la puerta de enlace de Direct Connect a todas las demás VPCs utilizando un gateway de tránsito en cada región.",
            "C. Crear una conexión de AWS Site-to-Site VPN entre el centro de datos local y una nueva VPC central. Usar un transit gateway con enrutamiento dinámico. Conectar el transit gateway a todas las demás VPCs.",
            "D. Crear una conexión de AWS Direct Connect entre el centro de datos local y AWS. Establecer una conexión de AWS Site-to-Site VPN entre todas las VPCs de cada región. Crear conexiones de emparejamiento de VPC que inicien desde la VPC central hacia todas las demás VPCs."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "233.- Una empresa está migrando sus cargas de trabajo de desarrollo y producción a una nueva organización en AWS Organizations. La empresa ha creado una cuenta miembro separada para desarrollo y una cuenta miembro separada para producción. La facturación consolidada está vinculada a la cuenta de administración. En la cuenta de administración, un arquitecto de soluciones necesita crear un usuario de IAM que pueda detener o terminar recursos en ambas cuentas miembros. ¿Qué solución cumplirá con este requisito?",
        "opciones": [
            "A. Crear un usuario de IAM y un rol de acceso entre cuentas en la cuenta de administración. Configurar el rol de acceso entre cuentas con acceso de privilegio mínimo a las cuentas miembros.",
            "B. Crear un usuario de IAM en cada cuenta miembro. En la cuenta de administración, crear un rol de acceso entre cuentas que tenga acceso de privilegio mínimo. Conceder acceso a los usuarios de IAM al rol de acceso entre cuentas mediante una política de confianza.",
            "C. Crear un usuario de IAM en la cuenta de administración. En las cuentas miembros, crear un grupo de IAM que tenga acceso de privilegio mínimo. Agregar el usuario de IAM de la cuenta de administración a cada grupo de IAM en las cuentas miembros.",
            "D. Crear un usuario de IAM en la cuenta de administración. En las cuentas miembros, crear roles de acceso entre cuentas que tengan acceso de privilegio mínimo. Conceder al usuario de IAM acceso a los roles mediante una política de confianza."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "234.- Una empresa desea utilizar AWS para recuperación ante desastres para una aplicación en sus servidores locales. La empresa tiene cientos de servidores basados en Windows que ejecutan la aplicación. Todos los servidores montan un recurso compartido común. La empresa tiene un RTO de 15 minutos y un RPO de 5 minutos. La solución debe soportar capacidades de conmutación por error (failover) y reversión (fallback) nativas. ¿Qué solución cumplirá con estos requisitos de manera MÁS rentable?",
        "opciones": [
            "A. Crear un AWS Storage Gateway File Gateway. Programar copias de seguridad diarias de los servidores Windows. Guardar los datos en Amazon S3. Durante un desastre, recuperar los servidores locales desde la copia de seguridad. Durante el retroceso (tailback), ejecutar los servidores locales en instancias de Amazon EC2.",
            "B. Crear un conjunto de plantillas de AWS CloudFormation para crear la infraestructura. Replicar todos los datos en Amazon Elastic File System (Amazon EFS) utilizando AWS DataSync. Durante un desastre, usar AWS CodePipeline para implementar las plantillas y restaurar los servidores locales. Recuperar los datos utilizando DataSync.",
            "C. Crear una tubería de AWS Cloud Development Kit (AWS CDK) para establecer un entorno activo-activo multi-sitio en AWS. Replicar los datos en Amazon S3 utilizando el comando s3 sync. Durante un desastre, cambiar los puntos finales DNS para que apunten a AWS. Recuperar los datos utilizando el comando s3 sync.",
            "D. Usar AWS Elastic Disaster Recovery para replicar los servidores locales. Replicar los datos en un sistema de archivos Amazon FSx for Windows File Server utilizando AWS DataSync. Montar el sistema de archivos en los servidores de AWS. Durante un desastre, conmutar por error los servidores locales a AWS. Recuperar los servidores locales en nuevos o existentes utilizando Elastic Disaster Recovery."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "235.- Una empresa ha construido un cluster de cómputo de alto rendimiento (HPC) en AWS para una carga de trabajo estrechamente acoplada que genera una gran cantidad de archivos compartidos almacenados en Amazon EFS. El cluster funcionaba bien cuando el número de instancias de Amazon EC2 era 100. Sin embargo, cuando la empresa aumentó el tamaño del cluster a 1.000 instancias EC2, el rendimiento general estuvo muy por debajo de las expectativas. ¿Qué conjunto de decisiones de diseño debe tomar un arquitecto de soluciones para lograr el máximo rendimiento del cluster HPC? (Elija tres.)",
        "opciones": [
            "A. Asegurar que el cluster HPC se lance dentro de una única Zona de Disponibilidad.",
            "B. Lanzar las instancias EC2 y adjuntar interfaces de red elásticas en múltiplos de cuatro.",
            "C. Seleccionar tipos de instancias EC2 con un Elastic Fabric Adapter (EFA) habilitado.",
            "D. Asegurar que el cluster se lance en múltiples Zonas de Disponibilidad.",
            "E. Reemplazar Amazon EFS con múltiples volúmenes de Amazon EBS en una matriz RAID.",
            "F. Reemplazar Amazon EFS con Amazon FSx para Lustre."
        ],
        "respuestas_correctas": [
            "C",
            "F",
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "236.- Una empresa está diseñando una estructura de AWS Organizations. La empresa desea estandarizar un proceso para aplicar etiquetas en toda la organización. La empresa requerirá etiquetas con valores específicos cuando un usuario cree un nuevo recurso. Cada una de las UO de la empresa tendrá valores de etiqueta únicos. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Utiliza una SCP para denegar la creación de recursos que no tengan las etiquetas requeridas. Crea una política de etiquetas que incluya los valores de las etiquetas que la empresa ha asignado a cada UO. Adjunta las políticas de etiquetas a las UO.",
            "B. Utiliza una SCP para denegar la creación de recursos que no tengan las etiquetas requeridas. Crea una política de etiquetas que incluya los valores de las etiquetas que la empresa ha asignado a cada UO. Adjunta las políticas de etiquetas a la cuenta de administración de la organización.",
            "C. Utiliza una SCP para permitir la creación de recursos solo cuando los recursos tengan las etiquetas requeridas. Crea una política de etiquetas que incluya los valores de las etiquetas que la empresa ha asignado a cada UO. Adjunta las políticas de etiquetas a las UO.",
            "D. Utiliza una SCP para denegar la creación de recursos que no tengan las etiquetas requeridas. Define la lista de etiquetas. Adjunta la SCP a las UO."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "237.- Una empresa tiene más de 10,000 sensores que envían datos a un servidor de Apache Kafka local utilizando el protocolo MQTT (Message Queuing Telemetry Transport). El servidor Kafka local transforma los datos y luego almacena los resultados como objetos en un bucket de Amazon S3. Recientemente, el servidor Kafka falló. La empresa perdió datos de los sensores mientras el servidor se restauraba. Un arquitecto de soluciones debe crear un nuevo diseño en AWS que sea altamente disponible y escalable para evitar que vuelva a ocurrir algo similar. ¿Qué solución cumple con estos requisitos?",
        "opciones": [
            "A. Lanzar dos instancias de Amazon EC2 para alojar el servidor Kafka en una configuración activo/standby a través de dos Zonas de Disponibilidad. Crear un nombre de dominio en Amazon Route 53. Crear una política de failover de Route 53. Enviar los datos de los sensores al nombre de dominio.",
            "B. Migrar el servidor Kafka local a Amazon Managed Streaming for Apache Kafka (Amazon MSK). Crear un Network Load Balancer (NLB) que apunte al broker de Amazon MSK. Habilitar las verificaciones de salud del NLB. Enviar los datos de los sensores al NLB.",
            "C. Implementar AWS IoT Core, y conectarlo a un stream de entrega de Amazon Kinesis Data Firehose. Usar una función de AWS Lambda para manejar la transformación de los datos. Enviar los datos de los sensores a AWS IoT Core.",
            "D. Implementar AWS IoT Core, y lanzar una instancia de Amazon EC2 para alojar el servidor Kafka. Configurar AWS IoT Core para enviar los datos a la instancia EC2. Enviar los datos de los sensores a AWS IoT Core."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "238.- Una empresa comenzó recientemente a alojar nuevas cargas de trabajo de aplicaciones en la nube de AWS. La empresa está utilizando instancias de Amazon EC2, sistemas de archivos de Amazon Elastic File System (Amazon EFS) e instancias de base de datos Amazon RDS. Para cumplir con los requisitos regulatorios y comerciales, la empresa debe realizar los siguientes cambios en las copias de seguridad de los datos: • Las copias de seguridad deben conservarse según los requisitos personalizados diarios, semanales y mensuales. • Las copias de seguridad deben replicarse a al menos otra región de AWS inmediatamente después de su captura. • La solución de copias de seguridad debe proporcionar una única fuente de estado de copias de seguridad en el entorno de AWS. • La solución de copias de seguridad debe enviar notificaciones inmediatas en caso de que falle alguna copia de seguridad de recurso. ¿Qué combinación de pasos cumplirá con estos requisitos con menor esfuerzo operativo? (Elija tres.)",
        "opciones": [
            "A. Crear un plan de AWS Backup con una regla de copia de seguridad para cada uno de los requisitos de retención.",
            "B. Configurar un plan de AWS Backup para copiar las copias de seguridad a otra región.",
            "C. Crear una función de AWS Lambda para replicar las copias de seguridad a otra región y enviar una notificación si ocurre un fallo.",
            "D. Añadir un tema de Amazon Simple Notification Service (Amazon SNS) al plan de copias de seguridad para enviar una notificación de trabajos finalizados que tengan cualquier estado excepto BACKUP_JOB_COMPLETED.",
            "E. Crear una política de ciclo de vida de instantáneas de Amazon Data Lifecycle Manager (Amazon DLM) para cada uno de los requisitos de retención.",
            "F. Configurar instantáneas de RDS en cada base de datos."
        ],
        "respuestas_correctas": [
            "B",
            "D",
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "239.- Una empresa está desarrollando un dispositivo de informes genéticos que recolectará información genómica para ayudar a los investigadores a recolectar grandes muestras de datos de una población diversa. El dispositivo enviará 8 KB de datos genómicos cada segundo a una plataforma de datos que deberá procesar y analizar los datos y proporcionar información de vuelta a los investigadores. La plataforma de datos debe cumplir con los siguientes requisitos: • Proporcionar análisis casi en tiempo real de los datos genómicos entrantes\n• Asegurar que los datos sean flexibles, paralelos y duraderos\n• Entregar los resultados del procesamiento a un almacén de datos ¿Qué estrategia debe usar un arquitecto de soluciones para cumplir con estos requisitos?",
        "opciones": [
            "A. Usar Amazon Kinesis Data Firehose para recolectar los datos del sensor entrantes, analizar los datos con clientes de Kinesis y guardar los resultados en una instancia de Amazon RDS.",
            "B. Usar Amazon Kinesis Data Streams para recolectar los datos del sensor entrantes, analizar los datos con clientes de Kinesis y guardar los resultados en un clúster de Amazon Redshift usando Amazon EMR.",
            "C. Usar Amazon S3 para recolectar los datos del dispositivo entrantes, analizar los datos desde Amazon SQS con Kinesis y guardar los resultados en un clúster de Amazon Redshift.",
            "D. Usar Amazon API Gateway para poner solicitudes en una cola Amazon SQS, analizar los datos con una función de AWS Lambda y guardar los resultados en un clúster de Amazon Redshift usando Amazon EMR."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "240.- Un arquitecto de soluciones necesita definir una arquitectura de referencia para una solución de aplicaciones de tres capas con capas de web, aplicación y datos NoSQL. La arquitectura de referencia debe cumplir con los siguientes requisitos: • Alta disponibilidad dentro de una región de AWS\n• Capacidad para conmutar por error en 1 minuto a otra región de AWS para recuperación ante desastres\n• Proveer la solución más eficiente mientras se minimiza el impacto en la experiencia del usuario ¿Qué combinación de pasos cumplirá con estos requisitos? (Elija tres opciones).",
        "opciones": [
            "A. Usar una política de enrutamiento ponderado de Amazon Route 53 configurada en 100/0 entre las dos regiones seleccionadas. Configurar el Tiempo de Vida (TTL) a 1 hora.",
            "B. Usar una política de enrutamiento de conmutación por error de Amazon Route 53 para la conmutación por error desde la región primaria a la región de recuperación ante desastres. Configurar el Tiempo de Vida (TTL) a 30 segundos.",
            "C. Usar una tabla global dentro de Amazon DynamoDB para que los datos puedan ser accesibles en las dos regiones seleccionadas.",
            "D. Realizar copias de seguridad de los datos de una tabla de Amazon DynamoDB en la región primaria cada 60 minutos y luego escribir los datos en Amazon S3. Usar la replicación cruzada de S3 para copiar los datos de la región primaria a la región de recuperación ante desastres. Tener un script que importe los datos a DynamoDB en un escenario de recuperación ante desastres.",
            "E. Implementar un modelo de reserva activa utilizando grupos de Auto Scaling para las capas web y de aplicación a través de múltiples Zonas de Disponibilidad en las regiones. Usar Instancias Reservadas zonales para el número mínimo de servidores e Instancias On-Demand para cualquier recurso adicional.",
            "F. Usar grupos de Auto Scaling para las capas web y de aplicación a través de múltiples Zonas de Disponibilidad en las regiones. Usar Instancias Spot para los recursos necesarios."
        ],
        "respuestas_correctas": [
            "C",
            "E",
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "241.- Una empresa fabrica vehículos inteligentes. La empresa utiliza una aplicación personalizada para recopilar datos de los vehículos. Los vehículos usan el protocolo MQTT para conectarse a la aplicación. La empresa procesa los datos en intervalos de 5 minutos. Luego, la empresa copia los datos de telemetría de los vehículos a almacenamiento local. Aplicaciones personalizadas analizan estos datos para detectar anomalías. El número de vehículos que envían datos crece constantemente. Los vehículos más nuevos generan grandes volúmenes de datos. La solución de almacenamiento local no puede escalar para el tráfico máximo, lo que provoca pérdida de datos. La empresa debe modernizar la solución y migrarla a AWS para resolver los desafíos de escalabilidad. ¿Qué solución cumplirá con estos requisitos con el MENOR esfuerzo operativo?",
        "opciones": [
            "A. Usar AWS IoT Greengrass para enviar los datos de los vehículos a Amazon Managed Streaming for Apache Kafka (Amazon MSK). Crear una aplicación de Apache Kafka para almacenar los datos en Amazon S3. Usar un modelo preentrenado en Amazon SageMaker para detectar anomalías.",
            "B. Usar AWS IoT Core para recibir los datos de los vehículos. Configurar reglas para enrutar los datos a un Amazon Kinesis Data Firehose delivery stream que almacene los datos en Amazon S3. Crear una aplicación de Amazon Kinesis Data Analytics que lea desde el delivery stream para detectar anomalías.",
            "C. Usar AWS IoT FleetWise para recopilar los datos de los vehículos. Enviar los datos a un stream de datos de Amazon Kinesis. Usar un Amazon Kinesis Data Firehose delivery stream para almacenar los datos en Amazon S3. Usar las transformaciones de aprendizaje automático integradas en AWS Glue para detectar anomalías.",
            "D. Usar Amazon MQ para RabbitMQ para recopilar los datos de los vehículos. Enviar los datos a un Amazon Kinesis Data Firehose delivery stream para almacenar los datos en Amazon S3. Usar Amazon Lookout for Metrics para detectar anomalías."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "242.- Durante una auditoría, un equipo de seguridad descubrió que un equipo de desarrollo estaba poniendo claves secretas de acceso de usuario IAM en su código y luego las estaba enviando a un repositorio de AWS CodeCommit. El equipo de seguridad quiere encontrar y remediar automáticamente las instancias de esta vulnerabilidad de seguridad. ¿Qué solución garantizará que las credenciales estén adecuadamente aseguradas automáticamente?",
        "opciones": [
            "A. Ejecutar un script nocturno usando AWS Systems Manager Run Command para buscar credenciales en las instancias de desarrollo. Si se encuentran, usar AWS Secrets Manager para rotar las credenciales.",
            "B. Usar una función programada de AWS Lambda para descargar y escanear el código de la aplicación desde CodeCommit. Si se encuentran credenciales, generar nuevas credenciales y almacenarlas en AWS KMS.",
            "C. Configurar Amazon Macie para escanear las credenciales en los repositorios de CodeCommit. Si se encuentran credenciales, activar una función de AWS Lambda para deshabilitar las credenciales y notificar al usuario.",
            "D. Configurar un disparador de CodeCommit para invocar una función de AWS Lambda que escanee los nuevos envíos de código en busca de credenciales. Si se encuentran credenciales, deshabilitarlas en AWS IAM y notificar al usuario."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "243.- Una empresa tiene un data lake en Amazon S3 que debe ser accesado por cientos de aplicaciones en múltiples cuentas de AWS. La política de seguridad de la información de la empresa establece que el bucket de S3 no debe ser accesado a través de internet público y que cada aplicación debe tener los permisos mínimos necesarios para funcionar. Para cumplir con estos requisitos, un arquitecto de soluciones planea usar un punto de acceso de S3 que esté restringido a VPCs específicas para cada aplicación. ¿Qué combinación de pasos debe seguir el arquitecto de soluciones para implementar esta solución? (Elija dos.)",
        "opciones": [
            "A. Crear un punto de acceso de S3 para cada aplicación en la cuenta de AWS que posee el bucket de S3. Configurar cada punto de acceso para que sea accesible solo desde la VPC de la aplicación. Actualizar la política del bucket para requerir acceso desde un punto de acceso.",
            "B. Crear un punto de enlace de interfaz para Amazon S3 en la VPC de cada aplicación. Configurar la política del punto de enlace para permitir acceso a un punto de acceso de S3. Crear un adjunto de puerta de enlace de VPC para el punto de enlace de S3.",
            "C. Crear un punto de enlace de puerta de enlace para Amazon S3 en la VPC de cada aplicación. Configurar la política del punto de enlace para permitir acceso a un punto de acceso de S3. Especificar la tabla de rutas que se usa para acceder al punto de acceso.",
            "D. Crear un punto de acceso de S3 para cada aplicación en cada cuenta de AWS y adjuntar los puntos de acceso al bucket de S3. Configurar cada punto de acceso para que sea accesible solo desde la VPC de la aplicación. Actualizar la política del bucket para requerir acceso desde un punto de acceso.",
            "E. Crear un punto de enlace de puerta de enlace para Amazon S3 en la VPC del data lake. Adjuntar una política de punto de enlace para permitir acceso al bucket de S3. Especificar la tabla de rutas que se usa para acceder al bucket."
        ],
        "respuestas_correctas": [
            "C",
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "244.- Una empresa ha desarrollado una solución híbrida entre su centro de datos y AWS. La empresa utiliza Amazon VPC y Amazon EC2 que envían los registros de aplicaciones a Amazon CloudWatch. Las instancias EC2 leen datos de múltiples bases de datos relacionales alojadas en sus instalaciones. La empresa quiere monitorear qué instancias EC2 están conectadas a las bases de datos en tiempo casi real. La empresa ya tiene una solución de monitoreo que utiliza Splunk en sus instalaciones. Un arquitecto de soluciones necesita determinar cómo enviar el tráfico de red a Splunk. ¿Cómo debería el arquitecto de soluciones cumplir con estos requisitos?",
        "opciones": [
            "A. Habilitar los registros de flujos de VPC y enviarlos a CloudWatch. Crear una función de AWS Lambda para exportar periódicamente los registros de CloudWatch a un bucket de Amazon S3 utilizando la función de exportación predefinida. Generar las credenciales de AWS ACCESS_KEY y SECRET_KEY. Configurar Splunk para extraer los registros desde el bucket de S3 usando esas credenciales.",
            "B. Crear un flujo de entrega de Amazon Kinesis Data Firehose con Splunk como destino. Configurar una función de AWS Lambda para procesamiento previo con un procesador de flujo de Kinesis Data Firehose que extraiga eventos de registros individuales de los registros enviados por los filtros de suscripción de CloudWatch Logs. Habilitar los registros de flujos de VPC y enviarlos a CloudWatch. Crear una suscripción de CloudWatch Logs que envíe eventos de registros al flujo de entrega de Kinesis Data Firehose.",
            "C. Pedir a la empresa que registre cada solicitud que se haga a las bases de datos junto con la dirección IP de la instancia EC2. Exportar los registros de CloudWatch a un bucket de Amazon S3. Usar Amazon Athena para consultar los registros agrupados por nombre de base de datos. Exportar los resultados de Athena a otro bucket de S3. Invocar una función de AWS Lambda para enviar automáticamente cualquier archivo nuevo que se ponga en el bucket de S3 a Splunk.",
            "D. Enviar los registros de CloudWatch a un flujo de datos de Amazon Kinesis con Amazon Kinesis Data Analytics for SQL Applications. Configurar una ventana deslizante de 1 minuto para recopilar los eventos. Crear una consulta SQL que utilice la plantilla de detección de anomalías para monitorear cualquier anomalía en el tráfico de red en tiempo casi real. Enviar el resultado a un flujo de entrega de Amazon Kinesis Data Firehose con Splunk como destino."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "245.- Una empresa tiene cinco equipos de desarrollo que han creado cinco cuentas de AWS cada una para desarrollar y alojar aplicaciones. Para realizar un seguimiento del gasto, los equipos de desarrollo inician sesión en cada cuenta cada mes, registran el costo actual desde la consola de AWS Billing and Cost Management y proporcionan la información al equipo de finanzas de la empresa. La empresa tiene requisitos estrictos de cumplimiento y necesita garantizar que los recursos se creen solo en las Regiones de AWS en los Estados Unidos. Sin embargo, algunos recursos se han creado en otras regiones. Un arquitecto de soluciones necesita implementar una solución que brinde al equipo de finanzas la capacidad de realizar un seguimiento y consolidar los gastos de todas las cuentas. La solución también debe garantizar que la empresa solo pueda crear recursos en las regiones de los Estados Unidos. ¿Cuál combinación de pasos cumplirá estos requisitos de la manera más eficiente en términos operativos? (Elija tres.)",
        "opciones": [
            "A. Crear una nueva cuenta que sirva como cuenta de administración. Crear un bucket de Amazon S3 para el equipo de finanzas. Utilizar los informes de AWS Cost and Usage para crear informes mensuales y almacenar los datos en el bucket S3 del equipo de finanzas.",
            "B. Crear una nueva cuenta que sirva como cuenta de administración. Desplegar una organización en AWS Organizations con todas las funciones habilitadas. Invitar a todas las cuentas existentes a la organización. Asegurarse de que cada cuenta acepte la invitación.",
            "C. Crear una UO que incluya a todos los equipos de desarrollo. Crear una SCP que permita la creación de recursos solo en las regiones que están en los Estados Unidos. Aplicar la SCP a la UO.",
            "D. Crear una UO que incluya a todos los equipos de desarrollo. Crear una SCP que deniegue la creación de recursos en regiones fuera de los Estados Unidos. Aplicar la SCP a la UO.",
            "E. Crear un rol IAM en la cuenta de administración. Adjuntar una política que incluya permisos para ver la consola de Billing and Cost Management. Permitir que los usuarios del equipo de finanzas asuman el rol. Utilizar AWS Cost Explorer y la consola de Billing and Cost Management para analizar los costos.",
            "F. Crear un rol IAM en cada cuenta de AWS. Adjuntar una política que incluya permisos para ver la consola de Billing and Cost Management. Permitir que los usuarios del equipo de finanzas asuman el rol."
        ],
        "respuestas_correctas": [
            "E",
            "D",
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "246.- Una empresa necesita crear y gestionar múltiples cuentas de AWS para varios departamentos desde una ubicación central. El equipo de seguridad requiere acceso de solo lectura a todas las cuentas desde su propia cuenta de AWS. La empresa está utilizando AWS Organizations y ha creado una cuenta para el equipo de seguridad. ¿Cómo debe un arquitecto de soluciones cumplir con estos requisitos?",
        "opciones": [
            "A. Usar el rol OrganizationAccountAccessRole de IAM para crear una nueva política de IAM con acceso de solo lectura en cada cuenta miembro. Establecer una relación de confianza entre la política de IAM en cada cuenta miembro y la cuenta de seguridad. Pedir al equipo de seguridad que use la política de IAM para obtener acceso.",
            "B. Usar el rol OrganizationAccountAccessRole de IAM para crear un nuevo rol de IAM con acceso de solo lectura en cada cuenta miembro. Establecer una relación de confianza entre el rol de IAM en cada cuenta miembro y la cuenta de seguridad. Pedir al equipo de seguridad que use el rol de IAM para obtener acceso.",
            "C. Pedir al equipo de seguridad que use AWS Security Token Service (AWS STS) para llamar a la API AssumeRole para el rol OrganizationAccountAccessRole de IAM en la cuenta de administración desde la cuenta de seguridad. Usar las credenciales temporales generadas para obtener acceso.",
            "D. Pedir al equipo de seguridad que use AWS Security Token Service (AWS STS) para llamar a la API AssumeRole para el rol OrganizationAccountAccessRole de IAM en la cuenta miembro desde la cuenta de seguridad. Usar las credenciales temporales generadas para obtener acceso"
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "247.- Una gran empresa ejecuta cargas de trabajo en VPCs que están desplegadas a través de cientos de cuentas de AWS. Cada VPC consta de subredes públicas y subredes privadas que se extienden por varias zonas de disponibilidad. Se han desplegado gateways NAT en las subredes públicas, los cuales permiten la conectividad de salida a internet desde las subredes privadas. Un arquitecto de soluciones está trabajando en un diseño de hub-and-spoke. Todas las subredes privadas en las VPCs spoke deben enrutar el tráfico a internet a través de una VPC de salida (egress VPC). El arquitecto de soluciones ya ha desplegado un gateway NAT en una VPC de salida en una cuenta central de AWS. ¿Qué conjunto de pasos adicionales debe tomar el arquitecto de soluciones para cumplir con estos requisitos?",
        "opciones": [
            "A. Crear conexiones de peering entre la VPC de salida y las VPCs spoke. Configurar el enrutamiento requerido para permitir el acceso a internet.",
            "B. Crear un gateway de tránsito (transit gateway), y compartirlo con las cuentas de AWS existentes. Adjuntar las VPCs existentes al gateway de tránsito. Configurar el enrutamiento requerido para permitir el acceso a internet.",
            "C. Crear un gateway de tránsito en cada cuenta. Adjuntar el gateway NAT a los gateways de tránsito. Configurar el enrutamiento requerido para permitir el acceso a internet.",
            "D. Crear una conexión de AWS PrivateLink entre la VPC de salida y las VPCs spoke. Configurar el enrutamiento requerido para permitir el acceso a internet."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "248.- Una empresa educativa está ejecutando una aplicación web utilizada por estudiantes universitarios de todo el mundo. La aplicación se ejecuta en un clúster de Amazon Elastic Container Service (Amazon ECS) en un grupo de Auto Scaling detrás de un Balanceador de Carga de Aplicaciones (ALB). Un administrador de sistemas detecta un pico semanal en la cantidad de intentos de inicio de sesión fallidos, lo que abruma el servicio de autenticación de la aplicación. Todos los intentos de inicio de sesión fallidos se originan en aproximadamente 500 direcciones IP diferentes que cambian cada semana. Un arquitecto de soluciones debe evitar que los intentos de inicio de sesión fallidos abrumen el servicio de autenticación. ¿Qué solución cumple con estos requisitos con la MAYOR eficiencia operativa?",
        "opciones": [
            "A. Usar AWS Firewall Manager para crear un grupo de seguridad y una política de grupo de seguridad para denegar el acceso desde las direcciones IP.",
            "B. Crear una ACL web de AWS WAF con una regla basada en la tasa y configurar la acción de la regla como Bloquear. Conectar la ACL web al ALB.",
            "C. Usar AWS Firewall Manager para crear un grupo de seguridad y una política de grupo de seguridad para permitir el acceso solo a rangos CIDR específicos.",
            "D. Crear una ACL web de AWS WAF con una regla de coincidencia de conjunto de IP y configurar la acción de la regla como Bloquear. Conectar la ACL web al ALB."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "249.- Una empresa opera una solución de software como servicio (SaaS) en sus instalaciones que ingiere varios archivos a diario. La empresa proporciona múltiples puntos finales públicos de SFTP a sus clientes para facilitar las transferencias de archivos. Los clientes agregan las direcciones IP de los puntos finales SFTP a su lista blanca de firewalls para el tráfico saliente. No se permiten cambios en las direcciones IP de los puntos finales SFTP. La empresa desea migrar la solución SaaS a AWS y reducir la sobrecarga operativa del servicio de transferencia de archivos. ¿Cuál de las siguientes soluciones cumple con estos requisitos?",
        "opciones": [
            "A. Registrar el bloque de direcciones IP propiedad del cliente en la cuenta de AWS de la empresa. Crear direcciones IP elásticas desde el grupo de direcciones y asignarlas a un punto final de AWS Transfer for SFTP. Usar AWS Transfer para almacenar los archivos en Amazon S3.",
            "B. Agregar una subred que contenga el bloque de direcciones IP propiedad del cliente a una VPC. Crear direcciones IP elásticas desde el grupo de direcciones y asignarlas a un Application Load Balancer (ALB). Lanzar instancias EC2 que hospeden servicios FTP en un grupo de Auto Scaling detrás del ALB y almacenar los archivos en volúmenes adjuntos de Amazon Elastic Block Store (Amazon EBS).",
            "C. Registrar el bloque de direcciones IP propiedad del cliente en Amazon Route 53. Crear registros alias en Route 53 que apunten a un Network Load Balancer (NLB). Lanzar instancias EC2 que hospeden servicios FTP en un grupo de Auto Scaling detrás del NLB. Almacenar los archivos en Amazon S3.",
            "D. Registrar el bloque de direcciones IP propiedad del cliente en la cuenta de AWS de la empresa. Crear direcciones IP elásticas desde el grupo de direcciones y asignarlas a un punto final de VPC de Amazon S3. Activar el soporte de SFTP en el bucket de S3."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "250.- Una empresa tiene una nueva aplicación que necesita ejecutarse en cinco instancias de Amazon EC2 en una sola región de AWS. La aplicación requiere conexiones de red de alto rendimiento y baja latencia entre todas las instancias de EC2 donde se ejecutará la aplicación. No hay un requisito para que la aplicación sea tolerante a fallos. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Lanzar cinco nuevas instancias de EC2 en un grupo de colocación en clúster. Asegurarse de que el tipo de instancia de EC2 sea compatible con redes mejoradas.",
            "B. Lanzar cinco nuevas instancias de EC2 en un grupo de Auto Scaling en la misma zona de disponibilidad. Adjuntar una interfaz de red elástica adicional a cada instancia de EC2.",
            "C. Lanzar cinco nuevas instancias de EC2 en un grupo de colocación por partición. Asegurarse de que el tipo de instancia de EC2 sea compatible con redes mejoradas.",
            "D. Lanzar cinco nuevas instancias de EC2 en un grupo de colocación distribuida. Adjuntar una interfaz de red elástica adicional a cada instancia de EC2."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "251.- Una empresa está creando una API REST para compartir información con seis de sus socios ubicados en los Estados Unidos. La empresa ha creado un endpoint regional de Amazon API Gateway. Cada uno de los seis socios accederá a la API una vez por día para publicar las cifras diarias de ventas. Después del despliegue inicial, la empresa observa 1,000 solicitudes por segundo originadas desde 500 direcciones IP diferentes en todo el mundo. La empresa cree que este tráfico proviene de una botnet y desea asegurar su API mientras minimiza los costos. ¿Qué enfoque debe seguir la empresa para asegurar su API?",
        "opciones": [
            "A. Crear una distribución de Amazon CloudFront con la API como origen. Crear un AWS WAF web ACL con una regla para bloquear a los clientes que envíen más de cinco solicitudes por día. Asociar el web ACL con la distribución de CloudFront. Configurar CloudFront con una identidad de acceso de origen (OAI) y asociarla con la distribución. Configurar API Gateway para garantizar que solo el OAI pueda ejecutar el método POST.",
            "B. Crear una distribución de Amazon CloudFront con la API como origen. Crear un AWS WAF web ACL con una regla para bloquear a los clientes que envíen más de cinco solicitudes por día. Asociar el web ACL con la distribución de CloudFront. Agregar un encabezado personalizado a la distribución de CloudFront que se llene con una clave de API. Configurar la API para requerir una clave de API en el método POST.",
            "C. Crear un AWS WAF web ACL con una regla para permitir el acceso a las direcciones IP usadas por los seis socios. Asociar el web ACL con la API. Crear una política de recursos con un límite de solicitudes y asociarla con la API. Configurar la API para requerir una clave de API en el método POST.",
            "D. Crear un AWS WAF web ACL con una regla para permitir el acceso a las direcciones IP usadas por los seis socios. Asociar el web ACL con la API. Crear un plan de uso con un límite de solicitudes y asociarlo con la API. Crear una clave de API y agregarla al plan de uso."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "252.- Una empresa utiliza un clúster de base de datos Amazon Aurora PostgreSQL para aplicaciones en una sola región de AWS. El equipo de bases de datos de la empresa debe monitorear toda la actividad de datos en todas las bases de datos. ¿Qué solución logrará este objetivo?",
        "opciones": [
            "A. Configurar una tarea de AWS Database Migration Service (AWS DMS) con captura de datos de cambios (CDC). Especificar el clúster de Aurora DB como fuente. Especificar Amazon Kinesis Data Firehose como destino. Usar Kinesis Data Firehose para cargar los datos en un clúster de Amazon OpenSearch Service para su posterior análisis.",
            "B. Iniciar un flujo de actividad de base de datos en el clúster de Aurora DB para capturar el flujo de actividad en Amazon EventBridge. Definir una función de AWS Lambda como destino para EventBridge. Programar la función Lambda para descifrar los mensajes de EventBridge y publicar toda la actividad de la base de datos en Amazon S3 para su posterior análisis.",
            "C. Iniciar un flujo de actividad de base de datos en el clúster de Aurora DB para enviar el flujo de actividad a un stream de datos de Amazon Kinesis. Configurar Amazon Kinesis Data Firehose para consumir el stream de datos de Kinesis y entregar los datos en Amazon S3 para su posterior análisis.",
            "D. Configurar una tarea de AWS Database Migration Service (AWS DMS) con captura de datos de cambios (CDC). Especificar el clúster de Aurora DB como fuente. Especificar Amazon Kinesis Data Firehose como destino. Usar Kinesis Data Firehose para cargar los datos en un clúster de Amazon Redshift. Ejecutar consultas sobre los datos de Amazon Redshift para determinar las actividades de la base de datos en la base de datos Aurora."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "253.- Una empresa de entretenimiento lanzó recientemente un nuevo juego. Para asegurar una buena experiencia para los jugadores durante el período de lanzamiento, la empresa desplegó una cantidad estática de 12 instancias r6g.16xlarge (optimizada para memoria) de Amazon EC2 detrás de un Network Load Balancer. El equipo de operaciones de la empresa usó el agente de Amazon CloudWatch y una métrica personalizada para incluir la utilización de memoria en su estrategia de monitoreo. El análisis de las métricas de CloudWatch del período de lanzamiento mostró un consumo de aproximadamente una cuarta parte de la CPU y memoria de lo que la empresa esperaba. La demanda inicial del juego ha disminuido y se ha vuelto más variable. La empresa decide usar un grupo de Auto Scaling que monitoree el consumo de CPU y memoria para escalar dinámicamente la flota de instancias. Un arquitecto de soluciones debe configurar el grupo de Auto Scaling para satisfacer la demanda de manera más rentable. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Configurar el grupo de Auto Scaling para desplegar instancias c6g.4xlarge (optimizadas para cómputo). Configurar una capacidad mínima de 3, una capacidad deseada de 3 y una capacidad máxima de 12.",
            "B. Configurar el grupo de Auto Scaling para desplegar instancias m6g.4xlarge (de propósito general). Configurar una capacidad mínima de 3, una capacidad deseada de 3 y una capacidad máxima de 12.",
            "C. Configurar el grupo de Auto Scaling para desplegar instancias r6g.4xlarge (optimizadas para memoria). Configurar una capacidad mínima de 3, una capacidad deseada de 3 y una capacidad máxima de 12.",
            "D. Configurar el grupo de Auto Scaling para desplegar instancias r6g.8xlarge (optimizadas para memoria). Configurar una capacidad mínima de 2, una capacidad deseada de 2 y una capacidad máxima de 6."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "254.- Una empresa de servicios financieros cargó millones de transacciones históricas de acciones en una tabla de Amazon DynamoDB. La tabla utiliza el modo de capacidad bajo demanda. Todos los días a la medianoche, se cargan unos pocos millones de nuevos registros en la tabla. La actividad de lectura de la aplicación contra la tabla ocurre en ráfagas a lo largo del día, y un conjunto limitado de claves se consulta repetidamente. La empresa necesita reducir los costos asociados con DynamoDB. ¿Qué estrategia debería recomendar un arquitecto de soluciones para cumplir con este requisito?",
        "opciones": [
            "A. Implementar un clúster de Amazon ElastiCache delante de la tabla de DynamoDB.",
            "B. Implementar DynamoDB Accelerator (DAX). Configurar el escalado automático de DynamoDB. Comprar Savings Plans en Cost Explorer.",
            "C. Usar modo de capacidad provisionada. Comprar Savings Plans en Cost Explorer.",
            "D. Implementar DynamoDB Accelerator (DAX). Usar modo de capacidad provisionada. Configurar el escalado automático de DynamoDB."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "255.- Una empresa está creando un servicio de registro centralizado que se ejecuta en Amazon EC2 y recibirá y analizará registros de cientos de cuentas de AWS. Se está utilizando AWS PrivateLink para proporcionar conectividad entre los servicios del cliente y el servicio de registros. En cada cuenta de AWS con un cliente, se ha creado un punto final de interfaz para el servicio de registros y está disponible. El servicio de registros, que se ejecuta en instancias EC2 con un Network Load Balancer (NLB), está desplegado en diferentes subredes. Los clientes no pueden enviar registros utilizando el punto final VPC. ¿Qué combinación de pasos debe tomar un arquitecto de soluciones para resolver este problema? (Elija dos.)",
        "opciones": [
            "A. Verificar que el NACL esté adjunto a la subred del servicio de registros para permitir las comunicaciones hacia y desde las subredes del NLB. Verificar que el NACL esté adjunto a la subred del NLB para permitir las comunicaciones hacia y desde las subredes del servicio de registros que se ejecutan en instancias EC2.",
            "B. Verificar que el NACL esté adjunto a las subredes del servicio de registros para permitir las comunicaciones hacia y desde las subredes del punto final de interfaz. Verificar que el NACL esté adjunto a la subred del punto final de interfaz para permitir las comunicaciones hacia y desde las subredes del servicio de registros que se ejecutan en instancias EC2.",
            "C. Verificar el grupo de seguridad del servicio de registros que se ejecuta en las instancias EC2 para asegurarse de que permita el ingreso desde las subredes del NLB.",
            "D. Verificar el grupo de seguridad del servicio de registros que se ejecuta en las instancias EC2 para asegurarse de que permita el ingreso desde los clientes.",
            "E. Verificar el grupo de seguridad del NLB para asegurarse de que permita el ingreso desde las subredes del punto final de interfaz."
        ],
        "respuestas_correctas": [
            "B",
            "E"
        ],
        "imagenes": []
    },
    {
        "pregunta": "256.- Una empresa tiene millones de objetos en un bucket de Amazon S3. Los objetos están en la clase de almacenamiento S3 Standard. Todos los objetos de S3 se acceden con frecuencia. El número de usuarios y aplicaciones que acceden a los objetos está aumentando rápidamente. Los objetos están cifrados con cifrado del lado del servidor utilizando claves de AWS KMS (SSE-KMS). Un arquitecto de soluciones revisa la factura mensual de AWS de la empresa y nota que los costos de AWS KMS están aumentando debido al alto número de solicitudes provenientes de Amazon S3. El arquitecto de soluciones necesita optimizar los costos con cambios mínimos en la aplicación. ¿Qué solución cumplirá con estos requisitos con la MENOR sobrecarga operativa?",
        "opciones": [
            "A. Crear un nuevo bucket de S3 que tenga cifrado del lado del servidor con claves proporcionadas por el cliente (SSE-C) como tipo de cifrado. Copiar los objetos existentes al nuevo bucket de S3. Especificar SSE-C.",
            "B. Crear un nuevo bucket de S3 que tenga cifrado del lado del servidor con claves administradas por Amazon S3 (SSE-S3) como tipo de cifrado. Usar S3 Batch Operations para copiar los objetos existentes al nuevo bucket de S3. Especificar SSE-S3.",
            "C. Usar AWS CloudHSM para almacenar las claves de cifrado. Crear un nuevo bucket de S3. Usar S3 Batch Operations para copiar los objetos existentes al nuevo bucket de S3. Cifrar los objetos utilizando las claves de CloudHSM.",
            "D. Usar la clase de almacenamiento S3 Intelligent-Tiering para el bucket de S3. Crear una configuración de archivo S3 Intelligent-Tiering para transferir los objetos que no se accedan durante 90 días a S3 Glacier Deep Archive."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "257.- Una aplicación de almacenamiento de medios carga fotos de usuarios a Amazon S3 para su procesamiento por funciones de AWS Lambda. El estado de la aplicación se almacena en tablas de Amazon DynamoDB. Los usuarios informan que algunas fotos cargadas no se procesan correctamente. Los desarrolladores de la aplicación rastrean los registros y descubren que Lambda está experimentando problemas de procesamiento de fotos cuando miles de usuarios cargan fotos simultáneamente. Los problemas son el resultado de los límites de concurrencia de Lambda y el rendimiento de DynamoDB cuando se guardan los datos. ¿Qué combinación de acciones debe tomar un arquitecto de soluciones para aumentar el rendimiento y la confiabilidad de la aplicación? (Elija dos).",
        "opciones": [
            "A. Evaluar y ajustar las RCU para las tablas de DynamoDB.",
            "B. Evaluar y ajustar las WCU para las tablas de DynamoDB.",
            "C. Agregar una capa de Amazon ElastiCache para aumentar el rendimiento de las funciones de Lambda.",
            "D. Agregar una cola de Amazon Simple Queue Service (Amazon SQS) y lógica de reprocesamiento entre Amazon S3 y las funciones de Lambda.",
            "E. Usar S3 Transfer Acceleration para proporcionar una menor latencia a los usuarios."
        ],
        "respuestas_correctas": [
            "D",
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "258.- Una empresa ejecuta una aplicación en un centro de datos local. La aplicación permite a los usuarios cargar archivos multimedia. Los archivos se almacenan en un servidor de archivos. La aplicación web tiene muchos usuarios. El servidor de aplicaciones está sobreutilizado, lo que provoca que las cargas de datos fallen ocasionalmente. La empresa agrega frecuentemente nuevo almacenamiento al servidor de archivos. La empresa desea resolver estos desafíos migrando la aplicación a AWS. Los usuarios de todo Estados Unidos y Canadá acceden a la aplicación. Solo los usuarios autenticados deben tener la capacidad de acceder a la aplicación para cargar archivos. La empresa considerará una solución que reestructure la aplicación, y la empresa necesita acelerar el desarrollo de la aplicación. ¿Qué solución cumplirá con estos requisitos con el MENOR esfuerzo operativo?",
        "opciones": [
            "A. Usar AWS Application Migration Service para migrar el servidor de aplicaciones a instancias de Amazon EC2. Crear un grupo de Auto Scaling para las instancias de EC2. Usar un Application Load Balancer para distribuir las solicitudes. Modificar la aplicación para usar Amazon S3 para almacenar los archivos. Usar Amazon Cognito para autenticar a los usuarios.",
            "B. Usar AWS Application Migration Service para migrar el servidor de aplicaciones a instancias de Amazon EC2. Crear un grupo de Auto Scaling para las instancias de EC2. Usar un Application Load Balancer para distribuir las solicitudes. Configurar AWS IAM Identity Center (AWS Single Sign-On) para permitir a los usuarios iniciar sesión en la aplicación. Modificar la aplicación para usar Amazon S3 para almacenar los archivos.",
            "C. Crear un sitio web estático para cargar archivos multimedia. Almacenar los activos estáticos en Amazon S3. Usar AWS AppSync para crear una API. Usar AWS Lambda como resolutores para cargar los archivos multimedia en Amazon S3. Usar Amazon Cognito para autenticar a los usuarios.",
            "D. Usar AWS Amplify para crear un sitio web estático para cargar archivos multimedia. Usar Amplify Hosting para servir el sitio web a través de Amazon CloudFront. Usar Amazon S3 para almacenar los archivos multimedia cargados. Usar Amazon Cognito para autenticar a los usuarios."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "259.- Una empresa tiene una aplicación que está desplegada en instancias de Amazon EC2 detrás de un Application Load Balancer (ALB). Las instancias forman parte de un grupo de Auto Scaling. La aplicación tiene cargas de trabajo impredecibles y escala hacia afuera y hacia adentro con frecuencia. El equipo de desarrollo de la empresa desea analizar los registros de la aplicación para encontrar maneras de mejorar el rendimiento de la aplicación. Sin embargo, los registros ya no están disponibles después de que las instancias escalen hacia adentro. ¿Qué solución le dará al equipo de desarrollo la capacidad de ver los registros de la aplicación después de un evento de escalado hacia adentro?",
        "opciones": [
            "A. Habilitar los registros de acceso para el ALB. Almacenar los registros en un bucket de Amazon S3.",
            "B. Configurar las instancias EC2 para publicar los registros en Amazon CloudWatch Logs mediante el agente unificado de CloudWatch.",
            "C. Modificar el grupo de Auto Scaling para usar una política de escalado por pasos.",
            "D. Instrumentar la aplicación con el rastreo de AWS X-Ray."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "260.- Una empresa ejecuta un sitio web estático no autenticado (www.example.com) que incluye un formulario de registro para los usuarios. El sitio web usa Amazon S3 para la hospedaje y Amazon CloudFront como la red de entrega de contenido, con AWS WAF configurado. Cuando se envía el formulario de registro, el sitio web llama a un punto de enlace de la API de Amazon API Gateway que invoca una función de AWS Lambda para procesar la carga útil y reenviarla a una llamada a una API externa. Durante las pruebas, un arquitecto de soluciones se encuentra con un error de intercambio de recursos de origen cruzado (CORS). El arquitecto confirma que el origen de la distribución de CloudFront tiene el encabezado Access-Control-Allow-Origin configurado a www.example.com. ¿Qué debería hacer el arquitecto de soluciones para resolver el error?",
        "opciones": [
            "A. Cambiar la configuración CORS en el bucket de S3. Agregar reglas para CORS al elemento AllowedOrigin para www.example.com.",
            "B. Habilitar la configuración CORS en AWS WAF. Crear una regla de ACL web en la que el encabezado Access-Control-Allow-Origin esté configurado a www.example.com.",
            "C. Habilitar la configuración CORS en el punto de enlace de la API de API Gateway. Asegurarse de que el punto de enlace de la API esté configurado para devolver todas las respuestas con el encabezado Access-Control-Allow-Origin configurado a www.example.com.",
            "D. Habilitar la configuración CORS en la función Lambda. Asegurarse de que el código de retorno de la función tenga el encabezado Access-Control-Allow-Origin configurado a www.example.com."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "261.- Una empresa tiene muchas cuentas de AWS separadas y no utiliza facturación ni gestión centralizadas. Cada cuenta de AWS aloja servicios para diferentes departamentos de la empresa. La empresa tiene un Microsoft Azure Active Directory desplegado. Un arquitecto de soluciones necesita centralizar la facturación y la gestión de las cuentas de AWS de la empresa. La empresa quiere comenzar a usar federación de identidades en lugar de la gestión manual de usuarios. Además, la empresa desea usar credenciales temporales en lugar de claves de acceso de larga duración. ¿Qué combinación de pasos cumplirá con estos requisitos? (Elija tres.)",
        "opciones": [
            "A. Crear una nueva cuenta de AWS para que sirva como cuenta de gestión. Desplegar una organización en AWS Organizations. Invitar a cada cuenta de AWS existente a unirse a la organización. Asegurarse de que cada cuenta acepte la invitación.",
            "B. Configurar la dirección de correo electrónico de cada cuenta de AWS como aws+@example.com para que los mensajes de correo electrónico sobre la gestión de la cuenta y las facturas se envíen al mismo lugar.",
            "C. Desplegar AWS IAM Identity Center (AWS Single Sign-On) en la cuenta de gestión. Conectar IAM Identity Center al Azure Active Directory. Configurar IAM Identity Center para la sincronización automática de usuarios y grupos.",
            "D. Desplegar un directorio AWS Managed Microsoft AD en la cuenta de gestión. Compartir el directorio con todas las demás cuentas de la organización utilizando AWS Resource Access Manager (AWS RAM).",
            "E. Crear conjuntos de permisos de AWS IAM Identity Center (AWS Single Sign-On). Asociar los conjuntos de permisos a los grupos adecuados de IAM Identity Center y las cuentas de AWS.",
            "F. Configurar AWS Identity and Access Management (IAM) en cada cuenta de AWS para usar AWS Managed Microsoft AD para la autenticación y autorización."
        ],
        "respuestas_correctas": [
            "C",
            "E",
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "262.- Una empresa quiere gestionar los costos asociados a un grupo de 20 aplicaciones que se usan de forma poco frecuente, pero que son críticas para el negocio, mediante la migración a AWS. Las aplicaciones son una mezcla de Java y Node.js distribuidas en diferentes clústeres de instancias. La empresa desea minimizar los costos mientras estandariza mediante el uso de una única metodología de implementación. La mayoría de las aplicaciones son parte de las rutinas de procesamiento de fin de mes con un pequeño número de usuarios concurrentes, pero ocasionalmente se ejecutan en otros momentos. El consumo promedio de memoria de las aplicaciones es inferior a 1 GB, aunque algunas aplicaciones usan hasta 2,5 GB de memoria durante el procesamiento pico. La aplicación más importante del grupo es un informe de facturación escrito en Java que accede a múltiples fuentes de datos y que a menudo se ejecuta durante varias horas. ¿Cuál es la solución más rentable?",
        "opciones": [
            "A. Desplegar una función de AWS Lambda separada para cada aplicación. Usar los registros de AWS CloudTrail y las alarmas de Amazon CloudWatch para verificar la finalización de trabajos críticos.",
            "B. Desplegar contenedores Amazon ECS en Amazon EC2 con Auto Scaling configurado para una utilización de memoria del 75%. Desplegar una tarea ECS para cada aplicación migrada con escalado de tareas ECS. Monitorear los servicios y hosts usando Amazon CloudWatch.",
            "C. Desplegar AWS Elastic Beanstalk para cada aplicación con Auto Scaling para garantizar que todas las solicitudes tengan suficientes recursos. Monitorear cada implementación de AWS Elastic Beanstalk usando alarmas de CloudWatch.",
            "D. Desplegar un nuevo clúster de instancias de Amazon EC2 que albergue todas las aplicaciones usando EC2 Auto Scaling y Application Load Balancers. Escalar el tamaño del clúster basado en una métrica personalizada configurada en la utilización de memoria de la instancia. Comprar reservas de Instancia Reservada de 3 años equivalentes al parámetro GroupMaxSize del grupo de Auto Scaling."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "263.- Un arquitecto de soluciones necesita revisar el diseño de un clúster de Amazon EMR que está utilizando EMR File System (EMRFS). El clúster realiza tareas que son críticas para las necesidades comerciales. El clúster está ejecutando Amazon EC2 On-Demand Instances en todo momento para todos los nodos de tarea, primarios y de núcleo. Las tareas de EMR se ejecutan cada mañana, comenzando a la 1:00 AM y tardan 6 horas en finalizar. El tiempo para completar el procesamiento no es una prioridad porque los datos no se consultan hasta tarde en el día. El arquitecto de soluciones debe revisar la arquitectura y sugerir una solución para minimizar los costos de cómputo. ¿Qué solución debe recomendar el arquitecto de soluciones para cumplir con estos requisitos?",
        "opciones": [
            "A. Lanzar todos los nodos de tarea, primarios y de núcleo en Spot Instances en una flota de instancias. Terminar el clúster, incluyendo todas las instancias, cuando se haya completado el procesamiento.",
            "B. Lanzar los nodos primarios y de núcleo en On-Demand Instances. Lanzar los nodos de tarea en Spot Instances en una flota de instancias. Terminar el clúster, incluyendo todas las instancias, cuando se haya completado el procesamiento. Comprar Compute Savings Plans para cubrir el uso de instancias On-Demand.",
            "C. Continuar lanzando todos los nodos en On-Demand Instances. Terminar el clúster, incluyendo todas las instancias, cuando se haya completado el procesamiento. Comprar Compute Savings Plans para cubrir el uso de instancias On-Demand.",
            "D. Lanzar los nodos primarios y de núcleo en On-Demand Instances. Lanzar los nodos de tarea en Spot Instances en una flota de instancias. Terminar solo las instancias de los nodos de tarea cuando se haya completado el procesamiento. Comprar Compute Savings Plans para cubrir el uso de instancias On-Demand."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "264.- Una empresa ha migrado una aplicación heredada a la nube de AWS. La aplicación se ejecuta en tres instancias de Amazon EC2 distribuidas en tres Zonas de Disponibilidad. Una instancia de EC2 se encuentra en cada Zona de Disponibilidad. Las instancias de EC2 se ejecutan en tres subredes privadas de la VPC y están configuradas como destinos para un Application Load Balancer (ALB) asociado a tres subredes públicas. La aplicación necesita comunicarse con sistemas locales. Solo el tráfico proveniente de direcciones IP en el rango de direcciones IP de la empresa tiene permiso para acceder a los sistemas locales. El equipo de seguridad de la empresa está trayendo solo una dirección IP de su rango de direcciones IP internas a la nube. Esta dirección IP se ha agregado a la lista blanca del firewall de la empresa. La empresa también ha creado una dirección IP elástica para esta dirección IP. Un arquitecto de soluciones debe crear una solución que permita a la aplicación comunicarse con los sistemas locales. La solución también debe ser capaz de mitigar fallos automáticamente. ¿Qué solución cumple con estos requisitos?",
        "opciones": [
            "A. Implementar tres NAT gateways, uno en cada subred pública. Asignar la dirección IP elástica a los NAT gateways. Activar las verificaciones de estado para los NAT gateways. Si un NAT gateway no pasa la verificación de estado, recrear el NAT gateway y asignar la dirección IP elástica al nuevo NAT gateway.",
            "B. Reemplazar el ALB por un Network Load Balancer (NLB). Asignar la dirección IP elástica al NLB. Activar las verificaciones de estado para el NLB. En caso de que falle una verificación de estado, volver a implementar el NLB en diferentes subredes.",
            "C. Implementar un solo NAT gateway en una subred pública. Asignar la dirección IP elástica al NAT gateway. Usar Amazon CloudWatch con una métrica personalizada para monitorear el NAT gateway. Si el NAT gateway no es saludable, invocar una función AWS Lambda para crear un nuevo NAT gateway en una subred diferente. Asignar la dirección IP elástica al nuevo NAT gateway.",
            "D. Asignar la dirección IP elástica al ALB. Crear un registro simple en Amazon Route 53 con la dirección IP elástica como valor. Crear una verificación de estado en Route 53. En caso de que falle una verificación de estado, volver a crear el ALB en diferentes subredes."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "265.- Una empresa utiliza AWS Organizations para gestionar más de 1,000 cuentas de AWS. La empresa ha creado una nueva organización para desarrolladores. Hay 540 cuentas de desarrollador que deben trasladarse a la nueva organización para desarrolladores. Todas las cuentas están configuradas con toda la información necesaria para que cada cuenta pueda operar de forma independiente. ¿Qué combinación de pasos debe seguir un arquitecto de soluciones para mover todas las cuentas de desarrollador a la nueva organización para desarrolladores? (Elija tres.)",
        "opciones": [
            "A. Llamar a la operación MoveAccount en la API de Organizations desde la cuenta de gestión de la antigua organización para migrar las cuentas de desarrollador a la nueva organización para desarrolladores.",
            "B. Desde la cuenta de gestión, eliminar cada cuenta de desarrollador de la antigua organización utilizando la operación RemoveAccountFromOrganization en la API de Organizations.",
            "C. Desde cada cuenta de desarrollador, eliminar la cuenta de la antigua organización utilizando la operación RemoveAccountFromOrganization en la API de Organizations.",
            "D. Iniciar sesión en la cuenta de gestión de la nueva organización para desarrolladores y crear una cuenta miembro de marcador de posición que actúe como objetivo para la migración de las cuentas de desarrollador.",
            "E. Llamar a la operación InviteAccountToOrganization en la API de Organizations desde la cuenta de gestión de la nueva organización para desarrolladores para enviar invitaciones a las cuentas de desarrollador.",
            "F. Hacer que cada desarrollador inicie sesión en su cuenta y confirme unirse a la nueva organización para desarrolladores."
        ],
        "respuestas_correctas": [
            "E",
            "B",
            "F"
        ],
        "imagenes": []
    },
    {
        "pregunta": "266.- La aplicación web interactiva de una empresa utiliza una distribución de Amazon CloudFront para servir imágenes desde un bucket de Amazon S3. Ocasionalmente, herramientas de terceros cargan imágenes corruptas en el bucket de S3. Esta corrupción de imágenes provoca una mala experiencia de usuario en la aplicación más adelante. La empresa ha implementado y probado con éxito una lógica en Python para detectar imágenes corruptas. Un arquitecto de soluciones debe recomendar una solución para integrar la lógica de detección con mínima latencia entre la ingestión y la entrega de las imágenes. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Utilizar una función Lambda@Edge que se invoque mediante un evento de viewer-response.",
            "B. Utilizar una función Lambda@Edge que se invoque mediante un evento de origin-response.",
            "C. Utilizar una notificación de evento de S3 que invoque una función de AWS Lambda.",
            "D. Utilizar una notificación de evento de S3 que invoque una máquina de estados de AWS Step Functions."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "267.- Una empresa tiene una aplicación que se ejecuta en instancias de Amazon EC2 en un grupo de Amazon EC2 Auto Scaling. La empresa utiliza AWS CodePipeline para desplegar la aplicación. Las instancias que se ejecutan en el grupo de Auto Scaling están cambiando constantemente debido a eventos de escalado. Cuando la empresa despliega nuevas versiones de código de la aplicación, instala el agente de AWS CodeDeploy en cualquier nueva instancia EC2 de destino y asocia las instancias con el grupo de despliegue de CodeDeploy. La aplicación se pondrá en vivo dentro de las próximas 24 horas. ¿Qué debe recomendar un arquitecto de soluciones para automatizar el proceso de despliegue de la aplicación con la menor cantidad de overhead operativo?",
        "opciones": [
            "A. Configurar Amazon EventBridge para invocar una función AWS Lambda cuando se lance una nueva instancia EC2 en el grupo de Auto Scaling. Programar la función Lambda para asociar las instancias EC2 con el grupo de despliegue de CodeDeploy.",
            "B. Escribir un script para suspender las operaciones de Amazon EC2 Auto Scaling antes del despliegue de un nuevo código. Una vez que el despliegue se complete, crear una nueva AMI y configurar la plantilla de lanzamiento del grupo de Auto Scaling para usar la nueva AMI para los nuevos lanzamientos. Reanudar las operaciones de Amazon EC2 Auto Scaling.",
            "C. Crear un nuevo proyecto de AWS CodeBuild que cree una nueva AMI que contenga el nuevo código. Configurar CodeBuild para actualizar la plantilla de lanzamiento del grupo de Auto Scaling con la nueva AMI. Ejecutar una operación de Amazon EC2 Auto Scaling instance refresh.",
            "D. Crear una nueva AMI que tenga el agente de CodeDeploy instalado. Configurar la plantilla de lanzamiento del grupo de Auto Scaling para usar la nueva AMI. Asociar el grupo de despliegue de CodeDeploy con el grupo de Auto Scaling en lugar de con las instancias EC2."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "268.- Una empresa tiene un sitio web que se ejecuta en cuatro instancias de Amazon EC2 que están detrás de un Application Load Balancer (ALB). Cuando el ALB detecta que una instancia de EC2 ya no está disponible, una alarma de Amazon CloudWatch entra en estado ALARM. Un miembro del equipo de operaciones de la empresa luego agrega manualmente una nueva instancia de EC2 detrás del ALB. Un arquitecto de soluciones necesita diseñar una solución altamente disponible que maneje automáticamente el reemplazo de instancias de EC2. La empresa necesita minimizar el tiempo de inactividad durante el cambio a la nueva solución. ¿Qué conjunto de pasos debe seguir el arquitecto de soluciones para cumplir con estos requisitos?",
        "opciones": [
            "A. Eliminar el ALB existente. Crear un grupo de Auto Scaling que esté configurado para manejar el tráfico de la aplicación web. Adjuntar una nueva plantilla de lanzamiento al grupo de Auto Scaling. Crear un nuevo ALB. Adjuntar el grupo de Auto Scaling al nuevo ALB. Adjuntar las instancias de EC2 existentes al grupo de Auto Scaling.",
            "B. Crear un grupo de Auto Scaling que esté configurado para manejar el tráfico de la aplicación web. Adjuntar una nueva plantilla de lanzamiento al grupo de Auto Scaling. Adjuntar el grupo de Auto Scaling al ALB existente. Adjuntar las instancias de EC2 existentes al grupo de Auto Scaling.",
            "C. Eliminar el ALB y las instancias de EC2 existentes. Crear un grupo de Auto Scaling que esté configurado para manejar el tráfico de la aplicación web. Adjuntar una nueva plantilla de lanzamiento al grupo de Auto Scaling. Crear un nuevo ALB. Adjuntar el grupo de Auto Scaling al nuevo ALB. Esperar a que el grupo de Auto Scaling lance el número mínimo de instancias de EC2.",
            "D. Crear un grupo de Auto Scaling que esté configurado para manejar el tráfico de la aplicación web. Adjuntar una nueva plantilla de lanzamiento al grupo de Auto Scaling. Adjuntar el grupo de Auto Scaling al ALB existente. Esperar a que el ALB existente registre las instancias de EC2 existentes en el grupo de Auto Scaling."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "269.- Una empresa quiere optimizar los costos de transferencia de datos y los costos de cómputo de AWS en cuentas de desarrolladores dentro de la organización de la empresa en AWS Organizations. Los desarrolladores pueden configurar VPC y lanzar instancias de Amazon EC2 en una sola región de AWS. Las instancias de EC2 recuperan aproximadamente 1 TB de datos cada día desde Amazon S3. La actividad de los desarrolladores lleva a cargos excesivos de transferencia de datos mensual y cargos de procesamiento de NAT gateway entre las instancias de EC2 y los buckets de S3, junto con altos costos de cómputo. La empresa desea hacer cumplir de manera proactiva patrones arquitectónicos aprobados para cualquier instancia de EC2 y la infraestructura de VPC que los desarrolladores implementen dentro de las cuentas de AWS. La empresa no quiere que esta aplicación de políticas afecte negativamente la velocidad con la que los desarrolladores pueden realizar sus tareas. ¿Cuál solución cumplirá con estos requisitos de manera más rentable?",
        "opciones": [
            "A. Crear SCPs para evitar que los desarrolladores lancen tipos de instancias de EC2 no aprobados. Proporcionar a los desarrolladores una plantilla de AWS CloudFormation para implementar una configuración de VPC aprobada con S3 interface endpoints. Limitar los permisos de IAM de los desarrolladores para que solo puedan lanzar recursos de VPC a través de CloudFormation.",
            "B. Crear un presupuesto pronosticado diario con AWS Budgets para monitorear los costos de cómputo de EC2 y los costos de transferencia de datos de S3 en las cuentas de desarrolladores. Cuando el costo pronosticado sea el 75% del costo real del presupuesto, enviar una alerta a los equipos de desarrolladores. Si el costo real del presupuesto es el 100%, crear una acción de presupuesto para finalizar las instancias de EC2 y la infraestructura de VPC de los desarrolladores.",
            "C. Crear un portafolio de AWS Service Catalog que los usuarios puedan usar para crear una configuración de VPC aprobada con S3 gateway endpoints y instancias de EC2 aprobadas. Compartir el portafolio con las cuentas de desarrolladores. Configurar una restricción de lanzamiento de AWS Service Catalog para usar un rol de IAM aprobado. Limitar los permisos de IAM de los desarrolladores para permitir el acceso solo a AWS Service Catalog.",
            "D. Crear y desplegar reglas de AWS Config para monitorear el cumplimiento de recursos de EC2 y VPC en las cuentas de AWS de los desarrolladores. Si los desarrolladores lanzan instancias de EC2 no aprobadas o crean VPCs sin S3 gateway endpoints, realizar una acción de remediación para finalizar los recursos no aprobados."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "270.- Una empresa está expandiéndose. La empresa planea separar sus recursos en cientos de cuentas de AWS diferentes en múltiples Regiones de AWS. Un arquitecto de soluciones debe recomendar una solución que deniegue el acceso a cualquier operación fuera de las Regiones específicamente designadas. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Crear roles de IAM para cada cuenta. Crear políticas de IAM con permisos condicionales de permiso que incluyan solo las Regiones aprobadas para las cuentas.",
            "B. Crear una organización en AWS Organizations. Crear usuarios de IAM para cada cuenta. Adjuntar una política a cada usuario para bloquear el acceso a las Regiones donde una cuenta no pueda desplegar infraestructura.",
            "C. Lanzar un zona de aterrizaje de AWS Control Tower. Crear OUs y adjuntar SCPs que nieguen el acceso para ejecutar servicios fuera de las Regiones aprobadas.",
            "D. Habilitar AWS Security Hub en cada cuenta. Crear controles para especificar las Regiones donde una cuenta puede desplegar infraestructura."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "271.- Una empresa quiere refactorizar su aplicación web de pedidos en línea, que actualmente tiene una flota de instancias de Amazon EC2 balanceadas para hospedaje web, servicios de API de base de datos y lógica empresarial. La empresa necesita crear una arquitectura desacoplada y escalable con un mecanismo para retener pedidos fallidos, mientras minimiza los costos operacionales. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Usar Amazon S3 para el hospedaje web con Amazon API Gateway para los servicios de API de base de datos. Usar Amazon Simple Queue Service (Amazon SQS) para la cola de pedidos. Usar Amazon Elastic Container Service (Amazon ECS) para la lógica empresarial con sondeo largo de Amazon SQS para retener pedidos fallidos.",
            "B. Usar AWS Elastic Beanstalk para el hospedaje web con Amazon API Gateway para los servicios de API de base de datos. Usar Amazon MQ para la cola de pedidos. Usar AWS Step Functions para la lógica empresarial con Amazon S3 Glacier Deep Archive para retener pedidos fallidos.",
            "C. Usar Amazon S3 para el hospedaje web con AWS AppSync para los servicios de API de base de datos. Usar Amazon Simple Queue Service (Amazon SQS) para la cola de pedidos. Usar AWS Lambda para la lógica empresarial con una cola de mensajes no entregados (dead-letter queue) de Amazon SQS para retener pedidos fallidos.",
            "D. Usar Amazon Lightsail para el hospedaje web con AWS AppSync para los servicios de API de base de datos. Usar Amazon Simple Email Service (Amazon SES) para la cola de pedidos. Usar Amazon Elastic Kubernetes Service (Amazon EKS) para la lógica empresarial con Amazon OpenSearch Service para retener pedidos fallidos."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "272.- Una empresa aloja una aplicación web en AWS en la región us-east-1. Los servidores de la aplicación están distribuidos en tres Zonas de Disponibilidad detrás de un Application Load Balancer. La base de datos está alojada en una instancia de Amazon EC2 con una base de datos MySQL. Un arquitecto de soluciones necesita diseñar una solución de recuperación de datos entre regiones utilizando los servicios de AWS con un RTO (Tiempo Objetivo de Recuperación) de menos de 5 minutos y un RPO (Objetivo de Punto de Recuperación) de menos de 1 minuto. El arquitecto de soluciones está desplegando servidores de aplicación en us-west-2, y ha configurado Amazon Route 53 con comprobaciones de salud y conmutación por error de DNS hacia us-west-2. ¿Qué paso adicional debe tomar el arquitecto de soluciones?",
        "opciones": [
            "A. Migrar la base de datos a una instancia de Amazon RDS for MySQL con una réplica de lectura entre regiones en us-west-2.",
            "B. Migrar la base de datos a una base de datos global de Amazon Aurora, con el primario en us-east-1 y el secundario en us-west-2.",
            "C. Migrar la base de datos a una instancia de Amazon RDS for MySQL con una implementación Multi-AZ.",
            "D. Crear una base de datos de respaldo de MySQL en una instancia de Amazon EC2 en us-west-2."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "273.- Una empresa está utilizando AWS Organizations para gestionar varias cuentas. Debido a requisitos regulatorios, la empresa desea restringir cuentas miembros específicas a ciertas Regiones de AWS, donde se les permite desplegar recursos. Los recursos en las cuentas deben estar etiquetados, ser aplicados según un estándar grupal y gestionados de forma centralizada con una configuración mínima. ¿Qué debe hacer un arquitecto de soluciones para cumplir con estos requisitos?",
        "opciones": [
            "A. Crear una regla de AWS Config en las cuentas miembros específicas para limitar las Regiones y aplicar una política de etiquetas.",
            "B. Desde la consola de AWS Billing and Cost Management, en la cuenta de gestión, desactivar las Regiones para las cuentas miembros específicas y aplicar una política de etiquetas en el nivel raíz.",
            "C. Asociar las cuentas miembros específicas con el nivel raíz. Aplicar una política de etiquetas y un SCP (Control de Políticas de Servicio) usando condiciones para limitar las Regiones.",
            "D. Asociar las cuentas miembros específicas con una nueva OU (Unidad Organizativa). Aplicar una política de etiquetas y un SCP usando condiciones para limitar las Regiones."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "274.- Una empresa tiene una aplicación que genera informes y los almacena en un Amazon S3 bucket. Cuando un usuario accede a su informe, la aplicación genera una URL firmada para permitir que el usuario descargue el informe. El equipo de seguridad de la empresa ha descubierto que los archivos son públicos y que cualquiera puede descargarlos sin autenticación. La empresa ha suspendido la generación de nuevos informes hasta que se resuelva el problema. ¿Qué conjunto de acciones corregirá inmediatamente el problema de seguridad sin afectar el flujo de trabajo normal de la aplicación?",
        "opciones": [
            "A. Crear una función de AWS Lambda que aplique una política de denegación para los usuarios que no estén autenticados. Crear un evento programado para invocar la función Lambda.",
            "B. Revisar la comprobación de permisos de bucket en AWS Trusted Advisor e implementar las acciones recomendadas.",
            "C. Ejecutar un script que aplique un ACL privado a todos los objetos en el bucket.",
            "D. Usar la función Block Public Access en Amazon S3 para configurar la opción IgnorePublicAcIs a TRUE en el bucket."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "275.- Una empresa está planeando migrar una base de datos Amazon RDS para Oracle a una RDS para PostgreSQL en otra cuenta de AWS. Un arquitecto de soluciones necesita diseñar una estrategia de migración que no requiera tiempo de inactividad y que minimice el tiempo necesario para completar la migración. La estrategia de migración debe replicar todos los datos existentes y cualquier dato nuevo que se cree durante la migración. La base de datos de destino debe ser idéntica a la base de datos de origen al finalizar el proceso de migración. Todas las aplicaciones usan actualmente un registro CNAME de Amazon Route 53 como su punto final para la comunicación con la base de datos RDS para Oracle. La base de datos RDS para Oracle se encuentra en una subred privada. ¿Qué combinación de pasos debe seguir el arquitecto de soluciones para cumplir con estos requisitos? (Elija tres.)",
        "opciones": [
            "A. Crear una nueva instancia de RDS para PostgreSQL en la cuenta de destino. Usar la Herramienta de Conversión de Esquema de AWS (AWS SCT) para migrar el esquema de la base de datos desde la base de datos de origen a la base de datos de destino.",
            "B. Usar la Herramienta de Conversión de Esquema de AWS (AWS SCT) para crear una nueva instancia de RDS para PostgreSQL en la cuenta de destino con el esquema y los datos iniciales desde la base de datos de origen.",
            "C. Configurar un emparejamiento de VPC entre las VPCs de las dos cuentas de AWS para proporcionar conectividad a ambas instancias de base de datos desde la cuenta de destino. Configurar los grupos de seguridad que están asociados a cada instancia de base de datos para permitir el tráfico en el puerto de la base de datos desde la VPC en la cuenta de destino.",
            "D. Permitir temporalmente que la instancia de la base de datos de origen sea accesible públicamente para proporcionar conectividad desde la VPC en la cuenta de destino. Configurar los grupos de seguridad que están asociados a cada instancia de base de datos para permitir el tráfico en el puerto de la base de datos desde la VPC en la cuenta de destino.",
            "E. Usar AWS Database Migration Service (AWS DMS) en la cuenta de destino para realizar una migración de carga completa más captura de datos de cambios (CDC) desde la base de datos de origen hacia la base de datos de destino. Cuando la migración esté completa, cambiar el registro CNAME para que apunte al punto final de la instancia de base de datos de destino.",
            "F. Usar AWS Database Migration Service (AWS DMS) en la cuenta de destino para realizar una migración solo con captura de datos de cambios (CDC) desde la base de datos de origen hacia la base de datos de destino. Cuando la migración esté completa, cambiar el registro CNAME para que apunte al punto final de la instancia de base de datos de destino."
        ],
        "respuestas_correctas": [
            "C",
            "E",
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "276.- Una empresa ha implementado un sistema de pedidos utilizando una arquitectura orientada a eventos. Durante las pruebas iniciales, el sistema dejó de procesar pedidos. Un análisis adicional de los registros reveló que un mensaje de pedido en una cola estándar de Amazon Simple Queue Service (Amazon SQS) estaba causando un error en el backend y bloqueando todos los mensajes de pedidos posteriores. El tiempo de visibilidad de la cola está configurado en 30 segundos y el tiempo de espera de procesamiento del backend está configurado en 10 segundos. Un arquitecto de soluciones necesita analizar los mensajes de pedido defectuosos y garantizar que el sistema siga procesando los mensajes posteriores. ¿Qué paso debe seguir el arquitecto de soluciones para cumplir con estos requisitos?",
        "opciones": [
            "A. Aumentar el tiempo de espera de procesamiento del backend a 30 segundos para que coincida con el tiempo de visibilidad.",
            "B. Reducir el tiempo de visibilidad de la cola para eliminar automáticamente el mensaje defectuoso.",
            "C. Configurar una nueva cola FIFO de SQS como una cola de mensajes no procesados (dead-letter queue) para aislar los mensajes defectuosos.",
            "D. Configurar una nueva cola estándar de SQS como una cola de mensajes no procesados (dead-letter queue) para aislar los mensajes defectuosos."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "277.- Una empresa ha automatizado el reentrenamiento nocturno de sus modelos de aprendizaje automático utilizando AWS Step Functions. El flujo de trabajo consta de múltiples pasos que usan AWS Lambda. Cada paso puede fallar por diversas razones, y cualquier error causa que falle el flujo de trabajo completo. Una revisión revela que el reentrenamiento ha fallado varias noches consecutivas sin que la empresa se haya dado cuenta del fallo. Un arquitecto de soluciones necesita mejorar el flujo de trabajo para que se envíen notificaciones para todos los tipos de fallos en el proceso de reentrenamiento. ¿Qué combinación de pasos debe tomar el arquitecto de soluciones para cumplir con estos requisitos? (Elija tres.)",
        "opciones": [
            "A. Crear un tema de Amazon Simple Notification Service (Amazon SNS) con una suscripción de tipo Correo electrónico que apunte a la lista de correo del equipo.",
            "B. Crear una tarea llamada Email que reenvíe los argumentos de entrada al tema SNS.",
            "C. Agregar un campo Catch a todos los estados Task, Map y Parallel que tenga la declaración ErrorEquals: [ States.ALL ] y Next: Email.",
            "D. Agregar una nueva dirección de correo electrónico a Amazon Simple Email Service (Amazon SES). Verificar la dirección de correo electrónico.",
            "E. Crear una tarea llamada Email que reenvíe los argumentos de entrada a la dirección de correo electrónico de SES.",
            "F. Agregar un campo Catch a todos los estados Task, Map y Parallel que tenga la declaración ErrorEquals: [ States.Runtime ] y Next: Email."
        ],
        "respuestas_correctas": [
            "C",
            "B",
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "278.- Una empresa planea implementar un nuevo servicio de intranet privado en instancias de Amazon EC2 dentro de una VPC. Una VPN de sitio a sitio de AWS conecta la VPC con la red local de la empresa. El nuevo servicio debe comunicarse con los servicios locales existentes. Los servicios locales son accesibles mediante nombres de host que residen en la zona DNS company.example. Esta zona DNS está completamente alojada en las instalaciones y solo está disponible en la red privada de la empresa. Un arquitecto de soluciones debe garantizar que el nuevo servicio pueda resolver los nombres de host en el dominio company.example para integrarse con los servicios existentes.",
        "opciones": [
            "A. Crear una zona privada vacía en Amazon Route 53 para company.example. Agregar un registro NS adicional a la zona company.example de la empresa en las instalaciones que apunte a los servidores de nombres autorizados para la nueva zona privada en Route 53.",
            "B. Activar los nombres de host DNS para la VPC. Configurar un nuevo punto de salida con Amazon Route 53 Resolver. Crear una regla de Resolver para reenviar las solicitudes de company.example a los servidores de nombres en las instalaciones.",
            "C. Activar los nombres de host DNS para la VPC. Configurar un nuevo punto de entrada con Amazon Route 53 Resolver. Configurar el servidor DNS en las instalaciones para reenviar las solicitudes de company.example al nuevo resolvedor.",
            "D. Usar AWS Systems Manager para configurar un documento de ejecución que instalará un archivo de hosts que contenga los nombres de host requeridos. Usar una regla de Amazon EventBridge para ejecutar el documento cuando una instancia entre en estado en ejecución."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "279.- Una empresa usa AWS CloudFormation para implementar aplicaciones dentro de múltiples VPC que están todas conectadas a un transit gateway. Cada VPC que envía tráfico a Internet público debe enviar ese tráfico a través de una VPC de servicios compartidos. Cada subred dentro de una VPC usa la tabla de rutas predeterminada de la VPC, y el tráfico se enruta al transit gateway. El transit gateway utiliza su tabla de rutas predeterminada para cualquier conexión de VPC. Una auditoría de seguridad revela que una instancia de Amazon EC2 implementada dentro de una VPC puede comunicarse con una instancia de EC2 que está desplegada en cualquiera de las otras VPCs de la empresa. Un arquitecto de soluciones necesita limitar el tráfico entre las VPCs. Cada VPC debe poder comunicarse solo con un conjunto predefinido y limitado de VPCs autorizadas. ¿Qué debería hacer el arquitecto de soluciones para cumplir con estos requisitos?",
        "opciones": [
            "A. Actualizar el network ACL de cada subred dentro de una VPC para permitir solo tráfico saliente hacia las VPCs autorizadas. Eliminar todas las reglas de denegación, excepto la regla de denegación predeterminada.",
            "B. Actualizar todos los grupos de seguridad utilizados dentro de una VPC para denegar tráfico saliente hacia los grupos de seguridad utilizados dentro de las VPC no autorizadas.",
            "C. Crear una tabla de rutas dedicada para el transit gateway para cada conexión de VPC. Enrutar el tráfico solo hacia las VPC autorizadas.",
            "D. Actualizar la tabla de rutas principal de cada VPC para enrutar el tráfico solo hacia las VPC autorizadas a través del transit gateway."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "280.- Una empresa tiene una aplicación de escritorio basada en Windows que está empaquetada y desplegada en las máquinas Windows de los usuarios. La empresa adquirió recientemente otra empresa cuyos empleados usan principalmente máquinas con un sistema operativo Linux. La empresa adquiriente ha decidido migrar y reubicar la aplicación de escritorio basada en Windows a AWS. Todos los empleados deben ser autenticados antes de usar la aplicación. La empresa adquiriente utiliza Active Directory en las instalaciones, pero quiere una forma simplificada de gestionar el acceso a la aplicación en AWS para todos los empleados. ¿Qué solución reubica la aplicación en AWS con el MENOR esfuerzo de desarrollo?",
        "opciones": [
            "A. Configurar y provisionar un escritorio virtual de Amazon Workspaces para cada empleado. Implementar la autenticación utilizando grupos de identidad de Amazon Cognito. Instruir a los empleados para ejecutar la aplicación desde sus escritorios virtuales de Workspaces provisionados.",
            "B. Crear un grupo de Auto Scaling de instancias de Amazon EC2 basadas en Windows. Unir cada instancia de EC2 al dominio de Active Directory de la empresa. Implementar la autenticación utilizando el Active Directory que se ejecuta en las instalaciones. Instruir a los empleados para ejecutar la aplicación usando un escritorio remoto de Windows.",
            "C. Usar un creador de imágenes de Amazon AppStream 2.0 para crear una imagen que incluya la aplicación y las configuraciones necesarias. Provisionar una flota bajo demanda de AppStream 2.0 con políticas de autoescalado dinámico para ejecutar la imagen. Implementar la autenticación utilizando grupos de usuarios de AppStream 2.0. Instruir a los empleados para acceder a la aplicación iniciando sesiones de transmisión basadas en navegador de AppStream 2.0.",
            "D. Refactorizar y contenedorar la aplicación para que se ejecute como una aplicación basada en la web. Ejecutar la aplicación en Amazon Elastic Container Service (Amazon ECS) en AWS Fargate con políticas de escalado por pasos. Implementar la autenticación utilizando grupos de usuarios de Amazon Cognito. Instruir a los empleados para ejecutar la aplicación desde sus navegadores."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "281.- Una empresa está recopilando una gran cantidad de datos desde una flota de dispositivos IoT. Los datos se almacenan como archivos Optimized Row Columnar (ORC) en el Hadoop Distributed File System (HDFS) dentro de un clúster Amazon EMR persistente. El equipo de análisis de datos de la empresa consulta los datos mediante SQL en Apache Presto, que está desplegado en el mismo clúster de EMR. Las consultas analizan grandes volúmenes de datos, siempre duran menos de 15 minutos y solo se ejecutan entre las 5 PM y las 10 PM. La empresa está preocupada por los altos costos asociados con la solución actual. Un arquitecto de soluciones debe proponer la opción más rentable que permita realizar consultas SQL sobre los datos. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Almacenar los datos en Amazon S3. Usar Amazon Redshift Spectrum para consultar los datos.",
            "B. Almacenar los datos en Amazon S3. Usar AWS Glue Data Catalog y Amazon Athena para consultar los datos.",
            "C. Almacenar los datos en EMR File System (EMRFS). Usar Presto en Amazon EMR para consultar los datos.",
            "D. Almacenar los datos en Amazon Redshift. Usar Amazon Redshift para consultar los datos."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "282.- Una gran empresa experimentó recientemente un aumento inesperado en los costos de Amazon RDS y Amazon DynamoDB. La empresa necesita mejorar la visibilidad en los detalles de AWS Billing and Cost Management. Hay varias cuentas asociadas con AWS Organizations, incluidas muchas cuentas de desarrollo y producción. No existe una estrategia de etiquetado consistente en toda la organización, pero hay directrices que requieren que toda la infraestructura se implemente utilizando AWS CloudFormation con etiquetado coherente. La gerencia exige que todas las tablas de DynamoDB y instancias de RDS, tanto existentes como futuras, incluyan números de centro de costos y números de ID de proyecto. ¿Qué estrategia debería proporcionar el arquitecto de soluciones para cumplir con estos requisitos?",
        "opciones": [
            "A. Usar Tag Editor para etiquetar los recursos existentes. Crear etiquetas de asignación de costos para definir el centro de costos y el ID del proyecto y esperar 24 horas para que las etiquetas se propaguen a los recursos existentes.",
            "B. Usar una regla de AWS Config para alertar al equipo financiero sobre recursos sin etiquetar. Crear una solución centralizada basada en AWS Lambda para etiquetar cada hora los recursos de RDS y DynamoDB sin etiquetas, utilizando un rol entre cuentas.",
            "C. Usar Tag Editor para etiquetar los recursos existentes. Crear etiquetas de asignación de costos para definir el centro de costos y el ID del proyecto. Usar SCPs (Service Control Policies) para restringir la creación de recursos que no tengan las etiquetas obligatorias.",
            "D. Crear etiquetas de asignación de costos para definir el centro de costos y el ID del proyecto y esperar 24 horas para que las etiquetas se propaguen a los recursos existentes. Actualizar los roles federados existentes para restringir permisos de aprovisionamiento de recursos que no incluyan las etiquetas obligatorias."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "283.- Una empresa quiere enviar datos desde sus sistemas on-premises a buckets de Amazon S3. La empresa creó los buckets S3 en tres cuentas diferentes. Debe enviar los datos de forma privada, sin que viajen por internet. La empresa no tiene conectividad dedicada existente con AWS. ¿Qué combinación de pasos debe seguir un arquitecto de soluciones para cumplir con estos requisitos? (Elige dos.)",
        "opciones": [
            "A. Establecer una cuenta de red en la nube de AWS. Crear una VPC privada en la cuenta de red. Configurar una conexión AWS Direct Connect con una VIF privada entre el entorno on-premises y la VPC privada.",
            "B. Establecer una cuenta de red en la nube de AWS. Crear una VPC privada en la cuenta de red. Configurar una conexión AWS Direct Connect con una VIF pública entre el entorno on-premises y la VPC privada.",
            "C. Crear un endpoint de interfaz de Amazon S3 en la cuenta de red.",
            "D. Crear un endpoint de gateway de Amazon S3 en la cuenta de red.",
            "E. Establecer una cuenta de red en la nube de AWS. Crear una VPC privada en la cuenta de red. Interconectar las VPCs de las cuentas que alojan los buckets S3 con la VPC en la cuenta de red."
        ],
        "respuestas_correctas": [
            "C",
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "284.- Una empresa opera restaurantes de servicio rápido. Los restaurantes siguen un modelo predecible con un alto tráfico de ventas durante 4 horas diarias. Fuera de esas horas pico, el tráfico de ventas es menor. La plataforma de punto de venta y gestión está desplegada en la nube de AWS y tiene un backend basado en Amazon DynamoDB. La tabla de la base de datos usa el modo de rendimiento aprovisionado con 100,000 RCUs y 80,000 WCUs para cubrir el consumo máximo de recursos durante los picos de tráfico conocidos. La empresa quiere reducir los costos de DynamoDB y minimizar la sobrecarga operativa para el equipo de TI. ¿Qué solución cumple mejor con estos requisitos de manera más rentable?",
        "opciones": [
            "A. Reducir las RCUs y WCUs aprovisionadas.",
            "B. Cambiar la tabla de DynamoDB para que use capacidad bajo demanda.",
            "C. Habilitar el autoescalado de DynamoDB para la tabla.",
            "D. Comprar capacidad reservada por 1 año para cubrir la carga máxima durante las 4 horas pico diarias."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "285.- Una empresa aloja una aplicación de blogs en AWS utilizando Amazon API Gateway, Amazon DynamoDB y AWS Lambda. Actualmente, la aplicación no usa claves de API para autorizar solicitudes. El modelo de API es el siguiente: GET /posts/{postId}: para obtener los detalles de una publicación GET /users/{userId}: para obtener los detalles de un usuario GET /comments/{commentId}: para obtener los detalles de un comentario La empresa ha notado que los usuarios están discutiendo activamente temas en la sección de comentarios y desea aumentar la interacción de los usuarios haciendo que los comentarios aparezcan en tiempo real. ¿Qué diseño debería utilizarse para reducir la latencia de los comentarios y mejorar la experiencia del usuario?",
        "opciones": [
            "A. Usar una API optimizada para el edge con Amazon CloudFront para almacenar en caché las respuestas de la API.",
            "B. Modificar el código de la aplicación del blog para solicitar GET /comments/{commentId} cada 10 segundos.",
            "C. Usar AWS AppSync y aprovechar WebSockets para entregar los comentarios en tiempo real.",
            "D. Cambiar el límite de concurrencia de las funciones Lambda para reducir el tiempo de respuesta de la API."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "286.- Una empresa administra cientos de cuentas de AWS de forma centralizada dentro de una organización en AWS Organizations. Recientemente, la empresa permitió que los equipos de productos crearan y administraran sus propios puntos de acceso de S3 en sus cuentas. Los puntos de acceso de S3 solo deben ser accesibles dentro de VPCs, no a través de Internet. ¿Cuál es la forma MÁS eficiente operativamente para hacer cumplir este requisito?",
        "opciones": [
            "A. Configurar la política de recursos del punto de acceso de S3 para denegar la acción s3:CreateAccessPoint a menos que la clave de condición s3:AccessPointNetworkOrigin evalúe como VPC.",
            "B. Crear una SCP (Service Control Policy) a nivel raíz en la organización para denegar la acción s3:CreateAccessPoint a menos que la clave de condición s3:AccessPointNetworkOrigin evalúe como VPC.",
            "C. Usar AWS CloudFormation StackSets para crear una nueva política de IAM en cada cuenta de AWS que permita la acción s3:CreateAccessPoint solo si la clave de condición s3:AccessPointNetworkOrigin evalúa como VPC.",
            "D. Configurar la política del bucket de S3 para denegar la acción s3:CreateAccessPoint a menos que la clave de condición s3:AccessPointNetworkOrigin evalúe como VPC."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "287.- Un arquitecto de soluciones debe actualizar un entorno de aplicación dentro de AWS Elastic Beanstalk utilizando una metodología de implementación blue/green. El arquitecto de soluciones crea un entorno idéntico al entorno de aplicación existente y despliega la aplicación en el nuevo entorno. ¿Qué se debe hacer a continuación para completar la actualización?",
        "opciones": [
            "A. Redirigir al nuevo entorno usando Amazon Route 53.",
            "B. Seleccionar la opción Swap Environment URLs.",
            "C. Reemplazar la configuración de lanzamiento de Auto Scaling.",
            "D. Actualizar los registros DNS para apuntar al entorno green."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "288.- Una empresa está desarrollando un servicio de imágenes en la web que permitirá a los usuarios subir y buscar fotos aleatorias. En los momentos de mayor uso, hasta 10,000 usuarios en todo el mundo subirán sus imágenes. Luego, los usuarios superpondrán texto en las imágenes cargadas, que luego se publicarán en el sitio web de la empresa. ¿Qué diseño debería implementar un arquitecto de soluciones?",
        "opciones": [
            "A. Almacenar las imágenes subidas en Amazon Elastic File System (Amazon EFS). Enviar la información de los registros de la aplicación sobre cada imagen a Amazon CloudWatch Logs. Crear un grupo de instancias de Amazon EC2 que use CloudWatch Logs para determinar qué imágenes deben procesarse. Colocar las imágenes procesadas en otro directorio en Amazon EFS. Habilitar Amazon CloudFront y configurar el origen para que sea una de las instancias EC2 en el grupo.",
            "B. Almacenar las imágenes subidas en un bucket de Amazon S3 y configurar una notificación de eventos del bucket S3 para enviar un mensaje a Amazon Simple Notification Service (Amazon SNS). Crear un grupo de instancias de Amazon EC2 detrás de un Application Load Balancer (ALB) para obtener mensajes de Amazon SNS, procesar las imágenes y almacenarlas en Amazon EFS. Usar Amazon CloudWatch Metrics para monitorear el volumen de mensajes en SNS y escalar las instancias EC2. Habilitar Amazon CloudFront y configurar el origen para que sea el ALB frente a las instancias EC2.",
            "C. Almacenar las imágenes subidas en un bucket de Amazon S3 y configurar una notificación de eventos del bucket S3 para enviar un mensaje a Amazon Simple Queue Service (Amazon SQS). Crear un grupo de instancias de Amazon EC2 para obtener mensajes de la cola SQS, procesar las imágenes y colocarlas en otro bucket de S3. Usar Amazon CloudWatch Metrics para monitorear la profundidad de la cola y escalar las instancias EC2. Habilitar Amazon CloudFront y configurar el origen para que sea el bucket de S3 que contiene las imágenes procesadas.",
            "D. Almacenar las imágenes subidas en un volumen compartido de Amazon Elastic Block Store (Amazon EBS) montado en un grupo de instancias Spot de Amazon EC2. Crear una tabla de Amazon DynamoDB que contenga información sobre cada imagen subida y su estado de procesamiento. Usar una regla de Amazon EventBridge para escalar las instancias EC2. Habilitar Amazon CloudFront y configurar el origen para que haga referencia a un Elastic Load Balancer (ELB) frente al grupo de instancias EC2."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "289.- Una empresa ha implementado su base de datos en una instancia de Amazon RDS para MySQL en la región us-east-1. La empresa necesita que sus datos estén disponibles para clientes en Europa. Los clientes en Europa deben tener acceso a los mismos datos que los clientes en Estados Unidos (EE. UU.) y no tolerarán una alta latencia de la aplicación ni datos desactualizados. Tanto los clientes en Europa como los de EE. UU. necesitan escribir en la base de datos. Ambos grupos de clientes deben ver las actualizaciones del otro grupo en tiempo real. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Crear una réplica de Amazon Aurora MySQL de la instancia RDS para MySQL. Pausar las escrituras en la instancia RDS. Promocionar la réplica de Aurora a un clúster de base de datos independiente. Reconfigurar la aplicación para usar la base de datos de Aurora y reanudar las escrituras. Agregar eu-west-1 como una región secundaria al clúster de base de datos. Habilitar el reenvío de escritura en el clúster de base de datos. Implementar la aplicación en eu-west-1. Configurar la aplicación para usar el endpoint de Aurora MySQL en eu-west-1.",
            "B. Agregar una réplica entre regiones en eu-west-1 para la instancia RDS para MySQL. Configurar la réplica para replicar las consultas de escritura de vuelta a la instancia de base de datos primaria. Implementar la aplicación en eu-west-1. Configurar la aplicación para usar el endpoint de RDS para MySQL en eu-west-1.",
            "C. Copiar la instantánea más reciente de la instancia RDS para MySQL a eu-west-1. Crear una nueva instancia de RDS para MySQL en eu-west-1 a partir de la instantánea. Configurar la replicación lógica de MySQL de us-east-1 a eu-west-1. Habilitar el reenvío de escritura en el clúster de base de datos. Implementar la aplicación en eu-west-1. Configurar la aplicación para usar el endpoint de RDS para MySQL en eu-west-1.",
            "D. Convertir la instancia RDS para MySQL en un clúster de Amazon Aurora MySQL. Agregar eu-west-1 como una región secundaria al clúster de base de datos. Habilitar el reenvío de escritura en el clúster de base de datos. Implementar la aplicación en eu-west-1. Configurar la aplicación para usar el endpoint de Aurora MySQL en eu-west-1."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "290.- Una empresa proporciona archivos a sus clientes a través de un servidor SFTP accesible por internet. El servidor SFTP se ejecuta en una única instancia de Amazon EC2 con una dirección IP elástica adjunta. Los clientes se conectan al servidor SFTP a través de su dirección IP elástica y usan SSH para autenticarse. La instancia de EC2 también tiene un grupo de seguridad adjunto que permite el acceso desde todas las direcciones IP de los clientes. Un arquitecto de soluciones debe implementar una solución para mejorar la disponibilidad, minimizar la complejidad de la gestión de la infraestructura y reducir al mínimo la interrupción para los clientes que acceden a los archivos. La solución no debe cambiar la forma en que los clientes se conectan. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Desasociar la dirección IP elástica de la instancia de EC2. Crear un bucket de Amazon S3 para el alojamiento de archivos SFTP. Crear un servidor de AWS Transfer Family. Configurar el servidor de Transfer Family con un endpoint accesible públicamente. Asociar la dirección IP elástica de SFTP con el nuevo endpoint. Apuntar el servidor de Transfer Family al bucket de S3. Sincronizar todos los archivos del servidor SFTP con el bucket de S3.",
            "B. Desasociar la dirección IP elástica de la instancia de EC2. Crear un bucket de Amazon S3 para el alojamiento de archivos SFTP. Crear un servidor de AWS Transfer Family. Configurar el servidor de Transfer Family con un endpoint alojado en la VPC y accesible por internet. Asociar la dirección IP elástica de SFTP con el nuevo endpoint. Adjuntar el grupo de seguridad con las direcciones IP de los clientes al nuevo endpoint. Apuntar el servidor de Transfer Family al bucket de S3. Sincronizar todos los archivos del servidor SFTP con el bucket de S3.",
            "C. Desasociar la dirección IP elástica de la instancia de EC2. Crear un nuevo sistema de archivos Amazon Elastic File System (Amazon EFS) para el alojamiento de archivos SFTP. Crear una definición de tarea de AWS Fargate para ejecutar un servidor SFTP. Especificar el sistema de archivos EFS como un montaje en la definición de tarea. Crear un servicio de Fargate usando la definición de tarea y colocar un Network Load Balancer (NLB) delante del servicio. Al configurar el servicio, adjuntar el grupo de seguridad con las direcciones IP de los clientes a las tareas que ejecutan el servidor SFTP. Asociar la dirección IP elástica con el NLB. Sincronizar todos los archivos del servidor SFTP con el bucket de S3.",
            "D. Desasociar la dirección IP elástica de la instancia de EC2. Crear un volumen Amazon Elastic Block Store (Amazon EBS) de adjunte múltiple para el alojamiento de archivos SFTP. Crear un Network Load Balancer (NLB) con la dirección IP elástica adjunta. Crear un grupo de Auto Scaling con instancias de EC2 que ejecutan un servidor SFTP. Definir en el grupo de Auto Scaling que las instancias lanzadas deben adjuntar el nuevo volumen EBS de adjunte múltiple. Configurar el grupo de Auto Scaling para agregar automáticamente instancias detrás del NLB. Configurar el grupo de Auto Scaling para usar el grupo de seguridad que permite las direcciones IP de los clientes para las instancias de EC2 que lanza el grupo de Auto Scaling. Sincronizar todos los archivos del servidor SFTP con el nuevo volumen EBS de adjunte múltiple."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "291.- Una empresa recibe y procesa datos de mercado en tiempo real. La tasa de datos es constante. Un proceso nocturno que calcula estadísticas agregadas tarda 4 horas en completarse. El análisis estadístico no es crítico para el negocio, y los puntos de datos se procesan en la siguiente iteración si un proceso determinado falla. La arquitectura actual utiliza un conjunto de instancias reservadas de Amazon EC2 con reservas de 1 año. Estas instancias de EC2 funcionan todo el tiempo para recibir y almacenar los datos en tiempo real en volúmenes adjuntos de Amazon Elastic Block Store (Amazon EBS). Un script programado lanza instancias de EC2 On-Demand cada noche para realizar el procesamiento nocturno. Las instancias acceden a los datos almacenados desde comparticiones NFS en los servidores de ingesta. El script termina las instancias cuando el procesamiento se completa. Las reservas de las instancias reservadas están a punto de vencer. La empresa necesita determinar si comprar nuevas reservas o implementar un nuevo diseño. ¿Qué solución cumplirá con estos requisitos de la manera MÁS rentable?",
        "opciones": [
            "A. Actualizar el proceso de ingesta para usar Amazon Kinesis Data Firehose para guardar los datos en Amazon S3. Utilizar un script programado para lanzar un grupo de instancias de EC2 On-Demand cada noche para realizar el procesamiento por lotes de los datos en S3. Configurar el script para terminar las instancias cuando el procesamiento se complete.",
            "B. Actualizar el proceso de ingesta para usar Amazon Kinesis Data Firehose para guardar los datos en Amazon S3. Utilizar AWS Batch con instancias Spot para realizar el procesamiento nocturno con un precio máximo de Spot que sea un 50% del precio On-Demand.",
            "C. Actualizar el proceso de ingesta para usar un conjunto de instancias reservadas de EC2 con reservas de 3 años detrás de un Network LoadBalancer. Utilizar AWS Batch con instancias Spot para realizar el procesamiento nocturno con un precio máximo de Spot que sea un 50% del precio On-Demand.",
            "D. Actualizar el proceso de ingesta para usar Amazon Kinesis Data Firehose para guardar los datos en Amazon Redshift. Utilizar Amazon EventBridge para programar una función de AWS Lambda para ejecutarse cada noche para consultar Amazon Redshift y generar las estadísticas diarias."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "292.- Una empresa necesita migrar un sitio SFTP local a AWS. El sitio SFTP actualmente se ejecuta en una máquina virtual Linux. Los archivos cargados están disponibles para aplicaciones posteriores a través de un recurso compartido NFS. Como parte de la migración a AWS, un arquitecto de soluciones debe implementar alta disponibilidad. La solución debe proporcionar a los proveedores externos un conjunto de direcciones IP públicas estáticas que los proveedores puedan permitir. La empresa ha configurado una conexión AWS Direct Connect entre su centro de datos local y su VPC. ¿Qué solución cumplirá con estos requisitos con el MENOR esfuerzo operativo?",
        "opciones": [
            "A. Crear un servidor AWS Transfer Family. Configurar un punto final de VPC accesible por Internet para el servidor de Transfer Family. Especificar una dirección IP elástica para cada subred. Configurar el servidor de Transfer Family para colocar los archivos en un sistema de archivos de Amazon Elastic File System (Amazon EFS) desplegado en múltiples Zonas de Disponibilidad. Modificar la configuración de las aplicaciones posteriores que acceden al recurso compartido NFS existente para montar el punto final de EFS en su lugar.",
            "B. Crear un servidor AWS Transfer Family. Configurar un punto final accesible públicamente para el servidor de Transfer Family. Configurar el servidor de Transfer Family para colocar los archivos en un sistema de archivos de Amazon Elastic File System (Amazon EFS) desplegado en múltiples Zonas de Disponibilidad. Modificar la configuración de las aplicaciones posteriores que acceden al recurso compartido NFS existente para montar el punto final de EFS en su lugar.",
            "C. Usar el Servicio de Migración de Aplicaciones de AWS para migrar la máquina virtual Linux existente a una instancia de Amazon EC2. Asignar una dirección IP elástica a la instancia EC2. Montar un sistema de archivos de Amazon Elastic File System (Amazon EFS) en la instancia EC2. Configurar el servidor SFTP para colocar los archivos en el sistema de archivos EFS. Modificar la configuración de las aplicaciones posteriores que acceden al recurso compartido NFS existente para montar el punto final de EFS en su lugar.",
            "D. Usar el Servicio de Migración de Aplicaciones de AWS para migrar la máquina virtual Linux existente a un servidor AWS Transfer Family. Configurar un punto final accesible públicamente para el servidor de Transfer Family. Configurar el servidor de Transfer Family para colocar los archivos en un sistema de archivos Amazon FSx for Lustre desplegado en múltiples Zonas de Disponibilidad. Modificar la configuración de las aplicaciones posteriores que acceden al recurso compartido NFS existente para montar el punto final de FSx for Lustre en su lugar."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "293.- Un arquitecto de soluciones tiene una carga de trabajo operativa desplegada en instancias de Amazon EC2 en un grupo de Auto Scaling. La arquitectura de la VPC abarca dos zonas de disponibilidad (AZ) con una subred en cada una, que el grupo de Auto Scaling está utilizando. La VPC está conectada a un entorno local y la conectividad no puede interrumpirse. El tamaño máximo del grupo de Auto Scaling es de 20 instancias en servicio. La asignación de direcciones IPv4 de la VPC es la siguiente: CIDR de la VPC: 10.0.0.0/23 CIDR de la subred AZ1: 10.0.0.0/24 CIDR de la subred AZ2: 10.0.1.0/24 Desde el despliegue, una tercera zona de disponibilidad ha quedado disponible en la región. El arquitecto de soluciones quiere adoptar la nueva AZ sin agregar espacio adicional de direcciones IPv4 y sin tiempo de inactividad del servicio. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Actualice el grupo de Auto Scaling para que utilice solo la subred AZ2. Elimine y vuelva a crear la subred AZ1 utilizando la mitad del espacio de direcciones original. Ajuste el grupo de Auto Scaling para que también utilice la nueva subred AZ1. Cuando las instancias estén sanas, ajuste el grupo de Auto Scaling para usar solo la subred AZ1. Elimine la subred actual de AZ2. Cree una nueva subred AZ2 utilizando la segunda mitad del espacio de direcciones de la subred original de AZ1. Cree una nueva subred AZ3 utilizando la mitad del espacio de direcciones original de la subred AZ2, luego actualice el grupo de Auto Scaling para que apunte a las tres nuevas subredes.",
            "B. Termine las instancias de EC2 en la subred AZ1. Elimine y vuelva a crear la subred AZ1 utilizando la mitad del espacio de direcciones. Actualice el grupo de Auto Scaling para utilizar esta nueva subred. Repita este proceso para la segunda AZ. Defina una nueva subred en AZ3, luego actualice el grupo de Auto Scaling para que apunte a las tres nuevas subredes.",
            "C. Cree una nueva VPC con el mismo espacio de direcciones IPv4 y defina tres subredes, una para cada AZ. Actualice el grupo de Auto Scaling existente para que apunte a las nuevas subredes de la nueva VPC.",
            "D. Actualice el grupo de Auto Scaling para que utilice solo la subred AZ2. Actualice la subred AZ1 para que tenga la mitad del espacio de direcciones original. Ajuste el grupo de Auto Scaling para que también utilice nuevamente la subred AZ1. Cuando las instancias estén sanas, ajuste el grupo de Auto Scaling para usar solo la subred AZ1. Actualice la subred actual de AZ2 y asigne la segunda mitad del espacio de direcciones de la subred original de AZ1. Cree una nueva subred AZ3 utilizando la mitad del espacio de direcciones original de la subred AZ2, luego actualice el grupo de Auto Scaling para que apunte a las tres nuevas subredes."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "294.- Una empresa usa una organización en AWS Organizations para gestionar las cuentas de AWS de la empresa. La empresa usa AWS CloudFormation para desplegar toda la infraestructura. Un equipo de finanzas quiere construir un modelo de asignación de costos. El equipo de finanzas pidió a cada unidad de negocio que etiquetara los recursos usando una lista predefinida de valores de proyecto. Cuando el equipo de finanzas usó el Informe de Costos y Uso en AWS Cost Explorer y filtró según el proyecto, el equipo notó valores de proyecto no conformes. La empresa quiere hacer cumplir el uso de etiquetas de proyecto para nuevos recursos. ¿Qué solución cumplirá con estos requisitos con el MENOR esfuerzo?",
        "opciones": [
            "A. Crear una política de etiquetas que contenga los valores permitidos de la etiqueta de proyecto en la cuenta de administración de la organización. Crear una SCP que deniegue la operación API “cloudformation:CreateStack” a menos que se agregue una etiqueta de proyecto. Adjuntar la SCP a cada OU.",
            "B. Crear una política de etiquetas que contenga los valores permitidos de la etiqueta de proyecto en cada OU. Crear una SCP que deniegue la operación API “cloudformation:CreateStack” a menos que se agregue una etiqueta de proyecto. Adjuntar la SCP a cada OU.",
            "C. Crear una política de etiquetas que contenga los valores permitidos de la etiqueta de proyecto en la cuenta de administración de AWS. Crear una política IAM que deniegue la operación API “cloudformation:CreateStack” a menos que se agregue una etiqueta de proyecto. Asignar la política a cada usuario.",
            "D. Usar AWS Service Catalog para gestionar los stacks de CloudFormation como productos. Usar una biblioteca TagOptions para controlar los valores de las etiquetas de proyecto. Compartir el portafolio con todas las OU que están en la organización."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "295.- Una aplicación está desplegada en instancias de Amazon EC2 que se ejecutan en un grupo de Auto Scaling. La configuración del grupo de Auto Scaling utiliza solo un tipo de instancia. Las métricas de utilización de CPU y memoria muestran que las instancias están infrautilizadas. Un arquitecto de soluciones necesita implementar una solución para reducir permanentemente el costo de EC2 y aumentar la utilización. ¿Cuál solución cumplirá con estos requisitos con la MENOR cantidad de cambios en la configuración en el futuro?",
        "opciones": [
            "A. Listar los tipos de instancias que tienen propiedades similares a las propiedades que tienen las instancias actuales. Modificar la configuración de la plantilla de lanzamiento del grupo de Auto Scaling para usar múltiples tipos de instancias de la lista.",
            "B. Utilizar la información sobre la utilización de CPU y memoria de la aplicación para seleccionar un tipo de instancia que coincida con los requisitos. Modificar la configuración del grupo de Auto Scaling agregando el nuevo tipo de instancia. Eliminar el tipo de instancia actual de la configuración.",
            "C. Utilizar la información sobre la utilización de CPU y memoria de la aplicación para especificar los requisitos de CPU y memoria en una nueva revisión de la plantilla de lanzamiento del grupo de Auto Scaling. Eliminar el tipo de instancia actual de la configuración.",
            "D. Crear un script que seleccione los tipos de instancias apropiadas de la API de Lista de Precios en Masa de AWS. Usar los tipos de instancias seleccionados para crear una nueva revisión de la plantilla de lanzamiento del grupo de Auto Scaling."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "296.- Una empresa implementa una aplicación contenerizada utilizando Amazon Elastic Container Service (Amazon ECS) y Amazon API Gateway. Los datos de la aplicación se almacenan en bases de datos Amazon Aurora y Amazon DynamoDB. La empresa automatiza la provisión de infraestructura utilizando AWS CloudFormation. La empresa automatiza el despliegue de la aplicación utilizando AWS CodePipeline. Un arquitecto de soluciones debe implementar una estrategia de recuperación ante desastres (DR) que cumpla con un RPO de 2 horas y un RTO de 4 horas. ¿Cuál de las siguientes soluciones cumplirá con estos requisitos de la manera más rentable?",
        "opciones": [
            "A. Configurar una base de datos global de Aurora y tablas globales de DynamoDB para replicar las bases de datos a una región secundaria de AWS. En la región primaria y en la región secundaria, configurar una API de API Gateway con un endpoint regional. Implementar Amazon CloudFront con conmutación por error de origen para dirigir el tráfico a la región secundaria durante un escenario de DR.",
            "B. Utilizar AWS Database Migration Service (AWS DMS), Amazon EventBridge y AWS Lambda para replicar las bases de datos de Aurora a una región secundaria de AWS. Utilizar DynamoDB Streams, EventBridge y Lambda para replicar las bases de datos de DynamoDB a la región secundaria. En la región primaria y en la región secundaria, configurar una API de API Gateway con un endpoint regional. Implementar el enrutamiento por conmutación por error de Amazon Route 53 para cambiar el tráfico de la región primaria a la región secundaria.",
            "C. Utilizar AWS Backup para crear copias de seguridad de las bases de datos de Aurora y DynamoDB en una región secundaria de AWS. En la región primaria y en la región secundaria, configurar una API de API Gateway con un endpoint regional. Implementar el enrutamiento por conmutación por error de Amazon Route 53 para cambiar el tráfico de la región primaria a la región secundaria.",
            "D. Configurar una base de datos global de Aurora y tablas globales de DynamoDB para replicar las bases de datos a una región secundaria de AWS. En la región primaria y en la región secundaria, configurar una API de API Gateway con un endpoint regional. Implementar el enrutamiento por conmutación por error de Amazon Route 53 para cambiar el tráfico de la región primaria a la región secundaria."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "297.- Una empresa tiene una aplicación web compleja que utiliza Amazon CloudFront para escalabilidad global y rendimiento. Con el tiempo, los usuarios informan que la aplicación web se está ralentizando. El equipo de operaciones de la empresa informa que la tasa de aciertos en la caché de CloudFront ha ido cayendo constantemente. El informe de métricas de la caché indica que las cadenas de consulta en algunas URLs no están ordenadas de manera consistente y se especifican algunas veces en letras mayúsculas y otras veces en minúsculas. ¿Qué conjunto de acciones debe tomar el arquitecto de soluciones para aumentar la tasa de aciertos de la caché lo más rápido posible?",
        "opciones": [
            "A. Desplegar una función Lambda@Edge para ordenar los parámetros por nombre y forzarlos a ser minúsculas. Seleccionar el disparador de solicitud del visor de CloudFront para invocar la función.",
            "B. Actualizar la distribución de CloudFront para desactivar la caché basada en parámetros de la cadena de consulta.",
            "C. Desplegar un proxy inverso después del balanceador de carga para postprocesar las URLs emitidas en la aplicación y forzar que las cadenas de URL sean minúsculas.",
            "D. Actualizar la distribución de CloudFront para especificar un procesamiento de cadenas de consulta insensible a mayúsculas."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "298.- Una empresa ejecuta una aplicación de comercio electrónico en una única región de AWS. La aplicación utiliza un clúster de base de datos Amazon Aurora MySQL de cinco nodos para almacenar información sobre los clientes y sus pedidos recientes. El clúster de la base de datos experimenta una gran cantidad de transacciones de escritura durante todo el día. La empresa necesita replicar los datos en la base de datos Aurora a otra región para cumplir con los requisitos de recuperación ante desastres. La empresa tiene un RPO de 1 hora. ¿Qué solución cumplirá con estos requisitos con el COSTO MÁS BAJO?",
        "opciones": [
            "A. Modificar la base de datos Aurora para que sea una base de datos global de Aurora. Crear una segunda base de datos Aurora en otra región.",
            "B. Habilitar la función de retroceso (Backtrack) para la base de datos Aurora. Crear una función AWS Lambda que se ejecute diariamente para copiar las instantáneas de la base de datos a una región de respaldo.",
            "C. Usar el Servicio de Migración de Bases de Datos de AWS (AWS DMS). Crear una tarea de captura de datos de cambios (CDC) de DMS que replique los cambios continuos de la base de datos Aurora a un bucket de Amazon S3 en otra región.",
            "D. Apagar las copias de seguridad automatizadas de Aurora. Configurar las copias de seguridad de Aurora con una frecuencia de copia de seguridad de 1 hora. Especificar otra región como la región de destino. Seleccionar la base de datos Aurora como el recurso asignado."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "299.- Un arquitecto de soluciones de una empresa está evaluando una carga de trabajo de AWS que se implementó hace varios años. El nivel de la aplicación no tiene estado y se ejecuta en una sola instancia de Amazon EC2 grande que se lanzó desde una AMI. La aplicación almacena datos en una base de datos MySQL que se ejecuta en una sola instancia de EC2. La utilización de CPU en la instancia del servidor de aplicaciones EC2 a menudo alcanza el 100% y causa que la aplicación deje de responder. La empresa instala manualmente los parches en las instancias. La instalación de parches ha causado tiempo de inactividad en el pasado. La empresa necesita hacer que la aplicación sea altamente disponible. ¿Qué solución cumplirá con estos requisitos con el MENOR esfuerzo de desarrollo?",
        "opciones": [
            "A. Mover el nivel de la aplicación a funciones de AWS Lambda en la VPC existente. Crear un Balanceador de Carga de Aplicación para distribuir el tráfico entre las funciones Lambda. Usar Amazon GuardDuty para escanear las funciones Lambda. Migrar la base de datos a Amazon DocumentDB (compatible con MongoDB).",
            "B. Cambiar el tipo de instancia de EC2 a un tipo de instancia más pequeño basado en Graviton. Usar la AMI existente para crear una plantilla de lanzamiento para un grupo de Auto Scaling. Crear un Balanceador de Carga de Aplicación para distribuir el tráfico entre las instancias en el grupo de Auto Scaling. Configurar el grupo de Auto Scaling para escalar según la utilización de la CPU. Migrar la base de datos a Amazon DynamoDB.",
            "C. Mover el nivel de la aplicación a contenedores utilizando Docker. Ejecutar los contenedores en Amazon Elastic Container Service (Amazon ECS) con instancias de EC2. Crear un Balanceador de Carga de Aplicación para distribuir el tráfico entre el clúster ECS. Configurar el clúster ECS para escalar según la utilización de la CPU. Migrar la base de datos a Amazon Neptune.",
            "D. Crear una nueva AMI configurada con AWS Systems Manager Agent (SSM Agent). Usar la nueva AMI para crear una plantilla de lanzamiento para un grupo de Auto Scaling. Usar instancias más pequeñas en el grupo de Auto Scaling. Crear un Balanceador de Carga de Aplicación para distribuir el tráfico entre las instancias en el grupo de Auto Scaling. Configurar el grupo de Auto Scaling para escalar según la utilización de la CPU. Migrar la base de datos a Amazon Aurora MySQL."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "300.- Una empresa está planeando migrar varias aplicaciones a AWS. La empresa no tiene un buen entendimiento de toda su infraestructura de aplicaciones. La infraestructura consiste en una mezcla de máquinas físicas y máquinas virtuales (VMs). Una de las aplicaciones que la empresa migrará tiene muchas dependencias que son sensibles a la latencia. La empresa no está segura de cuáles son todas las dependencias. Sin embargo, sabe que las comunicaciones de baja latencia usan un protocolo basado en IP personalizado que corre en el puerto 1000. La empresa quiere migrar la aplicación y estas dependencias juntas para mover todas las interfaces de baja latencia a AWS al mismo tiempo. La empresa ha instalado el AWS Application Discovery Agent y ha estado recolectando datos durante varios meses. ¿Qué debe hacer la empresa para identificar las dependencias que deben migrarse en la misma fase que la aplicación?",
        "opciones": [
            "A. Usar AWS Migration Hub y seleccionar los servidores que alojan la aplicación. Visualizar el gráfico de red para encontrar los servidores que interactúan con la aplicación. Activar la exploración de datos en Amazon Athena. Consultar los datos que se transfieren entre los servidores para identificar los servidores que se comunican en el puerto 1000. Volver a Migration Hub. Crear un grupo de movimiento basado en los hallazgos de las consultas de Athena.",
            "B. Usar AWS Application Migration Service y seleccionar los servidores que alojan la aplicación. Visualizar el gráfico de red para encontrar los servidores que interactúan con la aplicación. Configurar Application Migration Service para lanzar instancias de prueba para todos los servidores que interactúan con la aplicación. Realizar pruebas de aceptación en las instancias de prueba. Si no se identifican problemas, crear un grupo de movimiento basado en los servidores probados.",
            "C. Usar AWS Migration Hub y seleccionar los servidores que alojan la aplicación. Activar la exploración de datos en Network Access Analyzer. Usar la consola de Network Access Analyzer para seleccionar los servidores que alojan la aplicación. Seleccionar un alcance de red del puerto 1000 y tomar nota de los servidores que coinciden. Volver a Migration Hub. Crear un grupo de movimiento basado en los hallazgos de Network Access Analyzer.",
            "D. Usar AWS Migration Hub y seleccionar los servidores que alojan la aplicación. Empujar el agente de Amazon CloudWatch a los servidores identificados usando el AWS Application Discovery Agent. Exportar los logs de CloudWatch que los agentes recojan a Amazon S3. Usar Amazon Athena para consultar los logs y encontrar los servidores que se comunican en el puerto 1000. Volver a Migration Hub. Crear un grupo de movimiento basado en los hallazgos de las consultas de Athena."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "301.- Una empresa está construyendo una aplicación que se ejecutará en una función de AWS Lambda. Cientos de clientes utilizarán la aplicación. La empresa quiere asignar a cada cliente una cuota de solicitudes para un período de tiempo específico. Las cuotas deben coincidir con los patrones de uso de los clientes. Algunos clientes deben recibir una cuota más alta para un período de tiempo más corto. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Crear una API REST de Amazon API Gateway con una integración de proxy para invocar la función Lambda. Para cada cliente, configurar un plan de uso de API Gateway que incluya una cuota de solicitudes apropiada. Crear una clave de API a partir del plan de uso para cada usuario que el cliente necesite.",
            "B. Crear una API HTTP de Amazon API Gateway con una integración de proxy para invocar la función Lambda. Para cada cliente, configurar un plan de uso de API Gateway que incluya una cuota de solicitudes apropiada. Configurar la limitación de velocidad a nivel de ruta para cada plan de uso. Crear una clave de API a partir del plan de uso para cada usuario que el cliente necesite.",
            "C. Crear un alias de función Lambda para cada cliente. Incluir un límite de concurrencia con una cuota de solicitudes apropiada. Crear una URL de función Lambda para cada alias de función. Compartir la URL de la función Lambda para cada alias con el cliente relevante.",
            "D. Crear un Application Load Balancer (ALB) en una VPC. Configurar la función Lambda como un objetivo para el ALB. Configurar un ACL web de AWS WAF para el ALB. Para cada cliente, configurar una regla basada en rutas que incluya una cuota de solicitudes apropiada."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "302.- Una empresa está planeando migrar su clúster VMware local de 120 máquinas virtuales (VM) a AWS. Las VMs tienen diferentes sistemas operativos y muchos paquetes de software personalizados instalados. La empresa también tiene un servidor NFS local de 10 TB de tamaño. La empresa ha configurado una conexión de AWS Direct Connect de 10 Gbps a AWS para la migración. ¿Qué solución completará la migración a AWS en el MENOR tiempo posible?",
        "opciones": [
            "A. Exportar las VMs locales y copiarlas a un bucket de Amazon S3. Usar VM Import/Export para crear AMIs a partir de las imágenes de las VMs almacenadas en Amazon S3. Pedir un dispositivo AWS Snowball Edge. Copiar los datos del servidor NFS al dispositivo. Restaurar los datos del servidor NFS a una instancia de Amazon EC2 que tenga NFS configurado.",
            "B. Configurar AWS Application Migration Service con una conexión al clúster VMware. Crear un trabajo de replicación para las VMs. Crear un sistema de archivos Amazon Elastic File System (Amazon EFS). Configurar AWS DataSync para copiar los datos del servidor NFS al sistema de archivos EFS a través de la conexión Direct Connect.",
            "C. Recrear las VMs en AWS como instancias de Amazon EC2. Instalar todos los paquetes de software necesarios. Crear un sistema de archivos Amazon FSx for Lustre. Configurar AWS DataSync para copiar los datos del servidor NFS al sistema de archivos FSx for Lustre a través de la conexión Direct Connect.",
            "D. Pedir dos dispositivos AWS Snowball Edge. Copiar las VMs y los datos del servidor NFS a los dispositivos. Ejecutar VM Import/Export después de que los datos de los dispositivos se carguen en un bucket de Amazon S3. Crear un sistema de archivos Amazon Elastic File System (Amazon EFS). Copiar los datos del servidor NFS desde Amazon S3 al sistema de archivos EFS."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "303.- Una empresa de encuestas en línea ejecuta su aplicación en la nube de AWS. La aplicación está distribuida y consiste en microservicios que se ejecutan en un clúster de Amazon Elastic Container Service (Amazon ECS) que se escala automáticamente. El clúster de ECS es un destino para un Application Load Balancer (ALB). El ALB es un origen personalizado para una distribución de Amazon CloudFront. La empresa tiene una encuesta que contiene datos sensibles. Los datos sensibles deben ser cifrados cuando se muevan a través de la aplicación. El microservicio de manejo de datos de la aplicación es el único microservicio que debe poder descifrar los datos. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Cree una clave simétrica de AWS Key Management Service (AWS KMS) que esté dedicada al microservicio de manejo de datos. Cree un perfil de cifrado a nivel de campo y una configuración. Asocie la clave KMS y la configuración con el comportamiento de caché de CloudFront.",
            "B. Cree un par de claves RSA que esté dedicado al microservicio de manejo de datos. Cargue la clave pública a la distribución de CloudFront. Cree un perfil de cifrado a nivel de campo y una configuración. Agregue la configuración al comportamiento de caché de CloudFront.",
            "C. Cree una clave simétrica de AWS Key Management Service (AWS KMS) que esté dedicada al microservicio de manejo de datos. Cree una función Lambda@Edge. Programe la función para que utilice la clave KMS para cifrar los datos sensibles.",
            "D. Cree un par de claves RSA que esté dedicado al microservicio de manejo de datos. Cree una función Lambda@Edge. Programe la función para que utilice la clave privada del par de claves RSA para cifrar los datos sensibles."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "304.- Un arquitecto de soluciones está determinando la estrategia DNS para una VPC existente. La VPC está provisionada para usar el bloque CIDR 10.24.34.0/24. La VPC también utiliza Amazon Route 53 Resolver para DNS. Los nuevos requisitos exigen que las consultas DNS deben usar zonas hospedadas privadas. Además, las instancias que tienen direcciones IP públicas deben recibir nombres de host públicos correspondientes. ¿Qué solución cumplirá con estos requisitos para asegurar que los nombres de dominio se resuelvan correctamente dentro de la VPC?",
        "opciones": [
            "A. Crear una zona hospedada privada. Activar el atributo enableDnsSupport y el atributo enableDnsHostnames para la VPC. Actualizar el conjunto de opciones DHCP de la VPC para incluir domain-name-servers=10.24.34.2.",
            "B. Crear una zona hospedada privada. Asociar la zona hospedada privada con la VPC. Activar el atributo enableDnsSupport y el atributo enableDnsHostnames para la VPC. Crear un nuevo conjunto de opciones DHCP para la VPC, y configurar domain-name-servers=AmazonProvidedDNS. Asociar el nuevo conjunto de opciones DHCP con la VPC.",
            "C. Desactivar el atributo enableDnsSupport para la VPC. Activar el atributo enableDnsHostnames para la VPC. Crear un nuevo conjunto de opciones DHCP para la VPC, y configurar domain-name-servers=10.24.34.2. Asociar el nuevo conjunto de opciones DHCP con la VPC.",
            "D. Crear una zona hospedada privada. Asociar la zona hospedada privada con la VPC. Activar el atributo enableDnsSupport para la VPC. Desactivar el atributo enableDnsHostnames para la VPC. Actualizar el conjunto de opciones DHCP de la VPC para incluir domain-name-servers=AmazonProvidedDNS."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "305.- Una empresa de análisis de datos tiene un clúster de Amazon Redshift que consta de varios nodos reservados. El clúster está experimentando picos inesperados de uso porque un equipo de empleados está compilando un informe de análisis de auditoría profundo. Las consultas para generar el informe son consultas de lectura complejas y son intensivas en CPU. Los requisitos comerciales dictan que el clúster debe ser capaz de atender consultas de lectura y escritura en todo momento. Un arquitecto de soluciones debe idear una solución que acomode los picos de uso. ¿Cuál solución cumple con estos requisitos de la manera MÁS rentable?",
        "opciones": [
            "A. Provisionar un clúster de Amazon EMR y transferir las tareas complejas de procesamiento de datos.",
            "B. Implementar una función de AWS Lambda para agregar capacidad al clúster de Amazon Redshift mediante una operación de redimensionamiento clásico cuando las métricas de CPU del clúster en Amazon CloudWatch alcancen el 80%.",
            "C. Implementar una función de AWS Lambda para agregar capacidad al clúster de Amazon Redshift mediante una operación de redimensionamiento elástico cuando las métricas de CPU del clúster en Amazon CloudWatch alcancen el 80%.",
            "D. Activar la función de Escalado de Concurrencia para el clúster de Amazon Redshift."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "306.- Un centro de investigación está migrando a la nube de AWS y ha trasladado su almacenamiento de objetos de 1 PB desde las instalaciones locales a un bucket de Amazon S3. Cien científicos están utilizando este almacenamiento de objetos para guardar sus documentos relacionados con el trabajo. Cada científico tiene una carpeta personal en el almacenamiento de objetos. Todos los científicos son miembros de un único grupo de usuarios de IAM. El oficial de cumplimiento del centro de investigación está preocupado porque los científicos podrán acceder al trabajo de los demás. El centro de investigación tiene la obligación estricta de informar sobre qué científico accede a qué documentos. El equipo responsable de estos informes tiene poca experiencia en AWS y busca una solución lista para usar que minimice la sobrecarga operativa. ¿Qué combinación de acciones debe tomar un arquitecto de soluciones para cumplir con estos requisitos? (Elija dos.)",
        "opciones": [
            "A. Crear una política de identidad que otorgue acceso de lectura y escritura. Añadir una condición que especifique que las rutas de S3 deben comenzar con $(aws:username). Aplicar la política en el grupo de usuarios de IAM de los científicos.",
            "B. Configurar una pista con AWS CloudTrail para capturar todos los eventos a nivel de objeto en el bucket de S3. Almacenar la salida de la pista en otro bucket de S3. Usar Amazon Athena para consultar los registros y generar informes.",
            "C. Habilitar el registro de acceso del servidor S3. Configurar otro bucket de S3 como destino para la entrega de los registros. Usar Amazon Athena para consultar los registros y generar informes.",
            "D. Crear una política de bucket de S3 que otorgue acceso de lectura y escritura a los usuarios del grupo de usuarios de IAM de los científicos.",
            "E. Configurar una pista con AWS CloudTrail para capturar todos los eventos a nivel de objeto en el bucket de S3 y escribir los eventos en Amazon CloudWatch. Usar el conector de CloudWatch de Amazon Athena para consultar los registros y generar informes."
        ],
        "respuestas_correctas": [
            "B",
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "307.- Una empresa utiliza AWS Organizations para gestionar una estructura multi-cuenta. La empresa tiene cientos de cuentas de AWS y espera que el número de cuentas aumente. La empresa está desarrollando una nueva aplicación que utiliza imágenes Docker. La empresa empujará las imágenes Docker a Amazon Elastic Container Registry (Amazon ECR). Solo las cuentas dentro de la organización de la empresa deberían tener acceso a las imágenes. La empresa tiene un proceso de CI/CD que se ejecuta con frecuencia. La empresa quiere conservar todas las imágenes etiquetadas. Sin embargo, la empresa solo quiere conservar las cinco imágenes sin etiquetar más recientes. ¿Qué solución cumplirá con estos requisitos con el MENOR esfuerzo operativo?",
        "opciones": [
            "A. Crear un repositorio privado en Amazon ECR. Crear una política de permisos para el repositorio que permita solo las operaciones ECR requeridas. Incluir una condición para permitir las operaciones ECR si el valor de la clave de condición aws:PrincipalOrglD es igual al ID de la organización de la empresa. Agregar una regla de ciclo de vida al repositorio ECR que elimine todas las imágenes no etiquetadas que superen la cantidad de cinco.",
            "B. Crear un repositorio público en Amazon ECR. Crear un rol IAM en la cuenta ECR. Establecer permisos para que cualquier cuenta pueda asumir el rol si el valor de la clave de condición aws:PrincipalOrglD es igual al ID de la organización de la empresa. Agregar una regla de ciclo de vida al repositorio ECR que elimine todas las imágenes no etiquetadas que superen la cantidad de cinco.",
            "C. Crear un repositorio privado en Amazon ECR. Crear una política de permisos para el repositorio que incluya solo las operaciones ECR requeridas. Incluir una condición para permitir las operaciones ECR para todos los ID de cuentas en la organización. Programar una regla diaria de Amazon EventBridge para invocar una función AWS Lambda que elimine todas las imágenes no etiquetadas que superen la cantidad de cinco.",
            "D. Crear un repositorio público en Amazon ECR. Configurar Amazon ECR para usar un punto de enlace VPC de interfaz con una política de punto de enlace que incluya los permisos requeridos para las imágenes que la empresa necesita extraer. Incluir una condición para permitir las operaciones ECR para todos los ID de cuentas en la organización de la empresa. Programar una regla diaria de Amazon EventBridge para invocar una función AWS Lambda que elimine todas las imágenes no etiquetadas que superen la cantidad de cinco."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "308.- Un arquitecto de soluciones está revisando el proceso de una empresa para tomar instantáneas de las instancias de bases de datos de Amazon RDS. La empresa toma instantáneas automáticas todos los días y conserva las instantáneas durante 7 días. El arquitecto de soluciones necesita recomendar una solución que tome instantáneas cada 6 horas y conserve las instantáneas durante 30 días. La empresa usa AWS Organizations para administrar todas sus cuentas de AWS. La empresa necesita una vista consolidada de la salud de las instantáneas de RDS. ¿Qué solución cumplirá con estos requisitos con el MENOR esfuerzo operativo?",
        "opciones": [
            "A. Activar la función de administración entre cuentas en AWS Backup. Crear un plan de respaldo que especifique los requisitos de frecuencia y retención. Agregar una etiqueta a las instancias de DB. Aplicar el plan de respaldo usando etiquetas. Usar AWS Backup para monitorear el estado de las copias de seguridad.",
            "B. Activar la función de administración entre cuentas en Amazon RDS. Crear una política global de instantáneas que especifique los requisitos de frecuencia y retención. Usar la consola de RDS en la cuenta de administración para monitorear el estado de las copias de seguridad.",
            "C. Activar la función de administración entre cuentas en AWS CloudFormation. Desde la cuenta de administración, desplegar un conjunto de pilas de CloudFormation que contenga un plan de respaldo de AWS Backup que especifique los requisitos de frecuencia y retención. Crear una función AWS Lambda en la cuenta de administración para monitorear el estado de las copias de seguridad. Crear una regla de Amazon EventBridge en cada cuenta para ejecutar la función Lambda en un horario.",
            "D. Configurar AWS Backup en cada cuenta. Crear una política de ciclo de vida de Amazon Data Lifecycle Manager que especifique los requisitos de frecuencia y retención. Especificar las instancias de DB como el recurso objetivo. Usar la consola de Amazon Data Lifecycle Manager en cada cuenta miembro para monitorear el estado de las copias de seguridad."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "309.- Una empresa está utilizando AWS Organizations con una arquitectura de múltiples cuentas. La configuración de seguridad actual de la empresa para la arquitectura de cuentas incluye SCPs, políticas basadas en recursos, políticas basadas en identidades, políticas de confianza y políticas de sesión. Un arquitecto de soluciones necesita permitir que un usuario IAM en la Cuenta A asuma un rol en la Cuenta B. ¿Qué combinación de pasos debe seguir el arquitecto de soluciones para cumplir con este requisito? (Elija tres).",
        "opciones": [
            "A. Configurar el SCP para la Cuenta A para permitir la acción.",
            "B. Configurar las políticas basadas en recursos para permitir la acción.",
            "C. Configurar la política basada en identidades en el usuario de la Cuenta A para permitir la acción.",
            "D. Configurar la política basada en identidades en el usuario de la Cuenta B para permitir la acción.",
            "E. Configurar la política de confianza en el rol de destino en la Cuenta B para permitir la acción.",
            "F. Configurar la política de sesión para permitir la acción y ser pasada programáticamente mediante la operación GetSessionToken de la API."
        ],
        "respuestas_correctas": [
            "C",
            "E",
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "310.- Una empresa quiere usar Amazon S3 para hacer una copia de seguridad de su solución de almacenamiento de archivos local. La solución de almacenamiento de archivos local de la empresa es compatible con NFS, y la empresa quiere que su nueva solución también sea compatible con NFS. La empresa desea archivar los archivos de respaldo después de 5 días. Si la empresa necesita archivos archivados para recuperación ante desastres, está dispuesta a esperar unos días para la recuperación de esos archivos. ¿Qué solución cumple con estos requisitos de manera MÁS rentable?",
        "opciones": [
            "A. Implementar un AWS Storage Gateway file gateway asociado con un bucket de S3. Mover los archivos de la solución de almacenamiento de archivos local al file gateway. Crear una regla de ciclo de vida de S3 para mover los archivos a S3 Standard-Infrequent Access (S3 Standard-IA) después de 5 días.",
            "B. Implementar un AWS Storage Gateway volume gateway asociado con un bucket de S3. Mover los archivos de la solución de almacenamiento de archivos local al volume gateway. Crear una regla de ciclo de vida de S3 para mover los archivos a S3 Glacier Deep Archive después de 5 días.",
            "C. Implementar un AWS Storage Gateway tape gateway asociado con un bucket de S3. Mover los archivos de la solución de almacenamiento de archivos local al tape gateway. Crear una regla de ciclo de vida de S3 para mover los archivos a S3 Standard-Infrequent Access (S3 Standard-IA) después de 5 días.",
            "D. Implementar un AWS Storage Gateway file gateway asociado con un bucket de S3. Mover los archivos de la solución de almacenamiento de archivos local al file gateway. Crear una regla de ciclo de vida de S3 para mover los archivos a S3 Glacier Deep Archive después de 5 días."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "311.- Una empresa ejecuta su aplicación en instancias de Amazon EC2 y funciones de AWS Lambda. Las instancias de EC2 experimentan una carga continua y estable. Las funciones de Lambda experimentan una carga variable e impredecible. La aplicación incluye una capa de caché que utiliza un clúster de Amazon MemoryDB para Redis. Un arquitecto de soluciones debe recomendar una solución para minimizar los costos mensuales generales de la empresa. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Comprar un Plan de Ahorros de instancias de EC2 para cubrir las instancias de EC2. Comprar un Plan de Ahorros de Cómputo para Lambda para cubrir el consumo mínimo esperado de las funciones de Lambda. Comprar nodos reservados para cubrir los nodos de la caché de MemoryDB.",
            "B. Comprar un Plan de Ahorros de Cómputo para cubrir las instancias de EC2. Comprar concurrencia reservada de Lambda para cubrir el uso esperado de Lambda. Comprar nodos reservados para cubrir los nodos de la caché de MemoryDB.",
            "C. Comprar un Plan de Ahorros de Cómputo para cubrir todo el costo esperado de las instancias de EC2, las funciones de Lambda y los nodos de la caché de MemoryDB.",
            "D. Comprar un Plan de Ahorros de Cómputo para cubrir las instancias de EC2 y los nodos de la caché de MemoryDB. Comprar concurrencia reservada de Lambda para cubrir el uso esperado de Lambda."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "312.- Una empresa está lanzando un nuevo juego en línea en instancias de Amazon EC2. El juego debe estar disponible globalmente. La empresa planea ejecutar el juego en tres regiones de AWS: us-east-1, eu-west-1 y ap-southeast-1. Los tableros de líderes del juego, el inventario de los jugadores y el estado de los eventos deben estar disponibles en todas las regiones. Un arquitecto de soluciones debe diseñar una solución que dé a cualquier región la capacidad de escalar para manejar la carga de todas las regiones. Además, los usuarios deben conectarse automáticamente a la región que ofrezca la menor latencia. ¿Qué solución cumplirá con estos requisitos con el MENOR esfuerzo operativo?",
        "opciones": [
            "A. Crear una EC2 Spot Fleet. Adjuntar la Spot Fleet a un Network Load Balancer (NLB) en cada región. Crear una dirección IP de AWS Global Accelerator que apunte al NLB. Crear una entrada de enrutamiento basada en latencia en Amazon Route 53 para la dirección IP de Global Accelerator. Guardar los metadatos del juego en una instancia de base de datos Amazon RDS para MySQL en cada región. Configurar una réplica de solo lectura en las otras regiones.",
            "B. Crear un grupo de Auto Scaling para las instancias de EC2. Adjuntar el grupo de Auto Scaling a un Network Load Balancer (NLB) en cada región. Para cada región, crear una entrada de Amazon Route 53 que use enrutamiento por geoproximidad y apunte al NLB en esa región. Guardar los metadatos del juego en bases de datos MySQL en instancias de EC2 en cada región. Configurar la replicación entre las bases de datos de las instancias EC2 en cada región.",
            "C. Crear un grupo de Auto Scaling para las instancias de EC2. Adjuntar el grupo de Auto Scaling a un Network Load Balancer (NLB) en cada región. Para cada región, crear una entrada de Amazon Route 53 que use enrutamiento basado en latencia y apunte al NLB en esa región. Guardar los metadatos del juego en una tabla global de Amazon DynamoDB.",
            "D. Usar EC2 Global View. Implementar las instancias de EC2 en cada región. Adjuntar las instancias a un Network Load Balancer (NLB). Implementar un servidor DNS en una instancia de EC2 en cada región. Configurar lógica personalizada en cada servidor DNS para redirigir al usuario a la región que proporcione la latencia más baja. Guardar los metadatos del juego en una base de datos global de Amazon Aurora."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "313.- Una empresa está implementando una solución de dispositivo de firewall de terceros desde AWS Marketplace para monitorear y proteger el tráfico que sale de los entornos de AWS de la empresa. La empresa desea implementar este dispositivo en una VPC de servicios compartidos y enrutar todo el tráfico de salida hacia Internet a través de los dispositivos de firewall. Un arquitecto de soluciones necesita recomendar un método de implementación que priorice la confiabilidad y minimice el tiempo de conmutación por error entre los dispositivos de firewall dentro de una sola región de AWS. La empresa ha configurado el enrutamiento desde la VPC de servicios compartidos a otras VPC. ¿Qué pasos debe recomendar el arquitecto de soluciones para cumplir con estos requisitos? (Elija tres.)",
        "opciones": [
            "A. Despliegue dos dispositivos de firewall en la VPC de servicios compartidos, cada uno en una zona de disponibilidad separada.",
            "B. Cree un nuevo Network Load Balancer en la VPC de servicios compartidos. Cree un nuevo grupo de destinos y conéctelo al nuevo Network Load Balancer. Agregue cada una de las instancias de los dispositivos de firewall al grupo de destinos.",
            "C. Cree un nuevo Gateway Load Balancer en la VPC de servicios compartidos. Cree un nuevo grupo de destinos y conéctelo al nuevo Gateway Load Balancer. Agregue cada una de las instancias de los dispositivos de firewall al grupo de destinos.",
            "D. Cree un nuevo punto de enlace de interfaz de VPC. Agregue una ruta a la tabla de rutas en la VPC de servicios compartidos. Designar el nuevo punto de enlace como el siguiente salto para el tráfico que ingresa a la VPC de servicios compartidos desde otras VPC.",
            "E. Despliegue dos dispositivos de firewall en la VPC de servicios compartidos, cada uno en la misma zona de disponibilidad.",
            "F. Cree un punto de enlace de Gateway Load Balancer en la VPC. Agregue una ruta a la tabla de rutas en la VPC de servicios compartidos. Designar el nuevo punto de enlace como el siguiente salto para el tráfico que ingresa a la VPC de servicios compartidos desde otras VPC."
        ],
        "respuestas_correctas": [
            "C",
            "F",
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "314.- Un arquitecto de soluciones necesita migrar una aplicación heredada de un entorno local a AWS. La aplicación se ejecuta en dos servidores detrás de un balanceador de carga. La aplicación requiere un archivo de licencia asociado con la dirección MAC del adaptador de red del servidor. Al proveedor de software le toma 12 horas enviar nuevos archivos de licencia. La aplicación también usa archivos de configuración con una dirección IP estática para acceder a un servidor de base de datos; los nombres de host no son compatibles. Dado estos requisitos, ¿qué combinación de pasos se debe seguir para implementar una arquitectura altamente disponible para los servidores de la aplicación en AWS? (Elija dos).",
        "opciones": [
            "A. Crear un grupo de ENIs. Solicitar archivos de licencia al proveedor para el grupo y almacenar los archivos de licencia en Amazon S3. Crear un script de automatización de inicio para descargar un archivo de licencia y adjuntar el ENI correspondiente a una instancia EC2 de Amazon.",
            "B. Crear un grupo de ENIs. Solicitar archivos de licencia al proveedor para el grupo, almacenar los archivos de licencia en una instancia EC2 de Amazon. Crear una AMI desde la instancia y usar esta AMI para todas las futuras instancias EC2.",
            "C. Crear un script de automatización de inicio para solicitar un nuevo archivo de licencia al proveedor. Cuando se reciba la respuesta, aplicar el archivo de licencia a una instancia EC2 de Amazon.",
            "D. Editar el script de automatización de inicio para leer la dirección IP del servidor de base de datos desde el AWS Systems Manager Parameter Store e inyectar el valor en los archivos de configuración locales.",
            "E. Editar una instancia EC2 de Amazon para incluir la dirección IP del servidor de base de datos en los archivos de configuración y volver a crear la AMI para usarla en todas las futuras instancias EC2."
        ],
        "respuestas_correctas": [
            "D",
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "315.- Una empresa ejecuta su aplicación de informes de ventas en una región de AWS en los Estados Unidos. La aplicación utiliza una API regional de Amazon API Gateway y funciones de AWS Lambda para generar informes bajo demanda desde los datos en una base de datos Amazon RDS para MySQL. El frontend de la aplicación está alojado en Amazon S3 y es accesado por los usuarios a través de una distribución de Amazon CloudFront. La empresa está utilizando Amazon Route 53 como el servicio DNS para el dominio. Route 53 está configurado con una política de enrutamiento simple para dirigir el tráfico a la API de API Gateway. En los próximos 6 meses, la empresa planea expandir sus operaciones a Europa. Más del 90% del tráfico de la base de datos es tráfico solo de lectura. La empresa ya ha desplegado una API de API Gateway y funciones Lambda en la nueva región. Un arquitecto de soluciones debe diseñar una solución que minimice la latencia para los usuarios que descargan informes. ¿Qué solución cumple con estos requisitos?",
        "opciones": [
            "A. Usar una tarea de AWS Database Migration Service (AWS DMS) con carga completa para replicar la base de datos principal de la región original a la base de datos de la nueva región. Cambiar el registro de Route 53 a enrutamiento basado en latencia para conectarse a la API de API Gateway.",
            "B. Usar una tarea de AWS Database Migration Service (AWS DMS) con carga completa más captura de datos modificados (CDC) para replicar la base de datos principal de la región original a la base de datos de la nueva región. Cambiar el registro de Route 53 a enrutamiento geográfico para conectarse a la API de API Gateway.",
            "C. Configurar una réplica de solo lectura entre regiones para la base de datos RDS en la nueva región. Cambiar el registro de Route 53 a enrutamiento basado en latencia para conectarse a la API de API Gateway.",
            "D. Configurar una réplica de solo lectura entre regiones para la base de datos RDS en la nueva región. Cambiar el registro de Route 53 a enrutamiento geográfico para conectarse a la API de API Gateway."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "316.- Una empresa de software necesita crear entornos de prueba de corta duración para probar solicitudes de extracción como parte de su proceso de desarrollo. Cada entorno de prueba consta de una única instancia de Amazon EC2 que se encuentra en un grupo de Auto Scaling. Los entornos de prueba deben poder comunicarse con un servidor central para informar los resultados de las pruebas. El servidor central se encuentra en un centro de datos local. Un arquitecto de soluciones debe implementar una solución para que la empresa pueda crear y eliminar entornos de prueba sin intervención manual. La empresa ha creado un gateway de tránsito con un adjunto VPN a la red local. ¿Qué solución cumplirá con estos requisitos con la MENOR sobrecarga operativa?",
        "opciones": [
            "A. Crear una plantilla de AWS CloudFormation que contenga un adjunto del gateway de tránsito y las configuraciones de enrutamiento relacionadas. Crear un conjunto de pilas de CloudFormation que incluya esta plantilla. Usar CloudFormation StackSets para implementar una nueva pila para cada VPC en la cuenta. Implementar una nueva VPC para cada entorno de prueba.",
            "B. Crear una sola VPC para los entornos de prueba. Incluir un adjunto del gateway de tránsito y las configuraciones de enrutamiento relacionadas. Usar AWS CloudFormation para implementar todos los entornos de prueba en la VPC.",
            "C. Crear una nueva unidad organizacional (OU) en AWS Organizations para las pruebas. Crear una plantilla de AWS CloudFormation que contenga una VPC, los recursos de red necesarios, un adjunto del gateway de tránsito y las configuraciones de enrutamiento relacionadas. Crear un conjunto de pilas de CloudFormation que incluya esta plantilla. Usar CloudFormation StackSets para implementaciones en cada cuenta bajo la OU de pruebas. Crear una nueva cuenta para cada entorno de prueba.",
            "D. Convertir las instancias EC2 del entorno de prueba en imágenes de Docker. Usar AWS CloudFormation para configurar un clúster de Amazon Elastic Kubernetes Service (Amazon EKS) en una nueva VPC, crear un adjunto del gateway de tránsito y crear las configuraciones de enrutamiento relacionadas. Usar Kubernetes para gestionar el despliegue y el ciclo de vida de los entornos de prueba."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "317.- Una empresa está desplegando una nueva API en AWS. La API utiliza Amazon API Gateway con un punto de enlace API Regional y una función AWS Lambda para alojarla. La API recupera datos de una API de un proveedor externo, almacena datos en una tabla global de Amazon DynamoDB y recupera datos de la tabla global de DynamoDB. La clave de API para la API del proveedor está almacenada en AWS Secrets Manager y está cifrada con una clave administrada por el cliente en AWS Key Management Service (AWS KMS). La empresa ha desplegado su propia API en una única región de AWS. Un arquitecto de soluciones necesita cambiar los componentes de la API de la empresa para asegurarse de que los componentes puedan ejecutarse en varias regiones en una configuración activa-activa. ¿Qué combinación de cambios cumplirá este requisito con el MENOR esfuerzo operativo? (Elija tres.)",
        "opciones": [
            "A. Desplegar la API en varias regiones. Configurar Amazon Route 53 con nombres de dominio personalizados que enruten el tráfico a cada punto de enlace de API Regional. Implementar una política de enrutamiento de respuesta múltiple de Route 53.",
            "B. Crear una nueva clave KMS administrada por el cliente multi-región. Crear una nueva clave réplica KMS administrada por el cliente en cada región aplicable.",
            "C. Replicar el secreto existente de Secrets Manager a otras regiones. Para cada secreto replicado en la región correspondiente, seleccionar la clave KMS apropiada.",
            "D. Crear una nueva clave KMS administrada por AWS en cada región aplicable. Convertir una clave existente en una clave multi-región. Usar la clave multi-región en otras regiones.",
            "E. Crear un nuevo secreto de Secrets Manager en cada región aplicable. Copiar el valor del secreto desde la región existente al nuevo secreto en cada región aplicable.",
            "F. Modificar el proceso de implementación para la función Lambda para repetir el despliegue a través de las regiones aplicables. Activar la opción multi-región para la API existente. Seleccionar la función Lambda que se despliega en cada región como el backend para la API multi-región."
        ],
        "respuestas_correctas": [
            "C",
            "B",
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "318.- Una empresa de comercio electrónico aloja su aplicación basada en la web con estado y su base de datos MySQL en un centro de datos local en un solo servidor. La empresa desea aumentar su base de clientes mediante la realización de más campañas de marketing y promociones. En preparación, la empresa quiere migrar su aplicación y base de datos a AWS para aumentar la fiabilidad de su arquitectura. ¿Qué solución debería proporcionar el nivel de fiabilidad MÁS ALTO?",
        "opciones": [
            "A. Migrar la base de datos a una instancia de base de datos MySQL Multi-AZ de Amazon RDS. Desplegar la aplicación en un grupo de Auto Scaling en instancias de Amazon EC2 detrás de un Application Load Balancer. Almacenar las sesiones en Amazon Neptune.",
            "B. Migrar la base de datos a Amazon Aurora MySQL. Desplegar la aplicación en un grupo de Auto Scaling en instancias de Amazon EC2 detrás de un Application Load Balancer. Almacenar las sesiones en un grupo de replicación de Amazon ElastiCache para Redis.",
            "C. Migrar la base de datos a Amazon DocumentDB (con compatibilidad con MongoDB). Desplegar la aplicación en un grupo de Auto Scaling en instancias de Amazon EC2 detrás de un Network Load Balancer. Almacenar las sesiones en Amazon Kinesis Data Firehose.",
            "D. Migrar la base de datos a una instancia de base de datos MariaDB Multi-AZ de Amazon RDS. Desplegar la aplicación en un grupo de Auto Scaling en instancias de Amazon EC2 detrás de un Application Load Balancer. Almacenar las sesiones en Amazon ElastiCache para Memcached."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "319.- Un arquitecto de soluciones de una empresa necesita proporcionar conectividad segura de Escritorio Remoto a los usuarios para las instancias de Amazon EC2 con Windows que están alojadas en una VPC. La solución debe integrar la gestión de usuarios centralizada con el Active Directory local de la empresa. La conectividad a la VPC se realiza a través de internet. La empresa tiene hardware que puede utilizar para establecer una conexión VPN Site-to-Site de AWS. ¿Cuál solución cumplirá estos requisitos de manera MÁS rentable?",
        "opciones": [
            "A. Desplegar un Active Directory administrado utilizando AWS Directory Service para Microsoft Active Directory. Establecer una relación de confianza con el Active Directory local. Desplegar una instancia de EC2 como host bastión en la VPC. Asegurarse de que la instancia EC2 esté unida al dominio. Usar el host bastión para acceder a las instancias de destino a través de RDP.",
            "B. Configurar AWS IAM Identity Center (AWS Single Sign-On) para integrarse con el Active Directory local mediante el AWS Directory Service para Microsoft Active Directory AD Connector. Configurar conjuntos de permisos para los grupos de usuarios con acceso a AWS Systems Manager. Usar Systems Manager Fleet Manager para acceder a las instancias de destino a través de RDP.",
            "C. Implementar una VPN entre el entorno local y la VPC de destino. Asegurarse de que las instancias de destino estén unidas al dominio Active Directory local a través de la conexión VPN. Configurar el acceso RDP a través de la VPN. Conectarse desde la red de la empresa a las instancias de destino.",
            "D. Desplegar un Active Directory administrado utilizando AWS Directory Service para Microsoft Active Directory. Establecer una relación de confianza con el Active Directory local. Desplegar un Remote Desktop Gateway en AWS utilizando un Quick Start de AWS. Asegurarse de que el Remote Desktop Gateway esté unido al dominio. Usar el Remote Desktop Gateway para acceder a las instancias de destino a través de RDP."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "320.- Una auditoría de cumplimiento de la empresa revela que algunos volúmenes de Amazon Elastic Block Store (Amazon EBS) creados en una cuenta de AWS no estaban cifrados. Un arquitecto de soluciones debe implementar una solución para cifrar todos los nuevos volúmenes de EBS en reposo. ¿Qué solución cumplirá con este requisito con el MENOR esfuerzo?",
        "opciones": [
            "A. Crear una regla de Amazon EventBridge para detectar la creación de volúmenes EBS no cifrados. Invocar una función de AWS Lambda para eliminar los volúmenes no conformes.",
            "B. Usar AWS Audit Manager con cifrado de datos.",
            "C. Crear una regla de AWS Config para detectar la creación de un nuevo volumen EBS. Cifrar el volumen utilizando AWS Systems Manager Automation.",
            "D. Activar el cifrado de EBS por defecto en todas las regiones de AWS."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "321.- Una empresa de investigación está ejecutando simulaciones diarias en la nube de AWS para satisfacer una alta demanda. Las simulaciones se ejecutan en varios cientos de instancias de Amazon EC2 que están basadas en Amazon Linux 2. Ocasionalmente, una simulación se queda atascada y requiere que un ingeniero de operaciones en la nube resuelva el problema conectándose a una instancia de EC2 a través de SSH. La política de la empresa establece que ninguna instancia de EC2 puede usar la misma clave SSH y que todas las conexiones deben ser registradas en AWS CloudTrail. ¿Cómo puede un arquitecto de soluciones cumplir con estos requisitos?",
        "opciones": [
            "A. Lanzar nuevas instancias de EC2 y generar una clave SSH individual para cada instancia. Almacenar la clave SSH en AWS Secrets Manager. Crear una nueva política de IAM y adjuntarla al rol de IAM de los ingenieros con una declaración Allow para la acción GetSecretValue. Indicar a los ingenieros que obtengan la clave SSH desde Secrets Manager cuando se conecten a través de cualquier cliente SSH.",
            "B. Crear un documento de AWS Systems Manager para ejecutar comandos en instancias de EC2 para configurar una nueva clave SSH única. Crear una nueva política de IAM y adjuntarla al rol de IAM de los ingenieros con una declaración Allow para ejecutar documentos de Systems Manager. Indicar a los ingenieros que ejecuten el documento para configurar la clave SSH y que se conecten a través de cualquier cliente SSH.",
            "C. Lanzar nuevas instancias de EC2 sin configurar ninguna clave SSH para las instancias. Configurar EC2 Instance Connect en cada instancia. Crear una nueva política de IAM y adjuntarla al rol de IAM de los ingenieros con una declaración Allow para la acción SendSSHPublicKey. Indicar a los ingenieros que se conecten a la instancia utilizando un cliente SSH basado en navegador desde la consola de EC2.",
            "D. Configurar AWS Secrets Manager para almacenar la clave SSH de EC2. Crear una nueva función de AWS Lambda para crear una nueva clave SSH y llamar a AWS Systems Manager Session Manager para establecer la clave SSH en la instancia de EC2. Configurar Secrets Manager para utilizar la función Lambda para la rotación automática una vez al día. Indicar a los ingenieros que obtengan la clave SSH desde Secrets Manager cuando se conecten a través de cualquier cliente SSH."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "322.- Una empresa está migrando aplicaciones de banca móvil para que se ejecuten en instancias de Amazon EC2 en una VPC. Las aplicaciones del servicio backend se ejecutan en un centro de datos local. El centro de datos tiene una conexión AWS Direct Connect hacia AWS. Las aplicaciones que se ejecutan en la VPC necesitan resolver solicitudes DNS hacia un dominio Active Directory local que se ejecuta en el centro de datos. ¿Qué solución cumplirá con estos requisitos con el MENOR esfuerzo administrativo?",
        "opciones": [
            "A. Provisionar un conjunto de instancias de EC2 en dos Zonas de Disponibilidad en la VPC como servidores DNS de caché para resolver consultas DNS desde los servidores de aplicaciones dentro de la VPC.",
            "B. Provisionar una zona hospedada privada de Amazon Route 53. Configurar registros NS que apunten a los servidores DNS locales.",
            "C. Crear puntos finales DNS utilizando Amazon Route 53 Resolver. Agregar reglas de reenvío condicional para resolver espacios de nombres DNS entre el centro de datos local y la VPC.",
            "D. Provisionar un nuevo controlador de dominio Active Directory en la VPC con una relación de confianza bidireccional entre este nuevo dominio y el dominio Active Directory local."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "323.- Una empresa procesa datos ambientales. La empresa ha instalado sensores para proporcionar un flujo continuo de datos desde diferentes áreas de una ciudad. Los datos están disponibles en formato JSON. La empresa desea utilizar una solución de AWS para enviar los datos a una base de datos que no requiera esquemas fijos para el almacenamiento. Los datos deben enviarse en tiempo real. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Use Amazon Kinesis Data Firehose para enviar los datos a Amazon Redshift.",
            "B. Use Amazon Kinesis Data Streams para enviar los datos a Amazon DynamoDB.",
            "C. Use Amazon Managed Streaming para Apache Kafka (Amazon MSK) para enviar los datos a Amazon Aurora.",
            "D. Use Amazon Kinesis Data Firehose para enviar los datos a Amazon Keyspaces (para Apache Cassandra)."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "324.- Una empresa está migrando una aplicación heredada desde un centro de datos local a AWS. La aplicación utiliza MongoDB como una base de datos clave-valor. De acuerdo con las directrices técnicas de la empresa, todas las instancias de Amazon EC2 deben estar alojadas en una subred privada sin conexión a Internet. Además, toda la conectividad entre las aplicaciones y las bases de datos debe estar cifrada. La base de datos debe ser capaz de escalar según la demanda. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Crear nuevas tablas de Amazon DocumentDB (con compatibilidad con MongoDB) para la aplicación con volúmenes de IOPS provisionados. Usar el endpoint de la instancia para conectarse a Amazon DocumentDB.",
            "B. Crear nuevas tablas de Amazon DynamoDB para la aplicación con capacidad bajo demanda. Usar un endpoint de VPC de puerta de enlace para DynamoDB para conectarse a las tablas de DynamoDB.",
            "C. Crear nuevas tablas de Amazon DynamoDB para la aplicación con capacidad bajo demanda. Usar un endpoint de VPC de interfaz para DynamoDB para conectarse a las tablas de DynamoDB.",
            "D. Crear nuevas tablas de Amazon DocumentDB (con compatibilidad con MongoDB) para la aplicación con volúmenes de IOPS provisionados. Usar el endpoint del clúster para conectarse a Amazon DocumentDB."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "325.- Una empresa está ejecutando una aplicación en instancias de Amazon EC2 en la nube de AWS. La aplicación está utilizando una base de datos MongoDB con un conjunto de réplicas como su capa de datos. La base de datos MongoDB está instalada en sistemas en el centro de datos local de la empresa y es accesible a través de una conexión de AWS Direct Connect al entorno del centro de datos. Un arquitecto de soluciones debe migrar la base de datos MongoDB local a Amazon DocumentDB (con compatibilidad con MongoDB). ¿Qué estrategia debe elegir el arquitecto de soluciones para realizar esta migración?",
        "opciones": [
            "A. Crear una flota de instancias de EC2. Instalar MongoDB Community Edition en las instancias de EC2 y crear una base de datos. Configurar replicación continua y sincrónica con la base de datos que se está ejecutando en el centro de datos local.",
            "B. Crear una instancia de replicación de AWS Database Migration Service (AWS DMS). Crear un punto final de origen para la base de datos MongoDB local usando captura de datos modificados (CDC). Crear un punto final de destino para la base de datos Amazon DocumentDB. Crear y ejecutar una tarea de migración de DMS.",
            "C. Crear una canalización de migración de datos utilizando AWS Data Pipeline. Definir nodos de datos para la base de datos MongoDB local y la base de datos Amazon DocumentDB. Crear una tarea programada para ejecutar la canalización de datos.",
            "D. Crear un punto final de origen para la base de datos MongoDB local utilizando rastreadores de AWS Glue. Configurar replicación continua y asincrónica entre la base de datos MongoDB y la base de datos Amazon DocumentDB."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "326.- Una empresa está reestructurando sus aplicaciones para ejecutarlas en AWS. La infraestructura de la empresa incluye múltiples instancias de Amazon EC2. El equipo de desarrollo de la empresa necesita diferentes niveles de acceso. La empresa quiere implementar una política que requiera que todas las instancias de EC2 con Windows estén unidas a un dominio de Active Directory en AWS. La empresa también quiere implementar procesos de seguridad mejorados, como la autenticación multifactor (MFA). La empresa quiere usar servicios administrados de AWS siempre que sea posible. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Crear una implementación de AWS Directory Service para Microsoft Active Directory. Lanzar un Amazon Workspace. Conectarse y usar el Workspace para tareas de configuración de seguridad de dominio.",
            "B. Crear una implementación de AWS Directory Service para Microsoft Active Directory. Lanzar una instancia de EC2. Conectarse y usar la instancia de EC2 para tareas de configuración de seguridad de dominio.",
            "C. Crear una implementación de AWS Directory Service Simple AD. Lanzar una instancia de EC2. Conectarse y usar la instancia de EC2 para tareas de configuración de seguridad de dominio.",
            "D. Crear una implementación de AWS Directory Service Simple AD. Lanzar un Amazon Workspace. Conectarse y usar el Workspace para tareas de configuración de seguridad de dominio."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "327.- Una empresa quiere migrar su aplicación local a AWS. La base de datos de la aplicación almacena datos estructurados de productos y datos temporales de sesiones de usuarios. La empresa necesita desacoplar los datos de productos de los datos de sesiones de usuarios. La empresa también necesita implementar replicación en otra región de AWS para recuperación ante desastres. ¿Qué solución cumplirá estos requisitos con el MAYOR rendimiento?",
        "opciones": [
            "A. Crear una instancia de base de datos Amazon RDS con esquemas separados para alojar los datos de productos y los datos de sesiones de usuarios. Configurar una réplica de solo lectura para la instancia de base de datos en otra región.",
            "B. Crear una instancia de base de datos Amazon RDS para alojar los datos de productos. Configurar una réplica de solo lectura para la instancia de base de datos en otra región. Crear un almacén de datos global en Amazon ElastiCache para Memcached para alojar los datos de sesiones de usuarios.",
            "C. Crear dos tablas globales de Amazon DynamoDB. Usar una tabla global para alojar los datos de productos. Usar la otra tabla global para alojar los datos de sesiones de usuarios. Usar DynamoDB Accelerator (DAX) para el almacenamiento en caché.",
            "D. Crear una instancia de base de datos Amazon RDS para alojar los datos de productos. Configurar una réplica de solo lectura para la instancia de base de datos en otra región. Crear una tabla global de Amazon DynamoDB para alojar los datos de sesiones de usuarios."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "328.- Una empresa organiza una estructura multi-cuenta en AWS utilizando AWS Control Tower. La empresa está usando AWS Organizations, AWS Config y AWS Trusted Advisor. La empresa tiene una OU específica para cuentas de desarrollo que los desarrolladores utilizan para experimentar en AWS. La empresa tiene cientos de desarrolladores, y cada desarrollador tiene una cuenta de desarrollo individual. La empresa quiere optimizar los costos en estas cuentas de desarrollo. Las instancias de Amazon EC2 y las instancias de Amazon RDS en estas cuentas deben ser escalables (burstable). La empresa quiere deshabilitar el uso de otros servicios que no son relevantes. ¿Qué debería recomendar un arquitecto de soluciones para cumplir con estos requisitos?",
        "opciones": [
            "A. Crear una SCP personalizada en AWS Organizations para permitir solo el despliegue de instancias escalables y deshabilitar los servicios que no son relevantes. Aplicar la SCP a la OU de desarrollo.",
            "B. Crear un control (guardrail) personalizado de tipo detective en AWS Control Tower. Configurar el control (guardrail) para permitir solo el despliegue de instancias escalables y deshabilitar los servicios que no son relevantes. Aplicar el control (guardrail) a la OU de desarrollo.",
            "C. Crear un control (guardrail) personalizado de tipo preventivo en AWS Control Tower. Configurar el control (guardrail) para permitir solo el despliegue de instancias escalables y deshabilitar los servicios que no son relevantes. Aplicar el control (guardrail) a la OU de desarrollo.",
            "D. Crear una regla de AWS Config en la cuenta de AWS Control Tower. Configurar la regla de AWS Config para permitir solo el despliegue de instancias escalables y deshabilitar los servicios que no son relevantes. Desplegar la regla de AWS Config a la OU de desarrollo usando AWS CloudFormation StackSets."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "329.- Una empresa de servicios financieros ejecuta una aplicación compleja de múltiples capas en instancias de Amazon EC2 y funciones de AWS Lambda. La aplicación almacena datos temporales en Amazon S3. Los objetos S3 son válidos solo durante 45 minutos y se eliminan después de 24 horas. La empresa despliega cada versión de la aplicación lanzando una pila de AWS CloudFormation. La pila crea todos los recursos necesarios para ejecutar la aplicación. Cuando la empresa despliega y valida una nueva versión de la aplicación, elimina la pila de CloudFormation de la versión anterior. Recientemente, la empresa intentó eliminar la pila de CloudFormation de una versión antigua de la aplicación, pero la operación falló. Un análisis muestra que CloudFormation no pudo eliminar un bucket de S3 existente. Un arquitecto de soluciones necesita resolver este problema sin realizar cambios importantes en la arquitectura de la aplicación. ¿Qué solución cumple con estos requisitos?",
        "opciones": [
            "A. Implementar una función Lambda que elimine todos los archivos de un bucket de S3 dado. Integrar esta función Lambda como un recurso personalizado en la pila de CloudFormation. Asegurarse de que el recurso personalizado tenga un atributo DependsOn que apunte al recurso del bucket de S3.",
            "B. Modificar la plantilla de CloudFormation para provisionar un sistema de archivos Amazon Elastic File System (Amazon EFS) para almacenar los archivos temporales en lugar de en Amazon S3. Configurar las funciones lambda para que se ejecuten en la misma VPC que el sistema de archivos. Montar el sistema de archivos en las instancias EC2 y las funciones Lambda.",
            "C. Modificar la pila de CloudFormation para crear una regla de ciclo de vida de S3 que expire todos los objetos 45 minutos después de su creación. Agregar un atributo DependsOn que apunte al recurso del bucket de S3.",
            "D. Modificar la pila de CloudFormation para adjuntar un atributo DeletionPolicy con el valor Delete al bucket de S3."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "330.- Una empresa ha desarrollado un juego móvil. El backend del juego se ejecuta en varias máquinas virtuales ubicadas en un centro de datos local. La lógica de negocio se expone mediante una API REST con múltiples funciones. Los datos de sesión de los jugadores se almacenan en un almacenamiento de archivos centralizado. Los servicios backend utilizan diferentes claves de API para la limitación de tráfico y para distinguir entre tráfico en vivo y de prueba. La carga del backend del juego varía a lo largo del día. Durante las horas pico, la capacidad del servidor no es suficiente. También hay problemas de latencia al recuperar los datos de sesión de los jugadores. La gerencia ha solicitado a un arquitecto de soluciones que presente una arquitectura en la nube que pueda manejar la carga variable del juego y proporcionar un acceso a datos de baja latencia. El modelo de la API no debe cambiarse. ¿Qué solución cumple con estos requisitos?",
        "opciones": [
            "A. Implementar la API REST utilizando un Network Load Balancer (NLB). Ejecutar la lógica de negocio en una instancia de Amazon EC2 detrás del NLB. Almacenar los datos de sesión de los jugadores en Amazon Aurora Serverless.",
            "B. Implementar la API REST utilizando un Application Load Balancer (ALB). Ejecutar la lógica de negocio en AWS Lambda. Almacenar los datos de sesión de los jugadores en Amazon DynamoDB con capacidad bajo demanda.",
            "C. Implementar la API REST utilizando Amazon API Gateway. Ejecutar la lógica de negocio en AWS Lambda. Almacenar los datos de sesión de los jugadores en Amazon DynamoDB con capacidad bajo demanda.",
            "D. Implementar la API REST utilizando AWS AppSync. Ejecutar la lógica de negocio en AWS Lambda. Almacenar los datos de sesión de los jugadores en Amazon Aurora Serverless."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "331.- Una empresa está migrando una aplicación a la nube de AWS. La aplicación se ejecuta en un centro de datos local y escribe miles de imágenes en un sistema de archivos NFS montado cada noche. Después de que la empresa migre la aplicación, la empresa alojará la aplicación en una instancia de Amazon EC2 con un sistema de archivos de Amazon Elastic File System (Amazon EFS) montado. La empresa ha establecido una conexión AWS Direct Connect a AWS. Antes de la migración, un arquitecto de soluciones debe construir un proceso que replique las imágenes recién creadas en las instalaciones al sistema de archivos EFS. ¿Cuál es la forma MÁS eficiente operativamente de replicar las imágenes?",
        "opciones": [
            "A. Configurar un proceso periódico para ejecutar el comando aws s3 sync desde el sistema de archivos local a Amazon S3. Configurar una función de AWS Lambda para procesar las notificaciones de eventos de Amazon S3 y copiar las imágenes de Amazon S3 al sistema de archivos EFS.",
            "B. Implementar un AWS Storage Gateway file gateway con un punto de montaje NFS. Montar el sistema de archivos del file gateway en el servidor local. Configurar un proceso para copiar periódicamente las imágenes al punto de montaje.",
            "C. Implementar un agente de AWS DataSync en un servidor local que tenga acceso al sistema de archivos NFS. Enviar datos a través de la conexión Direct Connect a un bucket de S3 utilizando un VIF público. Configurar una función de AWS Lambda para procesar las notificaciones de eventos de Amazon S3 y copiar las imágenes de Amazon S3 al sistema de archivos EFS.",
            "D. Implementar un agente de AWS DataSync en un servidor local que tenga acceso al sistema de archivos NFS. Enviar datos a través de la conexión Direct Connect a un punto de enlace de VPC de AWS PrivateLink para Amazon EFS utilizando un VIF privado. Configurar una tarea programada de DataSync para enviar las imágenes al sistema de archivos EFS cada 24 horas."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "332.- Una empresa recientemente migró una aplicación web de un centro de datos local a la nube de AWS. La infraestructura de la aplicación web consiste en una distribución de Amazon CloudFront que enruta hacia un Application Load Balancer (ALB), con Amazon Elastic Container Service (Amazon ECS) para procesar las solicitudes. Una auditoría de seguridad reciente reveló que la aplicación web es accesible utilizando tanto los puntos finales de CloudFront como los de ALB. Sin embargo, la empresa requiere que la aplicación web solo sea accesible utilizando el punto final de CloudFront. ¿Qué solución cumplirá con este requisito con el MENOR esfuerzo?",
        "opciones": [
            "A. Crear un nuevo grupo de seguridad y adjuntarlo a la distribución de CloudFront. Actualizar el grupo de seguridad del ALB para permitir el acceso solo desde el grupo de seguridad de CloudFront.",
            "B. Actualizar el grupo de seguridad del ALB para permitir el acceso solo desde la lista de prefijos administrada por CloudFront com.amazonaws.global.cloudfront.origin-facing.",
            "C. Crear un punto final de interfaz VPC com.amazonaws.region.elasticloadbalancing para Elastic Load Balancing. Actualizar el esquema del ALB de internet-facing a internal.",
            "D. Extraer las IPs de CloudFront del documento ip-ranges.json proporcionado por AWS. Actualizar el grupo de seguridad del ALB para permitir el acceso solo desde las IPs de CloudFront."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "333.- Una empresa aloja un sitio de foro comunitario utilizando un Application Load Balancer (ALB) y una aplicación Docker alojada en un Amazon ECS. Los datos del sitio se almacenan en Amazon RDS for MySQL y la imagen del contenedor se almacena en ECR. La empresa necesita proporcionar a sus clientes un SLA de recuperación ante desastres con un RTO (tiempo objetivo de recuperación) de no más de 24 horas y un RPO (punto objetivo de recuperación) de no más de 8 horas. ¿Cuál de las siguientes soluciones es la forma más rentable de cumplir con los requisitos?",
        "opciones": [
            "A. Use AWS CloudFormation para desplegar recursos idénticos de ALB, EC2, ECS y RDS en dos regiones. Programe instantáneas de RDS cada 8 horas. Use replicación multi-región de RDS para actualizar la copia de la base de datos en la región secundaria. En caso de falla, restaure desde la última instantánea y use una política de conmutación por error de Amazon Route 53 DNS para redirigir automáticamente a los clientes al ALB en la región secundaria.",
            "B. Almacene la imagen de Docker en ECR en dos regiones. Programe instantáneas de RDS cada 8 horas con instantáneas copiadas a la región secundaria. En caso de falla, use AWS CloudFormation para desplegar los recursos de ALB, EC2, ECS y RDS en la región secundaria, restaure desde la última instantánea y actualice el registro DNS para que apunte al ALB en la región secundaria.",
            "C. Use AWS CloudFormation para desplegar recursos idénticos de ALB, EC2, ECS y RDS en una región secundaria. Programe copias de seguridad de RDS MySQL cada hora en Amazon S3 y use replicación entre regiones para replicar los datos a un bucket en la región secundaria. En caso de falla, importe la última imagen Docker a Amazon ECR en la región secundaria, despliegue en la instancia de EC2, restaure la última copia de seguridad de MySQL y actualice el registro DNS para que apunte al ALB en la región secundaria.",
            "D. Despliegue un entorno de piloto ligero en una región secundaria con un ALB y una implementación mínima de EC2 para Docker en un grupo de escalado automático de AWS con una política de escalado para aumentar el tamaño de la instancia y el número de nodos. Cree una réplica de lectura entre regiones de los datos de RDS. En caso de falla, promueva la réplica a principal y actualice el registro DNS para que apunte al ALB en la región secundaria."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "334.- Una empresa está migrando su infraestructura a la nube de AWS. La empresa debe cumplir con una variedad de estándares regulatorios para diferentes proyectos. La empresa necesita un entorno multi-cuenta. Un arquitecto de soluciones necesita preparar la infraestructura base. La solución debe proporcionar una base coherente de gestión y seguridad, pero debe permitir flexibilidad para diferentes requisitos de cumplimiento dentro de varias cuentas de AWS. La solución también debe integrarse con el servidor de Active Directory Federation Services (AD FS) en las instalaciones existentes. ¿Qué solución cumple con estos requisitos con el MENOR esfuerzo operativo?",
        "opciones": [
            "A. Crear una organización en AWS Organizations. Crear un único SCP para acceso de menor privilegio en todas las cuentas. Crear una única OU para todas las cuentas. Configurar un proveedor de identidad IAM para la federación con el servidor AD FS en las instalaciones. Configurar una cuenta de registro central con un proceso definido para que los servicios generadores de registros envíen eventos de registro a la cuenta central. Habilitar AWS Config en la cuenta central con paquetes de conformidad para todas las cuentas.",
            "B. Crear una organización en AWS Organizations. Habilitar AWS Control Tower en la organización. Revisar los controles incluidos (guardrails) para los SCP. Verificar AWS Config para áreas que requieran adiciones. Añadir OUs según sea necesario. Conectar AWS IAM Identity Center (AWS Single Sign-On) con el servidor AD FS en las instalaciones.",
            "C. Crear una organización en AWS Organizations. Crear SCPs para acceso de menor privilegio. Crear una estructura de OUs y usarla para agrupar las cuentas de AWS. Conectar AWS IAM Identity Center (AWS Single Sign-On) con el servidor AD FS en las instalaciones. Configurar una cuenta de registro central con un proceso definido para que los servicios generadores de registros envíen eventos de registro a la cuenta central. Habilitar AWS Config en la cuenta central con agregadores y paquetes de conformidad.",
            "D. Crear una organización en AWS Organizations. Habilitar AWS Control Tower en la organización. Revisar los controles incluidos (guardrails) para los SCP. Verificar AWS Config para áreas que requieran adiciones. Configurar un proveedor de identidad IAM para la federación con el servidor AD FS en las instalaciones."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "335.- Una revista en línea lanzará su última edición este mes. Esta edición será la primera en ser distribuida globalmente. El sitio web dinámico de la revista actualmente utiliza un Balanceador de Carga de Aplicaciones (Application Load Balancer) frente a la capa web, una flota de instancias de Amazon EC2 para servidores web y de aplicaciones, y Amazon Aurora MySQL. Algunas partes del sitio web incluyen contenido estático y casi todo el tráfico es solo de lectura. Se espera que la revista reciba un aumento significativo en el tráfico de internet cuando se lance la nueva edición. El rendimiento óptimo es una prioridad principal durante la semana posterior al lanzamiento. ¿Qué combinación de pasos debe tomar un arquitecto de soluciones para reducir los tiempos de respuesta del sistema para una audiencia global? (Elija dos.)",
        "opciones": [
            "A. Usar replicación lógica entre regiones para replicar la base de datos Aurora MySQL a una región secundaria. Reemplazar los servidores web con Amazon S3. Desplegar los buckets de S3 en modo de replicación entre regiones.",
            "B. Asegurar que las capas web y de aplicación estén en grupos de Auto Scaling. Introducir una conexión de AWS Direct Connect. Desplegar las capas web y de aplicación en regiones de todo el mundo.",
            "C. Migrar la base de datos de Amazon Aurora a Amazon RDS para MySQL. Asegurar que las tres capas de la aplicación: web, aplicación y base de datos, estén en subredes privadas.",
            "D. Usar una base de datos global de Aurora para replicación física entre regiones. Usar Amazon S3 con replicación entre regiones para contenido estático y recursos. Desplegar las capas web y de aplicación en regiones de todo el mundo.",
            "E. Introducir Amazon Route 53 con enrutamiento basado en latencia y distribuciones de Amazon CloudFront. Asegurar que las capas web y de aplicación estén en grupos de Auto Scaling."
        ],
        "respuestas_correctas": [
            "E",
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "336.- Una empresa de juegos en línea necesita optimizar el costo de sus cargas de trabajo en AWS. La empresa usa una cuenta dedicada para alojar el entorno de producción de su aplicación de juegos en línea y una aplicación de análisis. Las instancias de Amazon EC2 alojan la aplicación de juegos y deben estar siempre disponibles. Las instancias de EC2 se ejecutan durante todo el año. La aplicación de análisis utiliza datos almacenados en Amazon S3. La aplicación de análisis puede interrumpirse y reanudarse sin problemas. ¿Qué solución cumplirá con estos requisitos de la manera más rentable?",
        "opciones": [
            "A. Comprar un EC2 Instance Savings Plan para las instancias de la aplicación de juegos en línea. Usar instancias bajo demanda para la aplicación de análisis.",
            "B. Comprar un EC2 Instance Savings Plan para las instancias de la aplicación de juegos en línea. Usar instancias Spot para la aplicación de análisis.",
            "C. Usar instancias Spot para la aplicación de juegos en línea y la aplicación de análisis. Configurar un catálogo en AWS Service Catalog para provisionar servicios con descuento.",
            "D. Usar instancias bajo demanda para la aplicación de juegos en línea. Usar instancias Spot para la aplicación de análisis. Configurar un catálogo en AWS Service Catalog para provisionar servicios con descuento."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "337.- Una empresa ejecuta aplicaciones en cientos de cuentas de producción de AWS. La empresa usa AWS Organizations con todas las funciones habilitadas y tiene una operación centralizada de copias de seguridad que utiliza AWS Backup. La empresa está preocupada por los ataques de ransomware. Para abordar esta preocupación, la empresa ha creado una nueva política que establece que todas las copias de seguridad deben ser resilientes a las violaciones de las credenciales de usuarios privilegiados en cualquier cuenta de producción. ¿Qué combinación de pasos cumplirá este nuevo requisito? (Elija tres.)",
        "opciones": [
            "A. Implementar copias de seguridad entre cuentas con cofres de AWS Backup en cuentas designadas como no productivas.",
            "B. Agregar una SCP que restrinja la modificación de los cofres de AWS Backup.",
            "C. Implementar AWS Backup Vault Lock en modo de cumplimiento.  Implementar acceso de privilegio mínimo para el rol de servicio IAM asignado a AWS Backup.",
            "D. Configurar la frecuencia de las copias de seguridad, el ciclo de vida y el período de retención para asegurar que siempre exista al menos una copia de seguridad en la capa fría.",
            "E. Configurar AWS Backup para escribir todas las copias de seguridad en un bucket de Amazon S3 en una cuenta designada como no productiva. Asegurarse de que el bucket de S3 tenga habilitado S3 Object Lock."
        ],
        "respuestas_correctas": [
            "C",
            "B",
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "338.- Una empresa necesita agregar los registros de Amazon CloudWatch desde sus cuentas de AWS en una cuenta central de registros. Los registros recopilados deben permanecer en la región de AWS donde fueron creados. Luego, la cuenta central de registros procesará los registros, los normalizará en un formato de salida estándar y transmitirá los registros de salida a una herramienta de seguridad para su procesamiento adicional. Un arquitecto de soluciones debe diseñar una solución que pueda manejar un gran volumen de datos de registro que deben ser ingeridos. Se espera que haya menos registros fuera del horario comercial normal que durante el horario comercial. La solución de registros debe escalar con la carga anticipada. El arquitecto de soluciones ha decidido usar un diseño de AWS Control Tower para manejar el proceso de registro multi-cuenta. ¿Qué combinación de pasos debe seguir el arquitecto de soluciones para cumplir con los requisitos? (Elija tres.)",
        "opciones": [
            "A. Crear un flujo de datos de Amazon Kinesis como destino en la cuenta central de registros.",
            "B. Crear una cola de Amazon Simple Queue Service (Amazon SQS) como destino en la cuenta central de registros.",
            "C. Crear un rol de IAM que otorgue a Amazon CloudWatch Logs el permiso para agregar datos al flujo de datos de Amazon Kinesis. Crear una política de confianza. Especificar la política de confianza en el rol de IAM. En cada cuenta miembro, crear un filtro de suscripción para cada grupo de registros para enviar los datos al flujo de datos de Kinesis.",
            "D. Crear un rol de IAM que otorgue a Amazon CloudWatch Logs el permiso para agregar datos a la cola de Amazon Simple Queue Service (Amazon SQS). Crear una política de confianza. Especificar la política de confianza en el rol de IAM. En cada cuenta miembro, crear un solo filtro de suscripción para todos los grupos de registros para enviar los datos a la cola de SQS.",
            "E. Crear una función de AWS Lambda. Programar la función Lambda para normalizar los registros en la cuenta central de registros y escribir los registros en la herramienta de seguridad.",
            "F. Crear una función de AWS Lambda. Programar la función Lambda para normalizar los registros en las cuentas miembro y escribir los registros en la herramienta de seguridad."
        ],
        "respuestas_correctas": [
            "C",
            "E",
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "339.- Una empresa está migrando una aplicación heredada desde un centro de datos local a AWS. La aplicación consiste en un único servidor de aplicaciones y un servidor de base de datos Microsoft SQL Server. Cada servidor está desplegado en una máquina virtual de VMware que consume 500 TB de datos a través de varios volúmenes adjuntos. La empresa ha establecido una conexión AWS Direct Connect de 10 Gbps desde la región de AWS más cercana a su centro de datos local. La conexión Direct Connect no está siendo utilizada actualmente por otros servicios. ¿Qué combinación de pasos debe seguir un arquitecto de soluciones para migrar la aplicación con la MENOR cantidad de tiempo de inactividad? (Elija dos).",
        "opciones": [
            "A. Usar un trabajo de replicación de AWS Server Migration Service (AWS SMS) para migrar la máquina virtual del servidor de base de datos a AWS.",
            "B. Usar VM Import/Export para importar la máquina virtual del servidor de aplicaciones.",
            "C. Exportar las imágenes de las máquinas virtuales a un dispositivo AWS Snowball Edge Storage Optimized.",
            "D. Usar un trabajo de replicación de AWS Server Migration Service (AWS SMS) para migrar la máquina virtual del servidor de aplicaciones a AWS.",
            "E. Usar una instancia de replicación de AWS Database Migration Service (AWS DMS) para migrar la base de datos a una instancia DB de Amazon RDS."
        ],
        "respuestas_correctas": [
            "E",
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "340.- Una empresa opera una flota de servidores locales y una flota de instancias de Amazon EC2 en su organización en AWS Organizations. Las cuentas de AWS de la empresa contienen cientos de VPCs. La empresa quiere conectar sus cuentas de AWS a su red local. Las conexiones VPN Site-to-Site ya están establecidas a una sola cuenta de AWS. La empresa quiere controlar qué VPCs pueden comunicarse con otras VPCs. ¿Qué combinación de pasos logrará este nivel de control con el MENOR esfuerzo operativo? (Elija tres).",
        "opciones": [
            "A. Crear un gateway de tránsito en una cuenta de AWS. Compartir el gateway de tránsito entre cuentas utilizando AWS Resource Access Manager (AWS RAM).",
            "B. Configurar los attachments (vinculaciones) a todas las VPCs y VPNs.",
            "C. Configurar tablas de rutas del gateway de tránsito. Asociar las VPCs y VPNs con las tablas de rutas.",
            "D. Configurar peering (emparejamiento) de VPC entre las VPCs.",
            "E. Configurar los attachments entre las VPCs y VPNs.",
            "F. Configurar tablas de rutas en las VPCs y VPNs."
        ],
        "respuestas_correctas": [
            "C",
            "B",
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "341.- Una empresa necesita optimizar el costo de su aplicación en AWS. La aplicación utiliza funciones de AWS Lambda y contenedores de Amazon Elastic Container Service (Amazon ECS) que se ejecutan en AWS Fargate. La aplicación tiene una carga de escritura elevada y almacena datos en una base de datos Amazon Aurora MySQL. La carga de la aplicación no es consistente. La aplicación experimenta largos períodos de inactividad, seguidos de aumentos y disminuciones repentinas y significativas en el tráfico. La base de datos se ejecuta en una instancia DB optimizada para memoria que no puede manejar la carga. Un arquitecto de soluciones debe diseñar una solución que pueda escalar para manejar los cambios en el tráfico. ¿Qué solución cumplirá estos requisitos de la manera MÁS rentable?",
        "opciones": [
            "A. Agregar réplicas de lectura adicionales a la base de datos. Comprar Planes de Ahorros de Instancias y Reservas de Instancias de RDS.",
            "B. Migrar la base de datos a un clúster de Aurora DB que tenga múltiples instancias escritoras. Comprar Planes de Ahorros de Instancias.",
            "C. Migrar la base de datos a una base de datos global de Aurora. Comprar Planes de Ahorros de Cómputo y Reservas de Instancias de RDS.",
            "D. Migrar la base de datos a Aurora Serverless v1. Comprar Compute Savings Plans."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "342.- Una empresa migró una aplicación a la nube de AWS. La aplicación se ejecuta en dos instancias de Amazon EC2 detrás de un Application Load Balancer (ALB). Los datos de la aplicación se almacenan en una base de datos MySQL que se ejecuta en una instancia EC2 adicional. El uso de la base de datos por parte de la aplicación es intensivo en lecturas. La aplicación carga contenido estático desde volúmenes de Amazon Elastic Block Store (Amazon EBS) que están adjuntos a cada instancia EC2. El contenido estático se actualiza con frecuencia y debe ser copiado a cada volumen de EBS. La carga de la aplicación cambia a lo largo del día. Durante las horas pico, la aplicación no puede manejar todas las solicitudes entrantes. Los datos de rastreo muestran que la base de datos no puede manejar la carga de lecturas durante las horas pico. ¿Qué solución mejorará la confiabilidad de la aplicación?",
        "opciones": [
            "A. Migrar la aplicación a un conjunto de funciones de AWS Lambda. Configurar las funciones Lambda como objetivos del ALB. Crear un nuevo volumen EBS único para el contenido estático. Configurar las funciones Lambda para leer desde el nuevo volumen EBS. Migrar la base de datos a un clúster DB Multi-AZ de Amazon RDS para MySQL.",
            "B. Migrar la aplicación a un conjunto de máquinas de estado de AWS Step Functions. Configurar las máquinas de estado como objetivos para el ALB. Crear un sistema de archivos Amazon Elastic File System (Amazon EFS) para el contenido estático. Configurar las máquinas de estado para leer desde el sistema de archivos EFS. Migrar la base de datos a Amazon Aurora MySQL Serverless v2 con una instancia de base de datos solo de lectura.",
            "C. Contenerizar la aplicación. Migrar la aplicación a un clúster de Amazon Elastic Container Service (Amazon ECS). Usar el tipo de lanzamiento AWS Fargate para las tareas que alojan la aplicación. Crear un nuevo volumen EBS único para el contenido estático. Montar el nuevo volumen EBS en el clúster ECS. Configurar AWS Application Auto Scaling en el clúster ECS. Configurar el servicio ECS como objetivo del ALB. Migrar la base de datos a un clúster DB Multi-AZ de Amazon RDS para MySQL.",
            "D. Contenerizar la aplicación. Migrar la aplicación a un clúster de Amazon Elastic Container Service (Amazon ECS). Usar el tipo de lanzamiento AWS Fargate para las tareas que alojan la aplicación. Crear un sistema de archivos Amazon Elastic File System (Amazon EFS) para el contenido estático. Montar el sistema de archivos EFS en cada contenedor. Configurar AWS Application Auto Scaling en el clúster ECS. Configurar el servicio ECS como objetivo del ALB. Migrar la base de datos a Amazon Aurora MySQL Serverless v2 con una instancia de base de datos solo de lectura."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "343.- Un arquitecto de soluciones quiere asegurarse de que solo los usuarios o roles de AWS con los permisos adecuados puedan acceder a un nuevo punto de enlace de Amazon API Gateway. El arquitecto de soluciones también quiere tener una vista de extremo a extremo de cada solicitud para analizar la latencia de la solicitud y crear mapas de servicio. ¿Cómo puede el arquitecto de soluciones diseñar el control de acceso de API Gateway y realizar inspecciones de las solicitudes?",
        "opciones": [
            "A. Para el método de API Gateway, establezca la autorización en AWS_IAM. Luego, otorgue al usuario o rol de IAM el permiso execute-api:Invoke en el recurso de la API REST. Habilite que el llamador de la API firme las solicitudes con la firma de AWS al acceder al punto de enlace. Use AWS X-Ray para trazar y analizar las solicitudes de los usuarios a API Gateway.",
            "B. Para el recurso de API Gateway, establezca CORS en habilitado y solo devuelva el dominio de la empresa en los encabezados Access-Control-Allow-Origin. Luego, otorgue al usuario o rol de IAM el permiso execute-api:Invoke en el recurso de la API REST. Use Amazon CloudWatch para trazar y analizar las solicitudes de los usuarios a API Gateway.",
            "C. Cree una función AWS Lambda como el autorizador personalizado, pida al cliente de la API que pase la clave y el secreto al hacer la llamada, y luego use Lambda para validar el par clave/secreto contra el sistema IAM. Use AWS X-Ray para trazar y analizar las solicitudes de los usuarios a API Gateway.",
            "D. Cree un certificado de cliente para API Gateway. Distribuya el certificado a los usuarios y roles de AWS que necesiten acceder al punto de enlace. Habilite que el llamador de la API pase el certificado de cliente al acceder al punto de enlace. Use Amazon CloudWatch para trazar y analizar las solicitudes de los usuarios a API Gateway."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "344.- Una empresa está utilizando AWS CodePipeline para la integración continua y la entrega continua (CI/CD) de una aplicación a un Amazon EC2 Auto Scaling group. Todos los recursos de AWS están definidos en plantillas de AWS CloudFormation. Los artefactos de la aplicación se almacenan en un bucket de Amazon S3 y se implementan en el grupo de Auto Scaling utilizando scripts de datos de usuario de la instancia. A medida que la aplicación se ha vuelto más compleja, los cambios recientes en los recursos dentro de las plantillas de CloudFormation han causado tiempos de inactividad no planificados. ¿Cómo debería un arquitecto de soluciones mejorar la canalización CI/CD para reducir la probabilidad de que los cambios en las plantillas causen tiempos de inactividad?",
        "opciones": [
            "A. Adapte los scripts de implementación para detectar e informar condiciones de error en CloudFormation al realizar implementaciones. Escriba planes de prueba para que un equipo de pruebas los ejecute en un entorno no de producción antes de aprobar el cambio para producción.",
            "B. Implemente pruebas automatizadas usando AWS CodeBuild en un entorno de pruebas. Utilice CloudFormation change sets para evaluar los cambios antes de la implementación. Use AWS CodeDeploy para aprovechar los patrones de implementación blue/green que permiten evaluaciones y la posibilidad de revertir los cambios, si es necesario.",
            "C. Use complementos para el entorno de desarrollo integrado (IDE) para verificar las plantillas en busca de errores y use la AWS CLI para validar que las plantillas sean correctas. Adapte el código de implementación para verificar las condiciones de error y generar notificaciones en caso de errores. Implemente en un entorno de pruebas y ejecute un plan de prueba manual antes de aprobar el cambio para producción.",
            "D. Use AWS CodeDeploy y un patrón de implementación blue/green con CloudFormation para reemplazar los scripts de implementación de datos de usuario. Haga que los operadores inicien sesión en las instancias en ejecución y sigan un plan de prueba manual para verificar que la aplicación esté funcionando según lo esperado."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "345.- Una empresa de América del Norte con sede en la costa este está desplegando una nueva aplicación web que se ejecuta en Amazon EC2 en la región us-east-1. La aplicación debe escalar dinámicamente para satisfacer la demanda de los usuarios y mantener la resiliencia. Además, la aplicación debe tener capacidades de recuperación ante desastres en una configuración activa-pasiva con la región us-west-1. ¿Qué pasos debe seguir un arquitecto de soluciones después de crear una VPC en la región us-east-1?",
        "opciones": [
            "A. Crear una VPC en la región us-west-1. Usar emparejamiento de VPC interregionales para conectar ambas VPCs. Desplegar un Balanceador de Carga de Aplicaciones (ALB) que abarque múltiples Zonas de Disponibilidad (AZ) en la VPC de la región us-east-1. Desplegar instancias EC2 en múltiples AZ en cada región como parte de un grupo de Auto Scaling que abarque ambas VPCs y que sea servido por el ALB.",
            "B. Desplegar un Balanceador de Carga de Aplicaciones (ALB) que abarque múltiples Zonas de Disponibilidad (AZ) en la VPC de la región us-east-1. Desplegar instancias EC2 en múltiples AZ como parte de un grupo de Auto Scaling servido por el ALB. Desplegar la misma solución en la región us-west-1. Crear un conjunto de registros de Amazon Route 53 con una política de enrutamiento por conmutación por error y con las comprobaciones de estado habilitadas para proporcionar alta disponibilidad entre ambas regiones.",
            "C. Crear una VPC en la región us-west-1. Usar emparejamiento de VPC interregionales para conectar ambas VPCs. Desplegar un Balanceador de Carga de Aplicaciones (ALB) que abarque ambas VPCs. Desplegar instancias EC2 en múltiples Zonas de Disponibilidad como parte de un grupo de Auto Scaling en cada VPC servido por el ALB. Crear un registro de Amazon Route 53 que apunte al ALB.",
            "D. Desplegar un Balanceador de Carga de Aplicaciones (ALB) que abarque múltiples Zonas de Disponibilidad (AZ) en la VPC de la región us-east-1. Desplegar instancias EC2 en múltiples AZ como parte de un grupo de Auto Scaling servido por el ALB. Desplegar la misma solución en la región us-west-1. Crear registros separados de Amazon Route 53 en cada región que apunten al ALB en la región. Usar las comprobaciones de estado de Route 53 para proporcionar alta disponibilidad entre ambas regiones."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "346.- Una empresa tiene una aplicación heredada que se ejecuta en varios componentes de .NET Framework. Los componentes comparten la misma base de datos de Microsoft SQL Server y se comunican entre sí de manera asincrónica utilizando Microsoft Message Queueing (MSMQ). La empresa está comenzando una migración hacia componentes de .NET Core contenerizados y desea refactorizar la aplicación para que se ejecute en AWS. Los componentes de .NET Core requieren orquestación compleja. La empresa debe tener control total sobre la configuración de la red y el host. El modelo de base de datos de la aplicación es fuertemente relacional. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Hospedar los componentes .NET Core en AWS App Runner. Hospedar la base de datos en Amazon RDS para SQL Server. Usar Amazon EventBridge para mensajería asincrónica.",
            "B. Hospedar los componentes .NET Core en Amazon Elastic Container Service (Amazon ECS) con el tipo de lanzamiento AWS Fargate. Hospedar la base de datos en Amazon DynamoDB. Usar Amazon Simple Notification Service (Amazon SNS) para mensajería asincrónica.",
            "C. Hospedar los componentes .NET Core en AWS Elastic Beanstalk. Hospedar la base de datos en Amazon Aurora PostgreSQL Serverless v2. Usar Amazon Managed Streaming for Apache Kafka (Amazon MSK) para mensajería asincrónica.",
            "D. Hospedar los componentes .NET Core en Amazon Elastic Container Service (Amazon ECS) con el tipo de lanzamiento Amazon EC2. Hospedar la base de datos en Amazon Aurora MySQL Serverless v2. Usar Amazon Simple Queue Service (Amazon SQS) para mensajería asincrónica."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "347.- Un arquitecto de soluciones ha lanzado varias instancias de Amazon EC2 en un grupo de colocación dentro de una sola zona de disponibilidad. Debido a una carga adicional en el sistema, el arquitecto de soluciones intenta agregar nuevas instancias al grupo de colocación. Sin embargo, recibe un error de capacidad insuficiente. ¿Qué debe hacer el arquitecto de soluciones para solucionar este problema?",
        "opciones": [
            "A. Usar un grupo de colocación de tipo spread. Establecer un mínimo de ocho instancias para cada zona de disponibilidad.",
            "B. Detener e iniciar todas las instancias en el grupo de colocación. Intentar el lanzamiento nuevamente.",
            "C. Crear un nuevo grupo de colocación. Fusionar el nuevo grupo de colocación con el grupo de colocación original.",
            "D. Lanzar las instancias adicionales como Dedicated Hosts en los grupos de colocación."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "348.- Una empresa ha utilizado infraestructura como código (IaC) para aprovisionar un conjunto de dos instancias de Amazon EC2. Las instancias han permanecido iguales durante varios años. El negocio de la empresa ha crecido rápidamente en los últimos meses. En respuesta, el equipo de operaciones de la empresa ha implementado un grupo de Auto Scaling para gestionar los aumentos repentinos en el tráfico. La política de la empresa requiere la instalación mensual de actualizaciones de seguridad en todos los sistemas operativos que se estén ejecutando. La actualización de seguridad más reciente requirió un reinicio. Como resultado, el grupo de Auto Scaling terminó las instancias y las reemplazó con nuevas instancias sin parchear. ¿Qué combinación de pasos debe recomendar un arquitecto de soluciones para evitar que este problema se repita? (Elija dos.)",
        "opciones": [
            "A. Modificar el grupo de Auto Scaling configurando la política de actualización para reemplazar la configuración de lanzamiento más antigua.",
            "B. Crear un nuevo grupo de Auto Scaling antes de la próxima ventana de mantenimiento de parches. Durante la ventana de mantenimiento, parchear ambos grupos y reiniciar las instancias.",
            "C. Crear un Elastic Load Balancer frente al grupo de Auto Scaling. Configurar la monitorización para garantizar que las verificaciones de salud del grupo de destino devuelvan saludable después de que el grupo de Auto Scaling reemplace las instancias terminadas.",
            "D. Crear scripts de automatización para parchear una AMI, actualizar la configuración de lanzamiento e invocar una actualización de instancias de Auto Scaling.",
            "E. Crear un Elastic Load Balancer frente al grupo de Auto Scaling. Configurar la protección contra terminación en las instancias."
        ],
        "respuestas_correctas": [
            "D",
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "349.- Un equipo de científicos de datos está utilizando instancias de Amazon SageMaker y las APIs de SageMaker para entrenar modelos de aprendizaje automático (ML). Las instancias de SageMaker están desplegadas en una VPC que no tiene acceso desde o hacia internet. Los conjuntos de datos para el entrenamiento de modelos ML se almacenan en un bucket de Amazon S3. Los puntos de enlace de VPC de interfaz proporcionan acceso a Amazon S3 y las APIs de SageMaker. Ocasionalmente, los científicos de datos requieren acceso al repositorio Python Package Index (PyPI) para actualizar los paquetes de Python que utilizan como parte de su flujo de trabajo. Un arquitecto de soluciones debe proporcionar acceso al repositorio PyPI mientras asegura que las instancias de SageMaker permanezcan aisladas de internet. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Crear un repositorio de AWS CodeCommit para cada paquete que los científicos de datos necesiten acceder. Configurar la sincronización de código entre el repositorio PyPI y el repositorio CodeCommit. Crear un punto de enlace de VPC para CodeCommit.",
            "B. Crear una puerta de enlace NAT en la VPC. Configurar rutas de VPC para permitir acceso a internet con un ACL de red que permita el acceso solo al punto de enlace del repositorio PyPI.",
            "C. Crear una instancia NAT en la VPC. Configurar rutas de VPC para permitir acceso a internet. Configurar reglas del firewall de la instancia de notebook de SageMaker que permitan el acceso solo al punto de enlace del repositorio PyPI.",
            "D. Crear un dominio y repositorio de AWS CodeArtifact. Agregar una conexión externa para public:pypi al repositorio CodeArtifact. Configurar el cliente de Python para usar el repositorio CodeArtifact. Crear un punto de enlace de VPC para CodeArtifact."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "350.- Un arquitecto de soluciones trabaja para una agencia gubernamental que tiene estrictos requisitos de recuperación ante desastres. Todos los snapshots de Amazon Elastic Block Store (Amazon EBS) deben guardarse en al menos dos regiones adicionales de AWS. La agencia también debe mantener la menor sobrecarga operativa posible. ¿Qué solución cumple con estos requisitos?",
        "opciones": [
            "A. Configurar una política en Amazon Data Lifecycle Manager (Amazon DLM) para que se ejecute una vez al día y copie los snapshots de EBS a las regiones adicionales.",
            "B. Usar Amazon EventBridge para programar una función de AWS Lambda que copie los snapshots de EBS a las regiones adicionales.",
            "C. Configurar AWS Backup para crear los snapshots de EBS. Configurar la replicación entre regiones de Amazon S3 para copiar los snapshots de EBS a las regiones adicionales.",
            "D. Programar Amazon EC2 Image Builder para que se ejecute una vez al día y cree una AMI y copie la AMI a las regiones adicionales."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "351.- Una empresa tiene un proyecto que lanza instancias de Amazon EC2 que son más grandes de lo requerido. La cuenta del proyecto no puede ser parte de la organización de la empresa en AWS Organizations debido a restricciones de política que mantienen esta actividad fuera del ámbito de TI corporativo. La empresa quiere permitir únicamente el lanzamiento de instancias EC2 t3.small por parte de los desarrolladores en la cuenta del proyecto. Estas instancias EC2 deben estar restringidas a la región us-east-2. ¿Qué debe hacer un arquitecto de soluciones para cumplir con estos requisitos?",
        "opciones": [
            "A. Crear una nueva cuenta de desarrollador. Mover todas las instancias EC2, usuarios y recursos a us-east-2. Agregar la cuenta a la organización de la empresa en AWS Organizations. Hacer cumplir una política de etiquetado que denote afinidad con la región.",
            "B. Crear un SCP que deniegue el lanzamiento de todas las instancias EC2, excepto las instancias EC2 t3.small en us-east-2. Adjuntar el SCP a la cuenta del proyecto.",
            "C. Crear y comprar una Instancia Reservada t3.small EC2 para cada desarrollador en us-east-2. Asignar a cada desarrollador una instancia EC2 específica con su nombre como etiqueta.",
            "D. Crear una política de IAM que permita el lanzamiento únicamente de instancias EC2 t3.small en us-east-2. Adjuntar la política a los roles y grupos que los desarrolladores usan en la cuenta del proyecto."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "352.- Una empresa científica necesita procesar datos de texto e imagen desde un bucket de Amazon S3. Los datos se recopilan de varias estaciones de radar durante una fase en vivo y crítica en el tiempo de una misión espacial profunda. Las estaciones de radar cargan los datos al bucket de S3 de origen. Los datos están prefijados con el número de identificación de la estación de radar. La empresa creó un bucket de S3 de destino en una segunda cuenta. Los datos deben copiarse desde el bucket de S3 de origen al bucket de S3 de destino para cumplir con un objetivo de cumplimiento. Esta replicación se realiza mediante una regla de replicación de S3 para cubrir todos los objetos en el bucket de S3 de origen. Una estación de radar específica se identifica como la que tiene los datos más precisos. La replicación de datos de esta estación de radar debe ser monitoreada para asegurar su finalización dentro de los 30 minutos posteriores a la carga de los objetos al bucket de S3 de origen. ¿Qué debe hacer un arquitecto de soluciones para cumplir con estos requisitos?",
        "opciones": [
            "A. Configurar un agente de AWS DataSync para replicar los datos prefijados desde el bucket de S3 de origen al bucket de S3 de destino. Seleccionar el uso de todo el ancho de banda disponible en la tarea y monitorear la tarea para asegurarse de que esté en el estado de TRANSFERRING. Crear una regla de Amazon EventBridge para iniciar una alerta si este estado cambia.",
            "B. En la segunda cuenta, crear otro bucket de S3 para recibir los datos de la estación de radar con los datos más precisos. Configurar una nueva regla de replicación para este nuevo bucket de S3 para separar la replicación de las otras estaciones de radar. Monitorear el tiempo máximo de replicación al destino. Crear una regla de Amazon EventBridge para iniciar una alerta cuando el tiempo exceda el umbral deseado.",
            "C. Habilitar la aceleración de transferencia de Amazon S3 en el bucket de S3 de origen y configurar la estación de radar con los datos más precisos para usar el nuevo punto final. Monitorear la métrica de latencia total de solicitudes del bucket de destino de S3. Crear una regla de Amazon EventBridge para iniciar una alerta si este estado cambia.",
            "D. Crear una nueva regla de replicación de S3 en el bucket de S3 de origen que filtre las claves que usen el prefijo de la estación de radar con los datos más precisos. Habilitar el Control de Tiempo de Replicación de S3 (S3 RTC). Monitorear el tiempo máximo de replicación al destino. Crear una regla de Amazon EventBridge para iniciar una alerta cuando el tiempo exceda el umbral deseado."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "353.- Una empresa quiere migrar su centro de datos local a la nube de AWS. Esto incluye miles de servidores virtualizados de Linux y Microsoft Windows, almacenamiento SAN, aplicaciones Java y PHP con MySQL, y bases de datos Oracle. Hay muchos servicios dependientes alojados ya sea en el mismo centro de datos o externamente. La documentación técnica está incompleta y desactualizada. Un arquitecto de soluciones necesita entender el entorno actual y estimar los costos de los recursos en la nube después de la migración. ¿Qué herramientas o servicios debe usar el arquitecto de soluciones para planificar la migración a la nube? (Elija tres.)",
        "opciones": [
            "A. AWS Application Discovery Service",
            "B. AWS SMS",
            "C. AWS X-Ray",
            "D. AWS Cloud Adoption Readiness Tool (CART)",
            "E. Amazon Inspector",
            "F. AWS Migration Hub"
        ],
        "respuestas_correctas": [
            "F",
            "D",
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "354.- Un arquitecto de soluciones está revisando la resiliencia de una aplicación antes de su lanzamiento. La aplicación se ejecuta en una instancia Amazon EC2 que está desplegada en una subred privada de un VPC. La instancia EC2 es aprovisionada por un grupo de Auto Scaling que tiene una capacidad mínima de 1 y una capacidad máxima de 1. La aplicación almacena datos en una instancia Amazon RDS for MySQL. El VPC tiene subredes configuradas en tres Availability Zones y está configurado con una única NAT gateway. El arquitecto de soluciones necesita recomendar una solución para garantizar que la aplicación operará a través de varias Availability Zones. ¿Qué solución cumplirá con este requisito?",
        "opciones": [
            "A. Despliegue una NAT gateway adicional en las otras Availability Zones. Actualice las tablas de rutas con las rutas apropiadas. Modifique la instancia RDS for MySQL a una configuración Multi-AZ. Configure el grupo de Auto Scaling para lanzar las instancias a través de las Availability Zones. Establezca la capacidad mínima y máxima del grupo de Auto Scaling a 3.",
            "B. Reemplace la NAT gateway con un virtual private gateway. Reemplace la instancia RDS for MySQL con un clúster de base de datos Amazon Aurora MySQL. Configure el grupo de Auto Scaling para lanzar instancias en todas las subredes del VPC. Establezca la capacidad mínima y máxima del grupo de Auto Scaling a 3.",
            "C. Reemplace la NAT gateway con una NAT instance. Migre la instancia RDS for MySQL a una instancia RDS for PostgreSQL. Lance una nueva instancia EC2 en las otras Availability Zones.",
            "D. Despliegue una NAT gateway adicional en las otras Availability Zones. Actualice las tablas de rutas con las rutas apropiadas. Modifique la instancia RDS for MySQL para habilitar las copias de seguridad automáticas y retener las copias de seguridad durante 7 días. Configure el grupo de Auto Scaling para lanzar instancias a través de todas las subredes del VPC. Mantenga la capacidad mínima y máxima del grupo de Auto Scaling en 1."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "355.- Una empresa está planeando migrar su aplicación de procesamiento de transacciones local a AWS. La aplicación se ejecuta dentro de contenedores Docker que están alojados en máquinas virtuales (VM) en el centro de datos de la empresa. Los contenedores Docker tienen almacenamiento compartido donde la aplicación registra los datos de las transacciones. Las transacciones son sensibles al tiempo. El volumen de transacciones dentro de la aplicación es impredecible. La empresa debe implementar una solución de almacenamiento de baja latencia que escale automáticamente el rendimiento para satisfacer la demanda creciente. La empresa no puede desarrollar más la aplicación ni continuar administrando el entorno de alojamiento Docker. ¿Cómo debería migrar la empresa la aplicación a AWS para cumplir con estos requisitos?",
        "opciones": [
            "A. Migrar los contenedores que ejecutan la aplicación a Amazon Elastic Kubernetes Service (Amazon EKS). Usar Amazon S3 para almacenar los datos de las transacciones que los contenedores comparten.",
            "B. Migrar los contenedores que ejecutan la aplicación a AWS Fargate para Amazon Elastic Container Service (Amazon ECS). Crear un sistema de archivos Amazon Elastic File System (Amazon EFS). Crear una definición de tarea de Fargate. Agregar un volumen a la definición de la tarea para apuntar al sistema de archivos EFS.",
            "C. Migrar los contenedores que ejecutan la aplicación a AWS Fargate para Amazon Elastic Container Service (Amazon ECS). Crear un volumen Amazon Elastic Block Store (Amazon EBS). Crear una definición de tarea de Fargate. Adjuntar el volumen EBS a cada tarea en ejecución.",
            "D. Lanzar instancias de Amazon EC2. Instalar Docker en las instancias EC2. Migrar los contenedores a las instancias EC2. Crear un sistema de archivos Amazon Elastic File System (Amazon EFS). Agregar un punto de montaje a las instancias EC2 para el sistema de archivos EFS."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "356.- Una empresa está planeando migrar a la nube de AWS. La empresa aloja muchas aplicaciones en servidores con Windows y Linux. Algunos de los servidores son físicos y otros son virtuales. La empresa utiliza varios tipos de bases de datos en su entorno local. La empresa no tiene un inventario preciso de sus servidores y aplicaciones locales. La empresa desea dimensionar correctamente sus recursos durante la migración. Un arquitecto de soluciones necesita obtener información sobre las conexiones de red y las relaciones entre aplicaciones. El arquitecto de soluciones debe evaluar el entorno actual de la empresa y desarrollar un plan de migración. ¿Qué solución proporcionará al arquitecto de soluciones la información necesaria para desarrollar el plan de migración?",
        "opciones": [
            "A. Usar Migration Evaluator para solicitar una evaluación del entorno de AWS. Usar el Agente sin agente de AWS Application Discovery Service para importar los detalles en un informe de Quick Insights de Migration Evaluator.",
            "B. Usar AWS Migration Hub e instalar el Agente de AWS Application Discovery en los servidores. Desplegar el recolector de datos de la aplicación Migration Hub Strategy Recommendations. Generar un informe usando Migration Hub Strategy Recommendations.",
            "C. Usar AWS Migration Hub y ejecutar el Agente sin agente de AWS Application Discovery Service en los servidores. Agrupar los servidores y bases de datos usando AWS Application Migration Service. Generar un informe usando Migration Hub Strategy Recommendations.",
            "D. Usar la herramienta de importación de AWS Migration Hub para cargar los detalles del entorno local de la empresa. Generar un informe usando Migration Hub Strategy Recommendations."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "357.- Una empresa de servicios financieros vende su plataforma de software como servicio (SaaS) para el cumplimiento de aplicaciones a grandes bancos globales. La plataforma SaaS se ejecuta en AWS y utiliza múltiples cuentas de AWS que se gestionan en una organización en AWS Organizations. La plataforma SaaS utiliza muchos recursos de AWS a nivel mundial. Para el cumplimiento normativo, todas las llamadas API a los recursos de AWS deben ser auditadas, rastreadas para cambios y almacenadas en un almacenamiento de datos seguro y duradero. ¿Qué solución cumplirá estos requisitos con el MENOR esfuerzo operativo?",
        "opciones": [
            "A. Crear una nueva pista de AWS CloudTrail. Usar un bucket de Amazon S3 existente en la cuenta de gestión de la organización para almacenar los registros. Desplegar la pista en todas las regiones de AWS. Habilitar la eliminación MFA y el cifrado en el bucket de S3.",
            "B. Crear una nueva pista de AWS CloudTrail en cada cuenta miembro de la organización. Crear nuevos buckets de Amazon S3 para almacenar los registros. Desplegar la pista en todas las regiones de AWS. Habilitar la eliminación MFA y el cifrado en los buckets de S3.",
            "C. Crear una nueva pista de AWS CloudTrail en la cuenta de gestión de la organización. Crear un nuevo bucket de Amazon S3 con versionado activado para almacenar los registros. Desplegar la pista para todas las cuentas de la organización. Habilitar la eliminación MFA y el cifrado en el bucket de S3.",
            "D. Crear una nueva pista de AWS CloudTrail en la cuenta de gestión de la organización. Crear un nuevo bucket de Amazon S3 para almacenar los registros. Configurar Amazon Simple Notification Service (Amazon SNS) para enviar notificaciones de entrega de archivos de registro a un sistema de gestión externo que rastreará los registros. Habilitar la eliminación MFA y el cifrado en el bucket de S3."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "358.- Una empresa está desplegando una base de datos distribuida en memoria en una flota de instancias de Amazon EC2. La flota consiste en un nodo primario y ocho nodos trabajadores. El nodo primario es responsable de monitorear la salud del clúster, aceptar solicitudes de usuarios, distribuir las solicitudes de usuarios a los nodos trabajadores y enviar una respuesta agregada de vuelta al cliente. Los nodos trabajadores se comunican entre sí para replicar particiones de datos. La empresa requiere la latencia de red más baja posible para lograr el máximo rendimiento. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Lanzar instancias EC2 optimizadas para memoria en un grupo de colocación de particiones.",
            "B. Lanzar instancias EC2 optimizadas para cómputo en un grupo de colocación de particiones.",
            "C. Lanzar instancias EC2 optimizadas para memoria en un grupo de colocación de clúster.",
            "D. Lanzar instancias EC2 optimizadas para cómputo en un grupo de colocación distribuida."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "359.- Una empresa mantiene información en sus instalaciones en aproximadamente 1 millón de archivos .csv que están alojados en una máquina virtual. Los datos inicialmente tienen un tamaño de 10 TB y crecen a una tasa de 1 TB por semana. La empresa necesita automatizar las copias de seguridad de los datos en la nube de AWS. Las copias de seguridad de los datos deben realizarse a diario. La empresa necesita una solución que aplique filtros personalizados para hacer una copia de seguridad solo de un subconjunto de los datos que están ubicados en directorios de origen designados. La empresa ha establecido una conexión AWS Direct Connect. ¿Qué solución cumplirá con los requisitos de copia de seguridad con el MENOR esfuerzo operativo?",
        "opciones": [
            "A. Usar la operación API CopyObject de Amazon S3 con carga multipart para copiar los datos existentes a Amazon S3. Usar la operación API CopyObject para replicar los nuevos datos a Amazon S3 a diario.",
            "B. Crear un plan de copia de seguridad en AWS Backup para respaldar los datos a Amazon S3. Programar el plan de copia de seguridad para que se ejecute a diario.",
            "C. Instalar el agente de AWS DataSync como una máquina virtual que se ejecute en el hipervisor local. Configurar una tarea de DataSync para replicar los datos a Amazon S3 a diario.",
            "D. Usar un dispositivo AWS Snowball Edge para la copia de seguridad inicial. Usar AWS DataSync para copias de seguridad incrementales a Amazon S3 a diario."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "360.- Una empresa de servicios financieros tiene un producto de gestión de activos que miles de clientes usan en todo el mundo. Los clientes proporcionan comentarios sobre el producto a través de encuestas. La empresa está construyendo una nueva solución analítica que se ejecuta en Amazon EMR para analizar los datos de estas encuestas. Las siguientes personas usuarias necesitan acceder a la solución analítica para realizar diferentes acciones: Administrador: Proporciona el clúster EMR para el equipo de análisis según los requisitos del equipo. Ingeniero de datos: Ejecuta scripts ETL para procesar, transformar y enriquecer los conjuntos de datos. Analista de datos: Ejecuta consultas SQL y Hive sobre los datos. Un arquitecto de soluciones debe asegurarse de que todas las personas usuarias tengan acceso de menor privilegio solo a los recursos que necesitan. Las personas usuarias deben poder lanzar solo las aplicaciones que estén aprobadas y autorizadas. La solución también debe garantizar el etiquetado de todos los recursos que las personas usuarias creen. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Crear roles de IAM para cada persona usuaria. Adjuntar políticas basadas en identidades para definir qué acciones puede realizar la persona usuaria que asuma el rol. Crear una regla de AWS Config para comprobar recursos no conformes. Configurar la regla para notificar al administrador para que remedie los recursos no conformes.",
            "B. Configurar autenticación basada en Kerberos para los clústeres EMR al lanzarlos. Especificar una configuración de seguridad de Kerberos junto con opciones de Kerberos específicas para el clúster.",
            "C. Usar AWS Service Catalog para controlar las versiones de Amazon EMR disponibles para su implementación, la configuración del clúster y los permisos para cada persona usuaria.",
            "D. Lanzar el clúster EMR utilizando AWS CloudFormation. Adjuntar políticas basadas en recursos al clúster EMR durante su creación. Crear una regla de AWS Config para comprobar clústeres no conformes y cubos de Amazon S3 no conformes. Configurar la regla para notificar al administrador para que remedie los recursos no conformes."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "361.- Una empresa de software como servicio (SaaS) usa AWS para alojar un servicio que está impulsado por AWS PrivateLink. El servicio consiste en un software propietario que se ejecuta en tres instancias de Amazon EC2 detrás de un Network Load Balancer (NLB). Las instancias están en subredes privadas en múltiples Zonas de Disponibilidad en la región eu-west-2. Todos los clientes de la empresa están en eu-west-2. Sin embargo, la empresa ahora adquiere un nuevo cliente en la región us-east-1. La empresa crea un nuevo VPC y nuevas subredes en us-east-1. La empresa establece un emparejamiento inter-región de VPC entre las VPC en ambas regiones. La empresa quiere dar acceso al nuevo cliente al servicio SaaS, pero no quiere implementar inmediatamente nuevos recursos EC2 en us-east-1. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Configurar un servicio de endpoint de PrivateLink en us-east-1 para usar el NLB existente que está en eu-west-2. Conceder acceso a cuentas específicas de AWS para conectar con el servicio SaaS.",
            "B. Crear un NLB en us-east-1. Crear un grupo de destino IP que use las direcciones IP de las instancias de la empresa en eu-west-2 que hospedan el servicio SaaS. Configurar un servicio de endpoint de PrivateLink que use el NLB en us-east-1. Conceder acceso a cuentas específicas de AWS para conectar con el servicio SaaS.",
            "C. Crear un Application Load Balancer (ALB) delante de las instancias de EC2 en eu-west-2. Crear un NLB en us-east-1. Asociar el NLB de us-east-1 con un grupo de destino ALB que use el ALB en eu-west-2. Configurar un servicio de endpoint de PrivateLink que use el NLB en us-east-1. Conceder acceso a cuentas específicas de AWS para conectar con el servicio SaaS.",
            "D. Usar AWS Resource Access Manager (AWS RAM) para compartir las instancias EC2 que están en eu-west-2. En us-east-1, crear un NLB y un grupo de destino de instancias que incluya las instancias EC2 compartidas de eu-west-2. Configurar un servicio de endpoint de PrivateLink que use el NLB en us-east-1. Conceder acceso a cuentas específicas de AWS para conectar con el servicio SaaS."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "362.- Una empresa necesita monitorear un número creciente de buckets de Amazon S3 en dos regiones de AWS. La empresa también necesita hacer un seguimiento del porcentaje de objetos que están cifrados en Amazon S3. La empresa necesita un panel de control para mostrar esta información a los equipos internos de cumplimiento. ¿Qué solución cumplirá con estos requisitos con el MENOR esfuerzo operativo?",
        "opciones": [
            "A. Crear un nuevo panel de control de Storage Lens en cada región para rastrear métricas de bucket y cifrado. Agregar los datos de ambos paneles de control de las regiones en un solo panel en Amazon QuickSight para los equipos de cumplimiento.",
            "B. Desplegar una función de AWS Lambda en cada región para listar la cantidad de buckets y el estado de cifrado de los objetos. Almacenar estos datos en Amazon S3. Usar consultas de Amazon Athena para mostrar los datos en un panel personalizado en Amazon QuickSight para los equipos de cumplimiento.",
            "C. Usar el panel de control predeterminado de S3 Storage Lens para rastrear métricas de bucket y cifrado. Dar acceso a los equipos de cumplimiento al panel directamente en la consola de S3.",
            "D. Crear una regla de Amazon EventBridge para detectar eventos de AWS CloudTrail para la creación de objetos de S3. Configurar la regla para invocar una función de AWS Lambda para registrar métricas de cifrado en Amazon DynamoDB. Usar Amazon QuickSight para mostrar las métricas en un panel de control para los equipos de cumplimiento."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "363.- El CISO de una empresa ha solicitado a un arquitecto de soluciones que rediseñe las prácticas actuales de CI/CD de la empresa para asegurarse de que los despliegues de parches a su aplicación puedan realizarse lo más rápido posible con un tiempo de inactividad mínimo si se descubren vulnerabilidades. La empresa también debe ser capaz de revertir rápidamente un cambio en caso de errores. La aplicación web está desplegada en una flota de instancias de Amazon EC2 detrás de un Application Load Balancer. La empresa actualmente usa GitHub para alojar el código fuente de la aplicación y ha configurado un proyecto de AWS CodeBuild para construir la aplicación. La empresa también tiene la intención de usar AWS CodePipeline para activar construcciones a partir de los commits de GitHub utilizando el proyecto CodeBuild existente. ¿Qué configuración de CI/CD cumple con todos los requisitos?",
        "opciones": [
            "A. Configurar CodePipeline con una etapa de despliegue usando AWS CodeDeploy configurado para despliegues en el lugar. Monitorear el código recién desplegado y, si hay problemas, enviar otra actualización de código.",
            "B. Configurar CodePipeline con una etapa de despliegue usando AWS CodeDeploy configurado para despliegues blue/green. Monitorear el código recién desplegado y, si hay problemas, activar un rollback manual usando CodeDeploy.",
            "C. Configurar CodePipeline con una etapa de despliegue usando AWS CloudFormation para crear una pipeline para las pilas de prueba y producción. Monitorear el código recién desplegado y, si hay problemas, enviar otra actualización de código.",
            "D. Configurar CodePipeline con una etapa de despliegue usando AWS OpsWorks y despliegues en el lugar. Monitorear el código recién desplegado y, si hay problemas, enviar otra actualización de código."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "364.- Una empresa está gestionando varias cuentas de AWS mediante una organización en AWS Organizations. Diferentes unidades de negocio en la empresa ejecutan aplicaciones en instancias de Amazon EC2. Todas las instancias de EC2 deben tener una etiqueta BusinessUnit para que la empresa pueda hacer un seguimiento del costo de cada unidad de negocio. Una auditoría reciente reveló que algunas instancias no tenían esta etiqueta. La empresa añadió manualmente la etiqueta que faltaba a las instancias. ¿Qué debe hacer un arquitecto de soluciones para hacer cumplir el requisito de etiquetado en el futuro?",
        "opciones": [
            "A. Habilitar políticas de etiquetas en la organización. Crear una política de etiquetas para la etiqueta BusinessUnit. Asegurarse de que la compatibilidad con la capitalización de las claves de etiquetas esté desactivada. Implementar la política de etiquetas para el tipo de recurso ec2:instance. Adjuntar la política de etiquetas a la raíz de la organización.",
            "B. Habilitar políticas de etiquetas en la organización. Crear una política de etiquetas para la etiqueta BusinessUnit. Asegurarse de que la compatibilidad con la capitalización de las claves de etiquetas esté activada. Implementar la política de etiquetas para el tipo de recurso ec2:instance. Adjuntar la política de etiquetas a la cuenta de gestión de la organización.",
            "C. Crear un SCP y adjuntarlo a la raíz de la organización. Incluir la siguiente declaración en el SCP:",
            "D. Crear un SCP y adjuntarlo a la cuenta de gestión de la organización. Incluir la siguiente declaración en el SCP:"
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": [ {
            "respuesta": "C",
            "url": "images/image364-1.png"
        },
        {
            "respuesta": "D",
            "url": "images/image364-2.png"
        }]
    },
    {
        "pregunta": "365.- Una empresa está ejecutando una carga de trabajo que consiste en miles de instancias de Amazon EC2. La carga de trabajo se ejecuta en una VPC que contiene varias subredes públicas y privadas. Las subredes públicas tienen una ruta para 0.0.0.0/0 a una puerta de enlace de internet existente. Las subredes privadas tienen una ruta para 0.0.0.0/0 a una puerta de enlace NAT existente. Un arquitecto de soluciones necesita migrar toda la flota de instancias EC2 para que usen IPv6. Las instancias EC2 que están en subredes privadas no deben ser accesibles desde Internet público. ¿Qué debe hacer el arquitecto de soluciones para cumplir con estos requisitos?",
        "opciones": [
            "A. Actualizar la VPC existente y asociar un bloque CIDR IPv6 personalizado con la VPC y todas las subredes. Actualizar todas las tablas de enrutamiento de la VPC y agregar una ruta para ::/0 a la puerta de enlace de internet.",
            "B. Actualizar la VPC existente y asociar un bloque CIDR IPv6 proporcionado por Amazon con la VPC y todas las subredes. Actualizar las tablas de enrutamiento de la VPC para todas las subredes privadas y agregar una ruta para ::/0 a la puerta de enlace NAT.",
            "C. Actualizar la VPC existente y asociar un bloque CIDR IPv6 proporcionado por Amazon con la VPC y todas las subredes. Crear una puerta de enlace de internet solo de salida. Actualizar las tablas de enrutamiento de la VPC para todas las subredes privadas y agregar una ruta para ::/0 a la puerta de enlace de internet solo de salida.",
            "D. Actualizar la VPC existente y asociar un bloque CIDR IPv6 personalizado con la VPC y todas las subredes. Crear una nueva puerta de enlace NAT y habilitar el soporte de IPv6. Actualizar las tablas de enrutamiento de la VPC para todas las subredes privadas y agregar una ruta para ::/0 a la puerta de enlace NAT habilitada para IPv6."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "366.- Una empresa está utilizando Amazon API Gateway para desplegar una API REST privada que proporcionará acceso a datos sensibles. La API debe ser accesible solo desde una aplicación desplegada en una VPC. La empresa ha desplegado la API con éxito. Sin embargo, la API no es accesible desde una instancia de Amazon EC2 que está desplegada en la VPC. ¿Qué solución proporcionará conectividad entre la instancia EC2 y la API?",
        "opciones": [
            "A. Crear un punto de enlace VPC de interfaz para API Gateway. Adjuntar una política de punto de enlace que permita las acciones apigateway:*. Deshabilitar el nombrado DNS privado para el punto de enlace VPC. Configurar una política de recursos de la API que permita el acceso desde la VPC. Usar el nombre DNS del punto de enlace VPC para acceder a la API.",
            "B. Crear un punto de enlace VPC de interfaz para API Gateway. Adjuntar una política de punto de enlace que permita la acción execute-api:Invoke. Habilitar el nombrado DNS privado para el punto de enlace VPC. Configurar una política de recursos de la API que permita el acceso desde el punto de enlace VPC. Usar los nombres DNS del punto de enlace de la API para acceder a la API.",
            "C. Crear un Network Load Balancer (NLB) y un enlace VPC. Configurar la integración privada entre API Gateway y el NLB. Usar los nombres DNS del punto de enlace de la API para acceder a la API.",
            "D. Crear un Application Load Balancer (ALB) y un VPC Link. Configurar la integración privada entre API Gateway y el ALB. Usar el nombre DNS del punto de enlace del ALB para acceder a la API."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "367.- Una gran empresa de nómina se fusionó recientemente con una pequeña empresa de personal. La empresa unificada ahora tiene varias unidades de negocio, cada una con su propia cuenta de AWS existente. Un arquitecto de soluciones debe garantizar que la empresa pueda gestionar de manera centralizada las políticas de facturación y acceso para todas las cuentas de AWS. El arquitecto de soluciones configura AWS Organizations enviando una invitación a todas las cuentas miembros de la empresa desde una cuenta de gestión centralizada. ¿Qué debe hacer el arquitecto de soluciones a continuación para cumplir con estos requisitos?",
        "opciones": [
            "A. Crear el grupo IAM OrganizationAccountAccess en cada cuenta miembro. Incluir los roles IAM necesarios para cada administrador.",
            "B. Crear la política IAM OrganizationAccountAccessPolicy en cada cuenta miembro. Conectar las cuentas miembros a la cuenta de gestión mediante acceso entre cuentas.",
            "C. Crear el rol IAM OrganizationAccountAccessRole en cada cuenta miembro. Conceder permiso a la cuenta de gestión para asumir el rol IAM.",
            "D. Crear el rol IAM OrganizationAccountAccessRole en la cuenta de gestión. Adjuntar la política administrada por AWS AdministratorAccess al rol IAM. Asignar el rol IAM a los administradores de cada cuenta miembro."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "368.- Una empresa tiene servicios de aplicaciones que han sido contenedorizados y desplegados en múltiples instancias de Amazon EC2 con IPs públicas. Se ha desplegado un clúster de Apache Kafka en las instancias de EC2. Una base de datos PostgreSQL ha sido migrada a Amazon RDS para PostgreSQL. La empresa espera un aumento significativo de pedidos en su plataforma cuando se lance una nueva versión de su producto insignia. ¿Qué cambios en la arquitectura actual reducirán la sobrecarga operativa y respaldarán el lanzamiento del producto?",
        "opciones": [
            "A. Crear un grupo de Auto Scaling de EC2 detrás de un Application Load Balancer. Crear réplicas de solo lectura adicionales para la instancia de la base de datos. Crear flujos de datos de Amazon Kinesis y configurar los servicios de la aplicación para usar los flujos de datos. Almacenar y servir contenido estático directamente desde Amazon S3.",
            "B. Crear un grupo de Auto Scaling de EC2 detrás de un Application Load Balancer. Desplegar la instancia de la base de datos en modo Multi-AZ y habilitar el auto escalado de almacenamiento. Crear flujos de datos de Amazon Kinesis y configurar los servicios de la aplicación para usar los flujos de datos. Almacenar y servir contenido estático directamente desde Amazon S3.",
            "C. Desplegar la aplicación en un clúster de Kubernetes creado en las instancias de EC2 detrás de un Application Load Balancer. Desplegar la instancia de la base de datos en modo Multi-AZ y habilitar el auto escalado de almacenamiento. Crear un clúster de Amazon Managed Streaming for Apache Kafka y configurar los servicios de la aplicación para usar el clúster. Almacenar contenido estático en Amazon S3 detrás de una distribución de Amazon CloudFront.",
            "D. Desplegar la aplicación en Amazon Elastic Kubernetes Service (Amazon EKS) con AWS Fargate y habilitar el auto escalado detrás de un Application Load Balancer. Crear réplicas de solo lectura adicionales para la instancia de la base de datos. Crear un clúster de Amazon Managed Streaming for Apache Kafka y configurar los servicios de la aplicación para usar el clúster. Almacenar contenido estático en Amazon S3 detrás de una distribución de Amazon CloudFront."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "369.- Una empresa aloja una VPN en un centro de datos local. Los empleados se conectan actualmente a la VPN para acceder a los archivos en sus directorios personales de Windows. Recientemente, ha habido un gran crecimiento en el número de empleados que trabajan de forma remota. Como resultado, el uso de ancho de banda para las conexiones al centro de datos ha comenzado a alcanzar el 100% durante las horas laborales. La empresa debe diseñar una solución en AWS que respalde el crecimiento de la fuerza laboral remota de la empresa, reduzca el uso de ancho de banda para las conexiones al centro de datos y reduzca la sobrecarga operativa. ¿Qué combinación de pasos cumplirá con estos requisitos con el MENOR esfuerzo operativo? (Elija dos).",
        "opciones": [
            "A. Crear un AWS Storage Gateway Volume Gateway. Montar un volumen desde el Volume Gateway en el servidor de archivos local.",
            "B. Migrar los directorios personales a Amazon FSx para Windows File Server.",
            "C. Migrar los directorios personales a Amazon FSx para Lustre.",
            "D. Migrar a los usuarios remotos a AWS Client VPN.",
            "E. Crear una conexión AWS Direct Connect desde el centro de datos local a AWS."
        ],
        "respuestas_correctas": [
            "D",
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "370.- Una empresa tiene varias cuentas de AWS. La empresa recientemente tuvo una auditoría de seguridad que reveló muchos volúmenes de Amazon Elastic Block Store (Amazon EBS) no cifrados, adjuntos a instancias de Amazon EC2. Un arquitecto de soluciones debe cifrar los volúmenes no cifrados y garantizar que los volúmenes no cifrados sean detectados automáticamente en el futuro. Además, la empresa desea una solución que pueda gestionar múltiples cuentas de AWS de manera centralizada, con un enfoque en cumplimiento y seguridad. ¿Qué combinación de pasos debe seguir el arquitecto de soluciones para cumplir con estos requisitos? (Elija dos).",
        "opciones": [
            "A. Crear una organización en AWS Organizations. Configurar AWS Control Tower y activar los controles (guardrails) fuertemente recomendados. Unir todas las cuentas a la organización. Categorizar las cuentas de AWS en OUs.",
            "B. Usar la AWS CLI para listar todos los volúmenes no cifrados en todas las cuentas de AWS. Ejecutar un script para cifrar todos los volúmenes no cifrados en su lugar.",
            "C. Crear una instantánea de cada volumen no cifrado. Crear un nuevo volumen cifrado a partir de la instantánea no cifrada. Desmontar el volumen existente y reemplazarlo con el volumen cifrado.",
            "D. Crear una organización en AWS Organizations. Configurar AWS Control Tower y activar los controles (guardrails) obligatorios. Unir todas las cuentas a la organización. Categorizar las cuentas de AWS en OUs.",
            "E. Activar AWS CloudTrail. Configurar una regla de Amazon EventBridge para detectar y cifrar automáticamente los volúmenes no cifrados."
        ],
        "respuestas_correctas": [
            "C",
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "371.- Una empresa aloja una aplicación web de intranet en instancias de Amazon EC2 detrás de un Application Load Balancer (ALB). Actualmente, los usuarios se autentican en la aplicación utilizando una base de datos interna de usuarios. La empresa necesita autenticar a los usuarios en la aplicación utilizando un directorio existente de AWS Directory Service para Microsoft Active Directory. Todos los usuarios que tengan cuentas en el directorio deben tener acceso a la aplicación. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Crear un nuevo cliente de aplicación en el directorio. Crear una regla de listener para el ALB. Especificar la acción authenticate-oidc para la regla del listener. Configurar la regla del listener con el emisor adecuado, el ID de cliente y el secreto, y los detalles de endpoint para el servicio de Active Directory. Configurar el nuevo cliente de aplicación con la URL de callback que proporciona el ALB.",
            "B. Configurar un grupo de usuarios de Amazon Cognito. Configurar el grupo de usuarios con un proveedor de identidad federado (IdP) que tenga metadatos del directorio. Crear un cliente de aplicación. Asociar el cliente de aplicación con el grupo de usuarios. Crear una regla de listener para el ALB. Especificar la acción authenticate-cognito para la regla del listener. Configurar la regla del listener para utilizar el grupo de usuarios y el cliente de aplicación.",
            "C. Agregar el directorio como un nuevo proveedor de identidad de IAM (IdP). Crear un nuevo rol de IAM que tenga un tipo de entidad de federación SAML 2.0. Configurar una política de rol que permita el acceso al ALB. Configurar el nuevo rol como el rol predeterminado para usuarios autenticados en el IdP. Crear una regla de listener para el ALB. Especificar la acción authenticate-oidc para la regla del listener.",
            "D. Habilitar AWS IAM Identity Center (AWS Single Sign-On). Configurar el directorio como un proveedor de identidad externo (IdP) que utilice SAML. Utilizar el método de aprovisionamiento automático. Crear un nuevo rol de IAM que tenga un tipo de entidad de federación SAML 2.0. Configurar una política de rol que permita el acceso al ALB. Adjuntar el nuevo rol a todos los grupos. Crear una regla de listener para el ALB. Especificar la acción authenticate-cognito para la regla del listener."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "372.- Una empresa tiene un sitio web que atiende a muchos visitantes. La empresa despliega un servicio de backend para el sitio web en una región primaria de AWS y en una región de recuperación ante desastres (DR). Se ha desplegado una única distribución de Amazon CloudFront para el sitio web. La empresa crea un conjunto de registros de Amazon Route 53 con verificaciones de salud y una política de enrutamiento de conmutación por error (failover) para el servicio de backend de la región primaria. La empresa configura dicho conjunto de registros de Route 53 como un origen para la distribución de CloudFront. Además, configura otro conjunto de registros que apunta al endpoint del servicio de backend en la región DR como un registro secundario de conmutación por error. El TTL para ambos conjuntos de registros es de 60 segundos. Actualmente, la conmutación por error toma más de 1 minuto. Un arquitecto de soluciones debe diseñar una solución que proporcione el tiempo de conmutación por error más rápido. ¿Qué solución logrará este objetivo?",
        "opciones": [
            "A. Desplegar una distribución adicional de CloudFront. Crear un nuevo conjunto de registros de Route 53 con verificación de salud para ambas distribuciones de CloudFront, utilizando una política de conmutación por error.",
            "B. Establecer el TTL a 4 segundos para los conjuntos de registros de Route 53 existentes que se utilizan para el servicio de backend en cada región.",
            "C. Crear nuevos conjuntos de registros para los servicios de backend utilizando una política de enrutamiento basada en latencia. Utilizar estos conjuntos de registros como origen en la distribución de CloudFront.",
            "D. Crear un grupo de orígenes (origin group) en CloudFront que incluya dos orígenes, uno para cada región del servicio de backend. Configurar la conmutación por error del origen como un comportamiento de caché para la distribución de CloudFront."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "373.- Una empresa está utilizando múltiples cuentas de AWS y cuenta con varios equipos de DevOps que ejecutan cargas de trabajo de producción y no producción en estas cuentas. La empresa desea restringir de forma centralizada el acceso a algunos de los servicios de AWS que los equipos de DevOps no utilizan. La empresa decidió utilizar AWS Organizations e invitó con éxito a todas las cuentas de AWS a la Organización. Desean permitir el acceso a los servicios que actualmente se usan y denegar algunos servicios específicos. Además, les gustaría administrar varias cuentas juntas como una sola unidad. ¿Qué combinación de pasos debe seguir el arquitecto de soluciones para satisfacer estos requisitos? (Elija tres.)",
        "opciones": [
            "A. Utilizar una estrategia de lista de denegación.",
            "B. Revisar el Access Advisor en AWS IAM para determinar los servicios utilizados recientemente.",
            "C. Revisar el informe de AWS Trusted Advisor para determinar los servicios utilizados recientemente.",
            "D. Eliminar la SCP predeterminada FullAWSAccess.",
            "E. Definir unidades organizativas (OU) y colocar las cuentas miembros en las OU.",
            "F. Eliminar la SCP predeterminada DenyAWSAccess."
        ],
        "respuestas_correctas": [
            "E",
            "B",
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "374.- Una empresa de eventos en vivo está diseñando una solución de escalado para su aplicación de venta de boletos en AWS. La aplicación tiene picos altos de utilización durante los eventos de venta. Cada evento de venta es un evento único y programado. La aplicación se ejecuta en instancias de Amazon EC2 que están en un grupo de Auto Scaling. La aplicación utiliza PostgreSQL para la capa de base de datos. La empresa necesita una solución de escalado para maximizar la disponibilidad durante los eventos de venta. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Utilizar una política de escalado predictivo para las instancias de EC2. Alojar la base de datos en una instancia de base de datos Amazon Aurora PostgreSQL Serverless v2 Multi-AZ con réplicas de lectura que se escalan automáticamente. Crear una máquina de estados de AWS Step Functions para ejecutar funciones AWS Lambda en paralelo y precalentar la base de datos antes de un evento de venta. Crear una regla de Amazon EventBridge para invocar la máquina de estados.",
            "B. Utilizar una política de escalado programado para las instancias de EC2. Alojar la base de datos en una instancia de base de datos Amazon RDS para PostgreSQL Multi-AZ con réplicas de lectura que se escalan automáticamente. Crear una regla de Amazon EventBridge que invoque una función AWS Lambda para crear una réplica de lectura más grande antes de un evento de venta. Realizar el cambio a la réplica de lectura más grande. Crear otra regla de EventBridge que invoque otra función Lambda para reducir la escala de la réplica de lectura después del evento de venta.",
            "C. Utilizar una política de escalado predictivo para las instancias de EC2. Alojar la base de datos en una instancia de base de datos Amazon RDS para PostgreSQL Multi-AZ con réplicas de lectura que se escalan automáticamente. Crear una máquina de estados de AWS Step Functions para ejecutar funciones AWS Lambda en paralelo y precalentar la base de datos antes de un evento de venta. Crear una regla de Amazon EventBridge para invocar la máquina de estados.",
            "D. Utilizar una política de escalado programado para las instancias de EC2. Alojar la base de datos en un clúster de base de datos Amazon Aurora PostgreSQL Multi-AZ. Crear una regla de Amazon EventBridge que invoque una función AWS Lambda para crear una réplica Aurora más grande antes de un evento de venta. Realizar el cambio a la réplica Aurora más grande. Crear otra regla de EventBridge que invoque otra función Lambda para reducir la escala de la réplica Aurora después del evento de venta."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "375.- Una empresa ejecuta una aplicación de intranet en sus instalaciones. La empresa desea configurar una copia de seguridad en la nube de la aplicación. La empresa ha seleccionado AWS Elastic Disaster Recovery para esta solución. La empresa requiere que el tráfico de replicación no viaje a través de Internet público. Además, la aplicación no debe ser accesible desde Internet. La empresa no quiere que esta solución consuma todo el ancho de banda de red disponible, ya que otras aplicaciones también requieren ancho de banda. ¿Qué combinación de pasos cumplirá con estos requisitos? (Elija tres.)",
        "opciones": [
            "A. Cree una VPC que tenga al menos dos subredes privadas, dos NAT gateways y un virtual private gateway.",
            "B. Cree una VPC que tenga al menos dos subredes públicas, un virtual private gateway y un internet gateway.",
            "C. Cree una conexión VPN Site-to-Site de AWS entre la red local y la red de destino en AWS.",
            "D. Cree una conexión de AWS Direct Connect y un Direct Connect gateway entre la red local y la red de destino en AWS.",
            "E. Durante la configuración de los servidores de replicación, seleccione la opción de utilizar direcciones IP privadas para la replicación de datos.",
            "F. Durante la configuración de los ajustes de inicio para los servidores de destino, seleccione la opción que asegure que la dirección IP privada de la instancia de recuperación coincida con la dirección IP privada del servidor de origen."
        ],
        "respuestas_correctas": [
            "E",
            "D",
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "376.- Una empresa que ofrece servicios de almacenamiento de imágenes desea desplegar una solución orientada al cliente en AWS. Millones de clientes individuales utilizarán la solución. La solución recibirá lotes de archivos de imagen de gran tamaño, redimensionará los archivos y los almacenará en un bucket de Amazon S3 durante hasta 6 meses. La solución debe ser capaz de manejar una variación significativa en la demanda. Además, la solución debe ser confiable a escala empresarial y tener la capacidad de reejecutar trabajos de procesamiento en caso de fallo. ¿Cuál solución cumplirá estos requisitos de la manera MÁS rentable?",
        "opciones": [
            "A. Utilizar AWS Step Functions para procesar el evento de S3 que ocurre cuando un usuario almacena una imagen. Ejecutar una función AWS Lambda que redimensione la imagen en el lugar y reemplace el archivo original en el bucket de S3. Crear una política de expiración de ciclo de vida de S3 para expirar todas las imágenes almacenadas después de 6 meses.",
            "B. Utilizar Amazon EventBridge para procesar el evento de S3 que ocurre cuando un usuario sube una imagen. Ejecutar una función AWS Lambda que redimensione la imagen en el lugar y reemplace el archivo original en el bucket de S3. Crear una política de expiración de ciclo de vida de S3 para expirar todas las imágenes almacenadas después de 6 meses.",
            "C. Utilizar notificaciones de eventos de S3 para invocar una función AWS Lambda cuando un usuario almacena una imagen. Usar la función Lambda para redimensionar la imagen en el lugar y almacenar el archivo original en el bucket de S3. Crear una política de ciclo de vida de S3 para mover todas las imágenes almacenadas a S3 Standard-Infrequent Access (S3 Standard-IA) después de 6 meses.",
            "D. Utilizar Amazon Simple Queue Service (Amazon SQS) para procesar el evento de S3 que ocurre cuando un usuario almacena una imagen. Ejecutar una función AWS Lambda que redimensione la imagen y almacene el archivo redimensionado en un bucket de S3 que utilice S3 Standard-Infrequent Access (S3 Standard-IA). Crear una política de ciclo de vida de S3 para mover todas las imágenes almacenadas a S3 Glacier Deep Archive después de 6 meses."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "377.- Una empresa tiene una organización en AWS Organizations que incluye una cuenta AWS separada para cada uno de los departamentos de la empresa. Los equipos de desarrollo de aplicaciones de diferentes departamentos desarrollan y despliegan soluciones de manera independiente. La empresa desea reducir los costos de cómputo y gestionar los costos adecuadamente entre los departamentos. Además, la empresa quiere mejorar la visibilidad de la facturación para cada departamento de forma individual. La empresa no quiere perder flexibilidad operativa al seleccionar los recursos de cómputo. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Utilizar AWS Budgets para cada departamento. Usar Tag Editor para aplicar etiquetas a los recursos correspondientes. Comprar EC2 Instance Savings Plans.",
            "B. Configurar AWS Organizations para utilizar la facturación consolidada. Implementar una estrategia de etiquetado que identifique a los departamentos. Usar SCPs para aplicar etiquetas a los recursos correspondientes. Comprar EC2 Instance Savings Plans.",
            "C. Configurar AWS Organizations para utilizar la facturación consolidada. Implementar una estrategia de etiquetado que identifique a los departamentos. Usar Tag Editor para aplicar etiquetas a los recursos correspondientes. Comprar Compute Savings Plans.",
            "D. Utilizar AWS Budgets para cada departamento. Usar SCPs para aplicar etiquetas a los recursos correspondientes. Comprar Compute Savings Plans."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "378.- Una empresa tiene una aplicación web que carga de forma segura imágenes y videos a un bucket de Amazon S3. La empresa requiere que solo los usuarios autenticados puedan publicar contenido. La aplicación genera una URL prefirmada que se utiliza para cargar objetos a través de una interfaz de navegador. La mayoría de los usuarios informa que los tiempos de carga son lentos para objetos mayores de 100 MB. ¿Qué puede hacer un arquitecto de soluciones para mejorar el rendimiento de estas cargas, asegurando al mismo tiempo que solo los usuarios autenticados puedan publicar contenido?",
        "opciones": [
            "A. Configurar un Amazon API Gateway con un punto final API optimizado para bordes que tenga un recurso configurado como proxy del servicio S3. Configurar el método PUT para este recurso para exponer la operación S3 PutObject. Proteger el API Gateway utilizando un autorizador COGNITO_USER_POOLS. Hacer que la interfaz de navegador utilice API Gateway en lugar de la URL prefirmada para cargar objetos.",
            "B. Configurar un Amazon API Gateway con un punto final API regional que tenga un recurso configurado como proxy del servicio S3. Configurar el método PUT para este recurso para exponer la operación S3 PutObject. Proteger el API Gateway utilizando un autorizador AWS Lambda. Hacer que la interfaz de navegador utilice API Gateway en lugar de la URL prefirmada para cargar objetos.",
            "C. Habilitar un endpoint de aceleración de transferencia S3 (S3 Transfer Acceleration) en el bucket de S3. Utilizar este endpoint al generar la URL prefirmada. Hacer que la interfaz de navegador cargue los objetos a esta URL utilizando la API de carga multipart de S3.",
            "D. Configurar una distribución de Amazon CloudFront para el bucket de destino S3. Habilitar los métodos PUT y POST para el comportamiento de la caché de CloudFront. Actualizar el origen de CloudFront para utilizar una Identidad de Acceso de Origen (OAI). Otorgar al usuario OAI permisos PutObject en la política del bucket. Hacer que la interfaz de navegador cargue objetos utilizando la distribución de CloudFront."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "379.- Una gran empresa está migrando todo su portafolio de TI a AWS. Cada unidad de negocio de la empresa tiene una cuenta de AWS independiente que soporta tanto entornos de desarrollo como de prueba. Pronto se necesitarán nuevas cuentas para soportar cargas de trabajo de producción. El departamento de finanzas requiere un método centralizado para el pago, pero debe mantener visibilidad del gasto de cada grupo para asignar costos. El equipo de seguridad requiere un mecanismo centralizado para controlar el uso de IAM en todas las cuentas de la empresa. ¿Qué combinación de las siguientes opciones cumple con las necesidades de la empresa con el MENOR esfuerzo? (Elija dos.)",
        "opciones": [
            "A. Utilizar una colección de plantillas parametrizadas de AWS CloudFormation que definan permisos IAM comunes y que se lancen en cada cuenta. Requerir que todas las cuentas nuevas y existentes lancen las pilas apropiadas para hacer cumplir el modelo de menor privilegio.",
            "B. Utilizar AWS Organizations para crear una nueva organización a partir de una cuenta pagadora elegida y definir una jerarquía de unidades organizativas. Invitar a las cuentas existentes a unirse a la organización y crear nuevas cuentas utilizando Organizations.",
            "C. Requerir que cada unidad de negocio utilice sus propias cuentas de AWS. Etiquetar cada cuenta de AWS apropiadamente y habilitar Cost Explorer para administrar los cargos.",
            "D. Habilitar todas las funciones de AWS Organizations y establecer las políticas de control de servicios apropiadas que filtren los permisos de IAM para las subcuentas.",
            "E. Consolidar todas las cuentas de AWS de la empresa en una única cuenta de AWS. Utilizar etiquetas para propósitos de facturación y la función Access Advisor de IAM para hacer cumplir el modelo de menor privilegio."
        ],
        "respuestas_correctas": [
            "D",
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "380.- Una empresa tiene una solución que analiza datos meteorológicos de miles de estaciones. Las estaciones meteorológicas envían los datos a través de una API REST de Amazon API Gateway que está integrada con una función de AWS Lambda. La función Lambda llama a un servicio de terceros para el preprocesamiento de datos. El servicio de terceros se sobrecarga y falla en el preprocesamiento, lo que provoca la pérdida de datos. Un arquitecto de soluciones debe mejorar la resiliencia de la solución. El arquitecto de soluciones debe asegurarse de que no se pierda ningún dato y de que los datos puedan procesarse posteriormente en caso de que ocurran fallos. ¿Qué debería hacer el arquitecto de soluciones para cumplir con estos requisitos?",
        "opciones": [
            "A. Crear una cola de Amazon Simple Queue Service (Amazon SQS). Configurar la cola como la cola de mensajes fallidos (dead-letter queue) para la API.",
            "B. Crear dos colas de Amazon Simple Queue Service (Amazon SQS): una cola primaria y una cola secundaria. Configurar la cola secundaria como la cola de mensajes fallidos para la cola primaria. Actualizar la API para que utilice una nueva integración con la cola primaria. Configurar la función Lambda como el objetivo de invocación para la cola primaria.",
            "C. Crear dos buses de eventos de Amazon EventBridge: un bus de eventos primario y un bus de eventos secundario. Actualizar la API para que utilice una nueva integración con el bus de eventos primario. Configurar una regla de EventBridge para reaccionar a todos los eventos en el bus de eventos primario. Especificar la función Lambda como el objetivo de la regla. Configurar el bus de eventos secundario como el destino de fallo para la función Lambda.",
            "D. Crear un bus de eventos personalizado de Amazon EventBridge. Configurar el bus de eventos como el destino de fallo para la función Lambda."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "381.- Una empresa construyó un sitio web de comercio electrónico en AWS utilizando una arquitectura web de tres niveles. La aplicación está basada en Java y se compone de una distribución de Amazon CloudFront, una capa de servidores web Apache en instancias de Amazon EC2 dentro de un grupo de Auto Scaling, y una base de datos backend de Amazon Aurora MySQL. El mes pasado, durante un evento promocional de ventas, los usuarios reportaron errores y tiempos de espera al agregar artículos a sus carros de compra. El equipo de operaciones recuperó los registros creados por los servidores web y revisó las métricas de rendimiento del clúster de Aurora. Algunos de los servidores web se terminaron antes de que se pudieran recopilar los registros y las métricas de Aurora no fueron suficientes para el análisis del rendimiento de las consultas. ¿Qué combinación de pasos debe tomar el arquitecto de soluciones para mejorar la visibilidad del rendimiento de la aplicación durante eventos de tráfico pico? (Elija tres.)",
        "opciones": [
            "A. Configurar el clúster Aurora MySQL para que publique los registros de consultas lentas y errores en Amazon CloudWatch Logs.",
            "B. Implementar el SDK de AWS X-Ray para rastrear las solicitudes HTTP entrantes en las instancias EC2 e implementar el rastreo de consultas SQL con el SDK de X-Ray para Java.",
            "C. Configurar el clúster Aurora MySQL para que transmita los registros de consultas lentas y errores a Amazon Kinesis.",
            "D. Instalar y configurar un agente de Amazon CloudWatch Logs en las instancias EC2 para enviar los registros de Apache a CloudWatch Logs.",
            "E. Habilitar y configurar AWS CloudTrail para recopilar y analizar la actividad de la aplicación desde Amazon EC2 y Aurora.",
            "F. Habilitar la evaluación comparativa de rendimiento del clúster Aurora MySQL y publicar la transmisión a AWS X-Ray."
        ],
        "respuestas_correctas": [
            "B",
            "D",
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "382.- Una empresa que provee bolsas de trabajo para una fuerza laboral estacional está experimentando un aumento en el tráfico y el uso. Los servicios de backend se ejecutan en un par de instancias de Amazon EC2 detrás de un Application Load Balancer, utilizando Amazon DynamoDB como almacén de datos. El tráfico de lectura y escritura de la aplicación es lento durante las temporadas altas. ¿Qué opción proporciona una arquitectura de aplicación escalable para manejar las temporadas altas con el menor esfuerzo de desarrollo?",
        "opciones": [
            "A. Migrar los servicios de backend a AWS Lambda. Incrementar la capacidad de lectura y escritura de DynamoDB.",
            "B. Migrar los servicios de backend a AWS Lambda. Configurar DynamoDB para utilizar tablas globales.",
            "C. Utilizar grupos de Auto Scaling para los servicios de backend. Utilizar auto scaling de DynamoDB.",
            "D. Utilizar grupos de Auto Scaling para los servicios de backend. Utilizar Amazon Simple Queue Service (Amazon SQS) y una función de AWS Lambda para escribir en DynamoDB."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "383.- Una empresa se está migrando a la nube. Quiere evaluar las configuraciones de las máquinas virtuales en su entorno de centro de datos existente para asegurarse de que puede dimensionar con precisión las nuevas instancias de Amazon EC2. La empresa desea recopilar métricas, tales como el uso de CPU, memoria y disco, y necesita un inventario de los procesos que se ejecutan en cada instancia. La empresa también desea monitorear las conexiones de red para mapear las comunicaciones entre servidores. ¿Qué opción habilitará la recopilación de estos datos de la manera MÁS rentable?",
        "opciones": [
            "A. Utilizar AWS Application Discovery Service y desplegar el agente de recopilación de datos en cada máquina virtual en el centro de datos.",
            "B. Configurar el agente de Amazon CloudWatch en todos los servidores dentro del entorno local y publicar las métricas en Amazon CloudWatch Logs.",
            "C. Utilizar AWS Application Discovery Service y habilitar el descubrimiento sin agentes en el entorno de virtualización existente.",
            "D. Habilitar AWS Application Discovery Service en la Consola de Administración de AWS y configurar el firewall corporativo para permitir escaneos a través de una VPN."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "384.- Una empresa ofrece una aplicación de software como servicio (SaaS) que se ejecuta en la nube de AWS. La aplicación funciona en instancias de Amazon EC2 detrás de un Network Load Balancer (NLB). Las instancias se encuentran en un grupo de Auto Scaling y están distribuidas en tres Zonas de Disponibilidad dentro de una única Región de AWS. La empresa está desplegando la aplicación en regiones adicionales. La empresa debe proporcionar direcciones IP estáticas para la aplicación a los clientes, de modo que los clientes puedan agregar dichas direcciones IP a sus listas de permitidos. La solución debe enrutar automáticamente a los clientes a la región que esté geográficamente más cerca de ellos. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Crear una distribución de Amazon CloudFront. Crear un grupo de orígenes de CloudFront. Agregar el NLB de cada región adicional al grupo de orígenes. Proporcionar a los clientes los rangos de direcciones IP de las ubicaciones edge de la distribución.",
            "B. Crear un acelerador estándar de AWS Global Accelerator. Crear un endpoint estándar para el NLB en cada región adicional. Proporcionar a los clientes la dirección IP de Global Accelerator.",
            "C. Crear una distribución de Amazon CloudFront. Crear un origen personalizado para el NLB en cada región adicional. Proporcionar a los clientes los rangos de direcciones IP de las ubicaciones edge de la distribución.",
            "D. Crear un acelerador de enrutamiento personalizado de AWS Global Accelerator. Crear un listener para el acelerador de enrutamiento personalizado. Agregar la dirección IP y los puertos para el NLB en cada región adicional. Proporcionar a los clientes la dirección IP de Global Accelerator."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "385.- Una empresa está ejecutando múltiples cargas de trabajo en la nube de AWS. La empresa cuenta con unidades separadas para el desarrollo de software. La empresa utiliza AWS Organizations y federación con SAML para otorgar permisos a los desarrolladores para gestionar recursos en sus cuentas de AWS. Las unidades de desarrollo implementan sus cargas de trabajo de producción en una cuenta de producción común. Recientemente, se produjo un incidente en la cuenta de producción en el que miembros de una unidad de desarrollo terminaron una instancia de EC2 que pertenecía a otra unidad de desarrollo. Un arquitecto de soluciones debe crear una solución que evite que se repita un incidente similar en el futuro. La solución también debe permitir a los desarrolladores la posibilidad de gestionar las instancias utilizadas para sus cargas de trabajo. ¿Qué estrategia cumplirá con estos requisitos?",
        "opciones": [
            "A. Crear OUs (Unidades Organizativas) separadas en AWS Organizations para cada unidad de desarrollo. Asignar las OUs creadas a las cuentas de AWS de la empresa. Crear SCPs (Políticas de Control de Servicio) separadas con una acción de denegar y una condición StringNotEquals para la etiqueta de recurso DevelopmentUnit que coincida con el nombre de la unidad de desarrollo. Asignar el SCP a la OU correspondiente.",
            "B. Pasar un atributo para DevelopmentUnit como una etiqueta de sesión de AWS Security Token Service (AWS STS) durante la federación SAML. Actualizar la política de IAM para el rol de IAM asumido por los desarrolladores con una acción de denegar y una condición StringNotEquals para la etiqueta de recurso DevelopmentUnit y aws:PrincipalTag/DevelopmentUnit.",
            "C. Pasar un atributo para DevelopmentUnit como una etiqueta de sesión de AWS Security Token Service (AWS STS) durante la federación SAML. Crear un SCP (Política de Control de Servicio) con una acción de permitir y una condición StringEquals para la etiqueta de recurso DevelopmentUnit y aws:PrincipalTag/DevelopmentUnit. Asignar el SCP a la OU raíz.",
            "D. Crear políticas IAM separadas para cada unidad de desarrollo. Para cada política IAM, agregar una acción de permitir y una condición StringEquals para la etiqueta de recurso DevelopmentUnit y el nombre de la unidad de desarrollo. Durante la federación SAML, utilizar AWS Security Token Service (AWS STS) para asignar la política IAM y hacer coincidir el nombre de la unidad de desarrollo con el rol de IAM asumido."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "386.- Una empresa corporativa está construyendo una plataforma de servicios de infraestructura para sus usuarios. La empresa tiene los siguientes requisitos: • Proveer acceso de mínimo privilegio a los usuarios al lanzar infraestructura en AWS, de modo que los usuarios no puedan aprovisionar servicios no aprobados.\n• Utilizar una cuenta central para gestionar la creación de servicios de infraestructura.\n• Proveer la capacidad de distribuir servicios de infraestructura a múltiples cuentas en AWS Organizations.\n• Proveer la capacidad de hacer cumplir etiquetas (tags) en cualquier infraestructura que se inicie por parte de los usuarios. ¿Qué combinación de acciones usando servicios de AWS cumplirá estos requisitos? (Elija tres.)",
        "opciones": [
            "A. Desarrollar servicios de infraestructura utilizando plantillas de AWS CloudFormation. Agregar las plantillas a un bucket central de Amazon S3 y agregar a la política del bucket S3 los roles o usuarios IAM que requieran acceso.",
            "B. Desarrollar servicios de infraestructura utilizando plantillas de AWS CloudFormation. Cargar cada plantilla como un producto de AWS Service Catalog en portfolios creados en una cuenta central de AWS. Compartir estos portfolios con la estructura de Organizations creada para la empresa.",
            "C. Permitir que los roles IAM de los usuarios tengan permisos AWSCloudFormationFullAccess y AmazonS3ReadOnlyAccess. Agregar una SCP (política de control de servicio) en el nivel de usuario raíz de la cuenta de AWS para denegar todos los servicios excepto AWS CloudFormation y Amazon S3.",
            "D. Permitir que los roles IAM de los usuarios tengan únicamente permisos ServiceCatalogEndUserAccess. Utilizar un script de automatización para importar los portfolios centrales a cuentas locales de AWS, copiar el TagOption, asignar acceso a los usuarios y aplicar restricciones de lanzamiento.",
            "E. Utilizar la biblioteca TagOption de AWS Service Catalog para mantener una lista de etiquetas requeridas por la empresa. Aplicar el TagOption a los productos o portfolios de AWS Service Catalog.",
            "F. Utilizar la propiedad Resource Tags de AWS CloudFormation para hacer cumplir la aplicación de etiquetas en cualquier plantilla de CloudFormation que se cree para los usuarios."
        ],
        "respuestas_correctas": [
            "E",
            "D",
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "387.- Una empresa despliega una nueva aplicación web. Como parte de la configuración, la empresa configura AWS WAF para registrar en Amazon S3 a través de Amazon Kinesis Data Firehose. La empresa desarrolla una consulta de Amazon Athena que se ejecuta una vez al día para devolver los datos de registros de AWS WAF de las últimas 24 horas. El volumen de registros diarios es constante. Sin embargo, con el tiempo, la misma consulta está tardando más en ejecutarse. Un arquitecto de soluciones necesita diseñar una solución para evitar que el tiempo de consulta continúe aumentando. La solución debe minimizar la sobrecarga operativa. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Crear una función AWS Lambda que consolide los registros de AWS WAF de cada día en un único archivo de registro.",
            "B. Reducir la cantidad de datos escaneados configurando AWS WAF para enviar los registros a un bucket de S3 diferente cada día.",
            "C. Actualizar la configuración de Kinesis Data Firehose para particionar los datos en Amazon S3 por fecha y hora. Crear tablas externas para Amazon Redshift. Configurar Amazon Redshift Spectrum para consultar la fuente de datos.",
            "D. Modificar la configuración de Kinesis Data Firehose y la definición de la tabla de Athena para particionar los datos por fecha y hora. Cambiar la consulta de Athena para ver las particiones relevantes."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "388.- Una empresa está desarrollando una aplicación web que se ejecuta en instancias de Amazon EC2 en un grupo de Auto Scaling, detrás de un Application Load Balancer (ALB) orientado al público. Solo se permite el acceso a la aplicación a los usuarios de un país específico. La empresa necesita la capacidad de registrar las solicitudes de acceso que han sido bloqueadas. La solución debe requerir el menor mantenimiento posible. ¿Qué solución cumple con estos requisitos?",
        "opciones": [
            "A. Crear un IPSet que contenga una lista de rangos de IP que pertenezcan al país especificado. Crear un web ACL de AWS WAF. Configurar una regla para bloquear cualquier solicitud que no se origine desde un rango de IP en el IPSet. Asociar la regla con el web ACL. Asociar el web ACL con el ALB.",
            "B. Crear un web ACL de AWS WAF. Configurar una regla para bloquear cualquier solicitud que no se origine en el país especificado. Asociar la regla con el web ACL. Asociar el web ACL con el ALB.",
            "C. Configurar AWS Shield para bloquear cualquier solicitud que no se origine en el país especificado. Asociar AWS Shield con el ALB.",
            "D. Crear una regla de grupo de seguridad que permita los puertos 80 y 443 desde rangos de IP que pertenezcan al país especificado. Asociar el grupo de seguridad con el ALB."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "389.- Una empresa está migrando una aplicación desde una infraestructura local a la nube de AWS. Durante las reuniones de diseño de la migración, la empresa expresó inquietudes sobre la disponibilidad y las opciones de recuperación para su servidor de archivos de Windows heredado. El servidor de archivos contiene datos sensibles y críticos para el negocio que no pueden recrearse en caso de corrupción o pérdida de datos. De acuerdo con los requisitos de cumplimiento, los datos no deben viajar a través de Internet público. La empresa desea migrar a servicios administrados de AWS siempre que sea posible. La empresa decide almacenar los datos en un sistema de archivos Amazon FSx for Windows File Server. Un arquitecto de soluciones debe diseñar una solución que copie los datos a otra Región de AWS para fines de recuperación ante desastres (DR). ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Crear un bucket de Amazon S3 de destino en la Región DR. Establecer conectividad entre el sistema de archivos FSx for Windows File Server en la Región primaria y el bucket S3 en la Región DR utilizando Amazon FSx File Gateway. Configurar el bucket S3 como una fuente de respaldo continuo en FSx File Gateway.",
            "B. Crear un sistema de archivos FSx for Windows File Server en la Región DR. Establecer conectividad entre la VPC en la Región primaria y la VPC en la Región DR utilizando AWS Site-to-Site VPN. Configurar AWS DataSync para comunicarse mediante endpoints de VPN.",
            "C. Crear un sistema de archivos FSx for Windows File Server en la Región DR. Establecer conectividad entre la VPC en la Región primaria y la VPC en la Región DR utilizando VPC peering. Configurar AWS DataSync para comunicarse mediante endpoints VPC de interfaz con AWS PrivateLink.",
            "D. Crear un sistema de archivos FSx for Windows File Server en la Región DR. Establecer conectividad entre la VPC en la Región primaria y la VPC en la Región DR utilizando AWS Transit Gateway en cada Región. Utilizar AWS Transfer Family para copiar archivos entre el sistema de archivos FSx for Windows File Server en la Región primaria y el sistema de archivos FSx for Windows File Server en la Región DR a través de la red troncal privada de AWS."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "390.- Una empresa se encuentra actualmente en la fase de diseño de una aplicación que necesitará un RPO de menos de 5 minutos y un RTO de menos de 10 minutos. El equipo de arquitectura de soluciones prevé que la base de datos almacenará aproximadamente 10 TB de datos. Como parte del diseño, están buscando una solución de base de datos que ofrezca a la empresa la capacidad de hacer failover (conmutación por error) a una región secundaria. ¿Qué solución cumplirá con estos requisitos comerciales al COSTO MÁS BAJO?",
        "opciones": [
            "A. Desplegar un clúster de bases de datos Amazon Aurora y tomar instantáneas del clúster cada 5 minutos. Una vez que se complete una instantánea, copiarla a una región secundaria para que sirva como respaldo en caso de fallo.",
            "B. Desplegar una instancia de Amazon RDS con una réplica de lectura entre regiones en una región secundaria. En caso de fallo, promover la réplica de lectura para que se convierta en la primaria.",
            "C. Desplegar un clúster de bases de datos Amazon Aurora en la región primaria y otro en una región secundaria. Utilizar AWS DMS para mantener la región secundaria sincronizada.",
            "D. Desplegar una instancia de Amazon RDS con una réplica de lectura en la misma región. En caso de fallo, promover la réplica de lectura para que se convierta en la primaria."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "391.- Una empresa financiera necesita crear una cuenta separada de AWS para una nueva aplicación de billetera digital. La empresa utiliza AWS Organizations para gestionar sus cuentas. Un arquitecto de soluciones utiliza el usuario IAM Support1 de la cuenta de administración para crear una nueva cuenta miembro con finance1@example.com como dirección de correo electrónico. ¿Qué debe hacer el arquitecto de soluciones para crear usuarios IAM en la nueva cuenta miembro?",
        "opciones": [
            "A. Inicia sesión en la Consola de administración de AWS con las credenciales del usuario raíz de la cuenta de AWS utilizando la contraseña de 64 caracteres del correo electrónico inicial de AWS Organizations enviado a finance1@example.com. Configura los usuarios IAM según sea necesario.",
            "B. Desde la cuenta de administración, cambia de rol para asumir el rol OrganizationAccountAccessRole utilizando el ID de la nueva cuenta miembro. Configura los usuarios IAM según sea necesario.",
            "C. Ve a la página de inicio de sesión de la Consola de administración de AWS. Elige “Iniciar sesión utilizando las credenciales del usuario raíz”. Inicia sesión utilizando la dirección de correo electrónico finance1@example.com y la contraseña del usuario raíz de la cuenta de administración. Configura los usuarios IAM según sea necesario.",
            "D. Ve a la página de inicio de sesión de la Consola de administración de AWS. Inicia sesión utilizando el ID de la nueva cuenta miembro y las credenciales IAM de Support1. Configura los usuarios IAM según sea necesario."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "392.- Una empresa de alquiler de coches ha construido una API REST sin servidor para proporcionar datos a su aplicación móvil. La aplicación consta de una API de Amazon API Gateway con un endpoint Regional, funciones AWS Lambda y un clúster de base de datos Amazon Aurora MySQL Serverless. La empresa abrió recientemente la API a las aplicaciones móviles de socios, lo que resultó en un aumento significativo en la cantidad de solicitudes y provocó errores esporádicos de memoria en la base de datos. El análisis del tráfico de la API indica que los clientes realizan múltiples solicitudes HTTP GET para las mismas consultas en un corto período de tiempo. El tráfico se concentra durante el horario laboral, con picos alrededor de las festividades y otros eventos. La empresa necesita mejorar su capacidad para soportar el uso adicional, minimizando al mismo tiempo el incremento de costos asociado a la solución. ¿Qué estrategia cumple con estos requisitos?",
        "opciones": [
            "A. Convertir el endpoint Regional de API Gateway en un endpoint optimizado para edge. Habilitar la caché en el stage de producción.",
            "B. Implementar una caché de Amazon ElastiCache for Redis para almacenar los resultados de las llamadas a la base de datos. Modificar las funciones Lambda para utilizar la caché.",
            "C. Modificar la configuración del clúster de Aurora Serverless para aumentar la cantidad máxima de memoria disponible.",
            "D. Habilitar la limitación de velocidad (throttling) en el stage de producción de API Gateway. Establecer los valores de tasa y ráfaga para limitar las llamadas entrantes."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "393.- Una empresa está migrando una aplicación local y una base de datos MySQL a AWS. La aplicación procesa datos altamente sensibles y la base de datos se actualiza constantemente con nuevos datos. Los datos no deben transferirse a través de Internet. Además, la empresa debe cifrar los datos tanto en tránsito como en reposo. La base de datos tiene un tamaño de 5 TB. La empresa ya ha creado el esquema de la base de datos en una instancia de Amazon RDS para MySQL. La empresa ha configurado una conexión de AWS Direct Connect de 1 Gbps a AWS y también ha configurado un VIF público y un VIF privado. Un arquitecto de soluciones necesita diseñar una solución que migre los datos a AWS con el menor tiempo de inactividad posible. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Realizar una copia de seguridad de la base de datos. Copiar los archivos de la copia de seguridad a un dispositivo AWS Snowball Edge Storage Optimized. Importar la copia de seguridad a Amazon S3. Utilizar cifrado del lado del servidor con claves de cifrado administradas por Amazon S3 (SSE-S3) para el cifrado en reposo. Utilizar TLS para el cifrado en tránsito. Importar los datos desde Amazon S3 a la instancia de la base de datos.",
            "B. Utilizar AWS Database Migration Service (AWS DMS) para migrar los datos a AWS. Crear una instancia de replicación de DMS en una subred privada. Crear endpoints de VPC para AWS DMS. Configurar una tarea de DMS para copiar los datos desde la base de datos local a la instancia de la base de datos utilizando carga completa más captura de datos de cambios (CDC). Utilizar la clave predeterminada de AWS Key Management Service (AWS KMS) para el cifrado en reposo. Utilizar TLS para el cifrado en tránsito.",
            "C. Realizar una copia de seguridad de la base de datos. Utilizar AWS DataSync para transferir los archivos de la copia de seguridad a Amazon S3. Utilizar cifrado del lado del servidor con claves de cifrado administradas por Amazon S3 (SSE-S3) para el cifrado en reposo. Utilizar TLS para el cifrado en tránsito. Importar los datos desde Amazon S3 a la instancia de la base de datos.",
            "D. Utilizar Amazon S3 File Gateway. Configurar una conexión privada a Amazon S3 mediante AWS PrivateLink. Realizar una copia de seguridad de la base de datos. Copiar los archivos de la copia de seguridad a Amazon S3. Utilizar cifrado del lado del servidor con claves de cifrado administradas por Amazon S3 (SSE-S3) para el cifrado en reposo. Utilizar TLS para el cifrado en tránsito. Importar los datos desde Amazon S3 a la instancia de la base de datos."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "394.- Una empresa está desplegando un nuevo clúster para análisis de big data en AWS. El clúster se ejecutará en muchas instancias de Amazon EC2 con Linux que están distribuidas en varias Zonas de Disponibilidad. Todos los nodos del clúster deben tener acceso de lectura y escritura a un almacenamiento subyacente común. El almacenamiento debe ser altamente disponible, resiliente, compatible con POSIX y debe admitir altos niveles de rendimiento. ¿Qué solución de almacenamiento cumplirá con estos requisitos?",
        "opciones": [
            "A. Provisione un recurso compartido NFS mediante un file gateway de AWS Storage Gateway que esté conectado a un bucket de Amazon S3. Monte el recurso compartido NFS en cada instancia EC2 del clúster.",
            "B. Provisione un nuevo sistema de archivos de Amazon Elastic File System (Amazon EFS) que utilice el modo de rendimiento General Purpose. Monte el sistema de archivos EFS en cada instancia EC2 del clúster.",
            "C. Provisione un nuevo volumen de Amazon Elastic Block Store (Amazon EBS) que utilice el tipo de volumen io2. Adjunte el volumen EBS a todas las instancias EC2 del clúster.",
            "D. Provisione un nuevo sistema de archivos de Amazon Elastic File System (Amazon EFS) que utilice el modo de rendimiento Max I/O. Monte el sistema de archivos EFS en cada instancia EC2 del clúster."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "395.- Una empresa aloja una solución de software como servicio (SaaS) en AWS. La solución cuenta con una API de Amazon API Gateway que expone un endpoint HTTPS. La API utiliza funciones AWS Lambda para el cómputo, y estas funciones almacenan datos en una base de datos Amazon Aurora Serverless v1. La empresa utilizó el AWS Serverless Application Model (AWS SAM) para desplegar la solución. La solución se extiende a través de múltiples Zonas de Disponibilidad y no tiene un plan de recuperación ante desastres (DR). Un arquitecto de soluciones debe diseñar una estrategia de DR que permita recuperar la solución en otra Región de AWS. La solución tiene un RTO (objetivo de tiempo de recuperación) de 5 minutos y un RPO (objetivo de punto de recuperación) de 1 minuto. ¿Qué debe hacer el arquitecto de soluciones para cumplir con estos requisitos?",
        "opciones": [
            "A. Crear una réplica de lectura de la base de datos Aurora Serverless v1 en la Región de destino. Utilizar AWS SAM para crear un runbook que despliegue la solución en la Región de destino. Promover la réplica de lectura a base de datos primaria en caso de desastre.",
            "B. Cambiar la base de datos Aurora Serverless v1 a una base de datos global estándar de Aurora MySQL que se extienda entre la Región de origen y la Región de destino. Utilizar AWS SAM para crear un runbook que despliegue la solución en la Región de destino.",
            "C. Crear un clúster de base de datos Aurora Serverless v1 que tenga múltiples instancias de escritura en la Región de destino. Lanzar la solución en la Región de destino. Configurar las dos soluciones regionales para operar en una configuración activo-pasivo.",
            "D. Cambiar la base de datos Aurora Serverless v1 a una base de datos global estándar de Aurora MySQL que se extienda entre la Región de origen y la Región de destino. Lanzar la solución en la Región de destino. Configurar las dos soluciones regionales para operar en una configuración activo-pasivo."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "396.- Una empresa posee una cadena de agencias de viajes y está ejecutando una aplicación en la nube de AWS. Los empleados de la empresa utilizan la aplicación para buscar información sobre destinos turísticos. El contenido de los destinos se actualiza cuatro veces al año. Dos instancias fijas de Amazon EC2 sirven a la aplicación. La empresa utiliza una zona hospedada pública de Amazon Route 53 con un registro multivalor para travel.example.com que devuelve las direcciones IP elásticas de las instancias EC2. La aplicación utiliza Amazon DynamoDB como su almacén de datos principal. La empresa utiliza una instancia autohospedada de Redis como solución de caché. Durante las actualizaciones de contenido, la carga en las instancias EC2 y en la solución de caché aumenta drásticamente. Este aumento de carga ha provocado tiempos de inactividad en varias ocasiones. Un arquitecto de soluciones debe actualizar la aplicación para que sea altamente disponible y pueda manejar la carga generada por las actualizaciones de contenido. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Configurar DynamoDB Accelerator (DAX) como caché en memoria. Actualizar la aplicación para que utilice DAX. Crear un grupo de Auto Scaling para las instancias EC2. Crear un Application Load Balancer (ALB). Establecer el grupo de Auto Scaling como destino para el ALB. Actualizar el registro de Route 53 para que utilice una política de enrutamiento simple que apunte al alias DNS del ALB. Configurar escalado programado para las instancias EC2 antes de las actualizaciones de contenido.",
            "B. Configurar Amazon ElastiCache para Redis. Actualizar la aplicación para que utilice ElastiCache. Crear un grupo de Auto Scaling para las instancias EC2. Crear una distribución de Amazon CloudFront y establecer el grupo de Auto Scaling como origen para la distribución. Actualizar el registro de Route 53 para que utilice una política de enrutamiento simple que apunte al alias DNS de la distribución de CloudFront. Escalar manualmente las instancias EC2 antes de las actualizaciones de contenido.",
            "C. Configurar Amazon ElastiCache para Memcached. Actualizar la aplicación para que utilice ElastiCache. Crear un grupo de Auto Scaling para las instancias EC2. Crear un Application Load Balancer (ALB). Establecer el grupo de Auto Scaling como destino para el ALB. Actualizar el registro de Route 53 para que utilice una política de enrutamiento simple que apunte al alias DNS del ALB. Configurar escalado programado para la aplicación antes de las actualizaciones de contenido.",
            "D. Configurar DynamoDB Accelerator (DAX) como caché en memoria. Actualizar la aplicación para que utilice DAX. Crear un grupo de Auto Scaling para las instancias EC2. Crear una distribución de Amazon CloudFront y establecer el grupo de Auto Scaling como origen para la distribución. Actualizar el registro de Route 53 para que utilice una política de enrutamiento simple que apunte al alias DNS de la distribución de CloudFront. Escalar manualmente las instancias EC2 antes de las actualizaciones de contenido."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "397.- Una empresa necesita almacenar y procesar datos de imágenes que se cargarán desde dispositivos móviles mediante una aplicación móvil personalizada. El uso alcanza su máximo entre las 8:00 a.m. y las 5:00 p.m. en días laborables, con miles de cargas por minuto. La aplicación se utiliza rara vez en cualquier otro momento. Se notifica a un usuario cuando se completa el procesamiento de la imagen. ¿Qué combinación de acciones debe tomar un arquitecto de soluciones para garantizar que el procesamiento de imágenes pueda escalar y manejar la carga? (Elija tres.)",
        "opciones": [
            "A. Cargar archivos desde el software móvil directamente a Amazon S3. Utilizar notificaciones de eventos de S3 para crear un mensaje en una cola de Amazon MQ.",
            "B. Cargar archivos desde el software móvil directamente a Amazon S3. Utilizar notificaciones de eventos de S3 para crear un mensaje en una cola estándar de Amazon Simple Queue Service (Amazon SQS).",
            "C. Invocar una función AWS Lambda para realizar el procesamiento de imágenes cuando haya un mensaje disponible en la cola.",
            "D. Invocar un trabajo de Operaciones por Lotes de S3 (S3 Batch Operations) para realizar el procesamiento de imágenes cuando haya un mensaje disponible en la cola.",
            "E. Enviar una notificación push a la aplicación móvil utilizando Amazon Simple Notification Service (Amazon SNS) cuando se complete el procesamiento.",
            "F. Enviar una notificación push a la aplicación móvil utilizando Amazon Simple Email Service (Amazon SES) cuando se complete el procesamiento."
        ],
        "respuestas_correctas": [
            "C",
            "E",
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "398.- Una empresa está construyendo una aplicación en AWS. La aplicación envía registros (logs) a un clúster de Amazon OpenSearch Service para su análisis. Todos los datos deben almacenarse dentro de una VPC. Algunos de los desarrolladores de la empresa trabajan desde casa. Otros desarrolladores trabajan desde tres ubicaciones diferentes de oficinas de la empresa. Los desarrolladores necesitan acceder a OpenSearch Service para analizar y visualizar los registros directamente desde sus máquinas de desarrollo locales. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Configurar y establecer un endpoint de AWS Client VPN. Asociar el endpoint de Client VPN con una subred en la VPC. Configurar un portal de autoservicio para Client VPN. Indicar a los desarrolladores que se conecten utilizando el cliente de Client VPN.",
            "B. Crear un transit gateway y conectarlo a la VPC. Crear una VPN de sitio a sitio (Site-to-Site VPN) de AWS. Crear un attachment (conexión) al transit gateway. Indicar a los desarrolladores que se conecten utilizando un cliente OpenVPN.",
            "C. Crear un transit gateway y conectarlo a la VPC; además, contratar una conexión de AWS Direct Connect. Configurar un VIF (interfaz virtual) pública en la conexión Direct Connect. Asociar el VIF público con el transit gateway. Indicar a los desarrolladores que se conecten a la conexión Direct Connect.",
            "D. Crear y configurar un bastión en una subred pública de la VPC. Configurar el grupo de seguridad del bastión para permitir el acceso SSH desde los rangos CIDR de la empresa. Indicar a los desarrolladores que se conecten utilizando SSH."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "399.- Una empresa desea migrar su sitio web desde un centro de datos local a AWS. Al mismo tiempo, quiere migrar el sitio web a una arquitectura basada en microservicios contenedorizados para mejorar la disponibilidad y la eficiencia en costos. La política de seguridad de la empresa establece que los privilegios y permisos de red deben configurarse de acuerdo con las mejores prácticas, utilizando el principio de menor privilegio. Un arquitecto de soluciones debe crear una arquitectura contenedorizada que cumpla con los requisitos de seguridad y ha desplegado la aplicación en un clúster de Amazon ECS. ¿Qué pasos se requieren después del despliegue para cumplir con los requisitos? (Elija dos.)",
        "opciones": [
            "A. Crear tareas utilizando el modo de red bridge.",
            "B. Crear tareas utilizando el modo de red awsvpc.",
            "C. Aplicar grupos de seguridad a las instancias de Amazon EC2, y utilizar roles de IAM para las instancias de EC2 para acceder a otros recursos.",
            "D. Aplicar grupos de seguridad a las tareas, y pasar credenciales de IAM al contenedor en el momento del lanzamiento para acceder a otros recursos.",
            "E. Aplicar grupos de seguridad a las tareas, y utilizar roles de IAM para tareas para acceder a otros recursos."
        ],
        "respuestas_correctas": [
            "E",
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "400.- Una empresa está ejecutando una aplicación sin servidor que consiste en varias funciones de AWS Lambda y tablas de Amazon DynamoDB. La empresa ha creado una nueva funcionalidad que requiere que las funciones Lambda accedan a un clúster de base de datos Amazon Neptune. El clúster de Neptune está ubicado en tres subredes en una VPC. ¿Cuáles de las siguientes soluciones permitirán que las funciones Lambda accedan al clúster de Neptune y a las tablas de DynamoDB? (Elija dos.)",
        "opciones": [
            "A. Crear tres subredes públicas en la VPC de Neptune y enrutar el tráfico a través de un gateway de Internet. Alojar las funciones Lambda en las tres nuevas subredes públicas.",
            "B. Crear tres subredes privadas en la VPC de Neptune y enrutar el tráfico de internet a través de un NAT gateway. Alojar las funciones Lambda en las tres nuevas subredes privadas.",
            "C. Alojar las funciones Lambda fuera de la VPC. Actualizar el grupo de seguridad de Neptune para permitir el acceso desde los rangos de IP de las funciones Lambda.",
            "D. Alojar las funciones Lambda fuera de la VPC. Crear un endpoint VPC para la base de datos Neptune y permitir que las funciones Lambda accedan a Neptune a través del endpoint VPC.",
            "E. Crear tres subredes privadas en la VPC de Neptune. Alojar las funciones Lambda en las tres nuevas subredes aisladas. Crear un endpoint VPC para DynamoDB y enrutar el tráfico de DynamoDB hacia el endpoint VPC."
        ],
        "respuestas_correctas": [
            "E",
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "401.- Una empresa quiere diseñar una solución de recuperación ante desastres (DR) para una aplicación que se ejecuta en el centro de datos de la empresa. La aplicación escribe en un recurso compartido SMB y crea una copia en un segundo recurso compartido. Ambos recursos compartidos se encuentran en el centro de datos. La aplicación utiliza dos tipos de archivos: archivos de metadatos y archivos de imágenes. La empresa desea almacenar la copia en AWS. Además, necesita la capacidad de utilizar SMB para acceder a los datos tanto desde el centro de datos como desde AWS en caso de que ocurra un desastre. La copia de los datos se accede con poca frecuencia, pero debe estar disponible en un plazo de 5 minutos.",
        "opciones": [
            "A. Desplegar AWS Outposts con almacenamiento de Amazon S3. Configurar una instancia de Amazon EC2 con Windows en Outposts como servidor de archivos.",
            "B. Desplegar un Amazon FSx File Gateway. Configurar un sistema de archivos Amazon FSx for Windows File Server Multi-AZ que utilice almacenamiento SSD.",
            "C. Desplegar un Amazon S3 File Gateway. Configurar el S3 File Gateway para que utilice Amazon S3 Standard-Infrequent Access (S3 Standard-IA) para los archivos de metadatos y S3 Glacier Deep Archive para los archivos de imágenes.",
            "D. Desplegar un Amazon S3 File Gateway. Configurar el S3 File Gateway para que utilice Amazon S3 Standard-Infrequent Access (S3 Standard-IA) tanto para los archivos de metadatos como para los archivos de imágenes."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "402.- Una empresa está creando una solución que permita trasladar a 400 empleados a un entorno de trabajo remoto en caso de un desastre inesperado. Los escritorios de los usuarios tienen una combinación de sistemas operativos Windows y Linux. En cada escritorio se instalan múltiples tipos de software, como navegadores web y clientes de correo. Un arquitecto de soluciones necesita implementar una solución que se integre con el Active Directory local de la empresa para permitir que los empleados utilicen sus credenciales de identidad existentes. La solución debe proporcionar autenticación multifactor (MFA) y debe replicar la experiencia de usuario de los escritorios actuales. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Utilizar Amazon WorkSpaces para el servicio de escritorios en la nube. Configurar una conexión VPN a la red local. Crear un AD Connector y conectarlo al Active Directory local. Activar la MFA para Amazon WorkSpaces utilizando la Consola de Administración de AWS.",
            "B. Utilizar Amazon AppStream 2.0 como servicio de transmisión de aplicaciones. Configurar Desktop View para los empleados. Configurar una conexión VPN a la red local. Configurar Active Directory Federation Services (AD FS) en las instalaciones. Conectar la red VPC a AD FS a través de la conexión VPN.",
            "C. Utilizar Amazon WorkSpaces para el servicio de escritorios en la nube. Configurar una conexión VPN a la red local. Crear un AD Connector y conectarlo al Active Directory local. Configurar un servidor RADIUS para la MFA.",
            "D. Utilizar Amazon AppStream 2.0 como servicio de transmisión de aplicaciones. Configurar Active Directory Federation Services en las instalaciones. Configurar la MFA para otorgar acceso a los usuarios en AppStream 2.0."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "403.- Una empresa ha implementado un centro de contacto con Amazon Connect. Los agentes del centro de contacto están reportando un gran número de llamadas generadas por computadora. La empresa está preocupada por los efectos en costos y productividad que generan estas llamadas. La empresa desea una solución que permita a los agentes marcar la llamada como spam y bloquear automáticamente esos números para que no sean dirigidos a un agente en el futuro. ¿Cuál es la solución más eficiente operativamente para cumplir con estos requisitos?",
        "opciones": [
            "A. Personalizar el Panel de Control de Contacto (CCP) agregando un botón para marcar la llamada que invoque una función AWS Lambda que llame a la API UpdateContactAttributes. Utilizar una tabla de Amazon DynamoDB para almacenar los números de spam. Modificar los flujos de contacto para buscar el atributo actualizado y para usar una función Lambda que lea y escriba en la tabla de DynamoDB.",
            "B. Utilizar una regla de Contact Lens para Amazon Connect que detecte llamadas spam. Utilizar una tabla de Amazon DynamoDB para almacenar los números de spam. Modificar los flujos de contacto para buscar la regla y para invocar una función AWS Lambda que lea y escriba en la tabla de DynamoDB.",
            "C. Utilizar una tabla de Amazon DynamoDB para almacenar los números de spam. Crear una conexión rápida (quick connect) a la que los agentes puedan transferir la llamada spam desde el Panel de Control de Contacto (CCP). Modificar el flujo de contacto de la conexión rápida para invocar una función AWS Lambda que escriba en la tabla de DynamoDB.",
            "D. Modificar el flujo de contacto inicial para solicitar la entrada del llamante. Si el agente no recibe una entrada, el agente debe marcar al llamante como spam. Utilizar una tabla de Amazon DynamoDB para almacenar los números de spam. Utilizar una función AWS Lambda para leer y escribir en la tabla de DynamoDB."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "404.- Una empresa ha instalado sensores para recopilar información sobre parámetros ambientales, como la humedad y la luz, en todas las fábricas de la empresa. La empresa necesita transmitir y analizar los datos en la nube de AWS en tiempo real. Si alguno de los parámetros se sale de los rangos aceptables, el equipo de operaciones de la fábrica debe recibir una notificación de inmediato. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Transmitir los datos a una secuencia de entrega de Amazon Kinesis Data Firehose. Utilizar AWS Step Functions para consumir y analizar los datos en la secuencia de entrega de Kinesis Data Firehose. Utilizar Amazon Simple Notification Service (Amazon SNS) para notificar al equipo de operaciones.",
            "B. Transmitir los datos a un clúster de Amazon Managed Streaming for Apache Kafka (Amazon MSK). Configurar un disparador en Amazon MSK para invocar una tarea en AWS Fargate que analice los datos. Utilizar Amazon Simple Email Service (Amazon SES) para notificar al equipo de operaciones.",
            "C. Transmitir los datos a una secuencia de datos de Amazon Kinesis. Crear una función de AWS Lambda para consumir la secuencia de datos de Kinesis y analizar los datos. Utilizar Amazon Simple Notification Service (Amazon SNS) para notificar al equipo de operaciones.",
            "D. Transmitir los datos a una aplicación de Amazon Kinesis Data Analytics. Utilizar un servicio containerizado y escalado automáticamente en Amazon Elastic Container Service (Amazon ECS) para consumir y analizar los datos. Utilizar Amazon Simple Email Service (Amazon SES) para notificar al equipo de operaciones."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "405.- Una empresa se está preparando para implementar un clúster de Amazon Elastic Kubernetes Service (Amazon EKS) para una carga de trabajo. La empresa espera que el clúster admita un número impredecible de pods sin estado. Muchos de los pods se crearán en un corto período de tiempo, ya que la carga de trabajo escala automáticamente el número de réplicas que utiliza. ¿Qué solución MAXIMIZARÁ la resiliencia de los nodos?",
        "opciones": [
            "A. Utilice una plantilla de lanzamiento separada para implementar el plano de control de EKS en un segundo clúster que esté separado de los grupos de nodos de la carga de trabajo.",
            "B. Actualice los grupos de nodos de la carga de trabajo. Utilice un número menor de grupos de nodos y emplee instancias más grandes en dichos grupos.",
            "C. Configure el Kubernetes Cluster Autoscaler para garantizar que la capacidad de cómputo de los grupos de nodos de la carga de trabajo se mantenga subprovisionada.",
            "D. Configure la carga de trabajo para utilizar restricciones de dispersión de topología basadas en la Zona de Disponibilidad."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "406.- Una empresa necesita implementar un plan de recuperación ante desastres (DR) para una aplicación web. La aplicación se ejecuta en una única Región de AWS. La aplicación utiliza microservicios que se ejecutan en contenedores. Los contenedores se alojan en AWS Fargate dentro de Amazon Elastic Container Service (Amazon ECS). La aplicación cuenta con una instancia de Amazon RDS para MySQL como capa de datos y utiliza Amazon Route 53 para la resolución de DNS. Una alarma de Amazon CloudWatch invoca una regla de Amazon EventBridge si la aplicación experimenta una falla. Un arquitecto de soluciones debe diseñar una solución DR para proporcionar la recuperación de la aplicación en una Región separada. La solución debe minimizar el tiempo necesario para recuperarse de una falla. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Configurar un segundo clúster de ECS y un servicio de ECS en Fargate en la Región separada. Crear una función AWS Lambda que realice las siguientes acciones: tomar una instantánea de la instancia RDS, copiar la instantánea a la Región separada, crear una nueva instancia de RDS a partir de la instantánea y actualizar Route 53 para dirigir el tráfico al segundo clúster de ECS. Actualizar la regla de EventBridge para agregar un objetivo que invoque la función Lambda.",
            "B. Crear una función AWS Lambda que cree un segundo clúster de ECS y un servicio de ECS en Fargate en la Región separada. Configurar la función Lambda para realizar las siguientes acciones: tomar una instantánea de la instancia RDS, copiar la instantánea a la Región separada, crear una nueva instancia de RDS a partir de la instantánea y actualizar Route 53 para dirigir el tráfico al segundo clúster de ECS. Actualizar la regla de EventBridge para agregar un objetivo que invoque la función Lambda.",
            "C. Configurar un segundo clúster de ECS y un servicio de ECS en Fargate en la Región separada. Crear una réplica de lectura entre regiones de la instancia RDS en la Región separada. Crear una función AWS Lambda para promover la réplica de lectura a base de datos principal. Configurar la función Lambda para actualizar Route 53 y dirigir el tráfico al segundo clúster de ECS. Actualizar la regla de EventBridge para agregar un objetivo que invoque la función Lambda.",
            "D. Configurar un segundo clúster de ECS y un servicio de ECS en Fargate en la Región separada. Tomar una instantánea de la instancia RDS. Convertir la instantánea en una tabla global de Amazon DynamoDB. Crear una función AWS Lambda para actualizar Route 53 y dirigir el tráfico al segundo clúster de ECS. Actualizar la regla de EventBridge para agregar un objetivo que invoque la función Lambda."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "407.- Una empresa tiene cuentas de AWS que forman parte de una organización en AWS Organizations. La empresa desea hacer un seguimiento del uso de Amazon EC2 como una métrica. El equipo de arquitectura de la empresa debe recibir una alerta diaria si el uso de EC2 es más de un 10% superior al uso promedio de EC2 de los últimos 30 días. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Configurar AWS Budgets en la cuenta de administración de la organización. Especificar un tipo de uso de horas de ejecución de EC2. Especificar un período diario. Establecer el monto presupuestado en un 10% más que el uso promedio reportado durante los últimos 30 días, según AWS Cost Explorer. Configurar una alerta para notificar al equipo de arquitectura si se cumple el umbral de uso.",
            "B. Configurar AWS Cost Anomaly Detection en la cuenta de administración de la organización. Configurar un tipo de monitor para AWS Service. Aplicar un filtro para Amazon EC2. Configurar una suscripción de alerta para notificar al equipo de arquitectura si el uso es un 10% superior al uso promedio de los últimos 30 días.",
            "C. Habilitar AWS Trusted Advisor en la cuenta de administración de la organización. Configurar una alerta de asesoramiento de optimización de costos para notificar al equipo de arquitectura si el uso de EC2 es un 10% superior al uso promedio reportado durante los últimos 30 días.",
            "D. Configurar Amazon Detective en la cuenta de administración de la organización. Configurar una alerta de anomalía de uso de EC2 para notificar al equipo de arquitectura si Detective identifica una anomalía de uso superior al 10%."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "408.- Una empresa está construyendo una aplicación en AWS. La aplicación envía registros (logs) a un clúster de Amazon OpenSearch Service para su análisis. Todos los datos deben almacenarse dentro de una VPC. Algunos de los desarrolladores de la empresa trabajan desde casa. Otros desarrolladores trabajan desde tres ubicaciones diferentes de oficinas de la empresa. Los desarrolladores necesitan acceder a OpenSearch Service para analizar y visualizar los registros directamente desde sus máquinas de desarrollo locales. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Configurar y establecer un endpoint de AWS Client VPN. Asociar el endpoint de Client VPN con una subred en la VPC. Configurar un portal de autoservicio para Client VPN. Indicar a los desarrolladores que se conecten utilizando el cliente de Client VPN.",
            "B. Crear un transit gateway y conectarlo a la VPC. Crear una VPN de sitio a sitio (Site-to-Site VPN) de AWS. Crear un attachment (conexión) al transit gateway. Indicar a los desarrolladores que se conecten utilizando un cliente OpenVPN.",
            "C. Crear un transit gateway y conectarlo a la VPC; además, contratar una conexión de AWS Direct Connect. Configurar un VIF (interfaz virtual) pública en la conexión Direct Connect. Asociar el VIF público con el transit gateway. Indicar a los desarrolladores que se conecten a la conexión Direct Connect.",
            "D. Crear y configurar un bastión en una subred pública de la VPC. Configurar el grupo de seguridad del bastión para permitir el acceso SSH desde los rangos CIDR de la empresa. Indicar a los desarrolladores que se conecten utilizando SSH."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "409.- Una empresa está implementando funciones de AWS Lambda que acceden a una base de datos Amazon RDS para PostgreSQL. La empresa necesita lanzar las funciones Lambda en un entorno de QA y en un entorno de producción. La empresa no debe exponer credenciales dentro del código de la aplicación y debe rotar las contraseñas de forma automática. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Almacenar las credenciales de la base de datos para ambos entornos en AWS Systems Manager Parameter Store. Encriptar las credenciales utilizando una clave de AWS Key Management Service (AWS KMS). Dentro del código de la aplicación de las funciones Lambda, extraer las credenciales del parámetro de Parameter Store utilizando el AWS SDK para Python (Boto3). Agregar un rol a las funciones Lambda para proporcionar acceso al parámetro de Parameter Store.",
            "B. Almacenar las credenciales de la base de datos para ambos entornos en AWS Secrets Manager con una entrada de clave distinta para el entorno de QA y para el entorno de producción. Activar la rotación. Proporcionar una referencia a la clave de Secrets Manager como una variable de entorno para las funciones Lambda.",
            "C. Almacenar las credenciales de la base de datos para ambos entornos en AWS Key Management Service (AWS KMS). Activar la rotación. Proporcionar una referencia a las credenciales almacenadas en AWS KMS como una variable de entorno para las funciones Lambda.",
            "D. Crear buckets de Amazon S3 separados para el entorno de QA y el entorno de producción. Activar el cifrado del lado del servidor con claves de AWS KMS (SSE-KMS) para los buckets de S3. Utilizar un patrón de nombres de objetos que permita que el código de la aplicación de cada función Lambda obtenga las credenciales correctas para el entorno correspondiente a la función. Otorgar al rol de ejecución de cada función Lambda acceso a Amazon S3."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "410.- Una empresa está utilizando AWS Control Tower para gestionar cuentas de AWS dentro de una organización en AWS Organizations. La empresa tiene una OU (Unidad Organizativa) que contiene cuentas. La empresa debe evitar que cualquier instancia de Amazon EC2, ya sea nueva o existente, en las cuentas de la OU obtenga una dirección IP pública. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Configurar todas las instancias en cada cuenta de la OU para que usen AWS Systems Manager. Utilizar un runbook de automatización de Systems Manager para evitar que se adjunten direcciones IP públicas a las instancias.",
            "B. Implementar el control proactivo de AWS Control Tower para verificar si las instancias en las cuentas de la OU tienen una dirección IP pública. Establecer la propiedad AssociatePublicIpAddress en False. Adjuntar el control proactivo a la OU.",
            "C. Crear una SCP que impida el lanzamiento de instancias que tengan una dirección IP pública. Además, configurar la SCP para evitar la asignación de una dirección IP pública a las instancias existentes. Adjuntar la SCP a la OU.",
            "D. Crear una regla personalizada de AWS Config que detecte instancias que tengan una dirección IP pública. Configurar una acción de remediación que utilice una función AWS Lambda para desvincular las direcciones IP públicas de las instancias."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "411.- Una empresa está implementando una aplicación web de terceros en AWS. La aplicación se empaqueta como una imagen Docker. La empresa ha desplegado la imagen Docker como un servicio de AWS Fargate en Amazon Elastic Container Service (Amazon ECS). Un Application Load Balancer (ALB) dirige el tráfico a la aplicación. La empresa necesita otorgar acceso a la aplicación desde internet solo a una lista específica de usuarios. La empresa no puede modificar la aplicación ni integrarla con un proveedor de identidad. Todos los usuarios deben autenticarse mediante autenticación multifactor (MFA). ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Crea un grupo de usuarios en Amazon Cognito. Configura el grupo para la aplicación. Llena el grupo con los usuarios requeridos. Configura el grupo para que requiera MFA. Configura una regla de listener en el ALB para requerir autenticación a través de la interfaz de usuario alojada de Amazon Cognito.",
            "B. Configura los usuarios en AWS Identity and Access Management (IAM). Adjunta una política de recursos al servicio Fargate para requerir que los usuarios usen MFA. Configura una regla de listener en el ALB para requerir autenticación a través de IAM.",
            "C. Configura los usuarios en AWS Identity and Access Management (IAM). Habilita AWS IAM Identity Center (AWS Single Sign-On). Configura la protección de recursos para el ALB. Crea una regla de protección de recursos para requerir que los usuarios usen MFA.",
            "D. Crea un grupo de usuarios en AWS Amplify. Configura el grupo para la aplicación. Llena el grupo con los usuarios requeridos. Configura el grupo para que requiera MFA. Configura una regla de listener en el ALB para requerir autenticación a través de la interfaz de usuario alojada de Amplify."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "412.- Un arquitecto de soluciones se está preparando para implementar una nueva herramienta de seguridad en varias regiones de AWS que anteriormente no se utilizaban. El arquitecto de soluciones implementará la herramienta utilizando un conjunto de pilas (stack set) de AWS CloudFormation. La plantilla del conjunto de pilas contiene un rol IAM que tiene un nombre personalizado. Tras la creación del conjunto de pilas, ninguna instancia de pila se crea correctamente. ¿Qué debería hacer el arquitecto de soluciones para desplegar las pilas correctamente?",
        "opciones": [
            "A. Habilitar las nuevas regiones en todas las cuentas relevantes. Especificar la capacidad CAPABILITY_NAMED_IAM durante la creación del conjunto de pilas.",
            "B. Utilizar la consola de Cuotas de Servicio para solicitar un aumento de cuota para la cantidad de pilas de CloudFormation en cada nueva región en todas las cuentas relevantes. Especificar la capacidad CAPABILITY_IAM durante la creación del conjunto de pilas.",
            "C. Especificar la capacidad CAPABILITY_NAMED_IAM y el modelo de permisos SELF_MANAGED durante la creación del conjunto de pilas.",
            "D. Especificar un ARN de rol de administración y la capacidad CAPABILITY_IAM durante la creación del conjunto de pilas."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "413.- Una empresa tiene una aplicación que utiliza un clúster de Amazon Aurora PostgreSQL para la base de datos de la aplicación. El clúster de la base de datos contiene una instancia primaria pequeña y tres instancias réplicas de mayor tamaño. La aplicación se ejecuta en una función de AWS Lambda y establece muchas conexiones de corta duración a las instancias réplicas de la base de datos para realizar operaciones de solo lectura. Durante los períodos de alto tráfico, la aplicación se vuelve poco confiable y la base de datos informa que se están estableciendo demasiadas conexiones. La frecuencia de estos períodos de alto tráfico es impredecible. ¿Qué solución mejorará la confiabilidad de la aplicación?",
        "opciones": [
            "A. Utilizar Amazon RDS Proxy para crear un proxy para el clúster de la base de datos. Configurar un endpoint de solo lectura para el proxy. Actualizar la función Lambda para que se conecte al endpoint del proxy.",
            "B. Aumentar el parámetro max_connections en el grupo de parámetros del clúster de la base de datos. Reiniciar todas las instancias del clúster de la base de datos. Actualizar la función Lambda para que se conecte al endpoint del clúster de la base de datos.",
            "C. Configurar el escalado de instancias para el clúster de la base de datos de manera que se active cuando la métrica DatabaseConnections esté cerca del valor máximo de conexiones permitido. Actualizar la función Lambda para que se conecte al endpoint de lectura de Aurora.",
            "D. Utilizar Amazon RDS Proxy para crear un proxy para el clúster de la base de datos. Configurar un endpoint de solo lectura para la Aurora Data API en el proxy. Actualizar la función Lambda para que se conecte al endpoint del proxy."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "414.- Una empresa minorista está instalando sensores IoT en todas sus tiendas a nivel mundial. Durante la fabricación de cada sensor, la autoridad certificadora privada de la empresa emite un certificado X.509 que contiene un número de serie único. Luego, la empresa despliega cada certificado en su sensor respectivo. Un arquitecto de soluciones necesita darles a los sensores la capacidad de enviar datos a AWS después de que sean instalados. Los sensores no deben poder enviar datos a AWS hasta que estén instalados. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Cree una función AWS Lambda que pueda validar el número de serie. Cree una plantilla de aprovisionamiento de AWS IoT Core. Incluya el parámetro SerialNumber en la sección de parámetros. Agregue la función Lambda como un gancho de pre-aprovisionamiento. Durante la fabricación, llame a la operación de API RegisterThing y especifique la plantilla y los parámetros.",
            "B. Cree una máquina de estados de AWS Step Functions que pueda validar el número de serie. Cree una plantilla de aprovisionamiento de AWS IoT Core. Incluya el parámetro SerialNumber en la sección de parámetros. Especifique la máquina de estados de Step Functions para validar los parámetros. Llame a la operación de API StartThingRegistrationTask durante la instalación.",
            "C. Cree una función AWS Lambda que pueda validar el número de serie. Cree una plantilla de aprovisionamiento de AWS IoT Core. Incluya el parámetro SerialNumber en la sección de parámetros. Agregue la función Lambda como un gancho de pre-aprovisionamiento. Registre la CA en AWS IoT Core, especifique la plantilla de aprovisionamiento y configure el parámetro allow-auto-registration.",
            "D. Cree una plantilla de aprovisionamiento de AWS IoT Core. Incluya el parámetro SerialNumber en la sección de parámetros. Incluya la validación de parámetros en la plantilla. Provisione un certificado de reclamación y una clave privada para cada dispositivo que utilice la CA. Conceda permisos al servicio AWS IoT Core para actualizar los recursos IoT durante el aprovisionamiento."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "415.- Una startup ha migrado recientemente un gran sitio web de comercio electrónico a AWS. El sitio web ha experimentado un aumento del 70% en las ventas. Los ingenieros de software utilizan un repositorio privado de GitHub para gestionar el código. El equipo de DevOps utiliza Jenkins para compilar y realizar pruebas unitarias. Los ingenieros necesitan recibir notificaciones por compilaciones fallidas y garantizar que los despliegues se realicen sin tiempo de inactividad. Además, deben asegurarse de que cualquier cambio en producción sea transparente para los usuarios y se pueda revertir en caso de un problema importante. Los ingenieros de software han decidido utilizar AWS CodePipeline para gestionar su proceso de compilación y despliegue. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Utilizar websockets de GitHub para activar la pipeline de CodePipeline. Usar el plugin de Jenkins para AWS CodeBuild para realizar las pruebas unitarias. Enviar alertas a un tema de Amazon SNS para cualquier compilación fallida. Desplegar en una configuración de despliegue in-place, todo a la vez, utilizando AWS CodeDeploy.",
            "B. Utilizar webhooks de GitHub para activar la pipeline de CodePipeline. Usar el plugin de Jenkins para AWS CodeBuild para realizar las pruebas unitarias. Enviar alertas a un tema de Amazon SNS para cualquier compilación fallida. Desplegar en un despliegue blue/green utilizando AWS CodeDeploy.",
            "C. Utilizar websockets de GitHub para activar la pipeline de CodePipeline. Utilizar AWS X-Ray para realizar pruebas unitarias y análisis estático de código. Enviar alertas a un tema de Amazon SNS para cualquier compilación fallida. Desplegar en un despliegue blue/green utilizando AWS CodeDeploy.",
            "D. Utilizar webhooks de GitHub para activar la pipeline de CodePipeline. Utilizar AWS X-Ray para realizar pruebas unitarias y análisis estático de código. Enviar alertas a un tema de Amazon SNS para cualquier compilación fallida. Desplegar en una configuración de despliegue in-place, todo a la vez, utilizando AWS CodeDeploy."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "416.- Una empresa de software como servicio (SaaS) ha desarrollado un entorno multiinquilino. La empresa utiliza tablas de Amazon DynamoDB que son compartidas por los inquilinos para la capa de almacenamiento. La empresa utiliza funciones AWS Lambda para los servicios de la aplicación. La empresa desea ofrecer un modelo de suscripción escalonado basado en el consumo de recursos de cada inquilino. Cada inquilino se identifica mediante un ID de inquilino único que se envía como parte de cada solicitud a las funciones Lambda. La empresa ha creado un AWS Cost and Usage Report (AWS CUR) en una cuenta de AWS. La empresa quiere asignar los costos de DynamoDB a cada inquilino de forma que se correspondan con el consumo de recursos de ese inquilino. ¿Qué solución proporcionará una visión detallada del costo de DynamoDB para cada inquilino con el MENOR esfuerzo operativo?",
        "opciones": [
            "A. Asociar una nueva etiqueta denominada tenant ID a cada tabla en DynamoDB. Activar la etiqueta como etiqueta de asignación de costos en la consola de Administración de Facturación y Costos de AWS. Desplegar un nuevo código en las funciones Lambda para registrar el ID del inquilino en Amazon CloudWatch Logs. Utilizar el AWS CUR para separar el costo de consumo de DynamoDB para cada ID de inquilino.",
            "B. Configurar las funciones Lambda para registrar el ID del inquilino y el número de RCUs y WCUs consumidos de DynamoDB por cada transacción en Amazon CloudWatch Logs. Desplegar otra función Lambda para calcular los costos de cada inquilino utilizando las unidades de capacidad registradas y el costo total de DynamoDB obtenido de la API de AWS Cost Explorer. Crear una regla de Amazon EventBridge para invocar la función Lambda de cálculo de forma programada.",
            "C. Crear una nueva clave de partición que asocie los ítems de DynamoDB con inquilinos individuales. Desplegar una función Lambda para completar la nueva columna como parte de cada transacción. Desplegar otra función Lambda para calcular los costos de los inquilinos utilizando Amazon Athena para determinar el número de ítems por inquilino en DynamoDB y el costo total de DynamoDB obtenido del AWS CUR. Crear una regla de Amazon EventBridge para invocar la función Lambda de cálculo de forma programada.",
            "D. Desplegar una función Lambda para registrar el ID del inquilino, el tamaño de cada respuesta y la duración de la llamada de transacción como métricas personalizadas en Amazon CloudWatch Logs. Utilizar CloudWatch Logs Insights para consultar las métricas personalizadas por cada inquilino. Utilizar AWS Pricing Calculator para obtener el costo total de DynamoDB y para calcular los costos de cada inquilino."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "417.- Una empresa tiene una aplicación que almacena datos en un único bucket de Amazon S3. La empresa debe conservar todos los datos durante 1 año. El equipo de seguridad de la empresa está preocupado de que un atacante pueda acceder a la cuenta de AWS a través de credenciales de largo plazo filtradas. ¿Qué solución garantizará que los objetos existentes y futuros en el bucket S3 estén protegidos?",
        "opciones": [
            "A. Crear una nueva cuenta de AWS que sea accesible únicamente para el equipo de seguridad a través de un rol asumido. Crear un bucket de S3 en la nueva cuenta. Habilitar S3 Versioning y S3 Object Lock. Configurar un periodo de retención predeterminado de 1 año. Configurar la replicación desde el bucket S3 existente hacia el nuevo bucket S3. Crear un trabajo de replicación por lotes (S3 Batch Replication) para copiar todos los datos existentes.",
            "B. Usar la regla administrada de AWS Config s3-bucket-versioning-enabled. Configurar una acción de remediación automática que use una función AWS Lambda para habilitar S3 Versioning y MFA Delete en los recursos que no cumplan. Agregar una regla de ciclo de vida (Lifecycle) de S3 para eliminar objetos después de 1 año.",
            "C. Denegar explícitamente la creación de buckets a todos los usuarios y roles, excepto para un rol de restricción de lanzamiento de AWS Service Catalog. Definir un producto de Service Catalog para la creación del bucket S3 para forzar que se habiliten S3 Versioning y MFA Delete. Autorizar a los usuarios a lanzar el producto cuando necesiten crear un bucket S3.",
            "D. Habilitar Amazon GuardDuty con la función de protección para S3 en la cuenta y en la Región de AWS. Agregar una regla de ciclo de vida (Lifecycle) de S3 para eliminar objetos después de 1 año."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "418.- Una empresa necesita mejorar la seguridad de su aplicación web en AWS. La aplicación utiliza Amazon CloudFront con dos orígenes personalizados. El primer origen personalizado enruta las solicitudes a una API HTTP de Amazon API Gateway. El segundo origen personalizado enruta el tráfico a un Application Load Balancer (ALB). La aplicación se integra con un proveedor de identidad (IdP) OpenID Connect (OIDC) para la gestión de usuarios. Una auditoría de seguridad muestra que un autorizador de JSON Web Token (JWT) proporciona acceso a la API. La auditoría de seguridad también indica que el ALB acepta solicitudes de usuarios no autenticados. Un arquitecto de soluciones debe diseñar una solución que garantice que todos los servicios backend respondan únicamente a usuarios autenticados. ¿Cuál solución cumplirá con este requisito?",
        "opciones": [
            "A. Configurar el ALB para aplicar la autenticación y la autorización integrándolo con el IdP. Permitir que solo los usuarios autenticados accedan a los servicios backend.",
            "B. Modificar la configuración de CloudFront para utilizar URLs firmadas. Implementar una política de firma permisiva que permita que cualquier solicitud acceda a los servicios backend.",
            "C. Crear una ACL web de AWS WAF que filtre las solicitudes no autenticadas a nivel del ALB. Permitir que solo el tráfico autenticado llegue a los servicios backend.",
            "D. Habilitar AWS CloudTrail para registrar todas las solicitudes que llegan al ALB. Crear una función AWS Lambda para analizar los registros y bloquear cualquier solicitud que provenga de usuarios no autenticados."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "419.- Una empresa crea una zona de aterrizaje (landing zone) de AWS Control Tower para administrar y gobernar un entorno AWS de múltiples cuentas. El equipo de seguridad de la empresa implementará controles preventivos y controles de detección para monitorear los servicios de AWS en todas las cuentas. El equipo de seguridad necesita una vista centralizada del estado de seguridad de todas las cuentas. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Desde la cuenta de administración de AWS Control Tower, use AWS CloudFormation StackSets para desplegar un paquete de conformidad de AWS Config en todas las cuentas de la organización.",
            "B. Habilite Amazon Detective para la organización en AWS Organizations. Designe una cuenta de AWS como el administrador delegado para Detective.",
            "C. Desde la cuenta de administración de AWS Control Tower, despliegue un conjunto de pilas de AWS CloudFormation (stack set) que utilice la opción de despliegue automático para habilitar Amazon Detective para la organización.",
            "D. Habilite AWS Security Hub para la organización en AWS Organizations. Designe una cuenta de AWS como el administrador delegado para Security Hub."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "420.- Una empresa que desarrolla productos electrónicos de consumo y que tiene oficinas en Europa y Asia cuenta con 60 TB de imágenes de software almacenadas en sus instalaciones en Europa. La empresa desea transferir las imágenes a un bucket de Amazon S3 en la región ap-northeast-1. Se crean nuevas imágenes de software diariamente y deben estar cifradas en tránsito. La empresa necesita una solución que no requiera desarrollo personalizado para transferir automáticamente todas las imágenes de software, tanto las existentes como las nuevas, a Amazon S3. ¿Cuál es el siguiente paso en el proceso de transferencia?",
        "opciones": [
            "A. Desplegar un agente de AWS DataSync y configurar una tarea para transferir las imágenes al bucket de S3.",
            "B. Configurar Amazon Kinesis Data Firehose para transferir las imágenes utilizando S3 Transfer Acceleration.",
            "C. Utilizar un dispositivo AWS Snowball para transferir las imágenes teniendo como destino el bucket de S3.",
            "D. Transferir las imágenes a través de una conexión VPN sitio a sitio utilizando la API de S3 con carga múltiple (multipart upload)."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "421.- Una empresa tiene una aplicación web que utiliza Amazon API Gateway, AWS Lambda y Amazon DynamoDB. Una reciente campaña de marketing ha aumentado la demanda. El software de monitoreo informa que muchas solicitudes tienen tiempos de respuesta significativamente más largos que antes de la campaña de marketing. Un arquitecto de soluciones habilitó Amazon CloudWatch Logs para API Gateway y notó que se están produciendo errores en el 20% de las solicitudes. En CloudWatch, la métrica Throttles de la función Lambda representa el 1% de las solicitudes y la métrica Errors representa el 10% de las solicitudes. Los registros de la aplicación indican que, cuando ocurren errores, se realiza una llamada a DynamoDB. ¿Qué cambio debe realizar el arquitecto de soluciones para mejorar los tiempos de respuesta actuales a medida que la aplicación web se vuelve más popular?",
        "opciones": [
            "A. Aumentar el límite de concurrencia de la función Lambda.",
            "B. Implementar el escalado automático de DynamoDB en la tabla.",
            "C. Aumentar el límite de throttling de API Gateway.",
            "D. Recrear la tabla de DynamoDB con un índice primario mejor particionado."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "422.- Una empresa tiene una aplicación que cuenta con un frontend web. La aplicación se ejecuta en el centro de datos local de la empresa y requiere acceso a almacenamiento de archivos para datos críticos. La aplicación se ejecuta en tres máquinas virtuales Linux para garantizar la redundancia. La arquitectura incluye un balanceador de carga con enrutamiento basado en solicitudes HTTP. La empresa necesita migrar la aplicación a AWS lo más rápido posible. La arquitectura en AWS debe ser altamente disponible. ¿Qué solución cumplirá con estos requisitos realizando los CAMBIOS MÁS MÍNIMOS en la arquitectura?",
        "opciones": [
            "A. Migrar la aplicación a contenedores de Amazon Elastic Container Service (Amazon ECS) que utilicen el tipo de lanzamiento Fargate en tres zonas de disponibilidad. Utilizar Amazon S3 para proporcionar almacenamiento de archivos a los tres contenedores. Usar un balanceador de carga de red (Network Load Balancer) para dirigir el tráfico a los contenedores.",
            "B. Migrar la aplicación a instancias de Amazon EC2 en tres zonas de disponibilidad. Utilizar Amazon Elastic File System (Amazon EFS) para el almacenamiento de archivos. Montar el almacenamiento de archivos en las tres instancias EC2. Usar un balanceador de carga de aplicaciones (Application Load Balancer) para dirigir el tráfico a las instancias EC2.",
            "C. Migrar la aplicación a contenedores de Amazon Elastic Kubernetes Service (Amazon EKS) que utilicen el tipo de lanzamiento Fargate en tres zonas de disponibilidad. Utilizar Amazon FSx for Lustre para proporcionar almacenamiento de archivos a los tres contenedores. Usar un balanceador de carga de red (Network Load Balancer) para dirigir el tráfico a los contenedores.",
            "D. Migrar la aplicación a instancias de Amazon EC2 en tres regiones de AWS. Utilizar Amazon Elastic Block Store (Amazon EBS) para el almacenamiento de archivos. Habilitar la replicación entre regiones (Cross-Region Replication, CRR) para las tres instancias EC2. Usar un balanceador de carga de aplicaciones (Application Load Balancer) para dirigir el tráfico a las instancias EC2."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "423.- Una empresa está planificando migrar un centro de datos local a AWS. Actualmente, la empresa hospeda el centro de datos en máquinas virtuales VMware basadas en Linux. Un arquitecto de soluciones debe recopilar información sobre las dependencias de red entre las máquinas virtuales. La información debe presentarse en forma de un diagrama que detalle las direcciones IP de los hosts, los nombres de host y la información de las conexiones de red. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Utilizar AWS Application Discovery Service. Seleccionar una región principal de AWS Migration Hub. Instalar el agente de AWS Application Discovery en los servidores locales para la recopilación de datos. Conceder permisos a Application Discovery Service para utilizar los diagramas de red de Migration Hub.",
            "B. Utilizar el recolector sin agente (Agentless Collector) de AWS Application Discovery Service para la recopilación de datos de los servidores. Exportar los diagramas de red desde AWS Migration Hub en formato .png.",
            "C. Instalar el agente de AWS Application Migration Service en los servidores locales para la recopilación de datos. Utilizar los datos de AWS Migration Hub en Workload Discovery on AWS para generar diagramas de red.",
            "D. Instalar el agente de AWS Application Migration Service en los servidores locales para la recopilación de datos. Exportar los datos desde AWS Migration Hub en formato .csv hacia un panel de Amazon CloudWatch para generar diagramas de red."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "424.- Una empresa ejecuta una aplicación de software como servicio (SaaS) en AWS. La aplicación consta de funciones AWS Lambda y de una base de datos Amazon RDS para MySQL Multi-AZ. Durante eventos de mercado, la carga de trabajo de la aplicación es mucho mayor de lo normal. Los usuarios notan tiempos de respuesta lentos durante los períodos pico debido a la gran cantidad de conexiones a la base de datos. La empresa necesita mejorar el rendimiento escalable y la disponibilidad de la base de datos. ¿Qué solución cumple con estos requisitos?",
        "opciones": [
            "A. Crear una acción de alarma de Amazon CloudWatch que active una función Lambda para agregar una réplica de lectura de Amazon RDS para MySQL cuando la utilización de recursos alcance un umbral.",
            "B. Migrar la base de datos a Amazon Aurora y agregar una réplica de lectura. Agregar un grupo de conexiones a la base de datos fuera de la función handler de Lambda.",
            "C. Migrar la base de datos a Amazon Aurora y agregar una réplica de lectura. Utilizar registros ponderados de Amazon Route 53.",
            "D. Migrar la base de datos a Amazon Aurora y agregar una réplica Aurora. Configurar Amazon RDS Proxy para gestionar los grupos de conexiones de la base de datos."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "425.- Una empresa está planeando migrar una aplicación desde sus instalaciones a la nube de AWS. La empresa comenzará la migración trasladando el almacenamiento de datos subyacente de la aplicación a AWS. Los datos de la aplicación se almacenan en un sistema de archivos compartido en las instalaciones, y los servidores de la aplicación se conectan a este sistema de archivos compartido a través de SMB. Un arquitecto de soluciones debe implementar una solución que use un bucket de Amazon S3 para almacenamiento compartido. Hasta que la aplicación esté completamente migrada y el código sea reescrito para utilizar las API nativas de Amazon S3, la aplicación debe continuar teniendo acceso a los datos a través de SMB. El arquitecto de soluciones debe migrar los datos de la aplicación a AWS a su nueva ubicación, permitiendo al mismo tiempo que la aplicación local acceda a los datos. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Crear un nuevo sistema de archivos Amazon FSx for Windows File Server. Configurar AWS DataSync con una ubicación para el recurso compartido de archivos en las instalaciones y otra ubicación para el nuevo sistema de archivos Amazon FSx. Crear una nueva tarea de DataSync para copiar los datos desde la ubicación del recurso compartido en las instalaciones al sistema de archivos Amazon FSx.",
            "B. Crear un bucket de S3 para la aplicación. Copiar los datos del almacenamiento en las instalaciones al bucket de S3.",
            "C. Implementar una máquina virtual (VM) de AWS Server Migration Service (AWS SMS) en el entorno on premises. Utilizar AWS SMS para migrar el servidor de almacenamiento de archivos desde las instalaciones a una instancia de Amazon EC2.",
            "D. Crear un bucket de S3 para la aplicación. Implementar un nuevo gateway de archivos (file gateway) de AWS Storage Gateway en una VM local. Crear un nuevo recurso compartido de archivos que almacene los datos en el bucket de S3 y que esté asociado al file gateway. Copiar los datos del almacenamiento en las instalaciones al nuevo endpoint del file gateway."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "426.- Una empresa global tiene una aplicación móvil que muestra códigos de barras de boletos. Los clientes utilizan los boletos en la aplicación móvil para asistir a eventos en vivo. Los escáneres de eventos leen los códigos de barras de los boletos y llaman a una API de backend para validar los datos del código de barras contra los datos almacenados en una base de datos. Después de escanear el código de barras, la lógica del backend escribe en la tabla única de la base de datos para marcar el código de barras como usado. La empresa necesita desplegar la aplicación en AWS con un nombre DNS de api.example.com. La empresa alojará la base de datos en tres Regiones de AWS alrededor del mundo. ¿Qué solución cumplirá con estos requisitos con la MENOR latencia?",
        "opciones": [
            "A. Alojar la base de datos en clústeres globales de bases de datos de Amazon Aurora. Alojar el backend en tres clústeres de Amazon Elastic Container Service (Amazon ECS) que se encuentren en las mismas Regiones que la base de datos. Crear un acelerador en AWS Global Accelerator para dirigir las solicitudes al clúster de ECS más cercano. Crear un registro en Amazon Route 53 que asocie api.example.com al punto final del acelerador.",
            "B. Alojar la base de datos en clústeres globales de bases de datos de Amazon Aurora. Alojar el backend en tres clústeres de Amazon Elastic Kubernetes Service (Amazon EKS) que se encuentren en las mismas Regiones que la base de datos. Crear una distribución de Amazon CloudFront con los tres clústeres como orígenes. Dirigir las solicitudes al clúster de EKS más cercano. Crear un registro en Amazon Route 53 que asocie api.example.com a la distribución de CloudFront.",
            "C. Alojar la base de datos en tablas globales de Amazon DynamoDB. Crear una distribución de Amazon CloudFront. Asociar la distribución de CloudFront con una función de CloudFront que contenga la lógica del backend para validar los códigos de barras. Crear un registro en Amazon Route 53 que asocie api.example.com a la distribución de CloudFront.",
            "D. Alojar la base de datos en tablas globales de Amazon DynamoDB. Crear una distribución de Amazon CloudFront. Asociar la distribución de CloudFront con una función Lambda@Edge que contenga la lógica del backend para validar los códigos de barras. Crear un registro en Amazon Route 53 que asocie api.example.com a la distribución de CloudFront."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "427.- Una empresa del sector médico está ejecutando una API REST en un conjunto de instancias de Amazon EC2. Las instancias EC2 se ejecutan en un grupo de Auto Scaling detrás de un Application Load Balancer (ALB). El ALB se encuentra en tres subredes públicas, y las instancias EC2 se encuentran en tres subredes privadas. La empresa ha implementado una distribución de Amazon CloudFront que tiene al ALB como único origen. ¿Qué solución debería recomendar un arquitecto de soluciones para mejorar la seguridad del origen?",
        "opciones": [
            "A. Almacenar una cadena aleatoria en AWS Secrets Manager. Crear una función AWS Lambda para la rotación automática del secreto. Configurar CloudFront para inyectar la cadena aleatoria como un encabezado HTTP personalizado en la solicitud al origen. Crear una regla de ACL web de AWS WAF con una regla de coincidencia de cadena para el encabezado personalizado. Asociar la ACL web con el ALB.",
            "B. Crear una regla de ACL web de AWS WAF con una condición de coincidencia de IP basada en los rangos de direcciones IP del servicio CloudFront. Asociar la ACL web con el ALB. Mover el ALB a las tres subredes privadas.",
            "C. Almacenar una cadena aleatoria en AWS Systems Manager Parameter Store. Configurar la rotación automática en Parameter Store para la cadena. Configurar CloudFront para inyectar la cadena aleatoria como un encabezado HTTP personalizado en la solicitud al origen. Inspeccionar el valor del encabezado HTTP personalizado y bloquear el acceso en el ALB.",
            "D. Configurar AWS Shield Advanced. Crear una política de grupo de seguridad para permitir conexiones desde los rangos de direcciones IP del servicio CloudFront. Agregar la política a AWS Shield Advanced y adjuntarla al ALB."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "428.- Para cumplir con las regulaciones de la industria, un arquitecto de soluciones debe diseñar una solución que almacene los datos críticos de la empresa en múltiples Regiones públicas de AWS, incluyendo en los Estados Unidos, donde se encuentra la sede de la empresa. Se requiere que el arquitecto de soluciones proporcione acceso a los datos almacenados en AWS a la red WAN global de la empresa. El equipo de seguridad exige que ningún tráfico que acceda a estos datos transite por Internet público. ¿Cómo debe diseñar el arquitecto de soluciones una solución altamente disponible que cumpla con los requisitos y sea rentable?",
        "opciones": [
            "A. Establecer conexiones de AWS Direct Connect desde la sede de la empresa a todas las Regiones de AWS en uso. Utilizar la WAN de la empresa para enviar el tráfico a la sede y luego a la respectiva conexión Direct Connect para acceder a los datos.",
            "B. Establecer dos conexiones de AWS Direct Connect desde la sede de la empresa a una Región de AWS. Utilizar la WAN de la empresa para enviar el tráfico a través de una conexión Direct Connect. Utilizar emparejamiento de VPC entre regiones para acceder a los datos en otras Regiones de AWS.",
            "C. Establecer dos conexiones de AWS Direct Connect desde la sede de la empresa a una Región de AWS. Utilizar la WAN de la empresa para enviar el tráfico a través de una conexión Direct Connect. Utilizar una solución de VPC de tránsito de AWS para acceder a los datos en otras Regiones de AWS.",
            "D. Establecer dos conexiones de AWS Direct Connect desde la sede de la empresa a una Región de AWS. Utilizar la WAN de la empresa para enviar el tráfico a través de una conexión Direct Connect. Utilizar Direct Connect Gateway para acceder a los datos en otras Regiones de AWS."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "429.- Una empresa ha desarrollado una aplicación que se ejecuta en Windows Server sobre máquinas virtuales VMware vSphere que la empresa aloja en sus instalaciones. Los datos de la aplicación se almacenan en un formato propietario que debe ser leído a través de la aplicación. La empresa aprovisionó manualmente los servidores y la aplicación. Como parte de su plan de recuperación ante desastres, la empresa quiere tener la capacidad de alojar su aplicación en AWS de forma temporal si el entorno local se vuelve inaccesible. La empresa desea que la aplicación regrese a alojarse en las instalaciones una vez que se complete un evento de recuperación ante desastres. El RPO es de 5 minutos. ¿Qué solución cumple con estos requisitos con la MENOR cantidad de sobrecarga operativa?",
        "opciones": [
            "A. Configurar AWS DataSync. Replicar los datos en volúmenes de Amazon Elastic Block Store (Amazon EBS). Cuando el entorno local no esté disponible, usar plantillas de AWS CloudFormation para aprovisionar instancias de Amazon EC2 y adjuntar los volúmenes EBS.",
            "B. Configurar AWS Elastic Disaster Recovery. Replicar los datos en instancias de Amazon EC2 de replicación que estén adjuntas a volúmenes de Amazon Elastic Block Store (Amazon EBS). Cuando el entorno local no esté disponible, usar Elastic Disaster Recovery para lanzar instancias de EC2 que utilicen los volúmenes replicados.",
            "C. Aprovisionar un gateway de archivos de AWS Storage Gateway. Replicar los datos en un bucket de Amazon S3. Cuando el entorno local no esté disponible, usar AWS Backup para restaurar los datos en volúmenes de Amazon Elastic Block Store (Amazon EBS) y lanzar instancias de Amazon EC2 a partir de estos volúmenes EBS.",
            "D. Aprovisionar un sistema de archivos Amazon FSx for Windows File Server en AWS. Replicar los datos en el sistema de archivos. Cuando el entorno local no esté disponible, usar plantillas de AWS CloudFormation para aprovisionar instancias de Amazon EC2 y utilizar comandos AWS::CloudFormation::Init para montar los compartidos de archivos de Amazon FSx."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "430.- Una empresa ejecuta una aplicación de recopilación de datos altamente disponible en instancias de Amazon EC2 en la región eu-north-1. La aplicación recopila datos desde dispositivos de los usuarios finales y escribe registros en un flujo de datos de Amazon Kinesis, además de utilizar un conjunto de funciones de AWS Lambda que procesan dichos registros. La empresa almacena el resultado del procesamiento en un bucket de Amazon S3 ubicado en eu-north-1. Posteriormente, utiliza los datos en ese bucket como fuente de datos para Amazon Athena. La empresa desea aumentar su presencia global. Por ello, un arquitecto de soluciones debe lanzar las capacidades de recopilación de datos en las regiones sa-east-1 y ap-northeast-1. El arquitecto despliega la aplicación, el flujo de datos de Kinesis y las funciones Lambda en ambas nuevas regiones, pero mantiene el bucket S3 en eu-north-1 para cumplir con el requisito de centralizar el análisis de datos. Durante las pruebas de la nueva configuración, el arquitecto de soluciones detecta una latencia significativa en la llegada de datos desde las nuevas regiones hacia el bucket S3. ¿Cuál solución mejorará esta latencia al MÁXIMO?",
        "opciones": [
            "A. En cada una de las dos nuevas regiones, configure las funciones Lambda para que se ejecuten en una VPC. Configure un endpoint de gateway de S3 en esa VPC.",
            "B. Active **S3 Transfer Acceleration** en el bucket S3 de **eu-north-1**. Modifique la aplicación para que utilice el nuevo endpoint acelerado de S3 cuando cargue datos en el bucket.",
            "C. Cree un bucket de S3 en cada una de las dos nuevas regiones. Configure la aplicación en cada región para que cargue datos en su bucket respectivo. Configure **S3 Cross-Region Replication** para replicar los datos al bucket S3 en eu-north-1.",
            "D. Aumente la memoria asignada a las funciones Lambda para asegurarse de que dispongan de múltiples núcleos. Utilice la función de carga múltiple (multipart upload) cuando la aplicación suba datos a Amazon S3 desde Lambda."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "431.- Una empresa proporciona una aplicación centralizada de Amazon EC2 alojada en una única VPC compartida. La aplicación centralizada debe ser accesible desde aplicaciones cliente que se ejecutan en las VPC de otras unidades de negocio. El front-end de la aplicación centralizada está configurado con un Network Load Balancer (NLB) para lograr escalabilidad. Se necesitarán conectar hasta 10 VPC de unidades de negocio a la VPC compartida. Algunos de los bloques CIDR de las VPC de las unidades de negocio se superponen con la VPC compartida, y algunos se superponen entre sí. La conectividad de red hacia la aplicación centralizada en la VPC compartida debe permitirse únicamente desde las VPC autorizadas de las unidades de negocio. ¿Qué configuración de red debe usar un arquitecto de soluciones para proporcionar conectividad desde las aplicaciones cliente en las VPC de las unidades de negocio a la aplicación centralizada en la VPC compartida?",
        "opciones": [
            "A. Crear un AWS Transit Gateway. Adjuntar la VPC compartida y las VPC autorizadas de las unidades de negocio al transit gateway. Crear una única tabla de rutas del transit gateway y asociarla con todas las VPC adjuntas. Permitir la propagación automática de rutas desde las conexiones a la tabla de rutas. Configurar las tablas de rutas de las VPC para enviar el tráfico al transit gateway.",
            "B. Crear un servicio de endpoint de VPC utilizando el NLB de la aplicación centralizada y habilitar la opción para requerir aceptación de endpoints. Crear un endpoint de VPC en cada una de las VPC de las unidades de negocio utilizando el nombre de servicio del endpoint. Aceptar las solicitudes de endpoints autorizados desde la consola del servicio de endpoint.",
            "C. Crear una conexión de emparejamiento de VPC (VPC peering) desde cada VPC de las unidades de negocio hacia la VPC compartida. Aceptar las conexiones de emparejamiento desde la consola de la VPC compartida. Configurar las tablas de rutas de las VPC para enviar el tráfico a la conexión de emparejamiento.",
            "D. Configurar una gateway privada virtual para la VPC compartida y crear customer gateways para cada una de las VPC autorizadas de las unidades de negocio. Establecer una conexión VPN Site-to-Site desde las VPC de las unidades de negocio hacia la VPC compartida. Configurar las tablas de rutas de las VPC para enviar el tráfico a la conexión VPN."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "432.- Una empresa quiere migrar su sitio web a AWS. El sitio web utiliza microservicios y se ejecuta en contenedores que están desplegados en un clúster de Kubernetes autogestionado en las instalaciones. Todos los manifiestos que definen los despliegues de los contenedores en el despliegue de Kubernetes están en un sistema de control de versiones. Todos los datos del sitio web se almacenan en una base de datos PostgreSQL. Junto al entorno local se ejecuta un repositorio de imágenes de contenedores de código abierto. Un arquitecto de soluciones necesita determinar la arquitectura que la empresa utilizará para el sitio web en AWS. ¿Qué solución cumplirá con estos requisitos con el MENOR esfuerzo de migración?",
        "opciones": [
            "A. Crear un servicio de AWS App Runner. Conectar el servicio App Runner al repositorio de imágenes de contenedores de código abierto. Desplegar los manifiestos desde las instalaciones al servicio App Runner. Crear una base de datos Amazon RDS para PostgreSQL.",
            "B. Crear un clúster de Amazon Elastic Kubernetes Service (Amazon EKS) que tenga grupos de nodos administrados. Copiar los contenedores de la aplicación a un nuevo repositorio de Amazon Elastic Container Registry (Amazon ECR). Desplegar los manifiestos desde las instalaciones al clúster de EKS. Crear un clúster de base de datos Amazon Aurora PostgreSQL.",
            "C. Crear un clúster de Amazon Elastic Container Service (Amazon ECS) que cuente con un grupo de capacidad de Amazon EC2. Copiar los contenedores de la aplicación a un nuevo repositorio de Amazon Elastic Container Registry (Amazon ECR). Registrar cada imagen de contenedor como una nueva definición de tarea. Configurar servicios ECS para cada definición de tarea de modo que coincidan con los despliegues originales de Kubernetes. Crear un clúster de base de datos Amazon Aurora PostgreSQL.",
            "D. Reconstruir el clúster de Kubernetes en las instalaciones alojándolo en instancias de Amazon EC2. Migrar el repositorio de imágenes de contenedores de código abierto a las instancias EC2. Desplegar los manifiestos desde las instalaciones en el nuevo clúster en AWS. Desplegar una base de datos PostgreSQL de código abierto en el nuevo clúster."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "433.- Una empresa utiliza una aplicación móvil en AWS para ejecutar concursos en línea. La empresa selecciona un ganador al azar al final de cada concurso. Los concursos se ejecutan durante periodos de tiempo variables. La empresa no necesita conservar ningún dato de un concurso una vez que este ha finalizado. Actualmente, la empresa utiliza código personalizado alojado en instancias de Amazon EC2 para procesar los datos del concurso y seleccionar un ganador. Las instancias de EC2 se ejecutan detrás de un Application Load Balancer y almacenan las inscripciones al concurso en instancias de base de datos de Amazon RDS. La empresa debe diseñar una nueva arquitectura para reducir el costo de ejecución de los concursos. ¿Qué solución cumplirá estos requisitos de la manera más rentable?",
        "opciones": [
            "A. Migrar el almacenamiento de las inscripciones del concurso a Amazon DynamoDB. Crear un clúster de DynamoDB Accelerator (DAX). Reescribir el código para que se ejecute como contenedores de Amazon Elastic Container Service (Amazon ECS) utilizando el tipo de lanzamiento Fargate. Al finalizar el concurso, eliminar la tabla de DynamoDB.",
            "B. Migrar el almacenamiento de las inscripciones del concurso a Amazon Redshift. Reescribir el código como funciones de AWS Lambda. Al finalizar el concurso, eliminar el clúster de Redshift.",
            "C. Agregar un clúster de Amazon ElastiCache for Redis frente a las instancias de RDS para almacenar en caché las inscripciones del concurso. Reescribir el código para que se ejecute como contenedores de Amazon Elastic Container Service (Amazon ECS) utilizando el tipo de lanzamiento Fargate. Configurar el atributo TTL de ElastiCache en cada inscripción para que expire al finalizar el concurso.",
            "D. Migrar el almacenamiento de las inscripciones del concurso a Amazon DynamoDB. Reescribir el código como funciones de AWS Lambda. Configurar el atributo TTL de DynamoDB en cada inscripción para que expire al finalizar el concurso."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "434.- Una empresa ha implementado un nuevo requisito de seguridad. Según el nuevo requisito, la empresa debe escanear todo el tráfico de las instancias corporativas de AWS en la VPC de la empresa en busca de violaciones de las políticas de seguridad de la empresa. Como resultado de estos escaneos, la empresa puede bloquear el acceso desde y hacia direcciones IP específicas. Para cumplir con el nuevo requisito, la empresa implementa un conjunto de instancias de Amazon EC2 en subredes privadas para que funcionen como proxies transparentes. La empresa instala software de servidor proxy aprobado en estas instancias de EC2. La empresa modifica las tablas de enrutamiento en todas las subredes para utilizar las instancias de EC2 correspondientes con el software de proxy como la ruta predeterminada. La empresa también crea grupos de seguridad que cumplen con las políticas de seguridad y asigna estos grupos de seguridad a las instancias de EC2. A pesar de estas configuraciones, el tráfico de las instancias de EC2 en sus subredes privadas no se está redirigiendo correctamente a internet. ¿Qué debe hacer un arquitecto de soluciones para resolver este problema?",
        "opciones": [
            "A. Deshabilitar las verificaciones de origen/destino en las instancias de EC2 que ejecutan el software de proxy.",
            "B. Agregar una regla al grupo de seguridad asignado a las instancias proxy de EC2 para permitir todo el tráfico entre instancias que tienen este grupo de seguridad. Asignar este grupo de seguridad a todas las instancias de EC2 en la VPC.",
            "C. Cambiar el conjunto de opciones DHCP de la VPC. Configurar las opciones del servidor DNS para que apunten a las direcciones de las instancias proxy de EC2.",
            "D. Asignar una interfaz de red elástica adicional a cada instancia proxy de EC2. Asegurar que una de estas interfaces de red tenga una ruta a las subredes privadas y que la otra interfaz de red tenga una ruta a internet."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "435.- Una empresa está ejecutando su solución en AWS dentro de una VPC creada manualmente. La empresa está utilizando AWS CloudFormation para aprovisionar otras partes de la infraestructura. Según un nuevo requisito, la empresa debe gestionar toda la infraestructura de manera automatizada. ¿Qué debería hacer la empresa para cumplir con este nuevo requisito con el menor esfuerzo?",
        "opciones": [
            "A. Crear una nueva pila de AWS Cloud Development Kit (AWS CDK) que aprovisione estrictamente los recursos y la configuración de la VPC existente. Usar AWS CDK para importar la VPC en la pila y gestionarla desde allí.",
            "B. Crear un conjunto de pilas de CloudFormation (stack set) que cree la VPC. Utilizar el stack set para importar la VPC en la pila.",
            "C. Crear una nueva plantilla de CloudFormation que aprovisione estrictamente los recursos y la configuración de la VPC existente. Desde la consola de CloudFormation, crear una nueva pila importando los recursos existentes.",
            "D. Crear una nueva plantilla de CloudFormation que cree la VPC. Usar la CLI de AWS Serverless Application Model (AWS SAM) para importar la VPC."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "436.- Una empresa ha desarrollado una nueva versión de un popular videojuego y quiere ponerlo a disposición del público para su descarga. El paquete de la nueva versión tiene un tamaño aproximado de 5 GB. La empresa proporciona descargas de versiones anteriores desde un sitio FTP basado en Linux, accesible públicamente, alojado en un centro de datos local. La empresa espera que la nueva versión sea descargada por usuarios de todo el mundo. La empresa busca una solución que proporcione un mejor rendimiento de descarga y costos de transferencia bajos, independientemente de la ubicación del usuario. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Almacenar los archivos del juego en volúmenes de Amazon EBS montados en instancias de Amazon EC2 dentro de un grupo de Auto Scaling. Configurar un servicio FTP en las instancias EC2. Usar un Application Load Balancer frente al grupo de Auto Scaling. Publicar la URL de descarga del juego para que los usuarios descarguen el paquete.",
            "B. Almacenar los archivos del juego en volúmenes de Amazon EFS adjuntos a instancias de Amazon EC2 dentro de un grupo de Auto Scaling. Configurar un servicio FTP en cada una de las instancias EC2. Usar un Application Load Balancer frente al grupo de Auto Scaling. Publicar la URL de descarga del juego para que los usuarios descarguen el paquete.",
            "C. Configurar Amazon Route 53 y un bucket de Amazon S3 para alojamiento de sitios web. Cargar los archivos del juego en el bucket de S3. Usar Amazon CloudFront para el sitio web. Publicar la URL de descarga del juego para que los usuarios descarguen el paquete.",
            "D. Configurar Amazon Route 53 y un bucket de Amazon S3 para alojamiento de sitios web. Cargar los archivos del juego en el bucket de S3. Habilitar la opción Requester Pays en el bucket de S3. Publicar la URL de descarga del juego para que los usuarios descarguen el paquete."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "437. Una empresa ejecuta una aplicación en la nube que consta de una base de datos y un sitio web. Los usuarios pueden publicar datos en el sitio web, hacer que los datos sean procesados y recibirlos de vuelta por correo electrónico. Los datos se almacenan en una base de datos MySQL que se ejecuta en una instancia de Amazon EC2. La base de datos se ejecuta en una VPC con dos subredes privadas. El sitio web se ejecuta en Apache Tomcat en una única instancia de EC2 en una VPC diferente con una subred pública. Existe una única conexión de emparejamiento de VPC entre la base de datos y la VPC del sitio web. El sitio web ha sufrido varias interrupciones durante el último mes debido al alto tráfico. ¿Qué acciones debe tomar un arquitecto de soluciones para aumentar la confiabilidad de la aplicación? (Elija tres.)",
        "opciones": [
            "A. Colocar el servidor Tomcat en un grupo de Auto Scaling con múltiples instancias de EC2 detrás de un Application Load Balancer.",
            "B. Aprovisionar una conexión de emparejamiento de VPC adicional.",
            "C. Migrar la base de datos MySQL a Amazon Aurora con una réplica de Aurora.",
            "D. Aprovisionar dos gateways NAT en la VPC de la base de datos.",
            "E. Mover el servidor Tomcat a la VPC de la base de datos.",
            "F. Crear una subred pública adicional en una zona de disponibilidad diferente en la VPC del sitio web."
        ],
        "respuestas_correctas": [
            "C",
            "F",
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "438.- Una empresa minorista opera su aplicación de comercio electrónico en AWS. La aplicación se ejecuta en instancias de Amazon EC2 detrás de un Application Load Balancer (ALB). La empresa utiliza una instancia de Amazon RDS como la base de datos backend. Amazon CloudFront está configurado con un origen que apunta al ALB y almacena en caché contenido estático. Amazon Route 53 aloja todas las zonas públicas. Después de una actualización de la aplicación, el ALB ocasionalmente devuelve un código de estado 502 (Bad Gateway). La causa raíz es que el ALB recibe encabezados HTTP mal formateados. Sin embargo, cuando un arquitecto de soluciones recarga la página web inmediatamente después del error, la página se carga con éxito. Mientras la empresa trabaja en la solución del problema, el arquitecto de soluciones necesita proporcionar una página de error personalizada en lugar de la página de error estándar del ALB a los visitantes. ¿Qué combinación de pasos cumplirá con este requisito con el MENOR esfuerzo operativo? (Elija dos.)",
        "opciones": [
            "A. Crear un bucket de Amazon S3. Configurar el bucket de S3 para alojar una página web estática. Subir las páginas de error personalizadas a Amazon S3.",
            "B. Crear una alarma de Amazon CloudWatch para invocar una función de AWS Lambda si la respuesta de verificación de estado del ALB Target.FailedHealthChecks es mayor que 0. Configurar la función Lambda para modificar la regla de reenvío en el ALB para apuntar a un servidor web accesible públicamente.",
            "C. Modificar los registros existentes de Amazon Route 53 agregando verificaciones de estado. Configurar un destino de respaldo si la verificación de estado falla. Modificar los registros DNS para apuntar a una página web accesible públicamente.",
            "D. Crear una alarma de Amazon CloudWatch para invocar una función de AWS Lambda si la respuesta de verificación de estado del ALB Elb.InternalError es mayor que 0. Configurar la función Lambda para modificar la regla de reenvío en el ALB para apuntar a un servidor web accesible públicamente.",
            "E. Agregar una respuesta de error personalizada configurando una página de error personalizada en CloudFront. Modificar los registros DNS para apuntar a una página web accesible públicamente."
        ],
        "respuestas_correctas": [
            "E",
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "439.- Una empresa quiere migrar un clúster de base de datos Amazon Aurora MySQL desde una cuenta de AWS existente a una nueva cuenta de AWS dentro de la misma región de AWS. Ambas cuentas son miembros de la misma organización en AWS Organizations. La empresa debe minimizar la interrupción del servicio de la base de datos antes de realizar el cambio de DNS a la nueva base de datos. ¿Qué estrategia de migración cumplirá con este requisito? (Elija dos.)",
        "opciones": [
            "A. Tomar una instantánea de la base de datos Aurora existente. Compartir la instantánea con la nueva cuenta de AWS. Crear un clúster de Aurora en la nueva cuenta a partir de la instantánea.",
            "B. Crear un clúster de Aurora en la nueva cuenta de AWS. Usar AWS Database Migration Service (AWS DMS) para migrar los datos entre los dos clústeres de Aurora.",
            "C. Usar AWS Backup para compartir una copia de seguridad de la base de datos Aurora desde la cuenta de AWS existente a la nueva cuenta de AWS. Crear un clúster de Aurora en la nueva cuenta de AWS a partir de la instantánea.",
            "D. Crear un clúster de Aurora en la nueva cuenta de AWS. Usar AWS Application Migration Service para migrar los datos entre los dos clústeres de Aurora."
        ],
        "respuestas_correctas": [
            "B",
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "440.- Una empresa de software como servicio (SaaS) proporciona una solución de software de medios a clientes. La solución está alojada en 50 VPC en varias regiones de AWS y cuentas de AWS. Una de las VPC está designada como la VPC de gestión. Los recursos de cómputo en las VPC trabajan de forma independiente. La empresa ha desarrollado una nueva funcionalidad que requiere que las 50 VPC puedan comunicarse entre sí. La nueva funcionalidad también requiere acceso unidireccional desde cada VPC de cliente hacia la VPC de gestión de la empresa. La VPC de gestión aloja un recurso de cómputo que valida licencias para la solución de software de medios. El número de VPC que la empresa usará para alojar la solución continuará aumentando a medida que la solución crezca. ¿Qué combinación de pasos proporcionará la conectividad requerida entre VPC con la MENOR sobrecarga operativa? (Elija dos.)",
        "opciones": [
            "A. Crear un transit gateway. Adjuntar todas las VPC de la empresa y las subredes relevantes al transit gateway.",
            "B. Crear conexiones de VPC peering entre todas las VPC de la empresa.",
            "C. Crear un Network Load Balancer (NLB) que apunte al recurso de cómputo para la validación de licencias. Crear un servicio de AWS PrivateLink disponible para cada VPC de cliente. Asociar el servicio de endpoint con el NLB.",
            "D. Crear un appliance VPN en cada VPC de cliente. Conectar la VPC de gestión de la empresa con cada VPC de cliente utilizando AWS Site-to-Site VPN.",
            "E. Crear una conexión de VPC peering entre la VPC de gestión de la empresa y cada VPC de cliente."
        ],
        "respuestas_correctas": [
            "C",
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "441.- Una empresa tiene múltiples líneas de negocio (LOBs) que están bajo la empresa matriz. La empresa ha pedido a su arquitecto de soluciones que desarrolle una solución con los siguientes requisitos: Generar una única factura de AWS para todas las cuentas de AWS utilizadas por sus LOBs. Los costos de cada cuenta LOB deben estar desglosados en la factura. Proporcionar la capacidad de restringir servicios y funciones en las cuentas de LOB, según lo definido por la política de gobernanza de la empresa. Cada cuenta LOB debe tener permisos de administrador completos, independientemente de la política de gobernanza. ¿Qué combinación de pasos debe tomar el arquitecto de soluciones para cumplir con estos requisitos? (Elija dos).",
        "opciones": [
            "A. Usar AWS Organizations para crear una organización en la cuenta principal para cada LOB. Luego, invitar a cada cuenta LOB a la organización correspondiente.",
            "B. Usar AWS Organizations para crear una única organización en la cuenta principal. Luego, invitar a cada cuenta de AWS de los LOBs a unirse a la organización.",
            "C. Implementar cuotas de servicio para definir los servicios y características permitidas y aplicar las cuotas a cada LOB según corresponda.",
            "D. Crear una SCP (Service Control Policy) que permita solo los servicios y características aprobados, luego aplicar la política a las cuentas de LOB.",
            "E. Habilitar la facturación consolidada en la consola de facturación de la cuenta principal y vincular las cuentas de LOB."
        ],
        "respuestas_correctas": [
            "E",
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "442.- Un arquitecto de soluciones ha implementado una aplicación web que atiende a usuarios en dos regiones de AWS bajo un dominio personalizado. La aplicación utiliza enrutamiento basado en latencia de Amazon Route 53. El arquitecto de soluciones ha asociado conjuntos de registros ponderados con un par de servidores web en zonas de disponibilidad separadas para cada región. El arquitecto de soluciones ejecuta un escenario de recuperación ante desastres. Cuando se detienen todos los servidores web en una región, Route 53 no redirige automáticamente a los usuarios a la otra región. ¿Cuáles de las siguientes podrían ser las causas raíz de este problema? (Elija dos).",
        "opciones": [
            "A. El peso de la región donde se detuvieron los servidores web es mayor que el peso de la otra región.",
            "B. Uno de los servidores web en la región secundaria no pasó su verificación de estado HTTP.",
            "C. Los conjuntos de registros de recursos de latencia no pueden usarse en combinación con los conjuntos de registros de recursos ponderados.",
            "D. La configuración para evaluar el estado del destino no está activada para el conjunto de registros de recursos de alias de latencia asociado con el dominio en la región donde se detuvieron los servidores web.",
            "E. No se ha configurado una verificación de estado HTTP para uno o más de los conjuntos de registros de recursos ponderados asociados con los servidores web detenidos."
        ],
        "respuestas_correctas": [
            "E",
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "443.- Una agencia de monitoreo de inundaciones ha implementado más de 10,000 sensores de monitoreo del nivel del agua. Los sensores envían actualizaciones de datos de manera continua, y cada actualización tiene un tamaño inferior a 1 MB. La agencia tiene una flota de servidores de aplicaciones locales. Estos servidores reciben actualizaciones de los sensores, convierten los datos sin procesar en un formato legible para humanos y escriben los resultados en un servidor de base de datos relacional local. Los analistas de datos luego usan consultas SQL simples para monitorear los datos. La agencia quiere aumentar la disponibilidad general de la aplicación y reducir el esfuerzo requerido para realizar tareas de mantenimiento. Estas tareas de mantenimiento, que incluyen actualizaciones y parches en los servidores de aplicaciones, causan tiempos de inactividad. Mientras un servidor de aplicaciones está inactivo, se pierden datos de los sensores porque los servidores restantes no pueden manejar toda la carga de trabajo. La agencia quiere una solución que optimice la sobrecarga operativa y los costos. Un arquitecto de soluciones recomienda el uso de AWS IoT Core para recopilar los datos de los sensores. ¿Qué más debería recomendar el arquitecto de soluciones para cumplir con estos requisitos?",
        "opciones": [
            "A. Enviar los datos de los sensores a Amazon Kinesis Data Firehose. Usar una función de AWS Lambda para leer los datos de Kinesis Data Firehose, convertirlos a formato .csv e insertarlos en una instancia de base de datos Amazon Aurora MySQL. Indicar a los analistas de datos que consulten los datos directamente desde la instancia de la base de datos.",
            "B. Enviar los datos de los sensores a Amazon Kinesis Data Firehose. Usar una función de AWS Lambda para leer los datos de Kinesis Data Firehose, convertirlos a formato Apache Parquet y guardarlos en un bucket de Amazon S3. Indicar a los analistas de datos que consulten los datos utilizando Amazon Athena.",
            "C. Enviar los datos de los sensores a una aplicación de Amazon Managed Service for Apache Flink (anteriormente conocido como Amazon Kinesis Data Analytics) para convertir los datos a formato .csv y almacenarlos en un bucket de Amazon S3. Importar los datos a una instancia de base de datos Amazon Aurora MySQL. Indicar a los analistas de datos que consulten los datos directamente desde la instancia de la base de datos.",
            "D. Enviar los datos de los sensores a una aplicación de Amazon Managed Service for Apache Flink (anteriormente conocido como Amazon Kinesis Data Analytics) para convertir los datos a formato Apache Parquet y almacenarlos en un bucket de Amazon S3. Indicar a los analistas de datos que consulten los datos utilizando Amazon Athena."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "444.- Una aplicación web pública de venta al por menor utiliza un Application Load Balancer (ALB) frente a instancias de Amazon EC2 que se ejecutan en múltiples Zonas de Disponibilidad (AZs) dentro de una región. La base de datos está respaldada por una implementación Amazon RDS MySQL Multi-AZ. Los health checks del grupo de destino están configurados para usar HTTP y apuntan a la página del catálogo de productos. Auto Scaling está configurado para mantener el tamaño de la flota web en función del health check del ALB. Recientemente, la aplicación experimentó una interrupción. Durante la interrupción, Auto Scaling reemplazó continuamente las instancias. Una investigación posterior determinó que las métricas del servidor web estaban dentro del rango normal, pero la capa de la base de datos estaba experimentando una carga elevada, lo que resultó en tiempos de respuesta de consultas extremadamente altos. ¿Qué cambios en conjunto remediarían estos problemas y mejorarían las capacidades de monitoreo para la disponibilidad y funcionalidad de toda la pila de la aplicación para su crecimiento futuro? (Elige dos.)",
        "opciones": [
            "A. Configurar réplicas de lectura para Amazon RDS MySQL y usar el endpoint único de lectura en la aplicación web para reducir la carga en la capa de base de datos.",
            "B. Configurar el health check del grupo de destino para que apunte a una página HTML simple en lugar de la página del catálogo de productos y configurar un health check de Amazon Route 53 contra la página del producto para evaluar la funcionalidad completa de la aplicación. Configurar alarmas de Amazon CloudWatch para notificar a los administradores cuando el sitio falle.",
            "C. Configurar el health check del grupo de destino para utilizar una verificación TCP del servidor web en Amazon EC2 y el health check de Amazon Route 53 contra la página del producto para evaluar la funcionalidad completa de la aplicación. Configurar alarmas de Amazon CloudWatch para notificar a los administradores cuando el sitio falle.",
            "D. Configurar una alarma de Amazon CloudWatch para Amazon RDS con una acción para recuperar una instancia de RDS con alta carga y deterioro en la capa de base de datos.",
            "E. Configurar un clúster de Amazon ElastiCache y colocarlo entre la aplicación web y las instancias de RDS MySQL para reducir la carga en la capa de base de datos."
        ],
        "respuestas_correctas": [
            "E",
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "445.- Una empresa tiene un centro de datos local y está utilizando Kubernetes para desarrollar una nueva solución en AWS. La empresa usa clústeres de Amazon Elastic Kubernetes Service (Amazon EKS) para sus entornos de desarrollo y prueba. El control plane y el data plane de EKS para las cargas de trabajo en producción deben residir en las instalaciones locales. La empresa necesita una solución administrada por AWS para la gestión de Kubernetes. ¿Qué solución cumplirá con estos requisitos con el menor esfuerzo operativo?",
        "opciones": [
            "A. Instalar un servidor AWS Outposts en el centro de datos local. Implementar Amazon EKS utilizando una configuración de clúster local en el servidor Outposts para las cargas de trabajo de producción.",
            "B. Instalar Amazon EKS Anywhere en el hardware de la empresa en el centro de datos local. Implementar las cargas de trabajo de producción en un clúster de EKS Anywhere.",
            "C. Instalar un servidor AWS Outposts en el centro de datos local. Implementar Amazon EKS utilizando una configuración de clúster extendido en el servidor Outposts para las cargas de trabajo de producción.",
            "D. Instalar un servidor AWS Outposts en el centro de datos local. Instalar Amazon EKS Anywhere en el servidor Outposts. Implementar las cargas de trabajo de producción en un clúster de EKS Anywhere."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "446.- Una empresa utiliza AWS Organizations para gestionar su entorno de desarrollo. Cada equipo de desarrollo de la empresa tiene su propia cuenta de AWS. Cada cuenta tiene una única VPC y bloques CIDR que no se superponen. La empresa tiene un clúster de Amazon Aurora en una cuenta de servicios compartidos. Todos los equipos de desarrollo necesitan trabajar con datos en vivo del clúster de bases de datos. ¿Qué solución proporcionará la conectividad necesaria al clúster de bases de datos con la MENOR sobrecarga operativa?",
        "opciones": [
            "A. Crear un recurso compartido de AWS Resource Access Manager (AWS RAM) para el clúster de bases de datos. Compartir el clúster de bases de datos con todas las cuentas de desarrollo.",
            "B. Crear un transit gateway en la cuenta de servicios compartidos. Crear un recurso compartido de AWS Resource Access Manager (AWS RAM) para el transit gateway. Compartir el transit gateway con todas las cuentas de desarrollo. Instruir a los desarrolladores para que acepten el recurso compartido. Configurar la red.",
            "C. Crear un Application Load Balancer (ALB) que apunte a la dirección IP del clúster de bases de datos. Crear un servicio de AWS PrivateLink que utilice el ALB. Agregar permisos para permitir que cada cuenta de desarrollo se conecte al servicio de endpoint.",
            "D. Crear una conexión de AWS Site-to-Site VPN en la cuenta de servicios compartidos. Configurar la red. Usar software VPN del AWS Marketplace en cada cuenta de desarrollo para conectarse a la conexión Site-to-Site VPN."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "447.- Una empresa utilizó AWS CloudFormation para crear toda la nueva infraestructura en sus cuentas miembro de AWS. Los recursos rara vez cambian y están correctamente dimensionados para la carga esperada. La factura mensual de AWS es consistente. Ocasionalmente, un desarrollador crea un nuevo recurso para realizar pruebas y olvida eliminarlo cuando la prueba ha finalizado. La mayoría de estas pruebas duran unos pocos días antes de que los recursos ya no sean necesarios. La empresa quiere automatizar el proceso de identificación de recursos no utilizados. Un arquitecto de soluciones necesita diseñar una solución que determine si el costo en la factura de AWS está aumentando. La solución debe ayudar a identificar los recursos que causan un aumento en el costo y debe notificar automáticamente al equipo de operaciones de la empresa. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Activar las alertas de facturación. Usar AWS Cost Explorer para determinar los costos del último mes. Crear una alarma de Amazon CloudWatch para los cargos estimados totales. Especificar un umbral de costo superior a los costos determinados por Cost Explorer. Agregar una notificación para alertar al equipo de operaciones si se supera el umbral de la alarma.",
            "B. Activar las alertas de facturación. Usar AWS Cost Explorer para determinar el costo mensual promedio de los últimos 3 meses. Crear una alarma de Amazon CloudWatch para los cargos estimados totales. Especificar un umbral de costo superior a los costos determinados por Cost Explorer. Agregar una notificación para alertar al equipo de operaciones si se supera el umbral de la alarma.",
            "C. Usar AWS Cost Anomaly Detection para crear un monitor de costos con el tipo de monitor Cuenta vinculada. Crear una suscripción para enviar resúmenes diarios de costos de AWS al equipo de operaciones. Especificar un umbral para la variación de costos.",
            "D. Usar AWS Cost Anomaly Detection para crear un monitor de costos con el tipo de monitor Servicios de AWS. Crear una suscripción para enviar resúmenes diarios de costos de AWS al equipo de operaciones. Especificar un umbral para la variación de costos."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "448.- Una empresa está implementando una nueva aplicación basada en la web y necesita una solución de almacenamiento para los servidores de aplicaciones Linux. La empresa quiere crear una ubicación única para que todas las instancias actualicen los datos de la aplicación. El conjunto de datos activo tendrá un tamaño de hasta 100 GB. Un arquitecto de soluciones ha determinado que las operaciones pico ocurrirán durante 3 horas diarias y requerirán un total de 225 MiBps de rendimiento de lectura. El arquitecto de soluciones debe diseñar una solución Multi-AZ que haga una copia de los datos disponible en otra región de AWS para recuperación ante desastres (DR). La copia de DR debe tener un RPO de menos de 1 hora. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Implementar un nuevo sistema de archivos Multi-AZ de Amazon Elastic File System (Amazon EFS). Configurar el sistema de archivos con 75 MiBps de rendimiento aprovisionado. Implementar replicación a un sistema de archivos en la región de DR.",
            "B. Implementar un nuevo sistema de archivos Amazon FSx for Lustre. Configurar el modo de rendimiento Bursting Throughput para el sistema de archivos. Usar AWS Backup para hacer copias de seguridad del sistema de archivos en la región de DR.",
            "C. Implementar un volumen de Amazon Elastic Block Store (Amazon EBS) General Purpose SSD (gp3) con 225 MiBps de rendimiento. Habilitar Multi-Attach para el volumen de EBS. Usar AWS Elastic Disaster Recovery para replicar el volumen de EBS en la región de DR.",
            "D. Implementar un sistema de archivos Amazon FSx for OpenZFS tanto en la región de producción como en la región de DR. Crear una tarea programada de AWS DataSync para replicar los datos del sistema de archivos de producción al sistema de archivos de DR cada 10 minutos."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "449.- Una empresa necesita recopilar datos de un experimento en una ubicación remota que no tiene conectividad a internet. Durante el experimento, los sensores conectados a una red local generarán 6 TB de datos en un formato propietario en el transcurso de una semana. Los sensores pueden configurarse para cargar sus archivos de datos periódicamente en un servidor FTP, pero no cuentan con su propio servidor FTP. Los sensores tampoco admiten otros protocolos. La empresa necesita recopilar los datos de manera centralizada y trasladarlos al almacenamiento de objetos en la nube de AWS lo antes posible después del experimento. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Solicitar un dispositivo AWS Snowball Edge Compute Optimized. Conectar el dispositivo a la red local. Configurar AWS DataSync con un bucket de destino y descargar los datos en el dispositivo a través de NFS. Después del experimento, devolver el dispositivo a AWS para que los datos se carguen en Amazon S3.",
            "B. Solicitar un dispositivo AWS Snowcone con una AMI de Amazon Linux 2. Conectar el dispositivo a la red local. Iniciar una instancia de Amazon EC2 en el dispositivo. Crear un script en shell que descargue periódicamente los datos de cada sensor. Después del experimento, devolver el dispositivo a AWS para que los datos se carguen como un volumen de Amazon Elastic Block Store (Amazon EBS).",
            "C. Solicitar un dispositivo AWS Snowcone con una AMI de Amazon Linux 2. Conectar el dispositivo a la red local. Iniciar una instancia de Amazon EC2 en el dispositivo. Instalar y configurar un servidor FTP en la instancia de EC2. Configurar los sensores para cargar datos en la instancia de EC2. Después del experimento, devolver el dispositivo a AWS para que los datos se carguen en Amazon S3.",
            "D. Solicitar un dispositivo AWS Snowcone. Conectar el dispositivo a la red local. Configurar el dispositivo para usar Amazon FSx. Configurar los sensores para cargar datos en el dispositivo. Configurar AWS DataSync en el dispositivo para sincronizar los datos con un bucket de Amazon S3. Devolver el dispositivo a AWS para que los datos se carguen como un volumen de Amazon Elastic Block Store (Amazon EBS)."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "450.- Una empresa con múltiples unidades de negocio está utilizando AWS Organizations con todas las funciones habilitadas. La empresa ha implementado una estructura de cuentas en la que cada unidad de negocio tiene su propia cuenta de AWS. Los administradores de cada cuenta de AWS necesitan ver datos detallados de costos y utilización para su cuenta utilizando Amazon Athena. Cada unidad de negocio solo puede acceder a sus propios datos de costos y utilización. Las políticas de IAM que regulan la capacidad de configurar los AWS Cost and Usage Reports ya están implementadas. Un informe central de Cost and Usage Report que contiene todos los datos de la organización ya está disponible en un bucket de Amazon S3. ¿Qué solución cumplirá con estos requisitos con la MENOR complejidad operativa?",
        "opciones": [
            "A. En la cuenta de administración de la organización, utilizar AWS Resource Access Manager (AWS RAM) para compartir los datos del Cost and Usage Report con cada cuenta miembro.",
            "B. En la cuenta de administración de la organización, configurar un evento de S3 para invocar una función de AWS Lambda cada vez que llegue un nuevo archivo al bucket de S3 que contiene el Cost and Usage Report central. Configurar la función Lambda para extraer los datos de cada cuenta miembro y colocarlos en Amazon S3 bajo un prefijo separado. Modificar la política del bucket de S3 para permitir que cada cuenta miembro acceda a su propio prefijo.",
            "C. En cada cuenta miembro, acceder a AWS Cost Explorer. Crear un nuevo informe que contenga la información relevante de costos para la cuenta. Guardar el informe en Cost Explorer. Proporcionar instrucciones a los administradores de cuenta para que accedan al informe guardado.",
            "D. En cada cuenta miembro, crear un nuevo bucket de S3 para almacenar los datos del Cost and Usage Report. Configurar un Cost and Usage Report para entregar los datos en el nuevo bucket de S3."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "451.- Una empresa está diseñando un entorno de AWS para una aplicación de manufactura. La aplicación ha tenido éxito con los clientes y su base de usuarios ha aumentado. La empresa ha conectado el entorno de AWS con el centro de datos local a través de una conexión de AWS Direct Connect de 1 Gbps. La empresa ha configurado BGP para la conexión. La empresa debe actualizar la solución de conectividad de red existente para garantizar que sea altamente disponible, tolerante a fallos y segura. ¿Qué solución cumplirá con estos requisitos de la manera MÁS rentable?",
        "opciones": [
            "A. Agregar una VPN AWS Site-to-Site privada dinámica como un camino secundario para proteger los datos en tránsito y proporcionar resiliencia a la conexión de Direct Connect. Configurar MACsec para cifrar el tráfico dentro de la conexión de Direct Connect.",
            "B. Aprovisionar otra conexión de Direct Connect entre el centro de datos local y AWS para aumentar la velocidad de transferencia y proporcionar resiliencia. Configurar MACsec para cifrar el tráfico dentro de la conexión de Direct Connect.",
            "C. Configurar múltiples VIFs privadas. Balancear la carga del tráfico a través de las VIFs entre el centro de datos local y AWS para proporcionar resiliencia.",
            "D. Agregar una VPN AWS Site-to-Site estática como un camino secundario para proteger los datos en tránsito y proporcionar resiliencia a la conexión de Direct Connect."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "452.- Una empresa necesita modernizar una aplicación y migrarla a AWS. La aplicación almacena datos de perfil de usuario como texto en una única tabla en una base de datos MySQL local. Después de la modernización, los usuarios utilizarán la aplicación para subir archivos de video de hasta 4 GB de tamaño. Otros usuarios deben poder descargar los archivos de video desde la aplicación. La empresa necesita una solución de almacenamiento de videos que permita una escalabilidad rápida. La solución no debe afectar el rendimiento de la aplicación. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Migrar la base de datos a Amazon Aurora PostgreSQL utilizando AWS Database Migration Service (AWS DMS). Almacenar los videos como cadenas codificadas en base64 en una columna de tipo TEXT en la base de datos.",
            "B. Migrar la base de datos a Amazon DynamoDB utilizando AWS Database Migration Service (AWS DMS) con AWS Schema Conversion Tool (AWS SCT). Almacenar los videos como objetos en Amazon S3. Almacenar la clave de S3 en el elemento correspondiente de DynamoDB.",
            "C. Migrar la base de datos a Amazon Keyspaces (para Apache Cassandra) utilizando AWS Database Migration Service (AWS DMS) con AWS Schema Conversion Tool (AWS SCT). Almacenar los videos como objetos en Amazon S3. Almacenar el identificador del objeto S3 en la entrada correspondiente de Amazon Keyspaces.",
            "D. Migrar la base de datos a Amazon DynamoDB utilizando AWS Database Migration Service (AWS DMS) con AWS Schema Conversion Tool (AWS SCT). Almacenar los videos como cadenas codificadas en base64 en el elemento correspondiente de DynamoDB."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "453.- Una empresa almacena y gestiona documentos en un sistema de archivos Amazon Elastic File System (Amazon EFS). El sistema de archivos está cifrado con una clave de AWS Key Management Service (AWS KMS). El sistema de archivos está montado en una instancia de Amazon EC2 que ejecuta software propietario. La empresa ha habilitado las copias de seguridad automáticas para el sistema de archivos. Las copias de seguridad automáticas utilizan el plan de respaldo predeterminado de AWS Backup. Un arquitecto de soluciones debe asegurarse de que los documentos eliminados puedan recuperarse dentro de un RPO (Recovery Point Objective) de 100 minutos. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Crear un nuevo rol de IAM. Crear un nuevo plan de respaldo. Usar el nuevo rol de IAM para crear copias de seguridad. Actualizar la política de la clave KMS para permitir que el nuevo rol de IAM use la clave. Implementar un programa de copias de seguridad por hora para el sistema de archivos.",
            "B. Crear un nuevo plan de respaldo. Actualizar la política de la clave KMS para permitir que el rol AWSServiceRoleForBackup de IAM use la clave. Implementar una expresión cron personalizada para ejecutar una copia de seguridad del sistema de archivos cada 30 minutos.",
            "C. Crear un nuevo rol de IAM. Usar el plan de respaldo existente. Actualizar la política de la clave KMS para permitir que el nuevo rol de IAM use la clave. Habilitar copias de seguridad continuas para la recuperación en un punto en el tiempo (point-in-time recovery, PITR).",
            "D. Usar el plan de respaldo existente. Actualizar la política de la clave KMS para permitir que el rol AWSServiceRoleForBackup de IAM use la clave. Habilitar la replicación entre regiones (Cross-Region Replication) para el sistema de archivos."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "454.- Un arquitecto de soluciones debe proporcionar una forma segura para que un equipo de ingenieros en la nube utilice la AWS CLI para cargar objetos en un bucket de Amazon S3. Cada ingeniero en la nube tiene un usuario de IAM, claves de acceso de IAM y un dispositivo MFA (autenticación multifactor) virtual. Los usuarios de IAM de los ingenieros en la nube están en un grupo llamado S3-access. Los ingenieros en la nube deben usar MFA para realizar cualquier acción en Amazon S3. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Adjuntar una política al bucket de S3 para solicitar un código MFA cuando el usuario de IAM realice acciones en el bucket de S3. Usar claves de acceso de IAM con la AWS CLI para llamar a Amazon S3.",
            "B. Actualizar la política de confianza del grupo S3-access para exigir que los principales usen MFA cuando asuman el grupo. Usar claves de acceso de IAM con la AWS CLI para llamar a Amazon S3.",
            "C. Adjuntar una política al grupo S3-access para denegar todas las acciones en S3 a menos que MFA esté presente. Usar claves de acceso de IAM con la AWS CLI para llamar a Amazon S3.",
            "D. Adjuntar una política al grupo S3-access para denegar todas las acciones en S3 a menos que MFA esté presente. Solicitar credenciales temporales de AWS Security Token Service (AWS STS). Adjuntar las credenciales temporales en un perfil que Amazon S3 usará cuando el usuario realice acciones en S3."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "455.- Una empresa necesita migrar 60 aplicaciones heredadas locales a AWS. Las aplicaciones están basadas en el .NET Framework y se ejecutan en Windows. La empresa necesita una solución que minimice el tiempo de migración y no requiera cambios en el código de las aplicaciones. Además, la empresa no quiere administrar la infraestructura. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Refactorizar las aplicaciones y contenerizarlas usando AWS Toolkit for .NET Refactoring. Usar Amazon Elastic Container Service (Amazon ECS) con el tipo de lanzamiento Fargate para alojar las aplicaciones contenerizadas.",
            "B. Usar el Windows Web Application Migration Assistant para migrar las aplicaciones a AWS Elastic Beanstalk. Usar Elastic Beanstalk para desplegar y administrar las aplicaciones.",
            "C. Usar el Windows Web Application Migration Assistant para migrar las aplicaciones a instancias de Amazon EC2. Usar las instancias de EC2 para desplegar y administrar las aplicaciones.",
            "D. Refactorizar las aplicaciones y contenerizarlas usando AWS Toolkit for .NET Refactoring. Usar Amazon Elastic Kubernetes Service (Amazon EKS) con el tipo de lanzamiento Fargate para alojar las aplicaciones contenerizadas."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "456.- Una empresa necesita ejecutar trabajos de procesamiento por lotes en grandes volúmenes de datos almacenados en un bucket de Amazon S3. Los trabajos realizan simulaciones. Los resultados de los trabajos no son sensibles al tiempo, y el proceso puede soportar interrupciones. Cada trabajo debe procesar entre 15 y 20 GB de datos cuando los datos están almacenados en el bucket de S3. La empresa almacenará la salida de los trabajos en un bucket de Amazon S3 diferente para su posterior análisis. ¿Qué solución cumplirá con estos requisitos de la manera más rentable?",
        "opciones": [
            "A. Crear una canalización de datos sin servidor. Usar AWS Step Functions para la orquestación. Usar funciones de AWS Lambda con capacidad aprovisionada para procesar los datos.",
            "B. Crear un entorno de cómputo en AWS Batch que incluya instancias Spot de Amazon EC2. Especificar la estrategia de asignación SPOT_CAPACITY_OPTIMIZED.",
            "C. Crear un entorno de cómputo en AWS Batch que incluya instancias bajo demanda de Amazon EC2 y Spot Instances. Especificar la estrategia de asignación SPOT_CAPACITY_OPTIMIZED para las instancias Spot.",
            "D. Usar Amazon Elastic Kubernetes Service (Amazon EKS) para ejecutar los trabajos de procesamiento. Usar grupos de nodos administrados que contengan una combinación de instancias bajo demanda de Amazon EC2 e instancias Spot."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "457.- Una empresa tiene una aplicación que analiza y almacena datos de imágenes en las instalaciones. La aplicación recibe millones de archivos de imágenes nuevos cada día. Los archivos tienen un tamaño promedio de 1 MB. Los archivos se analizan en lotes de 1 GB. Cuando la aplicación analiza un lote, comprime las imágenes juntas en un archivo ZIP. Luego, la aplicación archiva las imágenes como un solo archivo en un servidor NFS local para almacenamiento a largo plazo. La empresa tiene un entorno Microsoft Hyper-V en las instalaciones y cuenta con capacidad de cómputo disponible. Sin embargo, no tiene capacidad de almacenamiento y desea archivar las imágenes en AWS. La empresa necesita la capacidad de recuperar los datos archivados dentro de una semana después de una solicitud. La empresa tiene una conexión AWS Direct Connect de 10 Gbps entre su centro de datos local y AWS. La empresa necesita establecer límites de ancho de banda y programar la copia de imágenes archivadas a AWS fuera del horario laboral. ¿Qué solución cumplirá con estos requisitos de la manera más rentable?",
        "opciones": [
            "A. Implementar un agente AWS DataSync en una nueva instancia de Amazon EC2 basada en GPU. Configurar el agente DataSync para copiar los lotes de archivos desde el servidor NFS local a Amazon S3 Glacier Instant Retrieval. Después de la copia exitosa, eliminar los datos del almacenamiento local.",
            "B. Implementar un agente AWS DataSync como una máquina virtual en Hyper-V en las instalaciones. Configurar el agente DataSync para copiar los lotes de archivos desde el servidor NFS local a Amazon S3 Glacier Deep Archive. Después de la copia exitosa, eliminar los datos del almacenamiento local.",
            "C. Implementar un agente AWS DataSync en una nueva instancia de Amazon EC2 de propósito general. Configurar el agente DataSync para copiar los lotes de archivos desde el servidor NFS local a Amazon S3 Standard. Después de la copia exitosa, eliminar los datos del almacenamiento local. Crear una regla de ciclo de vida en S3 para mover los objetos de S3 Standard a S3 Glacier Deep Archive después de 1 día.",
            "D. Implementar un AWS Storage Gateway Tape Gateway en las instalaciones en el entorno Hyper-V. Conectar Tape Gateway a AWS. Usar la creación automática de cintas. Especificar un grupo de almacenamiento en Amazon S3 Glacier Deep Archive. Expulsar la cinta después de que el lote de imágenes sea copiado."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "458.- Una empresa quiere registrar indicadores clave de rendimiento (KPIs) de su aplicación como parte de una estrategia para convertir su modelo de licencia a un esquema basado en usuarios. La aplicación es una aplicación multi-capa con una interfaz de usuario basada en la web. La empresa guarda todos los archivos de registro en Amazon CloudWatch mediante el agente de CloudWatch. Todos los inicios de sesión en la aplicación se guardan en un archivo de registro. Como parte del nuevo esquema de licencias, la empresa necesita determinar cuántos usuarios únicos tiene cada cliente en una base diaria, semanal y mensual. ¿Qué solución proporcionará esta información con el MENOR cambio en la aplicación?",
        "opciones": [
            "A. Configurar un filtro de métricas de Amazon CloudWatch Logs que guarde cada inicio de sesión exitoso como una métrica. Configurar el nombre de usuario y el nombre del cliente como dimensiones de la métrica.",
            "B. Cambiar la lógica de la aplicación para que cada inicio de sesión exitoso genere una llamada al AWS SDK para incrementar una métrica personalizada que registre el nombre de usuario y el nombre del cliente como dimensiones en CloudWatch.",
            "C. Configurar el agente de CloudWatch para extraer métricas de inicios de sesión exitosos de los registros. Adicionalmente, configurar el agente de CloudWatch para guardar las métricas de inicios de sesión exitosos como una métrica personalizada que utilice el nombre de usuario y el nombre del cliente como dimensiones de la métrica.",
            "D. Configurar una función de AWS Lambda para consumir un flujo de registros de Amazon CloudWatch Logs de los registros de la aplicación. Adicionalmente, configurar la función Lambda para incrementar una métrica personalizada en CloudWatch que utilice el nombre de usuario y el nombre del cliente como dimensiones de la métrica."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "459.- Una empresa está utilizando GitHub Actions para ejecutar una canalización de CI/CD que accede a recursos en AWS. La empresa tiene un usuario de IAM que utiliza una clave secreta en la canalización para autenticarse en AWS. Un rol de IAM existente con una política adjunta otorga los permisos necesarios para desplegar recursos. El equipo de seguridad de la empresa ha implementado un nuevo requisito que establece que las canalizaciones ya no pueden utilizar claves secretas de larga duración. Un arquitecto de soluciones debe reemplazar la clave secreta con una solución de corta duración. ¿Qué solución cumplirá con estos requisitos con el MENOR esfuerzo operativo?",
        "opciones": [
            "A. Crear un proveedor de identidad (IdP) SAML 2.0 en AWS Identity and Access Management (IAM). Crear un nuevo rol de IAM con la política de confianza adecuada que permita la llamada a la API sts:AssumeRole. Adjuntar la política de IAM existente al nuevo rol de IAM. Actualizar GitHub para utilizar la autenticación SAML en la canalización.",
            "B. Crear un proveedor de identidad (IdP) OpenID Connect (OIDC) en AWS Identity and Access Management (IAM). Crear un nuevo rol de IAM con la política de confianza adecuada que permita la llamada a la API sts:AssumeRoleWithWebIdentity desde el IdP de GitHub OIDC. Actualizar GitHub para asumir el rol en la canalización.",
            "C. Crear un grupo de identidades de Amazon Cognito. Configurar el proveedor de autenticación para usar GitHub. Crear un nuevo rol de IAM con la política de confianza adecuada que permita la llamada a la API sts:AssumeRoleWithWebIdentity desde el proveedor de autenticación de GitHub. Configurar la canalización para usar Cognito como su proveedor de autenticación.",
            "D. Crear un anclaje de confianza en AWS Private Certificate Authority. Generar un certificado de cliente para usar con AWS IAM Roles Anywhere. Crear un nuevo rol de IAM con la política de confianza adecuada que permita la llamada a la API sts:AssumeRole. Adjuntar la política de IAM existente al nuevo rol de IAM. Configurar la canalización para usar la herramienta de ayuda de credenciales y hacer referencia a la clave pública del certificado de cliente para asumir el nuevo rol de IAM."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "460.- Una empresa está ejecutando un proceso de rastreo web en una lista de URL de destino para obtener documentos de entrenamiento para algoritmos de aprendizaje automático. Una flota de instancias Amazon EC2 t2.micro extrae las URL de destino de una cola de Amazon Simple Queue Service (Amazon SQS). Luego, las instancias escriben el resultado del algoritmo de rastreo como un archivo .csv en un volumen de Amazon Elastic File System (Amazon EFS). El volumen de EFS está montado en todas las instancias de la flota. Un sistema separado agrega las URL a la cola de SQS a tasas poco frecuentes. Las instancias rastrean cada URL en 10 segundos o menos. Las métricas indican que algunas instancias están inactivas cuando no hay URL en la cola de SQS. Un arquitecto de soluciones necesita rediseñar la arquitectura para optimizar costos. ¿Qué combinación de pasos cumplirá con estos requisitos de la manera MÁS rentable? (Elija dos.)",
        "opciones": [
            "A. Usar instancias m5.8xlarge en lugar de instancias t2.micro para el proceso de rastreo web. Reducir el número de instancias en la flota en un 50%.",
            "B. Convertir el proceso de rastreo web en una función de AWS Lambda. Configurar la función Lambda para extraer URL de la cola de SQS.",
            "C. Modificar el proceso de rastreo web para almacenar los resultados en Amazon Neptune.",
            "D. Modificar el proceso de rastreo web para almacenar los resultados en una instancia de Amazon Aurora Serverless MySQL.",
            "E. Modificar el proceso de rastreo web para almacenar los resultados en Amazon S3."
        ],
        "respuestas_correctas": [
            "E",
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "461.- Una empresa necesita migrar su sitio web desde un centro de datos local a AWS. El sitio web consta de un balanceador de carga, un sistema de gestión de contenido (CMS) que se ejecuta en un sistema operativo Linux y una base de datos MySQL. El CMS requiere almacenamiento persistente compatible con NFS para un sistema de archivos. La nueva solución en AWS debe poder escalar desde 2 instancias de Amazon EC2 hasta 30 instancias EC2 en respuesta a aumentos impredecibles de tráfico. La nueva solución también debe requerir cero cambios en el sitio web y prevenir la pérdida de datos. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Crear un sistema de archivos Amazon Elastic File System (Amazon EFS). Implementar el CMS en AWS Elastic Beanstalk con un Application Load Balancer y un grupo de Auto Scaling Usar .ebextensions para montar el sistema de archivos EFS en las instancias EC2. Crear una base de datos Amazon Aurora MySQL separada del entorno de Elastic Beanstalk.",
            "B. Crear un volumen Amazon Elastic Block Store (Amazon EBS) Multi-Attach. Implementar el CMS en AWS Elastic Beanstalk con un Network Load Balancer y un grupo de Auto Scaling. Usar .ebextensions para montar el volumen EBS en las instancias EC2. Crear una base de datos Amazon RDS for MySQL dentro del entorno de Elastic Beanstalk.",
            "C. Crear un sistema de archivos Amazon Elastic File System (Amazon EFS). Crear una plantilla de lanzamiento y un grupo de Auto Scaling para lanzar instancias EC2 que soporten el CMS. Crear un Network Load Balancer para distribuir el tráfico. Crear una base de datos Amazon Aurora MySQL. Usar un gancho de ciclo de vida de Auto Scaling para montar el sistema de archivos EFS en las instancias EC2.",
            "D. Crear un volumen Amazon Elastic Block Store (Amazon EBS) Multi-Attach. Crear una plantilla de lanzamiento y un grupo de Auto Scaling para lanzar instancias EC2 que soporten el CMS. Crear un Application Load Balancer para distribuir el tráfico. Crear un clúster Amazon ElastiCache for Redis para soportar la base de datos MySQL. Usar user data de EC2 para adjuntar el volumen EBS a las instancias EC2."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "462.- Una empresa necesita implementar recuperación ante desastres para una aplicación crítica que se ejecuta en una sola región de AWS. Los usuarios de la aplicación interactúan con un frontend web alojado en instancias de Amazon EC2 detrás de un Application Load Balancer (ALB). La aplicación escribe en una instancia de base de datos Amazon RDS for MySQL. Además, la aplicación genera documentos procesados que se almacenan en un bucket de Amazon S3. El equipo financiero de la empresa consulta directamente la base de datos para generar informes. Durante los períodos de alta demanda, estas consultas consumen recursos y afectan negativamente el rendimiento de la aplicación. Un arquitecto de soluciones debe diseñar una solución que proporcione resiliencia durante un desastre. La solución debe minimizar la pérdida de datos y resolver los problemas de rendimiento causados por las consultas del equipo financiero. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Migrar la base de datos a Amazon DynamoDB y usar tablas globales de DynamoDB. Indicar al equipo financiero que consulte una tabla global en una región separada. Crear una función de AWS Lambda para sincronizar periódicamente el contenido del bucket S3 original con un nuevo bucket S3 en la región separada. Lanzar instancias EC2 y crear un ALB en la región separada. Configurar la aplicación para que apunte al nuevo bucket S3.",
            "B. Lanzar instancias EC2 adicionales que alojen la aplicación en una región separada. Agregar las instancias adicionales al ALB existente. En la región separada, crear una réplica de lectura de la instancia de RDS. Indicar al equipo financiero que ejecute sus consultas en la réplica de lectura. Usar S3 Cross-Region Replication (CRR) para replicar el contenido del bucket S3 original a un nuevo bucket S3 en la región separada. Durante un desastre, promover la réplica de lectura a una instancia de base de datos independiente. Configurar la aplicación para que apunte al nuevo bucket S3 y a la réplica promovida.",
            "C. Crear una réplica de lectura de la instancia de RDS en una región separada. Indicar al equipo financiero que ejecute sus consultas en la réplica de lectura. Crear AMIs de las instancias EC2 que alojan el frontend de la aplicación. Copiar las AMIs a la región separada. Usar S3 Cross-Region Replication (CRR) para replicar el contenido del bucket S3 original a un nuevo bucket S3 en la región separada. Durante un desastre, promover la réplica de lectura a una instancia de base de datos independiente. Lanzar instancias EC2 desde las AMIs y crear un ALB para presentar la aplicación a los usuarios finales. Configurar la aplicación para que apunte al nuevo bucket S3.",
            "D. Crear instantáneas de la base de datos RDS cada hora. Copiar las instantáneas a una región separada. Agregar un clúster de Amazon ElastiCache delante de la base de datos RDS existente. Crear AMIs de las instancias EC2 que alojan el frontend de la aplicación. Copiar las AMIs a la región separada. Usar S3 Cross-Region Replication (CRR) para replicar el contenido del bucket S3 original a un nuevo bucket S3 en la región separada. Durante un desastre, restaurar la base de datos a partir de la última instantánea de RDS. Lanzar instancias EC2 desde las AMIs y crear un ALB para presentar la aplicación a los usuarios finales. Configurar la aplicación para que apunte al nuevo bucket S3."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "463.- Una empresa tiene muchos servicios en ejecución en su centro de datos local. El centro de datos está conectado a AWS mediante AWS Direct Connect (DX) y una VPN IPSec. Los datos del servicio son sensibles y la conectividad no puede atravesar Internet. La empresa quiere expandirse a un nuevo segmento de mercado y comenzar a ofrecer sus servicios a otras empresas que usan AWS. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Crear un VPC Endpoint Service que acepte tráfico TCP, alojarlo detrás de un Network Load Balancer (NLB) y hacer que el servicio esté disponible a través de DX.",
            "B. Crear un VPC Endpoint Service que acepte tráfico HTTP o HTTPS, alojarlo detrás de un Application Load Balancer (ALB) y hacer que el servicio esté disponible a través de DX.",
            "C. Adjuntar un Internet Gateway a la VPC y asegurarse de que las reglas de control de acceso a la red y los grupos de seguridad permitan el tráfico de entrada y salida relevante.",
            "D. Adjuntar un NAT Gateway a la VPC y asegurarse de que las reglas de control de acceso a la red y los grupos de seguridad permitan el tráfico de entrada y salida relevante."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "464.- Una empresa utiliza AWS Organizations para gestionar sus cuentas de AWS. Un arquitecto de soluciones debe diseñar una solución en la que solo los roles de administrador puedan utilizar acciones de IAM. Sin embargo, el arquitecto de soluciones no tiene acceso a todas las cuentas de AWS en la empresa. ¿Qué solución cumple con estos requisitos con la MENOR sobrecarga operativa?",
        "opciones": [
            "A. Crear una Política de Control de Servicio (SCP) que se aplique a todas las cuentas de AWS para permitir acciones de IAM solo a los roles de administrador. Aplicar la SCP a la OU raíz.",
            "B. Configurar AWS CloudTrail para invocar una función de AWS Lambda en cada evento relacionado con acciones de IAM. Configurar la función para denegar la acción si el usuario que la invocó no es un administrador.",
            "C. Crear una Política de Control de Servicio (SCP) que se aplique a todas las cuentas de AWS para denegar acciones de IAM a todos los usuarios excepto a los roles de administrador. Aplicar la SCP a la OU raíz.",
            "D. Establecer un límite de permisos de IAM (permissions boundary) que permita acciones de IAM. Adjuntar el límite de permisos a cada rol de administrador en todas las cuentas de AWS."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "465.- Una empresa usa una organización en AWS Organizations para administrar múltiples cuentas de AWS. La empresa aloja algunas aplicaciones en una VPC en la cuenta de servicios compartidos. La empresa ha adjuntado un transit gateway a la VPC en la cuenta de servicios compartidos. La empresa está desarrollando una nueva funcionalidad y ha creado un entorno de desarrollo que requiere acceso a las aplicaciones en la cuenta de servicios compartidos. La empresa tiene la intención de eliminar y recrear recursos con frecuencia en la cuenta de desarrollo. Además, la empresa quiere otorgar al equipo de desarrollo la capacidad de recrear la conexión a la cuenta de servicios compartidos según sea necesario. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Crear un transit gateway en la cuenta de desarrollo. Crear una solicitud de emparejamiento de transit gateway a la cuenta de servicios compartidos. Configurar el transit gateway de la cuenta de servicios compartidos para aceptar automáticamente las conexiones de emparejamiento.",
            "B. Activar la aceptación automática para el transit gateway en la cuenta de servicios compartidos. Usar AWS Resource Access Manager (AWS RAM) para compartir el transit gateway de la cuenta de servicios compartidos con la cuenta de desarrollo. Aceptar el recurso en la cuenta de desarrollo. Crear un adjunto de transit gateway en la cuenta de desarrollo.",
            "C. Activar la aceptación automática para el transit gateway en la cuenta de servicios compartidos. Crear un VPC endpoint. Usar la política del endpoint para otorgar permisos en el VPC endpoint a la cuenta de desarrollo. Configurar el servicio de endpoint para aceptar automáticamente las solicitudes de conexión. Proporcionar los detalles del endpoint al equipo de desarrollo.",
            "D. Crear una regla de Amazon EventBridge para invocar una función AWS Lambda que acepte el adjunto del transit gateway cuando la cuenta de desarrollo haga una solicitud de adjunto. Usar AWS Network Manager para compartir el transit gateway en la cuenta de servicios compartidos con la cuenta de desarrollo. Aceptar el transit gateway en la cuenta de desarrollo."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "466.- Una empresa quiere migrar cargas de trabajo de Microsoft virtualizadas desde un centro de datos local a AWS. La empresa ha probado con éxito algunas cargas de trabajo en AWS. También ha creado una conexión AWS Site-to-Site VPN a una VPC. Un arquitecto de soluciones necesita generar un informe de costo total de propiedad (TCO) para la migración de todas las cargas de trabajo desde el centro de datos. El protocolo Simple Network Management Protocol (SNMP) está habilitado en cada máquina virtual (VM) en el centro de datos. La empresa no puede agregar más máquinas virtuales en el centro de datos ni instalar software adicional en las VM. Los datos de descubrimiento deben importarse automáticamente a AWS Migration Hub. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Usar el servicio sin agente de AWS Application Migration Service y AWS Migration Hub Strategy Recommendations para generar el informe de TCO.",
            "B. Lanzar una instancia de Windows en Amazon EC2. Instalar el colector sin agente de Migration Evaluator en la instancia de EC2. Configurar Migration Evaluator para generar el informe de TCO.",
            "C. Lanzar una instancia de Windows en Amazon EC2. Instalar el colector sin agente de Migration Evaluator en la instancia de EC2. Configurar Migration Hub para generar el informe de TCO.",
            "D. Usar la herramienta AWS Migration Readiness Assessment dentro de la VPC. Configurar Migration Evaluator para generar el informe de TCO."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "467.- Una empresa que está desarrollando un juego móvil está poniendo a disposición los recursos del juego en dos regiones de AWS. Los recursos del juego se sirven desde un conjunto de instancias de Amazon EC2 detrás de un Application Load Balancer (ALB) en cada región. La empresa requiere que los recursos del juego se obtengan desde la región más cercana. Si los recursos del juego se vuelven inaccesibles en la región más cercana, deben obtenerse desde la otra región. ¿Qué debe hacer un arquitecto de soluciones para cumplir con estos requisitos?",
        "opciones": [
            "A. Crear una distribución de Amazon CloudFront. Crear un grupo de orígenes con un origen para cada ALB. Establecer uno de los orígenes como primario.",
            "B. Crear una verificación de estado de Amazon Route 53 para cada ALB. Crear un registro de enrutamiento de conmutación por error (failover) en Route 53 apuntando a los dos ALB. Establecer el valor Evaluate Target Health en Yes.",
            "C. Crear dos distribuciones de Amazon CloudFront, cada una con un ALB como origen. Crear un registro de enrutamiento de conmutación por error en Amazon Route 53 apuntando a las dos distribuciones de CloudFront. Establecer el valor Evaluate Target Health en Yes.",
            "D. Crear una verificación de estado de Amazon Route 53 para cada ALB. Crear un registro de alias de latencia en Route 53 apuntando a los dos ALB. Establecer el valor Evaluate Target Health en Yes."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "468.- Una empresa implementa cargas de trabajo en múltiples cuentas de AWS. Cada cuenta tiene una VPC con registros de flujo de VPC (VPC Flow Logs) publicados en formato de texto en un bucket centralizado de Amazon S3. Cada archivo de registro está comprimido con compresión gzip. La empresa debe retener los archivos de registro indefinidamente. Un ingeniero de seguridad analiza ocasionalmente los registros utilizando Amazon Athena para consultar los registros de flujo de VPC. El rendimiento de las consultas se está degradando con el tiempo a medida que crece el número de registros ingeridos. Un arquitecto de soluciones debe mejorar el rendimiento del análisis de registros y reducir el espacio de almacenamiento utilizado por los registros de flujo de VPC. ¿Qué solución cumplirá con estos requisitos con la MAYOR mejora en el rendimiento?",
        "opciones": [
            "A. Crear una función de AWS Lambda para descomprimir los archivos gzip y comprimirlos nuevamente utilizando la compresión bzip2. Suscribir la función Lambda a un evento de notificación s3:ObjectCreated:Put para el bucket de S3.",
            "B. Habilitar S3 Transfer Acceleration para el bucket de S3. Crear una configuración de ciclo de vida en S3 para mover los archivos a la clase de almacenamiento S3 Intelligent-Tiering tan pronto como se carguen los archivos.",
            "C. Actualizar la configuración de los registros de flujo de VPC para almacenar los archivos en formato Apache Parquet. Especificar particiones horarias para los archivos de registro.",
            "D. Crear un nuevo grupo de trabajo de Athena sin límites de control de uso de datos. Usar la versión 2 del motor de Athena."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "469.- Una empresa quiere establecer una conexión dedicada entre su infraestructura local y AWS. La empresa está configurando una conexión de AWS Direct Connect de 1 Gbps a su VPC de cuenta. La arquitectura incluye un transit gateway y un Direct Connect gateway para conectar múltiples VPCs y la infraestructura local. La empresa debe conectarse a los recursos de la VPC a través de un transit VIF utilizando la conexión de Direct Connect. ¿Qué combinación de pasos cumplirá con estos requisitos? (Elija dos.)",
        "opciones": [
            "A. Actualizar la conexión de Direct Connect de 1 Gbps a 10 Gbps.",
            "B. Anunciar los prefijos de la red local sobre el transit VIF.",
            "C. Anunciar los prefijos de la VPC desde el Direct Connect gateway a la red local a través del transit VIF.",
            "D. Actualizar el atributo de modo de cifrado MACsec de la conexión de Direct Connect a must_encrypt.",
            "E. Asociar un par MACsec Connection Key Name/Connectivity Association Key (CKN/CAK) con la conexión de Direct Connect."
        ],
        "respuestas_correctas": [
            "C",
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "470.- Una empresa quiere usar Amazon WorkSpaces en combinación con dispositivos thin client para reemplazar los escritorios obsoletos. Los empleados usan los escritorios para acceder a aplicaciones que trabajan con datos de ensayos clínicos. La política de seguridad corporativa establece que el acceso a las aplicaciones debe estar restringido solo a las ubicaciones de las sucursales de la empresa. La empresa está considerando agregar una nueva sucursal en los próximos 6 meses. ¿Qué solución cumple con estos requisitos con la MAYOR eficiencia operativa?",
        "opciones": [
            "A. Crear una regla de grupo de control de acceso IP con la lista de direcciones públicas de las sucursales. Asociar el grupo de control de acceso IP con el directorio de WorkSpaces.",
            "B. Usar AWS Firewall Manager para crear una regla de ACL web con un IPSet que contenga la lista de direcciones públicas de las ubicaciones de las sucursales. Asociar la ACL web con el directorio de WorkSpaces.",
            "C. Usar AWS Certificate Manager (ACM) para emitir certificados de dispositivos confiables a las máquinas implementadas en las ubicaciones de las sucursales. Habilitar el acceso restringido en el directorio de WorkSpaces.",
            "D. Crear una imagen personalizada de WorkSpaces con Windows Firewall configurado para restringir el acceso a las direcciones públicas de las sucursales. Usar la imagen para implementar los WorkSpaces."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "471.- Una empresa utiliza AWS Organizations. La empresa ejecuta dos dispositivos de firewall en una cuenta de red centralizada. Cada dispositivo de firewall se ejecuta en una instancia de Amazon EC2 altamente disponible, configurada manualmente. Un transit gateway conecta la VPC de la cuenta de red centralizada con las VPC de las cuentas miembro. Cada dispositivo de firewall usa una dirección IP privada estática que luego se utiliza para enrutar el tráfico de las cuentas miembro hacia internet. Durante un incidente reciente, un script mal configurado inició la terminación de ambos dispositivos de firewall. Durante la reconstrucción de los dispositivos de firewall, la empresa escribió un nuevo script para configurarlos en el arranque. La empresa quiere modernizar la implementación de los dispositivos de firewall. Los dispositivos de firewall necesitan la capacidad de escalar horizontalmente para manejar el aumento del tráfico a medida que la red se expande. La empresa debe continuar utilizando los dispositivos de firewall para cumplir con la política de la empresa. El proveedor de los dispositivos de firewall ha confirmado que la última versión del código de firewall funcionará con todos los servicios de AWS. ¿Qué combinación de pasos debe recomendar el arquitecto de soluciones para cumplir con estos requisitos de la manera MÁS rentable? (Elija tres).",
        "opciones": [
            "A. Desplegar un Gateway Load Balancer en la cuenta de red centralizada. Configurar un servicio de endpoint que use AWS PrivateLink.",
            "B. Desplegar un Network Load Balancer en la cuenta de red centralizada. Configurar un servicio de endpoint que use AWS PrivateLink.",
            "C. Crear un Auto Scaling group y una plantilla de lanzamiento que utilice el nuevo script como user data para configurar los dispositivos de firewall. Crear un target group que use el tipo de destino instancia.",
            "D. Crear un Auto Scaling group. Configurar una implementación con AWS Launch Wizard que use el nuevo script como user data para configurar los dispositivos de firewall. Crear un target group que use el tipo de destino IP.",
            "E. Crear VPC endpoints en cada cuenta miembro. Actualizar las tablas de enrutamiento para apuntar a los VPC endpoints.",
            "F. Crear VPC endpoints en la cuenta de red centralizada. Actualizar las tablas de enrutamiento en cada cuenta miembro para apuntar a los VPC endpoints."
        ],
        "respuestas_correctas": [
            "C",
            "F",
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "472.- Un arquitecto de soluciones debe implementar una arquitectura multi-región para una base de datos Amazon RDS for PostgreSQL que soporta una aplicación web. La base de datos se lanza desde una plantilla de AWS CloudFormation, que incluye servicios y características de AWS que están presentes tanto en la Región primaria como en la Región secundaria. La base de datos está configurada para realizar copias de seguridad automatizadas y tiene un RTO (Recovery Time Objective) de 15 minutos y un RPO (Recovery Point Objective) de 2 horas. La aplicación web está configurada para usar un registro de Amazon Route 53 para dirigir el tráfico a la base de datos. ¿Qué combinación de pasos resultará en una arquitectura altamente disponible que cumpla con todos los requisitos? (Elija dos).",
        "opciones": [
            "A. Crear una réplica de lectura entre regiones de la base de datos en la Región secundaria. Configurar una función de AWS Lambda en la Región secundaria para promover la réplica de lectura durante un evento de conmutación por error (failover).",
            "B. En la Región primaria, crear un chequeo de estado (health check) sobre la base de datos que invoque una función de AWS Lambda cuando se detecte una falla. Programar la función Lambda para recrear la base de datos a partir del último snapshot en la Región secundaria y actualizar los registros de Route 53 para la base de datos.",
            "C. Crear una función de AWS Lambda para copiar la última copia de seguridad automatizada a la Región secundaria cada 2 horas.",
            "D. Crear una política de enrutamiento de failover en Route 53 para el registro DNS de la base de datos. Configurar los endpoints primario y secundario en cada Región.",
            "E. Crear una base de datos en espera activa (hot standby) en la Región secundaria. Usar una función de AWS Lambda para restaurar la base de datos secundaria a la última copia de seguridad automática de RDS en caso de que falle la base de datos primaria."
        ],
        "respuestas_correctas": [
            "D",
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "473.- Una empresa de comercio electrónico ejecuta una aplicación en AWS. La aplicación tiene una API de Amazon API Gateway que invoca una función de AWS Lambda. Los datos se almacenan en una instancia de Amazon RDS for PostgreSQL. Durante la venta relámpago más reciente de la empresa, un aumento repentino en las llamadas a la API afectó negativamente el rendimiento de la aplicación. Un arquitecto de soluciones revisó las métricas de Amazon CloudWatch durante ese período y notó un aumento significativo en las invocaciones de Lambda y en las conexiones a la base de datos. Además, la utilización de la CPU en la instancia de la base de datos era alta. ¿Qué debería recomendar el arquitecto de soluciones para optimizar el rendimiento de la aplicación?",
        "opciones": [
            "A. Aumentar la memoria de la función Lambda. Modificar la función Lambda para cerrar las conexiones a la base de datos cuando los datos sean recuperados.",
            "B. Agregar un clúster de Amazon ElastiCache for Redis para almacenar en caché los datos más frecuentemente accedidos de la base de datos RDS.",
            "C. Crear un RDS Proxy mediante la consola de Lambda. Modificar la función Lambda para usar el endpoint del proxy.",
            "D. Modificar la función Lambda para conectarse a la base de datos fuera del manejador de la función. Verificar si ya existe una conexión a la base de datos antes de crear una nueva conexión."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "474.- Una empresa de retail quiere mejorar la arquitectura de su aplicación. Las aplicaciones de la empresa registran nuevos pedidos, gestionan devoluciones de mercancía y proporcionan análisis. Las aplicaciones almacenan datos en una base de datos MySQL para retail y en una base de datos de Oracle OLAP para análisis. Todas las aplicaciones y bases de datos están alojadas en instancias de Amazon EC2. Cada aplicación consta de varios componentes que manejan diferentes partes del proceso de pedidos. Estos componentes reciben datos de varias fuentes. Un trabajo de ETL separado se ejecuta cada semana y copia los datos de cada aplicación a la base de datos de análisis. Un arquitecto de soluciones debe rediseñar la arquitectura en una solución basada en eventos y sin servidores (serverless). La solución debe proporcionar análisis en tiempo casi real. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Migrar las aplicaciones individuales como microservicios en Amazon Elastic Container Service (Amazon ECS) con AWS Fargate. Mantener la base de datos MySQL de retail en Amazon EC2. Mover la base de datos de análisis a Amazon Neptune. Usar Amazon Simple Queue Service (Amazon SQS) para enviar todos los datos entrantes a los microservicios y a la base de datos de análisis.",
            "B. Crear un Auto Scaling Group para cada aplicación. Especificar el número necesario de instancias de EC2 en cada Auto Scaling Group. Migrar la base de datos MySQL de retail y la base de datos de análisis a Amazon Aurora MySQL. Usar Amazon Simple Notification Service (Amazon SNS) para enviar todos los datos entrantes a las instancias EC2 correctas y a la base de datos de análisis.",
            "C. Migrar las aplicaciones individuales como microservicios en Amazon Elastic Kubernetes Service (Amazon EKS) con AWS Fargate. Migrar la base de datos MySQL de retail a Amazon Aurora Serverless MySQL. Migrar la base de datos de análisis a Amazon Redshift Serverless. Usar Amazon EventBridge para enviar todos los datos entrantes a los microservicios y a la base de datos de análisis.",
            "D. Migrar las aplicaciones individuales como microservicios en Amazon AppStream 2.0. Migrar la base de datos MySQL de retail a Amazon Aurora MySQL. Migrar la base de datos de análisis a Amazon Redshift Serverless. Usar AWS IoT Core para enviar todos los datos entrantes a los microservicios y a la base de datos de análisis."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "475.- Una empresa está planificando una migración desde un centro de datos local a la nube de AWS. La empresa planea utilizar múltiples cuentas de AWS que serán administradas dentro de una organización en AWS Organizations. Inicialmente, la empresa creará un pequeño número de cuentas y agregará más cuentas según sea necesario. Un arquitecto de soluciones debe diseñar una solución que habilite AWS CloudTrail en todas las cuentas de AWS. ¿Cuál es la solución más eficiente operativamente que cumple con estos requisitos?",
        "opciones": [
            "A. Crear una función de AWS Lambda que cree un nuevo trail de CloudTrail en todas las cuentas de AWS dentro de la organización. Invocar la función Lambda diariamente utilizando una acción programada en Amazon EventBridge.",
            "B. Crear un nuevo trail de CloudTrail en la cuenta de administración de la organización. Configurar el trail para registrar todos los eventos de todas las cuentas de AWS dentro de la organización.",
            "C. Crear un nuevo trail de CloudTrail en todas las cuentas de AWS dentro de la organización. Crear nuevos trails cada vez que se agregue una nueva cuenta. Definir una política de control de servicios (SCP) que impida la eliminación o modificación de los trails. Aplicar la SCP a la unidad organizativa (OU) raíz.",
            "D. Crear un runbook de AWS Systems Manager Automation que cree un trail de CloudTrail en todas las cuentas de AWS dentro de la organización. Invocar la automatización utilizando Systems Manager State Manager."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "476.- Una empresa de desarrollo de software tiene varios ingenieros que trabajan de forma remota. La empresa ejecuta Active Directory Domain Services (AD DS) en una instancia de Amazon EC2. La política de seguridad de la empresa establece que todos los servicios internos y no públicos desplegados en una VPC deben ser accesibles a través de una VPN. Además, el acceso a la VPN debe requerir autenticación multifactor (MFA). ¿Qué debe hacer un arquitecto de soluciones para cumplir con estos requisitos?",
        "opciones": [
            "A. Crear una conexión AWS Site-to-Site VPN. Configurar la integración entre la VPN y AD DS. Usar un cliente de Amazon WorkSpaces con soporte para MFA habilitado para establecer una conexión VPN.",
            "B. Crear un AWS Client VPN endpoint. Crear un AD Connector para la integración con AD DS. Habilitar MFA en AD Connector. Usar AWS Client VPN para establecer una conexión VPN.",
            "C. Crear múltiples conexiones AWS Site-to-Site VPN usando AWS VPN CloudHub. Configurar la integración entre AWS VPN CloudHub y AD DS. Usar AWS Copilot para establecer una conexión VPN.",
            "D. Crear un Amazon WorkLink endpoint. Configurar la integración entre Amazon WorkLink y AD DS. Habilitar MFA en Amazon WorkLink. Usar AWS Client VPN para establecer una conexión VPN."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "477.- Una empresa ejecuta una aplicación web de tres capas en un centro de datos local. El frontend es servido por un servidor web Apache, la capa intermedia es una aplicación monolítica en Java y la capa de almacenamiento es una base de datos PostgreSQL. Durante una promoción de marketing reciente, los clientes no pudieron realizar pedidos a través de la aplicación porque esta se bloqueó. Un análisis mostró que las tres capas estaban sobrecargadas. La aplicación se volvió no responsiva y la base de datos alcanzó su límite de capacidad debido a las operaciones de lectura. La empresa ya tiene varias promociones similares programadas en el futuro cercano. Un arquitecto de soluciones debe desarrollar un plan de migración a AWS para resolver estos problemas. La solución debe maximizar la escalabilidad y minimizar el esfuerzo operativo. ¿Qué combinación de pasos cumplirá con estos requisitos? (Elija tres.)",
        "opciones": [
            "A. Refactorizar el frontend para que los activos estáticos puedan alojarse en Amazon S3. Usar Amazon CloudFront para servir el frontend a los clientes. Conectar el frontend con la aplicación Java.",
            "B. Rehospedar el servidor web Apache del frontend en instancias de Amazon EC2 dentro de un grupo de Auto Scaling. Usar un balanceador de carga frente al grupo de Auto Scaling. Usar Amazon Elastic File System (Amazon EFS) para alojar los activos estáticos que el servidor Apache necesita.",
            "C. Rehospedar la aplicación Java en un entorno de AWS Elastic Beanstalk que incluya autoescalado.",
            "D. Refactorizar la aplicación Java. Desarrollar un contenedor Docker para ejecutar la aplicación Java. Usar AWS Fargate para alojar el contenedor.",
            "E. Usar AWS Database Migration Service (AWS DMS) para replataformar la base de datos PostgreSQL en Amazon Aurora PostgreSQL. Usar Aurora Auto Scaling para las réplicas de lectura.",
            "F. Rehospedar la base de datos PostgreSQL en una instancia de Amazon EC2 con el doble de memoria que el servidor local."
        ],
        "respuestas_correctas": [
            "C",
            "E",
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "478.- Una empresa está implementando una nueva aplicación en AWS. La aplicación consta de un clúster de Amazon Elastic Kubernetes Service (Amazon EKS) y un repositorio de Amazon Elastic Container Registry (Amazon ECR). El clúster de EKS tiene un grupo de nodos administrado por AWS. Las directrices de seguridad de la empresa establecen que todos los recursos en AWS deben ser escaneados continuamente en busca de vulnerabilidades de seguridad. ¿Qué solución cumplirá con este requisito con el MENOR esfuerzo operativo?",
        "opciones": [
            "A. Activar AWS Security Hub. Configurar Security Hub para escanear los nodos de EKS y el repositorio de ECR.",
            "B. Activar Amazon Inspector para escanear los nodos de EKS y el repositorio de ECR.",
            "C. Lanzar una nueva instancia de Amazon EC2 e instalar una herramienta de escaneo de vulnerabilidades desde AWS Marketplace. Configurar la instancia de EC2 para escanear los nodos de EKS. Configurar Amazon ECR para realizar un escaneo básico al subir imágenes.",
            "D. Instalar el agente de Amazon CloudWatch en los nodos de EKS. Configurar el agente de CloudWatch para escanear continuamente. Configurar Amazon ECR para realizar un escaneo básico al subir imágenes."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "479.- Una empresa necesita mejorar la confiabilidad de su aplicación de venta de boletos. La aplicación se ejecuta en un clúster de Amazon Elastic Container Service (Amazon ECS). La empresa usa Amazon CloudFront para servir la aplicación. Un único servicio de ECS en el clúster actúa como el origen de la distribución de CloudFront. La aplicación permite que solo un número específico de usuarios activos ingresen al flujo de compra de boletos. Estos usuarios son identificados por un atributo cifrado en su JSON Web Token (JWT). Todos los demás usuarios son redirigidos a un módulo de sala de espera hasta que haya capacidad disponible para la compra. La aplicación está experimentando altas cargas. El módulo de la sala de espera está funcionando según lo diseñado, pero la carga en la sala de espera está afectando la disponibilidad de la aplicación. Esta interrupción está impactando negativamente en las transacciones de venta de boletos. ¿Qué solución proporcionará la MAYOR confiabilidad para las transacciones de venta de boletos durante períodos de alta carga?",
        "opciones": [
            "A. Crear un servicio separado en el clúster de ECS para la sala de espera. Usar una configuración de escalado independiente. Asegurar que el servicio de venta de boletos use la información del JWT y reenvíe las solicitudes al servicio de sala de espera según corresponda.",
            "B. Mover la aplicación a un clúster de Amazon Elastic Kubernetes Service (Amazon EKS). Dividir el módulo de la sala de espera en un pod separado del pod de venta de boletos. Hacer que el pod de venta de boletos sea parte de un StatefulSet. Asegurar que el pod de venta de boletos use la información del JWT y reenvíe las solicitudes al pod de la sala de espera según corresponda.",
            "C. Crear un servicio separado en el clúster de ECS para la sala de espera. Usar una configuración de escalado independiente. Crear una función de CloudFront que inspeccione la información del JWT y redirija adecuadamente las solicitudes al servicio de venta de boletos o al servicio de sala de espera.",
            "D. Mover la aplicación a un clúster de Amazon Elastic Kubernetes Service (Amazon EKS). Dividir el módulo de la sala de espera en un pod separado del pod de venta de boletos. Usar AWS App Mesh aprovisionando el App Mesh controller para Kubernetes. Habilitar autenticación mTLS y autenticación servicio a servicio para la comunicación entre el pod de venta de boletos y el pod de la sala de espera. Asegurar que el pod de venta de boletos use la información del JWT y reenvíe las solicitudes al pod de la sala de espera según corresponda."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "480.- Un arquitecto de soluciones está creando una plantilla de AWS CloudFormation a partir de un entorno de AWS no productivo que se creó manualmente. La plantilla de CloudFormation puede ser destruida y recreada según sea necesario. El entorno contiene una instancia de Amazon EC2. La instancia de EC2 tiene un perfil de instancia que la instancia usa para asumir un rol en una cuenta principal. El arquitecto de soluciones recrea el rol en una plantilla de CloudFormation y usa el mismo nombre de rol. Cuando la plantilla de CloudFormation se lanza en la cuenta secundaria, la instancia de EC2 ya no puede asumir el rol en la cuenta principal debido a permisos insuficientes. ¿Qué debe hacer el arquitecto de soluciones para resolver este problema?",
        "opciones": [
            "A. En la cuenta principal, editar la política de confianza del rol que la instancia de EC2 necesita asumir. Asegurarse de que el ARN del rol de destino en la declaración existente que permite la acción sts:AssumeRole sea correcto. Guardar la política de confianza.",
            "B. En la cuenta principal, editar la política de confianza del rol que la instancia de EC2 necesita asumir. Agregar una declaración que permita la acción sts:AssumeRole para el principio raíz de la cuenta secundaria. Guardar la política de confianza.",
            "C. Actualizar la pila de CloudFormation nuevamente. Especificar solo la capacidad CAPABILITY_NAMED_IAM.",
            "D. Actualizar la pila de CloudFormation nuevamente. Especificar las capacidades CAPABILITY_IAM y CAPABILITY_NAMED_IAM"
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "481.- Una empresa tiene problemas de confiabilidad con su aplicación web. La aplicación atiende a clientes a nivel global y se ejecuta en una única instancia de Amazon EC2, realizando operaciones intensivas de lectura en una base de datos Amazon RDS for MySQL. Durante períodos de alta carga, la aplicación se vuelve no receptiva y requiere un reinicio manual de la instancia de EC2. Un arquitecto de soluciones debe mejorar la confiabilidad de la aplicación. ¿Qué solución cumplirá con este requisito con el menor esfuerzo de desarrollo?",
        "opciones": [
            "A. Crear una distribución de Amazon CloudFront. Especificar la instancia de EC2 como el origen de la distribución. Configurar una implementación Multi-AZ para la base de datos RDS for MySQL. Usar la instancia en espera de la base de datos para las operaciones intensivas de lectura.",
            "B. Ejecutar la aplicación en instancias EC2 dentro de un grupo de Auto Scaling. Colocar las instancias EC2 detrás de un balanceador de carga ELB (Elastic Load Balancer). Reemplazar el servicio de base de datos con Amazon Aurora. Usar Aurora Replicas para las operaciones intensivas de lectura.",
            "C. Implementar AWS Global Accelerator. Configurar una implementación Multi-AZ para la base de datos RDS for MySQL. Usar la instancia en espera de la base de datos para las operaciones intensivas de lectura.",
            "D. Migrar la aplicación a funciones AWS Lambda. Crear réplicas de lectura para la base de datos RDS for MySQL. Usar las réplicas de lectura para las operaciones intensivas de lectura."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "482.- Una empresa necesita utilizar un servidor habilitado para SFTP de AWS Transfer Family con un bucket de Amazon S3 para recibir actualizaciones de un proveedor de datos externo. Los datos están cifrados con Pretty Good Privacy (PGP). La empresa necesita una solución que descifre automáticamente los datos después de recibirlos. Un arquitecto de soluciones utilizará un flujo de trabajo gestionado por Transfer Family. La empresa ha creado un rol de servicio de IAM con una política de IAM que permite el acceso a AWS Secrets Manager y al bucket de S3. La relación de confianza del rol permite que el servicio transfer.amazonaws.com asuma el rol. ¿Qué debe hacer el arquitecto de soluciones a continuación para completar la solución de descifrado automático?",
        "opciones": [
            "A. Almacenar la clave pública PGP en Secrets Manager. Agregar un paso nominal en el flujo de trabajo gestionado por Transfer Family para descifrar archivos. Configurar los parámetros de cifrado PGP en el paso nominal. Asociar el flujo de trabajo con el servidor de Transfer Family.",
            "B. Almacenar la clave privada PGP en Secrets Manager. Agregar un paso de manejo de excepciones en el flujo de trabajo gestionado por Transfer Family para descifrar archivos. Configurar los parámetros de cifrado PGP en el manejador de excepciones. Asociar el flujo de trabajo con el usuario SFTP.",
            "C. Almacenar la clave privada PGP en Secrets Manager. Agregar un paso nominal en el flujo de trabajo gestionado por Transfer Family para descifrar archivos. Configurar los parámetros de descifrado PGP en el paso nominal. Asociar el flujo de trabajo con el servidor de Transfer Family.",
            "D. Almacenar la clave pública PGP en Secrets Manager. Agregar un paso de manejo de excepciones en el flujo de trabajo gestionado por Transfer Family para descifrar archivos. Configurar los parámetros de descifrado PGP en el manejador de excepciones. Asociar el flujo de trabajo con el usuario SFTP."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "483.- Una empresa está migrando la infraestructura de su juego multijugador masivo a AWS. La aplicación del juego incluye una tabla de clasificación donde los jugadores pueden ver las clasificaciones en tiempo real. La tabla de clasificación requiere lecturas en microsegundos y latencias de escritura de un solo dígito de milisegundo. Los conjuntos de datos son de un solo dígito de terabytes en tamaño y deben estar disponibles para aceptar escrituras en menos de un minuto si ocurre una falla del nodo primario. La empresa necesita una solución en la que los datos puedan persistir para un procesamiento analítico posterior a través de una canalización de datos. ¿Qué solución cumplirá con estos requisitos con la MENOR sobrecarga operativa?",
        "opciones": [
            "B. Crear una base de datos Amazon ROS con una réplica de lectura. Configurar la aplicación para que apunte las escrituras al endpoint de escritura. Configurar la aplicación para que apunte las lecturas al endpoint de lectura.",
            "C. Crear un clúster de Amazon MemoryDB para Redis en modo Multi-AZ. Configurar la aplicación para que interactúe con el nodo primario.",
            "D. Crear múltiples nodos de Redis en instancias de Amazon EC2 que estén distribuidas en múltiples Zonas de disponibilidad. Configurar copias de seguridad en Amazon S3."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "484.- Una empresa está ejecutando varias aplicaciones en la nube de AWS. Las aplicaciones son específicas para diferentes unidades de negocio dentro de la empresa. La empresa está ejecutando los componentes de las aplicaciones en varias cuentas de AWS que forman parte de una organización en AWS Organizations. Cada recurso en la nube dentro de la organización de la empresa tiene una etiqueta (tag) llamada BusinessUnit, y cada etiqueta ya tiene el valor correspondiente al nombre de la unidad de negocio. La empresa necesita asignar los costos de la nube a diferentes unidades de negocio. También necesita visualizar los costos de la nube para cada unidad de negocio. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. En la cuenta de administración de la organización, crear una etiqueta de asignación de costos llamada BusinessUnit. También en la cuenta de administración, crear un bucket de Amazon S3 y un AWS Cost and Usage Report (AWS CUR). Configurar el bucket de S3 como el destino del AWS CUR. Desde la cuenta de administración, consultar los datos del AWS CUR utilizando Amazon Athena. Usar Amazon QuickSight para la visualización.",
            "B. En cada cuenta miembro, crear una etiqueta de asignación de costos llamada BusinessUnit. En la cuenta de administración de la organización, crear un bucket de Amazon S3 y un AWS Cost and Usage Report (AWS CUR). Configurar el bucket de S3 como el destino del AWS CUR. Crear un panel de control de Amazon CloudWatch para la visualización.",
            "C. En la cuenta de administración de la organización, crear una etiqueta de asignación de costos llamada BusinessUnit. En cada cuenta miembro, crear un bucket de Amazon S3 y un AWS Cost and Usage Report (AWS CUR). Configurar cada bucket de S3 como el destino de su respectivo AWS CUR. En la cuenta de administración, crear un panel de control de Amazon CloudWatch para la visualización.",
            "D. En cada cuenta miembro, crear una etiqueta de asignación de costos llamada BusinessUnit. También en cada cuenta miembro, crear un bucket de Amazon S3 y un AWS Cost and Usage Report (AWS CUR). Configurar cada bucket de S3 como el destino de su respectivo AWS CUR. Desde la cuenta de administración, consultar los datos del AWS CUR utilizando Amazon Athena. Usar Amazon QuickSight para la visualización."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "485.- Una empresa de servicios públicos quiere recopilar datos de uso cada 5 minutos desde sus medidores inteligentes para facilitar la medición por tiempo de uso. Cuando un medidor envía datos a AWS, los datos se envían a Amazon API Gateway, son procesados por una función de AWS Lambda y almacenados en una tabla de Amazon DynamoDB. Durante la fase piloto, las funciones Lambda tardaban de 3 a 5 segundos en completarse. A medida que se despliegan más medidores inteligentes, los ingenieros notan que las funciones Lambda tardan de 1 a 2 minutos en completarse. Además, la duración de las funciones aumenta a medida que se recopilan nuevos tipos de métricas de los dispositivos. También hay muchos errores ProvisionedThroughputExceededException al realizar operaciones PUT en DynamoDB y muchos errores TooManyRequestsException en Lambda. ¿Qué combinación de cambios resolverá estos problemas? (Elija dos.)",
        "opciones": [
            "A. Aumentar las unidades de capacidad de escritura en la tabla de DynamoDB.",
            "B. Aumentar la memoria disponible para las funciones Lambda.",
            "C. Aumentar el tamaño de carga útil desde los medidores inteligentes para enviar más datos.",
            "D. Transmitir los datos a un Amazon Kinesis data stream desde API Gateway y procesar los datos en lotes.",
            "E. Recopilar datos en una Amazon SQS FIFO queue, que desencadene una función Lambda para procesar cada mensaje."
        ],
        "respuestas_correctas": [
            "D",
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "486.- Una empresa ha completado recientemente una prueba de concepto exitosa de Amazon WorkSpaces. Un arquitecto de soluciones necesita hacer que la solución sea altamente disponible en dos Regiones de AWS. Amazon WorkSpaces está implementado en una Región de conmutación por error (failover) y una zona hospedada está implementada en Amazon Route 53. ¿Qué debe hacer el arquitecto de soluciones para configurar la alta disponibilidad de la solución?",
        "opciones": [
            "A. Crear un alias de conexión en la Región primaria y en la Región de conmutación por error. Asociar los alias de conexión con un directorio en cada Región. Crear una política de enrutamiento de conmutación por error en Route 53. Configurar Evaluate Target Health en Yes.",
            "B. Crear un alias de conexión en la Región primaria y en la Región de conmutación por error. Asociar los alias de conexión con un directorio en la Región primaria. Crear una política de enrutamiento de multivalue answer en Route 53.",
            "C. Crear un alias de conexión en la Región primaria. Asociar el alias de conexión con un directorio en la Región primaria. Crear una política de enrutamiento ponderado (weighted) en Route 53.",
            "D. Crear un alias de conexión en la Región primaria. Asociar el alias de conexión con un directorio en la Región de conmutación por error. Crear una política de enrutamiento de conmutación por error en Route 53. Configurar Evaluate Target Health en Yes."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "487.- Una empresa planea migrar muchas máquinas virtuales (VM) desde un entorno local a AWS. La empresa requiere una evaluación inicial del entorno local antes de la migración, una visualización de las dependencias entre las aplicaciones que se ejecutan en las VM y un informe que proporcione una evaluación del entorno local. Para obtener esta información, la empresa ha iniciado una solicitud de evaluación de Migration Evaluator. La empresa puede instalar software de recopilación en su entorno local sin restricciones. ¿Qué solución proporcionará a la empresa la información requerida con el MENOR esfuerzo operativo?",
        "opciones": [
            "A. Instalar el AWS Application Discovery Agent en cada VM local. Después de que finalice el período de recopilación de datos, usar AWS Migration Hub para ver las dependencias de las aplicaciones. Descargar el informe de evaluación Quick Insights desde Migration Hub.",
            "B. Instalar el Migration Evaluator Collector en cada VM local. Después de que finalice el período de recopilación de datos, usar Migration Evaluator para ver las dependencias de las aplicaciones. Descargar y exportar la lista de servidores descubiertos desde Migration Evaluator. Subir la lista a Amazon QuickSight. Cuando se genere el informe en QuickSight, descargar el informe de evaluación Quick Insights.",
            "C. Configurar el AWS Application Discovery Service Agentless Collector en el entorno local. Después de que finalice el período de recopilación de datos, usar AWS Migration Hub para ver las dependencias de las aplicaciones. Exportar la lista de servidores descubiertos desde Application Discovery Service. Subir la lista a Migration Evaluator. Cuando se genere el informe en Migration Evaluator, descargar el informe de evaluación Quick Insights.",
            "D. Configurar el Migration Evaluator Collector en el entorno local. Instalar el AWS Application Discovery Agent en cada VM. Después de que finalice el período de recopilación de datos, usar AWS Migration Hub para ver las dependencias de las aplicaciones. Descargar el informe de evaluación Quick Insights desde Migration Evaluator."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "488.- Una empresa aloja su API principal en AWS mediante un Amazon API Gateway y funciones de AWS Lambda que contienen la lógica para los métodos de la API. Las aplicaciones internas de la empresa utilizan la API para funcionalidades clave y lógica empresarial. Los clientes de la empresa utilizan la API para acceder a los datos de sus cuentas. Varios clientes también tienen acceso a una API heredada que se ejecuta en una sola instancia de Amazon EC2. La empresa quiere aumentar la seguridad de estas APIs para prevenir mejor los ataques de denegación de servicio (DoS), verificar vulnerabilidades y protegerse contra exploits comunes. ¿Qué debería hacer un arquitecto de soluciones para cumplir con estos requisitos?",
        "opciones": [
            "A. Usar AWS WAF para proteger ambas APIs. Configurar Amazon Inspector para analizar la API heredada. Configurar Amazon GuardDuty para monitorear intentos maliciosos de acceso a las APIs.",
            "B. Usar AWS WAF para proteger la API de API Gateway. Configurar Amazon Inspector para analizar ambas APIs. Configurar Amazon GuardDuty para bloquear intentos maliciosos de acceso a las APIs.",
            "C. Usar AWS WAF para proteger la API de API Gateway. Configurar Amazon Inspector para analizar la API heredada. Configurar Amazon GuardDuty para monitorear intentos maliciosos de acceso a las APIs.",
            "D. Usar AWS WAF para proteger la API de API Gateway. Configurar Amazon Inspector para proteger la API heredada. Configurar Amazon GuardDuty para bloquear intentos maliciosos de acceso a las APIs."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "489.- Una empresa está ejecutando una aplicación de comercio electrónico sin servidor en AWS. La aplicación usa Amazon API Gateway para invocar funciones AWS Lambda en Java. Las funciones Lambda se conectan a una base de datos Amazon RDS for MySQL para almacenar datos. Durante un evento de ventas reciente, un aumento repentino en el tráfico web resultó en bajo rendimiento de la API y fallos en la conexión con la base de datos. La empresa necesita implementar una solución para minimizar la latencia de las funciones Lambda y soportar picos de tráfico. ¿Qué solución cumplirá con estos requisitos con el MENOR número de cambios en la aplicación?",
        "opciones": [
            "A. Actualizar el código de las funciones Lambda para que abran la conexión a la base de datos fuera del manejador de la función. Aumentar la concurrencia aprovisionada para las funciones Lambda.",
            "B. Crear un endpoint de RDS Proxy para la base de datos. Almacenar las credenciales de la base de datos en AWS Secrets Manager. Configurar los permisos de IAM requeridos. Actualizar las funciones Lambda para conectarse al endpoint de RDS Proxy. Aumentar la concurrencia aprovisionada para las funciones Lambda.",
            "C. Crear un grupo de parámetros personalizado. Aumentar el valor del parámetro max_connections. Asociar el grupo de parámetros personalizado con la instancia de RDS y programar un reinicio. Aumentar la concurrencia reservada para las funciones Lambda.",
            "D. Crear un endpoint de RDS Proxy para la base de datos. Almacenar las credenciales de la base de datos en AWS Secrets Manager. Configurar los permisos de IAM requeridos. Actualizar las funciones Lambda para conectarse al endpoint de RDS Proxy. Aumentar la concurrencia reservada para las funciones Lambda."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "490.- Una empresa requiere que toda la conectividad de las aplicaciones internas use direcciones IP privadas. Para facilitar esta política, un arquitecto de soluciones ha creado endpoints de interfaz para conectarse a los servicios públicos de AWS. Durante las pruebas, el arquitecto de soluciones nota que los nombres de los servicios están resolviendo direcciones IP públicas y que los servicios internos no pueden conectarse a los endpoints de interfaz. ¿Qué paso debe tomar el arquitecto de soluciones para resolver este problema?",
        "opciones": [
            "A. Actualizar la tabla de rutas de la subred con una ruta hacia el endpoint de interfaz.",
            "B. Habilitar la opción de DNS privado en los atributos de la VPC.",
            "C. Configurar el grupo de seguridad en el endpoint de interfaz para permitir la conectividad a los servicios de AWS.",
            "D. Configurar una zona alojada privada en Amazon Route 53 con un reenviador condicional para la aplicación interna."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "491.- Una empresa está desarrollando una aplicación sensible a la latencia. Parte de la aplicación incluye varias funciones AWS Lambda que necesitan inicializarse lo más rápido posible. Las funciones Lambda están escritas en Java y contienen código de inicialización fuera de los handlers, incluyendo la carga de bibliotecas, inicialización de clases y generación de identificadores únicos. ¿Qué solución cumplirá con el requisito de rendimiento en el arranque de la manera más rentable?",
        "opciones": [
            "A. Mover todo el código de inicialización a los handlers de cada función Lambda. Activar Lambda SnapStart para cada función Lambda. Configurar SnapStart para hacer referencia a la versión $LATEST de cada función Lambda.",
            "B. Publicar una versión de cada función Lambda. Crear un alias para cada función Lambda. Configurar cada alias para apuntar a su versión correspondiente. Configurar concurrencia aprovisionada en cada función Lambda para que apunte al alias correspondiente.",
            "C. Publicar una versión de cada función Lambda. Configurar concurrencia aprovisionada en cada función Lambda para que apunte a la versión correspondiente. Activar Lambda SnapStart para las versiones publicadas de las funciones Lambda.",
            "D. Actualizar las funciones Lambda para agregar un hook de pre-snapshot. Mover el código que genera identificadores únicos dentro de los handlers. Publicar una versión de cada función Lambda. Activar Lambda SnapStart para las versiones publicadas de las funciones Lambda."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "492.- Un arquitecto de soluciones está importando una máquina virtual (VM) desde un entorno local utilizando la función Amazon EC2 VM Import de AWS Import/Export. El arquitecto de soluciones ha creado una AMI y ha aprovisionado una instancia de Amazon EC2 basada en esa AMI. La instancia EC2 se ejecuta dentro de una subred pública en una VPC y tiene una dirección IP pública asignada. La instancia EC2 no aparece como una instancia administrada en la consola de AWS Systems Manager. ¿Qué combinación de pasos debe tomar el arquitecto de soluciones para solucionar este problema? (Elija dos).",
        "opciones": [
            "A. Verificar que el agente de Systems Manager (SSM Agent) esté instalado y en ejecución en la instancia.",
            "B. Verificar que la instancia tenga asignado un rol de IAM adecuado para Systems Manager.",
            "C. Verificar la existencia de un VPC endpoint en la VPC.",
            "D. Verificar que el AWS Application Discovery Agent esté configurado.",
            "E. Verificar la configuración correcta de los roles vinculados al servicio (service-linked roles) para Systems Manager."
        ],
        "respuestas_correctas": [
            "B",
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "493.- Una empresa está utilizando AWS CloudFormation como su herramienta de implementación para todas las aplicaciones. Almacena todas las versiones de los binarios de la aplicación y las plantillas en Amazon S3, con la versión habilitada. Los desarrolladores tienen acceso a una instancia de Amazon EC2 que aloja el entorno de desarrollo integrado (IDE). Los desarrolladores descargan los binarios de la aplicación desde Amazon S3 a la instancia de EC2, realizan cambios y vuelven a cargar los binarios en un bucket de S3 después de ejecutar pruebas unitarias localmente. Los desarrolladores desean mejorar el mecanismo de implementación existente e implementar CI/CD utilizando AWS CodePipeline. Los desarrolladores tienen los siguientes requisitos: Usar AWS CodeCommit para el control de versiones. Automatizar las pruebas unitarias y los escaneos de seguridad. Alertar a los desarrolladores cuando las pruebas unitarias fallen. Habilitar y deshabilitar dinámicamente funciones de la aplicación como parte del proceso de CI/CD. Requerir la aprobación del desarrollador líder antes de desplegar una aplicación. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Usar AWS CodeBuild para ejecutar pruebas unitarias y escaneos de seguridad. Usar una regla de Amazon EventBridge para enviar alertas de Amazon SNS a los desarrolladores cuando las pruebas unitarias fallen. Escribir constructos de AWS Cloud Development Kit (AWS CDK) para diferentes funciones de la solución y usar un archivo de manifiesto para activar y desactivar funciones en la aplicación de AWS CDK. Usar una etapa de aprobación manual en la canalización para permitir que el desarrollador líder apruebe las aplicaciones.",
            "B. Usar AWS Lambda para ejecutar pruebas unitarias y escaneos de seguridad. Usar Lambda en una etapa posterior de la canalización para enviar alertas de Amazon SNS a los desarrolladores cuando las pruebas unitarias fallen. Escribir plugins de AWS Amplify para diferentes funciones de la solución y utilizar solicitudes de usuario para activar y desactivar funciones. Usar Amazon SES en la canalización para permitir que el desarrollador líder apruebe las aplicaciones.",
            "C. Usar Jenkins para ejecutar pruebas unitarias y escaneos de seguridad. Usar una regla de Amazon EventBridge en la canalización para enviar alertas de Amazon SES a los desarrolladores cuando las pruebas unitarias fallen. Usar pilas anidadas de AWS CloudFormation para diferentes funciones de la solución y parámetros para activar y desactivar funciones. Usar AWS Lambda en la canalización para permitir que el desarrollador líder apruebe las aplicaciones.",
            "D. Usar AWS CodeDeploy para ejecutar pruebas unitarias y escaneos de seguridad. Usar una alarma de Amazon CloudWatch en la canalización para enviar alertas de Amazon SNS a los desarrolladores cuando las pruebas unitarias fallen. Usar imágenes de Docker para diferentes funciones de la solución y la AWS CLI para activar y desactivar funciones. Usar una etapa de aprobación manual en la canalización para permitir que el desarrollador líder apruebe las aplicaciones."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "494.- Una empresa global de comercio electrónico tiene muchos centros de datos en todo el mundo. Con el crecimiento de sus datos almacenados, la empresa necesita configurar una solución para proporcionar almacenamiento escalable para aplicaciones heredadas de archivos en sus instalaciones. La empresa debe poder tomar copias en un punto en el tiempo de los volúmenes utilizando AWS Backup y debe mantener un acceso de baja latencia a los datos que se acceden con frecuencia. Además, la empresa necesita tener volúmenes de almacenamiento que puedan montarse como dispositivos iSCSI desde los servidores de aplicaciones locales de la empresa. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Aprovisionar un AWS Storage Gateway tipo tape gateway. Configurar el tape gateway para almacenar datos en un bucket de Amazon S3. Implementar AWS Backup para tomar copias en un punto en el tiempo de los volúmenes.",
            "B. Aprovisionar un Amazon FSx File Gateway y un Amazon S3 File Gateway. Implementar AWS Backup para tomar copias en un punto en el tiempo de los datos.",
            "C. Aprovisionar un AWS Storage Gateway tipo volume gateway en modo caché. Realizar copias de seguridad de los volúmenes de Storage Gateway locales con AWS Backup.",
            "D. Aprovisionar un AWS Storage Gateway tipo file gateway en modo caché. Implementar AWS Backup para tomar copias en un punto en el tiempo de los volúmenes."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "495.- Una empresa tiene una aplicación que utiliza AWS Key Management Service (AWS KMS) para cifrar y descifrar datos. La aplicación almacena datos en un bucket de Amazon S3 en una Región de AWS. Las políticas de seguridad de la empresa requieren que los datos sean cifrados antes de ser almacenados en el bucket de S3. La aplicación debe descifrar los datos cuando los lee desde el bucket de S3. La empresa replica el bucket de S3 a otras Regiones. Un arquitecto de soluciones debe diseñar una solución para que la aplicación pueda cifrar y descifrar datos entre Regiones, utilizando la misma clave en cada Región. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Crear una clave primaria multi-Región de KMS. Usar la clave primaria de KMS para crear una clave réplica multi-Región de KMS en cada Región adicional donde se ejecuta la aplicación. Actualizar el código de la aplicación para utilizar la clave réplica específica en cada Región.",
            "B. Crear una nueva clave administrada por el cliente (CMK) de KMS en cada Región adicional donde se ejecuta la aplicación. Actualizar el código de la aplicación para utilizar la clave KMS específica en cada Región.",
            "C. Usar AWS Private Certificate Authority para crear una nueva autoridad certificadora (CA) en la Región principal. Emitir un certificado privado desde la CA para la URL del sitio web de la aplicación. Compartir la CA con las Regiones adicionales usando AWS Resource Access Manager (AWS RAM). Actualizar el código de la aplicación para utilizar los certificados de la CA compartida en cada Región.",
            "D. Usar AWS Systems Manager Parameter Store para crear un parámetro en cada Región adicional donde se ejecuta la aplicación. Exportar el material de la clave de KMS desde la Región primaria. Almacenar el material de la clave en el parámetro en cada Región. Actualizar el código de la aplicación para utilizar la clave almacenada en cada Región."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "496.- Una empresa aloja una aplicación que utiliza varias instancias de Amazon EC2 en un grupo de Auto Scaling detrás de un Application Load Balancer (ALB). Durante el inicio inicial de las instancias de EC2, estas ejecutan scripts de datos de usuario para descargar contenido crítico para la aplicación desde un bucket de Amazon S3. Las instancias de EC2 se están iniciando correctamente. Sin embargo, después de un tiempo, las instancias de EC2 se terminan con el siguiente mensaje de error: An instance was taken out of service in response to an ELB system health check failure.  Las instancias de EC2 continúan iniciándose y terminándose debido a eventos de Auto Scaling, en un ciclo infinito. El único cambio reciente en la implementación es que la empresa agregó una gran cantidad de contenido crítico al bucket de S3. La empresa no quiere modificar los scripts de datos de usuario en producción. ¿Qué debe hacer un arquitecto de soluciones para que el entorno de producción se implemente correctamente?",
        "opciones": [
            "A. Aumentar el tamaño de las instancias de EC2.",
            "B. Aumentar el tiempo de espera de la verificación de estado para el ALB.",
            "C. Cambiar la ruta de verificación de estado del ALB.",
            "D. Aumentar el período de gracia de la verificación de estado para el grupo de Auto Scaling."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "497.- Una empresa necesita mover algunas bases de datos Oracle locales a AWS. La empresa ha decidido mantener algunas de las bases de datos en sus instalaciones por razones de cumplimiento normativo. Las bases de datos locales contienen datos espaciales y ejecutan trabajos cron para mantenimiento. La empresa necesita conectarse directamente a los sistemas locales desde AWS para consultar los datos como una tabla externa. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Crear tablas globales de Amazon DynamoDB con escalado automático habilitado. Usar AWS Schema Conversion Tool (AWS SCT) y AWS Database Migration Service (AWS DMS) para mover los datos desde las instalaciones a DynamoDB. Crear una función de AWS Lambda para mover los datos espaciales a Amazon S3. Consultar los datos mediante Amazon Athena. Usar Amazon EventBridge para programar trabajos de mantenimiento en DynamoDB. Usar Amazon API Gateway para el soporte de tablas externas.",
            "B. Crear una instancia de base de datos Amazon RDS for Microsoft SQL Server. Usar replicación nativa para mover los datos desde las instalaciones a la instancia de RDS. Usar AWS Schema Conversion Tool (AWS SCT) para modificar el esquema de SQL Server después de la replicación. Mover los datos espaciales a Amazon Redshift. Usar procedimientos almacenados para el mantenimiento del sistema. Crear rastreadores de AWS Glue para conectarse a las bases de datos Oracle locales y soportar tablas externas.",
            "C. Lanzar instancias de Amazon EC2 para alojar las bases de datos Oracle. Colocar las instancias en un grupo de Auto Scaling. Usar AWS Application Migration Service para mover los datos desde las instalaciones a las instancias de EC2 y para la sincronización bidireccional en tiempo real mediante Change Data Capture (CDC). Usar el soporte nativo de datos espaciales de Oracle. Crear una función de AWS Lambda para ejecutar trabajos de mantenimiento como parte de un flujo de trabajo de AWS Step Functions. Crear un Internet Gateway para soportar tablas externas.",
            "D. Crear una instancia de base de datos Amazon RDS for PostgreSQL. Usar AWS Schema Conversion Tool (AWS SCT) y AWS Database Migration Service (AWS DMS) para mover los datos desde las instalaciones a la instancia de RDS. Usar el soporte nativo de datos espaciales de PostgreSQL. Ejecutar trabajos cron en la instancia de base de datos para mantenimiento. Usar AWS Direct Connect para conectar la instancia de RDS con el entorno local y permitir el acceso a tablas externas."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "498.- Una empresa ejecuta una aplicación en Amazon EC2 y AWS Lambda. La aplicación almacena datos temporales en Amazon S3. Los objetos de S3 se eliminan después de 24 horas. La empresa implementa nuevas versiones de la aplicación lanzando pilas de AWS CloudFormation. Las pilas crean los recursos necesarios. Después de validar una nueva versión, la empresa elimina la pila antigua. Recientemente, la eliminación de una pila de desarrollo falló. Un arquitecto de soluciones debe resolver este problema sin realizar cambios arquitectónicos importantes. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Crear una función de AWS Lambda para eliminar objetos de un bucket de S3. Agregar la función Lambda como un recurso personalizado en la pila de CloudFormation con un atributo DependsOn que apunte al recurso del bucket de S3.",
            "B. Modificar la pila de CloudFormation para adjuntar un atributo DeletionPolicy con un valor de Delete al bucket de S3.",
            "C. Actualizar la pila de CloudFormation para agregar un atributo DeletionPolicy con un valor de Snapshot para el recurso del bucket de S3.",
            "D. Actualizar la plantilla de CloudFormation para crear un sistema de archivos Amazon Elastic File System (Amazon EFS) en lugar de Amazon S3 para almacenar archivos temporales. Configurar las funciones Lambda para ejecutarse en la misma VPC que el sistema de archivos EFS."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "499.- Una empresa tiene una aplicación que almacena videos subidos por los usuarios en un bucket de Amazon S3 que utiliza S3 Standard. Los usuarios acceden con frecuencia a los videos durante los primeros 180 días después de la carga. Después de 180 días, el acceso es raro. Tanto usuarios autenticados como anónimos acceden a los videos. La mayoría de los videos tienen un tamaño superior a 100 MB. Los usuarios suelen tener una conectividad deficiente a internet al subir videos, lo que provoca fallos en las cargas. La empresa utiliza cargas multiparte (multipart uploads) para los videos. Un arquitecto de soluciones necesita optimizar los costos de S3 de la aplicación. ¿Qué combinación de acciones cumplirá con estos requisitos? (Elija dos.)",
        "opciones": [
            "A. Configurar el bucket de S3 para que sea un bucket de Requester Pays.",
            "B. Usar S3 Transfer Acceleration para subir los videos al bucket de S3.",
            "C. Crear una configuración de ciclo de vida de S3 para expirar las cargas multiparte incompletas después de 7 días desde su inicio.",
            "D. Crear una configuración de ciclo de vida de S3 para mover los objetos a S3 Glacier Instant Retrieval después de 1 día.",
            "E. Crear una configuración de ciclo de vida de S3 para mover los objetos a S3 Standard-IA después de 180 días."
        ],
        "respuestas_correctas": [
            "E",
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "500.- Una empresa ejecuta una aplicación web de comercio electrónico en AWS. La aplicación web está alojada como un sitio web estático en Amazon S3 con Amazon CloudFront para la entrega de contenido. Una API de Amazon API Gateway invoca funciones de AWS Lambda para manejar solicitudes de usuarios y procesar pedidos. Las funciones Lambda almacenan datos en un clúster de Amazon RDS para MySQL que usa instancias On-Demand. El uso del clúster ha sido constante en los últimos 12 meses. Recientemente, el sitio web ha experimentado intentos de inyección SQL y exploits web. Además, los clientes informan que el tiempo de procesamiento de pedidos ha aumentado durante los períodos de mayor tráfico. Durante estos períodos, las funciones Lambda a menudo experimentan cold starts. A medida que la empresa crece, necesita garantizar la escalabilidad y el acceso de baja latencia durante los picos de tráfico. Además, debe optimizar los costos de la base de datos y agregar protección contra inyección SQL y exploits web. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Configurar las funciones Lambda con un valor de tiempo de espera aumentado durante los períodos de mayor tráfico. Usar RDS Reserved Instances para la base de datos. Usar CloudFront y suscribirse a AWS Shield Advanced para proteger contra inyección SQL y exploits web.",
            "B. Aumentar la memoria de las funciones Lambda. Migrar la base de datos a Amazon Redshift. Integrar Amazon Inspector con CloudFront para proteger contra inyección SQL y exploits web.",
            "C. Usar funciones Lambda con provisioned concurrency para computación durante los períodos de mayor tráfico. Migrar la base de datos a Amazon Aurora Serverless. Usar CloudFront y suscribirse a AWS Shield Advanced para proteger contra inyección SQL y exploits web.",
            "D. Usar funciones Lambda con provisioned concurrency para computación durante los períodos de mayor tráfico. Usar RDS Reserved Instances para la base de datos. Integrar AWS WAF con CloudFront para proteger contra inyección SQL y exploits web."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "501.- Una empresa ejecuta una aplicación web en una única instancia de Amazon EC2. Los usuarios finales experimentan un rendimiento lento de la aplicación durante los momentos de mayor uso, cuando la utilización de la CPU supera constantemente el 95%. Un script de datos de usuario (user data) instala paquetes personalizados requeridos en la instancia EC2. El proceso de lanzamiento de la instancia tarda varios minutos. La empresa está creando un grupo de Auto Scaling con grupos de instancias mixtas, diferentes capacidades de CPU y un límite máximo de capacidad. El grupo de Auto Scaling utilizará una plantilla de lanzamiento para varias opciones de configuración. La empresa necesita reducir la latencia de la aplicación cuando se lancen nuevas instancias durante la escala automática. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Usar una política de escalado predictivo. Usar una política de mantenimiento de instancias para ejecutar el script de datos de usuario. Establecer el tiempo de calentamiento predeterminado de la instancia en 0 segundos.",
            "B. Usar una política de escalado dinámico. Usar ganchos de ciclo de vida (lifecycle hooks) para ejecutar el script de datos de usuario. Establecer el tiempo de calentamiento predeterminado de la instancia en 0 segundos.",
            "C. Usar una política de escalado predictivo. Habilitar pools de calentamiento (warm pools) para el grupo de Auto Scaling. Usar una política de mantenimiento de instancias para ejecutar el script de datos de usuario.",
            "D. Usar una política de escalado dinámico. Habilitar pools de calentamiento (warm pools) para el grupo de Auto Scaling. Usar ganchos de ciclo de vida (lifecycle hooks) para ejecutar el script de datos de usuario."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "502.- Una empresa necesita migrar su conjunto de bases de datos locales a Amazon RDS. Actualmente, la empresa usa una combinación de Microsoft SQL Server, MySQL y Oracle. Algunas de las bases de datos tienen esquemas personalizados y procedimientos almacenados. ¿Qué combinación de pasos debe seguir la empresa para realizar la migración? (Elija dos).",
        "opciones": [
            "A. Usar Migration Evaluator Quick Insights para analizar las bases de datos de origen e identificar los procedimientos almacenados que deben migrarse.",
            "B. Usar AWS Application Migration Service para analizar las bases de datos de origen e identificar los procedimientos almacenados que deben migrarse.",
            "C. Usar la AWS Schema Conversion Tool (AWS SCT) para analizar las bases de datos de origen y detectar los cambios necesarios.",
            "D. Usar AWS Database Migration Service (AWS DMS) para migrar las bases de datos de origen a Amazon RDS.",
            "E. Usar AWS DataSync para migrar los datos de las bases de datos de origen a Amazon RDS."
        ],
        "respuestas_correctas": [
            "D",
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "503.- Una empresa está migrando su plataforma de blogs a AWS. Los servidores locales de la empresa se conectan a AWS a través de una conexión AWS Site-to-Site VPN. El contenido del blog se actualiza varias veces al día por múltiples autores y se sirve desde un recurso compartido de archivos en un servidor NAS (Network-Attached Storage). La empresa necesita migrar la plataforma de blogs sin retrasar las actualizaciones de contenido. Ha implementado instancias de Amazon EC2 en múltiples Zonas de Disponibilidad para ejecutar la plataforma de blogs detrás de un Application Load Balancer. Además, la empresa necesita mover 200 TB de datos archivados desde sus servidores locales a Amazon S3 lo más rápido posible. ¿Qué combinación de pasos cumplirá con estos requisitos? (Elige dos.)",
        "opciones": [
            "A. Crear un trabajo cron semanal en Amazon EventBridge. Usar el trabajo cron para invocar una función de AWS Lambda que actualice las instancias de EC2 desde el servidor NAS.",
            "B. Configurar un volumen Amazon Elastic Block Store (Amazon EBS) Multi-Attach para que las instancias EC2 compartan el acceso al contenido. Escribir código para sincronizar el volumen EBS con el servidor NAS semanalmente.",
            "C. Montar un sistema de archivos Amazon Elastic File System (Amazon EFS) en los servidores locales para que actúe como servidor NAS. Copiar los datos del blog en el sistema de archivos EFS. Montar el sistema de archivos EFS en las instancias EC2 para servir el contenido.",
            "D. Pedir un dispositivo AWS Snowball Edge Storage Optimized. Copiar los archivos de datos estáticos al dispositivo. Enviar el dispositivo a AWS.",
            "E. Pedir un dispositivo AWS Snowcone SSD. Copiar los archivos de datos estáticos al dispositivo. Enviar el dispositivo a AWS."
        ],
        "respuestas_correctas": [
            "D",
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "504.- Una empresa planea migrar una aplicación heredada local a AWS. La aplicación es una aplicación web en Java que se ejecuta en Apache Tomcat con una base de datos PostgreSQL. La empresa no tiene acceso al código fuente, pero puede desplegar archivos JAR de la aplicación. Además, la aplicación experimenta un aumento de tráfico al final de cada mes. ¿Qué solución cumplirá con estos requisitos con el MENOR esfuerzo operativo?",
        "opciones": [
            "A. Lanzar instancias de Amazon EC2 en múltiples Zonas de Disponibilidad. Desplegar Tomcat y PostgreSQL en todas las instancias utilizando puntos de montaje de Amazon Elastic File System (Amazon EFS). Usar AWS Step Functions para desplegar instancias adicionales de EC2 y escalar el tráfico aumentado.",
            "B. Provisionar Amazon Elastic Kubernetes Service (Amazon EKS) en un grupo de Auto Scaling en múltiples Regiones de AWS. Desplegar Tomcat y PostgreSQL en imágenes de contenedor. Usar un Network Load Balancer para escalar el tráfico.",
            "C. Refactorizar la aplicación Java en contenedores basados en Python. Usar AWS Lambda para la lógica de la aplicación. Almacenar los datos en Amazon DynamoDB con tablas globales. Usar AWS Storage Gateway y concurrencia de Lambda para escalar con el tráfico.",
            "D. Usar AWS Elastic Beanstalk para desplegar los servidores Tomcat con autoescalado en múltiples Zonas de Disponibilidad. Almacenar los datos de la aplicación en Amazon RDS para PostgreSQL. Desplegar Amazon CloudFront y un Application Load Balancer para escalar con el tráfico."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "505.- Una empresa está migrando su plataforma IoT on-premises a AWS. La plataforma consta de los siguientes componentes: Un clúster de MongoDB como almacén de datos para todos los datos de IoT recopilados y procesados. Una aplicación que utiliza MQTT para conectarse a los dispositivos IoT cada 5 minutos y recopilar datos. Una aplicación que ejecuta trabajos periódicamente para generar informes a partir de los datos de IoT. Estos trabajos tardan entre 120 y 600 segundos en completarse. Una aplicación web que se ejecuta en un servidor web. Los usuarios finales utilizan la aplicación web para generar informes accesibles al público en general. La empresa necesita migrar la plataforma a AWS para reducir la sobrecarga operativa, manteniendo el rendimiento. ¿Qué combinación de pasos cumplirá con estos requisitos con el MENOR esfuerzo operativo? (Elija tres.)",
        "opciones": [
            "A. Crear máquinas de estado de AWS Step Functions con tareas de AWS Lambda para preparar los informes y escribirlos en Amazon S3. Configurar una distribución de Amazon CloudFront con origen en S3 para servir los informes.",
            "B. Crear una función de AWS Lambda. Programar la función Lambda para conectarse a los dispositivos IoT, procesar los datos y escribirlos en el almacén de datos. Configurar una capa de Lambda para almacenar temporalmente los mensajes para su procesamiento.",
            "C. Configurar un clúster de Amazon Elastic Kubernetes Service (Amazon EKS) con instancias de Amazon EC2 para preparar los informes. Crear un controlador de ingreso (ingress controller) en el clúster de EKS para servir los informes.",
            "D. Conectar los dispositivos IoT a AWS IoT Core para publicar mensajes. Crear una regla de AWS IoT que se active cuando se reciba un mensaje. Configurar la regla para llamar a una función de AWS Lambda. Programar la función Lambda para analizar, transformar y almacenar los datos del mensaje del dispositivo en el almacén de datos.",
            "E. Migrar el clúster de MongoDB a Amazon DocumentDB (con compatibilidad con MongoDB).",
            "F. Migrar el clúster de MongoDB a instancias de Amazon EC2."
        ],
        "respuestas_correctas": [
            "E",
            "D",
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "506.- Una empresa crea una API de Amazon API Gateway y comparte la API con un equipo de desarrollo externo. La API utiliza funciones de AWS Lambda y está desplegada en una etapa llamada Production. El equipo de desarrollo externo es el único consumidor de la API. La API experimenta aumentos repentinos en su uso en momentos específicos, lo que genera preocupación por los costos elevados. La empresa necesita limitar los costos y el uso sin modificar las funciones Lambda. ¿Qué solución cumplirá con estos requisitos de la manera más rentable?",
        "opciones": [
            "A. Configurar la API para enviar solicitudes a Amazon Simple Queue Service (Amazon SQS) en lugar de llamar directamente a las funciones Lambda. Actualizar las funciones Lambda para consumir mensajes de las colas y procesar las solicitudes. Configurar las colas para invocar las funciones Lambda cuando lleguen nuevos mensajes.",
            "B. Configurar provisioned concurrency para cada función Lambda. Usar AWS Application Auto Scaling para registrar las funciones Lambda como objetivos. Configurar escalado programado para aumentar y disminuir la capacidad según los cambios en el uso de la API.",
            "C. Crear una clave de API en API Gateway y una ACL web de AWS WAF Regional. Asociar la ACL web con la etapa Production. Agregar una regla basada en tasa a la ACL web. En la regla, especificar un límite de tasa y una agregación personalizada de solicitudes usando el encabezado X-API-Key. Compartir la clave de API con el equipo de desarrollo externo.",
            "D. Crear una clave de API en API Gateway y un plan de uso. Definir límites de limitación (throttling) y cuotas en el plan de uso. Asociar el plan de uso con la etapa Production y la clave de API. Compartir la clave de API con el equipo de desarrollo externo."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "507.- Una empresa de entretenimiento aloja un servicio de venta de boletos en una flota de instancias Amazon EC2 con Linux que están en un grupo de Auto Scaling. El servicio de venta de boletos usa un archivo de precios almacenado en un bucket de Amazon S3 con almacenamiento S3 Standard. Una solución central de precios, alojada por un tercero, actualiza el archivo de precios. El archivo de precios se actualiza cada 1-15 minutos y contiene varios miles de elementos. El archivo de precios se descarga en cada instancia de EC2 cuando esta se inicia. Ocasionalmente, las instancias de EC2 usan información de precios desactualizada, lo que puede generar cargos incorrectos para los clientes. ¿Qué solución resolverá este problema de la manera MÁS rentable?",
        "opciones": [
            "A. Crear una función de AWS Lambda para actualizar una tabla de Amazon DynamoDB con los nuevos precios cada vez que se actualice el archivo de precios. Modificar el servicio de venta de boletos para consultar DynamoDB en busca de los precios.",
            "B. Crear una función de AWS Lambda para actualizar un compartido de archivos en Amazon Elastic File System (Amazon EFS) cada vez que el archivo de precios sea actualizado. Modificar el servicio de venta de boletos para acceder al archivo de precios en Amazon EFS.",
            "C. Instalar Mountpoint for Amazon S3 en la AMI de las instancias de EC2. Configurar Mountpoint for Amazon S3 para montar el bucket de S3 que contiene el archivo de precios. Modificar el servicio de venta de boletos para acceder al archivo de precios a través del punto de montaje de S3.",
            "D. Crear un volumen de Amazon Elastic Block Store (Amazon EBS). Usar EBS Multi-Attach para adjuntar el volumen a cada instancia de EC2. Configurar las nuevas instancias para actualizar el archivo de precios en el volumen de EBS al iniciar. Modificar el servicio de venta de boletos para usar el archivo de precios desde la fuente local en EBS."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "508.- Una empresa tiene una aplicación que usa instancias de Amazon EC2 en un grupo de Auto Scaling. El departamento de aseguramiento de calidad (QA) necesita lanzar un gran número de entornos de corta duración para probar la aplicación. Actualmente, el gerente del departamento lanza los entornos utilizando una plantilla de AWS CloudFormation. Para lanzar la pila, el gerente usa un rol con permisos para CloudFormation, EC2 y Auto Scaling. Ahora, el gerente quiere permitir que los evaluadores lancen sus propios entornos sin otorgarles permisos amplios. ¿Qué configuración lograría estos objetivos?",
        "opciones": [
            "A. Cargar la plantilla de AWS CloudFormation en Amazon S3. Dar a los usuarios del departamento de QA permisos para asumir el rol del gerente y agregar una política que restrinja los permisos a la plantilla y los recursos que crea. Capacitar a los usuarios para lanzar la plantilla desde la consola de CloudFormation.",
            "B. Crear un producto de AWS Service Catalog a partir de la plantilla del entorno. Agregar una restricción de lanzamiento al producto con el rol existente. Dar a los usuarios del departamento de QA permisos para usar únicamente las APIs de AWS Service Catalog. Capacitar a los usuarios para lanzar la plantilla desde la consola de AWS Service Catalog.",
            "C. Cargar la plantilla de AWS CloudFormation en Amazon S3. Dar a los usuarios del departamento de QA permisos para usar las APIs de CloudFormation y S3, con condiciones que restrinjan los permisos a la plantilla y los recursos que crea. Capacitar a los usuarios para lanzar la plantilla desde la consola de CloudFormation.",
            "D. Crear una aplicación de AWS Elastic Beanstalk a partir de la plantilla del entorno. Dar a los usuarios del departamento de QA permisos solo para Elastic Beanstalk. Capacitar a los usuarios para lanzar entornos de Elastic Beanstalk con la CLI de Elastic Beanstalk, pasando el rol existente al entorno como un rol de servicio."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "509.- Una empresa está utilizando una sola región de AWS para su sitio web de comercio electrónico. El sitio web incluye una aplicación web que se ejecuta en varias instancias de Amazon EC2 detrás de un Application Load Balancer (ALB). También incluye una tabla de Amazon DynamoDB. Un nombre de dominio personalizado en Amazon Route 53 está vinculado al ALB. La empresa creó un certificado SSL/TLS en AWS Certificate Manager (ACM) y lo adjuntó al ALB. Actualmente, la empresa no está utilizando una red de entrega de contenido (CDN) en su diseño. La empresa quiere replicar toda su pila de aplicaciones en una segunda región para proporcionar recuperación ante desastres (DR), planificar el crecimiento futuro y mejorar los tiempos de acceso para los usuarios. Un arquitecto de soluciones necesita implementar una solución que cumpla con estos objetivos minimizando la sobrecarga administrativa. ¿Qué combinación de pasos debe seguir el arquitecto de soluciones para cumplir con estos requisitos? (Elija tres.)",
        "opciones": [
            "A. Crear una plantilla de AWS CloudFormation para el diseño de infraestructura actual. Usar parámetros para valores clave del sistema, incluida la región. Usar la plantilla de CloudFormation para crear la nueva infraestructura en la segunda región.",
            "B. Usar la consola de administración de AWS para documentar el diseño de la infraestructura existente en la primera región y para crear la nueva infraestructura en la segunda región.",
            "C. Actualizar el registro de la zona alojada en Route 53 para la aplicación utilizando enrutamiento ponderado (weighted routing). Enviar 50% del tráfico al ALB en cada región.",
            "D. Actualizar el registro de la zona alojada en Route 53 para la aplicación utilizando enrutamiento basado en latencia (latency-based routing). Enviar tráfico al ALB en cada región.",
            "E. Actualizar la configuración de la tabla existente de DynamoDB habilitando DynamoDB Streams. Agregar la segunda región para crear una tabla global de DynamoDB.",
            "F. Crear una nueva tabla de DynamoDB. Habilitar DynamoDB Streams para la nueva tabla. Agregar la segunda región para crear una tabla global de DynamoDB. Copiar los datos de la tabla existente a la nueva tabla como una operación única."
        ],
        "respuestas_correctas": [
            "E",
            "D",
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "510.- Una empresa quiere crear un único bucket de Amazon S3 para que sus científicos de datos almacenen documentos relacionados con su trabajo. La empresa utiliza AWS IAM Identity Center para autenticar a todos los usuarios y ha creado un grupo para los científicos de datos. La empresa quiere restringir el acceso para que cada científico de datos solo pueda acceder a sus propios documentos. Además, la empresa quiere generar informes mensuales que muestren qué documentos ha accedido cada usuario. ¿Qué combinación de pasos cumplirá con estos requisitos? (Elija dos.)",
        "opciones": [
            "A. Crear un conjunto de permisos personalizado en IAM Identity Center para otorgar a los científicos de datos acceso a un prefijo del bucket de S3 que coincida con su etiqueta de nombre de usuario. Usar una política para limitar el acceso a rutas con la condición ${aws:PrincipalTag/userName}/*.",
            "B. Crear un rol de IAM Identity Center para el grupo de científicos de datos con permisos de lectura y escritura en Amazon S3. Agregar una política de bucket de S3 que permita el acceso a este rol.",
            "C. Configurar AWS CloudTrail para registrar eventos de datos de S3 y enviar los registros a un bucket de S3. Usar Amazon Athena para ejecutar consultas en los registros de CloudTrail y generar informes.",
            "D. Configurar AWS CloudTrail para registrar eventos de gestión de S3 en CloudWatch. Usar el conector de Amazon Athena para CloudWatch para consultar los registros y generar informes.",
            "E. Habilitar S3 Access Logging en EMR File System (EMRFS). Usar Amazon S3 Select para consultar los registros y generar informes."
        ],
        "respuestas_correctas": [
            "C",
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "511.- Una empresa aloja una aplicación de procesamiento de datos en instancias de Amazon EC2. La aplicación consulta un sistema de archivos Amazon Elastic File System (Amazon EFS) en busca de archivos recién subidos. Cuando se detecta un nuevo archivo, la aplicación extrae los datos y ejecuta lógica para seleccionar una imagen de Docker que procesará el archivo. La aplicación inicia la imagen de contenedor correspondiente y pasa la ubicación del archivo como parámetro. El procesamiento de datos dentro del contenedor puede tardar hasta 2 horas. Cuando el procesamiento finaliza, el código dentro del contenedor escribe el archivo nuevamente en Amazon EFS y luego finaliza. La empresa necesita refactorizar la aplicación para eliminar las instancias EC2 que ejecutan los contenedores. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Crear un clúster de Amazon Elastic Container Service (Amazon ECS). Configurar el procesamiento para que se ejecute como tareas de AWS Fargate. Extraer la lógica de selección del contenedor para que se ejecute como una regla de Amazon EventBridge, que iniciará la tarea de Fargate correspondiente. Configurar la regla de EventBridge para que se active cuando se agreguen archivos al sistema de archivos EFS.",
            "B. Crear un clúster de Amazon Elastic Container Service (Amazon ECS). Configurar el procesamiento para que se ejecute como tareas de AWS Fargate. Actualizar y contenerizar la lógica de selección del contenedor para que se ejecute como un servicio de Fargate que inicie la tarea de Fargate correspondiente. Configurar una notificación de eventos de EFS para invocar el servicio de Fargate cuando se agreguen archivos al sistema de archivos EFS.",
            "C. Crear un clúster de Amazon Elastic Container Service (Amazon ECS). Configurar el procesamiento para que se ejecute como tareas de AWS Fargate. Extraer la lógica de selección del contenedor para que se ejecute como una función AWS Lambda que inicie la tarea de Fargate correspondiente. Migrar el almacenamiento de archivos a un bucket de Amazon S3. Actualizar el código de procesamiento para usar Amazon S3. Configurar una notificación de eventos de S3 para invocar la función Lambda cuando se creen objetos en el bucket.",
            "D. Crear imágenes de contenedores de AWS Lambda para el procesamiento. Configurar funciones Lambda para que usen las imágenes de contenedores. Extraer la lógica de selección del contenedor para que se ejecute como una función Lambda de decisión, que invocará la función Lambda de procesamiento correspondiente. Migrar el almacenamiento de archivos a un bucket de Amazon S3. Actualizar el código de procesamiento para usar Amazon S3. Configurar una notificación de eventos de S3 para invocar la función Lambda de decisión cuando se creen objetos en el bucket."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "512.- Una empresa de medios tiene un repositorio de 30 TB de videos de noticias digitales. Estos videos están almacenados en cintas en una biblioteca de cintas local y son referenciados por un sistema de gestión de activos multimedia (MAM). La empresa desea enriquecer los metadatos de estos videos de forma automatizada y organizarlos en un catálogo buscable mediante una función del MAM. La empresa debe poder realizar búsquedas basadas en información dentro del video, como objetos, elementos escénicos o rostros de personas. Un catálogo está disponible con los rostros de las personas que han aparecido en los videos, incluyendo imágenes de cada persona. La empresa desea migrar estos videos a AWS. Tiene una conexión AWS Direct Connect de alta velocidad y quiere mover el contenido de video del MAM directamente desde su sistema de archivos actual. ¿Cómo se pueden cumplir estos requisitos con la menor cantidad de gestión continua y la mínima disrupción al sistema existente?",
        "opciones": [
            "A. Configurar un AWS Storage Gateway con un file gateway appliance on-premises. Usar el MAM para extraer los videos del archivo actual y enviarlos al file gateway. Usar el catálogo de rostros para construir una colección en Amazon Rekognition. Crear una función de AWS Lambda que invoque el SDK de JavaScript de Rekognition para que Rekognition recupere los videos desde Amazon S3, extraiga los metadatos requeridos y los envíe al MAM.",
            "B. Configurar un AWS Storage Gateway con un tape gateway appliance on-premises. Usar el MAM para extraer los videos del archivo actual y enviarlos al tape gateway. Usar el catálogo de rostros para construir una colección en Amazon Rekognition. Crear una función de AWS Lambda que invoque el SDK de JavaScript de Rekognition para que Amazon Rekognition procese el video en el tape gateway, extraiga los metadatos requeridos y los envíe al MAM.",
            "C. Configurar un stream de ingestión de video utilizando Amazon Kinesis Video Streams. Usar el catálogo de rostros para construir una colección en Amazon Rekognition. Transmitir los videos desde el MAM a Kinesis Video Streams. Configurar Amazon Rekognition para procesar los videos transmitidos. Luego, usar un stream consumer para recuperar los metadatos requeridos y enviarlos al MAM. Configurar el stream para almacenar los videos en Amazon S3.",
            "D. Configurar una instancia de Amazon EC2 que ejecute las bibliotecas OpenCV. Copiar los videos, imágenes y el catálogo de rostros desde la biblioteca on-premises a un volumen de Amazon EBS montado en esta instancia EC2. Procesar los videos para extraer los metadatos requeridos y enviarlos al MAM, mientras se copian los archivos de video a un bucket de Amazon S3."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "513.- Una empresa necesita optimizar los costos de un entorno de AWS que contiene múltiples cuentas dentro de una organización en AWS Organizations. La empresa realizó actividades de optimización de costos hace 3 años y adquirió Instancias Reservadas Estándar de Amazon EC2, las cuales han expirado recientemente. La empresa necesita instancias EC2 por 3 años más. Además, ha implementado una nueva carga de trabajo serverless. ¿Qué estrategia proporcionará a la empresa el mayor ahorro de costos?",
        "opciones": [
            "A. Comprar las mismas Instancias Reservadas por un período adicional de 3 años con pago All Upfront. Adquirir un Plan de Ahorro de Cómputo (Compute Savings Plan) de 3 años con pago All Upfront en la cuenta de administración para cubrir cualquier costo adicional de cómputo.",
            "B. Comprar un Plan de Ahorro de Cómputo (Compute Savings Plan) de 1 año con pago No Upfront en cada cuenta miembro. Usar las recomendaciones de Savings Plans en la consola de AWS Cost Management para elegir el Compute Savings Plan.",
            "C. Comprar un Plan de Ahorro de Instancias EC2 (EC2 Instance Savings Plan) de 3 años con pago No Upfront en la cuenta de administración para cubrir los costos de EC2 en cada Región de AWS. Comprar un Plan de Ahorro de Cómputo (Compute Savings Plan) de 3 años con pago No Upfront en la cuenta de administración para cubrir cualquier costo adicional de cómputo.",
            "D. Comprar un Plan de Ahorro de Instancias EC2 (EC2 Instance Savings Plan) de 3 años con pago All Upfront en cada cuenta miembro. Usar las recomendaciones de Savings Plans en la consola de AWS Cost Management para elegir el EC2 Instance Savings Plan."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "514.- Una empresa opera una plataforma de distribución de contenido estático que atiende a clientes a nivel global. Los clientes consumen contenido desde sus propias cuentas de AWS. La empresa sirve su contenido desde un bucket de Amazon S3 y carga el contenido desde su entorno local al bucket de S3 utilizando un S3 File Gateway. La empresa quiere mejorar el rendimiento y la confiabilidad de la plataforma sirviendo contenido desde la Región de AWS más cercana geográficamente a los clientes. Además, la empresa debe enviar los datos desde su infraestructura local a Amazon S3 con la menor latencia posible y sin exponerlos a Internet público. ¿Qué combinación de pasos cumplirá con estos requisitos con el MENOR esfuerzo operativo? (Elija dos)",
        "opciones": [
            "A. Implementar S3 Multi-Region Access Points.",
            "B. Usar S3 Cross-Region Replication (CRR) para copiar contenido a diferentes Regiones.",
            "C. Crear una función de AWS Lambda que rastree la ruta de los clientes hacia las Regiones.",
            "D. Usar una conexión AWS Site-to-Site VPN para conectarse a un Multi-Region Access Point.",
            "E. Usar AWS PrivateLink y AWS Direct Connect para conectarse a un Multi-Region Access Point."
        ],
        "respuestas_correctas": [
            "E",
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "515.- Una empresa está migrando su centro de datos a la nube de AWS y necesita completar la migración lo más rápido posible. La empresa tiene muchas aplicaciones que se ejecutan en cientos de máquinas virtuales (VMs) de VMware en su centro de datos. Cada VM está configurada con una carpeta compartida de Windows que contiene archivos comunes. El tamaño del recurso compartido de archivos es mayor a 100 GB. El equipo de cumplimiento requiere que se presente y apruebe una solicitud de cambio para cada instalación o modificación de software en cada VM. La empresa tiene una conexión de AWS Direct Connect de 10 GB de ancho de banda entre AWS y el centro de datos. ¿Qué conjunto de pasos debería seguir la empresa para completar la migración en el MENOR tiempo posible?",
        "opciones": [
            "A. Usar VM Import/Export para crear imágenes de cada VM. Usar AWS Application Migration Service para administrar y ver las imágenes. Copiar los datos del recurso compartido de archivos de Windows a un sistema de archivos Amazon EFS. Después de la migración, volver a asignar el recurso compartido de archivos al sistema de EFS.",
            "B. Implementar el appliance sin agente de AWS Application Discovery Service en VMware vCenter. Revisar el portafolio de VMs descubiertas en AWS Migration Hub.",
            "C. Implementar el appliance sin agente de AWS Application Migration Service en VMware vCenter. Copiar los datos del recurso compartido de archivos de Windows a un nuevo sistema de archivos Amazon FSx for Windows File Server. Después de la migración, volver a asignar el recurso compartido de archivos en cada VM al sistema de FSx for Windows File Server.",
            "D. Crear y revisar un portafolio en AWS Migration Hub. Ordenar un dispositivo AWS Snowcone. Implementar AWS Application Migration Service en VMware vCenter y exportar todas las VMs al dispositivo Snowcone. Copiar todos los datos del recurso compartido de archivos de Windows al dispositivo Snowcone. Enviar el dispositivo a AWS. Usar Application Migration Service para desplegar todas las instancias migradas.",
            "E. Implementar AWS Application Discovery Service Agent y AWS Application Migration Service Agent en cada hipervisor VMware directamente. Revisar el portafolio en AWS Migration Hub. Copiar los datos del recurso compartido de archivos de cada VM a un nuevo sistema de archivos Amazon FSx for Windows File Server. Después de la migración, volver a asignar el recurso compartido de archivos en cada VM a FSx for Windows File Server."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "516.- Una empresa tiene múltiples cuentas de AWS que forman parte de una organización en AWS Organizations. La empresa necesita almacenar la actividad de las cuentas de AWS y consultar los datos desde una ubicación central utilizando SQL. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Crear un trail de AWS CloudTrail en cada cuenta. Especificar eventos de administración para el trail. Configurar CloudTrail para enviar los eventos a Amazon CloudWatch Logs. Configurar observabilidad entre cuentas en CloudWatch. Consultar los datos en CloudWatch Logs Insights.",
            "B. Usar una cuenta de administrador delegado para crear un almacén de datos en AWS CloudTrail Lake. Especificar eventos de administración de CloudTrail para el almacén de datos. Habilitar el almacén de datos para todas las cuentas en la organización. Consultar los datos en CloudTrail Lake.",
            "C. Usar una cuenta de administrador delegado para crear un trail de AWS CloudTrail. Especificar eventos de administración para el trail. Habilitar el trail para todas las cuentas en la organización. Mantener todas las demás configuraciones por defecto. Consultar los datos de CloudTrail desde la página de historial de eventos de CloudTrail.",
            "D. Usar AWS CloudFormation StackSets para implementar almacenes de datos de AWS CloudTrail Lake en cada cuenta. Especificar eventos de administración de CloudTrail para los almacenes de datos. Mantener todas las demás configuraciones por defecto. Consultar los datos en CloudTrail Lake"
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "517.- Una empresa está utilizando AWS para desarrollar y administrar su aplicación web de producción. La aplicación incluye una API HTTP de Amazon API Gateway que invoca una función de AWS Lambda. La función Lambda procesa los datos y los almacena en una base de datos. La empresa quiere implementar autorización de usuarios en la aplicación web de manera integrada. Ya utiliza un proveedor de identidad (IdP) de terceros que emite tokens OAuth para sus otras aplicaciones. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Integrar el proveedor de identidad de terceros con API Gateway. Configurar un autorizador Lambda en API Gateway para validar los tokens del proveedor de identidad. Requerir el autorizador Lambda en todas las rutas de la API. Actualizar la aplicación web para obtener tokens del proveedor de identidad e incluirlos en el encabezado Authorization al llamar a la API HTTP de API Gateway.",
            "B. Integrar el proveedor de identidad de terceros con AWS Directory Service. Configurar Directory Service como un autorizador en API Gateway para validar los tokens. Requerir Directory Service como autorizador en todas las rutas de la API. Configurar AWS IAM Identity Center como un proveedor de identidad SAML 2.0. Configurar la aplicación web como una aplicación SAML 2.0 personalizada.",
            "C. Integrar el proveedor de identidad de terceros con AWS IAM Identity Center. Configurar API Gateway para usar IAM Identity Center para autenticación y autorización sin configuración adicional. Actualizar la aplicación web para recuperar tokens de AWS STS desde IAM Identity Center e incluirlos en el encabezado Authorization al llamar a la API HTTP de API Gateway.",
            "D. Integrar el proveedor de identidad de terceros con AWS IAM Identity Center. Configurar usuarios de IAM con permisos para llamar a la API HTTP de API Gateway. Actualizar la aplicación web para extraer los parámetros de los usuarios de IAM e incluirlos en el encabezado Authorization al llamar a la API HTTP de API Gateway."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "518.- Una empresa ha implementado aplicaciones en miles de instancias de Amazon EC2 en una cuenta de AWS. Una auditoría de seguridad ha descubierto que varios volúmenes de Amazon Elastic Block Store (Amazon EBS) no están cifrados. La política de seguridad de la empresa requiere que todos los volúmenes de EBS estén cifrados. La empresa necesita implementar una solución automatizada para cifrar los volúmenes de EBS y también debe evitar que los equipos de desarrollo creen volúmenes de EBS sin cifrar. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Configurar la regla administrada de AWS Config que identifica los volúmenes de EBS sin cifrar. Configurar una acción de remediación automática. Asociar un AWS Systems Manager Automation runbook que incluya los pasos para crear un nuevo volumen de EBS cifrado. Crear una clave administrada por el cliente (CMK) de AWS Key Management Service (AWS KMS). En la política de la clave, incluir una declaración para denegar la creación de volúmenes de EBS sin cifrar.",
            "B. Usar AWS Systems Manager Fleet Manager para crear una lista de volúmenes de EBS sin cifrar. Crear un runbook de AWS Systems Manager Automation que incluya los pasos para crear un nuevo volumen de EBS cifrado. Crear una SCP para denegar la creación de volúmenes de EBS sin cifrar.",
            "C. Usar AWS Systems Manager Fleet Manager para crear una lista de volúmenes de EBS sin cifrar. Crear un runbook de AWS Systems Manager Automation que incluya los pasos para crear un nuevo volumen de EBS cifrado. Modificar la configuración de la cuenta de AWS para que siempre cifre los nuevos volúmenes de EBS.",
            "D. Configurar la regla administrada de AWS Config que identifica los volúmenes de EBS sin cifrar. Configurar una acción de remediación automática. Asociar un runbook de AWS Systems Manager Automation que incluya los pasos para crear un nuevo volumen de EBS cifrado. Modificar la configuración de la cuenta de AWS para que siempre cifre los nuevos volúmenes de EBS."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "519.- Una empresa está ejecutando una gran carga de trabajo contenedorizada en la nube de AWS. La carga de trabajo consta de aproximadamente 100 servicios diferentes. La empresa usa Amazon Elastic Container Service (Amazon ECS) para orquestar la carga de trabajo. Recientemente, el equipo de desarrollo de la empresa comenzó a usar AWS Fargate en lugar de instancias de Amazon EC2 en el clúster de ECS. En el pasado, la carga de trabajo ha estado cerca de alcanzar el número máximo de instancias de EC2 disponibles en la cuenta. La empresa está preocupada de que la carga de trabajo pueda alcanzar el número máximo de tareas de ECS permitidas. Un arquitecto de soluciones debe implementar una solución que notifique al equipo de desarrollo cuando Fargate alcance el 80% del número máximo de tareas permitidas. ¿Qué debe hacer el arquitecto de soluciones para cumplir con este requisito?",
        "opciones": [
            "A. Usar Amazon CloudWatch para monitorear la estadística Sample Count para cada servicio en el clúster de ECS. Configurar una alarma cuando la expresión matemática sample count / SERVICE_QUOTA(service) * 100 sea mayor que 80. Notificar al equipo de desarrollo usando Amazon Simple Notification Service (Amazon SNS).",
            "B. Usar Amazon CloudWatch para monitorear las cuotas de servicio publicadas en el namespace AWS/Usage. Configurar una alarma cuando la expresión matemática metric / SERVICE_QUOTA(metric) * 100 sea mayor que 80. Notificar al equipo de desarrollo usando Amazon Simple Notification Service (Amazon SNS).",
            "C. Crear una función de AWS Lambda para obtener métricas detalladas del clúster de ECS. Cuando el número de tareas en ejecución de Fargate sea mayor que 80, invocar Amazon Simple Email Service (Amazon SES) para notificar al equipo de desarrollo.",
            "D. Crear una regla de AWS Config para evaluar si la cuota de servicio Fargate SERVICE_QUOTA es mayor que 80. Usar Amazon Simple Email Service (Amazon SES) para notificar al equipo de desarrollo cuando la regla de AWS Config no sea conforme."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "520.- Una empresa tiene varias funciones de AWS Lambda escritas en Python. Las funciones se implementan con el tipo de implementación paquete .zip. Estas funciones utilizan una Lambda layer que contiene bibliotecas y paquetes comunes en un archivo .zip. Tanto los paquetes .zip de Lambda como el archivo .zip de la Lambda layer están almacenados en un bucket de Amazon S3. La empresa debe implementar un escaneo automático de las funciones Lambda y de la Lambda layer para identificar CVE (Common Vulnerabilities and Exposures). Un subconjunto de las funciones Lambda también debe recibir escaneos automatizados de código para detectar posibles filtraciones de datos y otras vulnerabilidades. Los escaneos de código deben ocurrir solo en funciones Lambda seleccionadas, no en todas las funciones Lambda. ¿Qué combinación de acciones cumplirá con estos requisitos? (Elija tres.)",
        "opciones": [
            "A. Activar Amazon Inspector e iniciar escaneos automáticos de CVE.",
            "B. Activar escaneo estándar de Lambda y escaneo de código de Lambda en Amazon Inspector.",
            "C. Habilitar Amazon GuardDuty y activar la función Lambda Protection en GuardDuty.",
            "D. Habilitar el escaneo en la configuración de Monitor de las funciones Lambda que requieren escaneo de código.",
            "E. Etiquetar las funciones Lambda que no necesitan escaneo de código. En la etiqueta, incluir la clave InspectorCodeExclusion y el valor LambdaCodeScanning.",
            "F. Usar Amazon Inspector para escanear el bucket de S3 que contiene los paquetes .zip de Lambda y la Lambda layer en busca de vulnerabilidades de código."
        ],
        "respuestas_correctas": [
            "E",
            "B",
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "521.- Una empresa está cambiando la forma en que gestiona el parcheo de instancias de Amazon EC2 en su cuenta de aplicación. Actualmente, la empresa parchea las instancias a través de internet usando un NAT gateway en una VPC dentro de la cuenta de aplicación. La empresa tiene instancias EC2 configuradas como un repositorio de parches en una VPC privada dedicada en una cuenta central (core account). La empresa quiere utilizar AWS Systems Manager Patch Manager y el repositorio de parches en la cuenta central para parchear las instancias EC2 en la cuenta de aplicación. Además, la empresa debe evitar que las instancias EC2 en la cuenta de aplicación accedan a internet. Las instancias EC2 en la cuenta de aplicación necesitan: Acceder a Amazon S3, donde se almacenan los datos de la aplicación. Conectividad con AWS Systems Manager. Acceder al repositorio de parches en la VPC privada de la cuenta central. ¿Qué solución cumplirá con estos requisitos?",
        "opciones": [
            "A. Crear una ACL de red que bloquee el tráfico saliente en el puerto 80. Asociar la ACL de red con todas las subredes en la cuenta de aplicación. En la cuenta de aplicación y la cuenta central, implementar una instancia EC2 con un servidor VPN personalizado. Crear un túnel VPN para acceder a la VPC privada. Actualizar la tabla de enrutamiento en la cuenta de aplicación.",
            "B. Crear VIFs privadas para Systems Manager y Amazon S3. Eliminar el NAT gateway de la VPC en la cuenta de aplicación. Crear un transit gateway para acceder a las instancias del repositorio de parches en la cuenta central. Actualizar la tabla de enrutamiento en la cuenta central.",
            "C. Crear VPC endpoints para Systems Manager y Amazon S3. Eliminar el NAT gateway de la VPC en la cuenta de aplicación. Crear una conexión de emparejamiento de VPC (VPC peering) para acceder a las instancias del repositorio de parches en la cuenta central. Actualizar las tablas de enrutamiento en ambas cuentas.",
            "D. Crear una ACL de red que bloquee el tráfico entrante en el puerto 80. Asociar la ACL de red con todas las subredes en la cuenta de aplicación. Crear un transit gateway para acceder a las instancias del repositorio de parches en la cuenta central. Actualizar las tablas de enrutamiento en ambas cuentas."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "522.- Una empresa en los Estados Unidos (EE. UU.) ha adquirido una empresa en Europa. Ambas empresas utilizan la nube de AWS. La empresa de EE. UU. ha creado una nueva aplicación con una arquitectura de microservicios. La empresa de EE. UU. está alojando la aplicación en cinco VPC en la región us-east-2. La aplicación debe poder acceder a los recursos en una VPC en la región eu-west-1. Sin embargo, la aplicación no debe poder acceder a ninguna otra VPC. Las VPC en ambas regiones no tienen rangos CIDR superpuestos. Todas las cuentas ya están consolidadas en una organización en AWS Organizations. ¿Qué solución cumplirá con estos requisitos de la manera MÁS rentable?",
        "opciones": [
            "A. Crear una puerta de enlace de tránsito en eu-west-1. Adjuntar las VPC en us-east-2 y la VPC en eu-west-1 a la puerta de enlace de tránsito. Crear las entradas de ruta necesarias en cada VPC para que el tráfico se enrute a través de la puerta de enlace de tránsito.",
            "B. Crear una puerta de enlace de tránsito en cada región. Adjuntar las subredes involucradas a la puerta de enlace de tránsito regional. Crear las entradas de ruta necesarias en las tablas de rutas asociadas para cada subred para que el tráfico se enrute a través de la puerta de enlace de tránsito regional. Emparejar las dos puertas de enlace de tránsito.",
            "C. Crear una configuración de conexión de peering de VPC de malla completa entre todas las VPC. Crear las entradas de ruta necesarias en cada VPC para que el tráfico se enrute a través de la conexión de peering de VPC.",
            "D. Crear una conexión de peering de VPC para cada VPC en us-east-2 a la VPC en eu-west-1. Crear las entradas de ruta necesarias en cada VPC para que el tráfico se enrute a través de la conexión de peering de VPC."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "523.- Una empresa de viajes creó una aplicación web que utiliza Amazon Simple Email Service (Amazon SES) para enviar notificaciones por correo electrónico a los usuarios. La empresa necesita habilitar el registro para ayudar a solucionar problemas de entrega de correo electrónico. La empresa también necesita la capacidad de realizar búsquedas basadas en el destinatario, el asunto y la hora de envío. ¿Qué combinación de pasos debe tomar un arquitecto de soluciones para cumplir con estos requisitos? (Elija dos).",
        "opciones": [
            "A. Crear un conjunto de configuración de Amazon SES con Amazon Data Firehose como destino. Elegir enviar registros a un bucket de Amazon S3.",
            "B. Habilitar el registro de AWS CloudTrail. Especificar un bucket de Amazon S3 como destino para los registros.",
            "C. Usar Amazon Athena para consultar los registros en el bucket de Amazon S3 para el destinatario, el asunto y la hora de envío.",
            "D. Crear un grupo de registros de Amazon CloudWatch. Configurar Amazon SES para enviar registros al grupo de registros.",
            "E. Usar Amazon Athena para consultar los registros en Amazon CloudWatch para el destinatario, el asunto y la hora de envío."
        ],
        "respuestas_correctas": [
            "C",
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "524.- Una empresa migró a AWS y utiliza AWS Business Support. La empresa quiere monitorear la rentabilidad de las instancias de Amazon EC2 en todas sus cuentas de AWS. Las instancias EC2 tienen etiquetas para departamento, unidad de negocio y entorno. Las instancias de desarrollo de EC2 tienen un costo elevado pero una utilización baja. La empresa necesita detectar y detener las instancias de desarrollo de EC2 que estén infrautilizadas. Una instancia se considera infrautilizada si ha tenido 10% o menos de utilización promedio diaria de la CPU y 5 MB o menos de E/S de red durante al menos 4 de los últimos 14 días. ¿Qué solución cumplirá con estos requisitos con el MENOR esfuerzo operativo?",
        "opciones": [
            "A. Configurar paneles de Amazon CloudWatch para monitorear la utilización de las instancias EC2 basándose en las etiquetas de departamento, unidad de negocio y entorno. Crear una regla de Amazon EventBridge que invoque una función de AWS Lambda para detener las instancias de desarrollo de EC2 infrautilizadas.",
            "B. Configurar AWS Systems Manager para rastrear la utilización de las instancias EC2 y reportar las instancias infrautilizadas a Amazon CloudWatch. Filtrar los datos de CloudWatch por etiquetas de departamento, unidad de negocio y entorno. Crear una regla de Amazon EventBridge que invoque una función de AWS Lambda para detener las instancias de desarrollo de EC2 infrautilizadas.",
            "C. Crear una regla de Amazon EventBridge para detectar la baja utilización de las instancias EC2 informada por AWS Trusted Advisor. Configurar la regla para invocar una función de AWS Lambda que filtre los datos por etiquetas de departamento, unidad de negocio y entorno y detenga las instancias de desarrollo de EC2 infrautilizadas.",
            "D. Crear una función de AWS Lambda que se ejecute diariamente para recuperar los datos de utilización de todas las instancias EC2. Guardar los datos en una tabla de Amazon DynamoDB. Crear un panel de control de Amazon QuickSight que utilice la tabla de DynamoDB como fuente de datos para identificar y detener las instancias de desarrollo de EC2 infrautilizadas."
        ],
        "respuestas_correctas": [
            "C"
        ],
        "imagenes": []
    },
    {
        "pregunta": "525.- Una empresa está alojando una aplicación en AWS para un proyecto que se ejecutará durante los próximos 3 años. La aplicación consta de 20 instancias bajo demanda de Amazon EC2 que están registradas en un grupo de destino para un Balanceador de carga de red (NLB). Las instancias están distribuidas en dos zonas de disponibilidad. La aplicación no tiene estado y se ejecuta las 24 horas del día, los 7 días de la semana. La empresa recibe informes de usuarios que experimentan respuestas lentas de la aplicación. Las métricas de rendimiento muestran que las instancias tienen una utilización de CPU del 10 % durante el uso normal de la aplicación. Sin embargo, la utilización de la CPU aumenta al 100 % en momentos de mayor actividad, que generalmente duran algunas horas. La empresa necesita una nueva arquitectura para resolver el problema de las respuestas lentas de la aplicación. ¿Qué solución cumplirá con estos requisitos de la manera MÁS rentable?",
        "opciones": [
            "A. Crear un grupo de Auto Scaling. Adjuntar el grupo de Auto Scaling al grupo de destino del NLB. Establecer la capacidad mínima en 20 y la capacidad deseada en 28. Comprar instancias reservadas para 20 instancias.",
            "B. Crear una flota de Spot que tenga un tipo de solicitud de solicitud. Establecer el parámetro TotalTargetCapacity en 20. Establecer el parámetro DefaultTargetCapacityType en On-Demand. Especificar el NLB al crear la flota de Spot.",
            "C. Crear una flota de Spot que tenga un tipo de solicitud de mantener. Establecer el parámetro TotalTargetCapacity en 20. Establecer el parámetro DefaultTargetCapacityType en Spot. Reemplazar el NLB con un Balanceador de carga de aplicaciones.",
            "D. Crear un grupo de Auto Scaling. Adjuntar el grupo de Auto Scaling al grupo de destino del NLB. Establecer la capacidad mínima en 4 y la capacidad máxima en 28. Comprar instancias reservadas para cuatro instancias."
        ],
        "respuestas_correctas": [
            "D"
        ],
        "imagenes": []
    },
    {
        "pregunta": "526.- Una empresa está construyendo una aplicación para recopilar y transmitir datos de sensores desde una fábrica. La aplicación utilizará AWS IoT Core para enviar datos desde cientos de dispositivos a un lago de datos de Amazon S3. La empresa debe enriquecer los datos antes de cargarlos en Amazon S3. La aplicación transmitirá los datos del sensor cada 5 segundos. Los nuevos datos del sensor deben estar disponibles en Amazon S3 menos de 30 minutos después de que la aplicación recopile los datos. Ninguna otra aplicación está procesando los datos del sensor desde AWS IoT Core. ¿Qué solución cumplirá con estos requisitos de la manera MÁS rentable?",
        "opciones": [
            "A. Crear un tema en AWS IoT Core para ingerir los datos del sensor. Crear una función de AWS Lambda para enriquecer los datos y escribir los datos en Amazon S3. Configurar una acción de regla de AWS IoT para invocar la función de Lambda.",
            "B. Usar AWS IoT Core Basic Ingest para ingerir los datos del sensor. Configurar una acción de regla de AWS IoT para escribir los datos en Amazon Kinesis Data Firehose. Establecer el intervalo de almacenamiento en búfer de Kinesis Data Firehose en 900 segundos. Usar Kinesis Data Firehose para invocar una función de AWS Lambda para enriquecer los datos. Configurar Kinesis Data Firehose para entregar los datos a Amazon S3.",
            "C. Crear un tema en AWS IoT Core para ingerir los datos del sensor. Configurar una acción de regla de AWS IoT para enviar los datos a una tabla de Amazon Timestream. Crear una función de AWS Lambda para leer los datos de Timestream. Configurar la función de Lambda para enriquecer los datos y escribir los datos en Amazon S3.",
            "D. Usar AWS IoT Core Basic Ingest para ingerir los datos del sensor. Configurar una acción de regla de AWS IoT para escribir los datos en Amazon Kinesis Data Streams. Crear una función de AWS Lambda de consumidor para procesar los datos de Kinesis Data Streams y enriquecer los datos. Llamar a la operación de la API S3 PutObject desde la función de Lambda para escribir los datos en Amazon S3."
        ],
        "respuestas_correctas": [
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "527.- Una empresa está recopilando datos de un gran conjunto de dispositivos IoT. Los datos se almacenan en un lago de datos de Amazon S3. Los científicos de datos realizan análisis en instancias de Amazon EC2 que se ejecutan en dos subredes públicas dentro de una VPC en una cuenta de AWS separada. Los científicos de datos necesitan acceder al lago de datos desde las instancias de EC2. Las instancias de EC2 ya tienen un rol asignado con permisos para acceder a Amazon S3.\nSegún las políticas de la empresa, solo las redes autorizadas pueden tener acceso a los datos de IoT. ¿Qué combinación de pasos debe tomar un arquitecto de soluciones para cumplir con estos requisitos? (Elija dos.)",
        "opciones": [
            "A. Crear un endpoint de VPC de tipo gateway para Amazon S3 en la VPC de los científicos de datos.",
            "B. Crear un punto de acceso de S3 en la cuenta de AWS de los científicos de datos para el lago de datos.",
            "C. Actualizar el rol de la instancia EC2. Agregar una política con una condición que permita la acción s3:GetObject cuando el valor de la clave de condición s3:DataAccessPointArn sea un ARN de punto de acceso válido.",
            "D. Actualizar la tabla de rutas de la VPC para dirigir el tráfico de S3 a un punto de acceso de S3. *(No es aplicable, ya que los puntos de acceso de S3 no se especifican en las tablas de rutas).",
            "E. Agregar una política de bucket de S3 con una condición que permita la acción s3:GetObject cuando el valor de la clave de condición s3:DataAccessPointArn sea un ARN de punto de acceso válido."
        ],
        "respuestas_correctas": [
            "E",
            "B"
        ],
        "imagenes": []
    },
    {
        "pregunta": "528.- Una empresa quiere migrar su sitio web a AWS. El sitio web utiliza contenedores que se implementan en un clúster de Kubernetes autogestionado on-premises. Todos los datos del sitio web están almacenados en una base de datos PostgreSQL on-premises. La empresa ha decidido migrar el clúster de Kubernetes on-premises a un clúster de Amazon Elastic Kubernetes Service (Amazon EKS). El clúster de EKS usará grupos de nodos administrados por EKS con un número estático de nodos. La empresa también migrará la base de datos PostgreSQL on-premises a Amazon RDS para PostgreSQL. Un arquitecto de soluciones necesita estimar el costo total de propiedad (TCO) para esta carga de trabajo antes de la migración. ¿Qué solución proporcionará la información necesaria del TCO?",
        "opciones": [
            "A. Solicitar acceso a Migration Evaluator. Ejecutar el Migration Evaluator Collector e importar los datos. Configurar un escenario. Exportar un informe de Quick Insights desde Migration Evaluator.",
            "B. Iniciar AWS Database Migration Service (AWS DMS) para la base de datos on-premises. Generar un informe de evaluación. Crear una estimación en AWS Pricing Calculator para los costos de la migración a EKS.",
            "C. Inicializar AWS Application Migration Service. Agregar los servidores on-premises como servidores de origen. Lanzar una instancia de prueba. Generar un informe de TCO desde Application Migration Service.",
            "D. Acceder a la página web de AWS Cloud Economics Center para evaluar el Cloud Value Framework de AWS. Crear un informe de AWS Cost and Usage a partir del Cloud Value Framework."
        ],
        "respuestas_correctas": [
            "A"
        ],
        "imagenes": []
    },
    {
        "pregunta": "529.- Una empresa de eventos opera una plataforma de venta de entradas en AWS. Los clientes de la empresa configuran y programan eventos en la plataforma. Estos eventos provocan grandes aumentos de tráfico en la plataforma. La empresa conoce la fecha y hora de cada evento de sus clientes. La empresa ejecuta la plataforma en un clúster de Amazon Elastic Container Service (Amazon ECS). El clúster de ECS usa instancias EC2 On-Demand dentro de un grupo de Auto Scaling con una política de escalado predictivo. El clúster de ECS realiza solicitudes frecuentes a un bucket de Amazon S3 para descargar archivos de entradas. Tanto el clúster de ECS como el bucket de S3 están en la misma Región y la misma cuenta de AWS. El tráfico entre el clúster de ECS y el bucket de S3 fluye a través de un NAT gateway. La empresa necesita optimizar los costos de la plataforma sin reducir su disponibilidad. ¿Qué combinación de pasos cumplirá con estos requisitos? (Elija dos.)",
        "opciones": [
            "A. Crear un endpoint de VPC de tipo gateway para el bucket de S3.",
            "B. Agregar otro proveedor de capacidad de ECS que utilice un grupo de Auto Scaling con instancias Spot. Configurar la estrategia de proveedor de capacidad para que tenga el mismo peso que la estrategia existente.",
            "C. Crear Reservas de Capacidad On-Demand para el tipo de instancia aplicable durante el período de las políticas de escalado programadas.",
            "D. Habilitar S3 Transfer Acceleration en el bucket de S3. (No es necesario, ya que Transfer Acceleration se usa para acelerar el tráfico desde ubicaciones geográficas distantes y no dentro de la misma Región de AWS).",
            "E. Reemplazar la política de escalado predictivo con políticas de escalado programadas para los eventos programados."
        ],
        "respuestas_correctas": [
            "E",
            "A"
        ],
        "imagenes": []
    }
]
